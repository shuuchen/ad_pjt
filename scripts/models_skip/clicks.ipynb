{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ読込"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = '../../data/val_1/skip'\n",
    "\n",
    "df_train_X = pd.read_excel(os.path.join(in_dir, 'train_X.xlsx'), header=0, index_col=0)\n",
    "df_train_Y = pd.read_excel(os.path.join(in_dir, 'train_Y.xlsx'), header=0, index_col=0)\n",
    "\n",
    "df_val_X = pd.read_excel(os.path.join(in_dir, 'val_X.xlsx'), header=0, index_col=0)\n",
    "df_val_Y = pd.read_excel(os.path.join(in_dir, 'val_Y.xlsx'), header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目的変数の分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dushu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(np.log(df_train_Y['Clicks'] + 0.00000001))\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(x):\n",
    "    return np.log(x + 0.00000001)\n",
    "\n",
    "#for c in ['Sales', 'Impressions', 'Clicks', 'Cost']:\n",
    "for c in ['Clicks']:\n",
    "    df_train_Y['Clicks_log'] = df_train_Y['Clicks'].apply(log)\n",
    "    df_val_Y['Clicks_log'] = df_val_Y['Clicks'].apply(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ構造転換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dushu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\dushu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "d_train_sales = xgb.DMatrix(df_train_X, label=df_train_Y['Clicks_log'])\n",
    "d_val_sales = xgb.DMatrix(df_val_X, label=df_val_Y['Clicks_log'])\n",
    "\n",
    "d_val = xgb.DMatrix(df_val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータのベイズ最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.49778858814503546, 'colsample_bytree': 0.75, 'gamma': 0.0017686929133595044, 'lambda': 3.6283152208524223, 'learning_rate': 0.225, 'max_depth': 6, 'min_child_weight': 0.18988168286106574, 'n_estimators': 760.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.74239\teval-rmse:4.26389                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.09835\teval-rmse:3.54902                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.64219\teval-rmse:3.03921                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.32545\teval-rmse:2.68739                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.11594\teval-rmse:2.44666                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.96785\teval-rmse:2.29284                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.87041\teval-rmse:2.19963                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.80089\teval-rmse:2.13996                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.75022\teval-rmse:2.10913                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.71451\teval-rmse:2.0913                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.68832\teval-rmse:2.07895                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.6632\teval-rmse:2.07275                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.64898\teval-rmse:2.06662                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.62531\teval-rmse:2.06113                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.61169\teval-rmse:2.06207                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.59728\teval-rmse:2.05938                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.58452\teval-rmse:2.06363                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.57206\teval-rmse:2.07073                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.56414\teval-rmse:2.06927                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.5528\teval-rmse:2.06656                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.54381\teval-rmse:2.07415                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.53606\teval-rmse:2.07612                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.52544\teval-rmse:2.07784                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.51672\teval-rmse:2.08017                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.51248\teval-rmse:2.08272                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.50565\teval-rmse:2.08532                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.49834\teval-rmse:2.08312                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.48956\teval-rmse:2.08456                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.48296\teval-rmse:2.08588                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.47066\teval-rmse:2.08713                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.46461\teval-rmse:2.08832                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.4533\teval-rmse:2.08991                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.44492\teval-rmse:2.09287                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.43637\teval-rmse:2.08902                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.42724\teval-rmse:2.093                                                                                \n",
      "\n",
      "[35]\ttrain-rmse:2.41545\teval-rmse:2.09828                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.59728\teval-rmse:2.05938\n",
      "\n",
      "\n",
      "loss: 97774044.48058482                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.34053233069783245, 'colsample_bytree': 0.65, 'gamma': 6.285372690704367e-07, 'lambda': 2.311116011544468e-06, 'learning_rate': 0.07500000000000001, 'max_depth': 6, 'min_child_weight': 0.8876742113691316, 'n_estimators': 501.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:5.34034\teval-rmse:4.91269                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.05846\teval-rmse:4.60783                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.80373\teval-rmse:4.33112                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.57193\teval-rmse:4.0785                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:4.36929\teval-rmse:3.8659                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:4.17888\teval-rmse:3.65878                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.00818\teval-rmse:3.4678                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.85496\teval-rmse:3.29962                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.71807\teval-rmse:3.14754                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.59851\teval-rmse:3.01307                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.49063\teval-rmse:2.89236                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.39578\teval-rmse:2.78373                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.30997\teval-rmse:2.68563                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.23225\teval-rmse:2.59943                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.16331\teval-rmse:2.52551                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.10377\teval-rmse:2.45873                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.04923\teval-rmse:2.40074                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.00081\teval-rmse:2.35013                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.95734\teval-rmse:2.3072                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.91809\teval-rmse:2.26903                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.88255\teval-rmse:2.23865                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.85216\teval-rmse:2.20895                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.82352\teval-rmse:2.18303                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.7992\teval-rmse:2.16091                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.77857\teval-rmse:2.13873                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.75979\teval-rmse:2.12207                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.74212\teval-rmse:2.10651                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.7279\teval-rmse:2.09697                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.71204\teval-rmse:2.08612                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.69829\teval-rmse:2.07742                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.68805\teval-rmse:2.0703                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.67598\teval-rmse:2.06624                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.66647\teval-rmse:2.06047                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.65355\teval-rmse:2.05563                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.64428\teval-rmse:2.05073                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.63391\teval-rmse:2.04775                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.62614\teval-rmse:2.04521                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.6187\teval-rmse:2.04714                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:2.61016\teval-rmse:2.04594                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.60352\teval-rmse:2.04424                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.59584\teval-rmse:2.04232                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.59019\teval-rmse:2.04141                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.58501\teval-rmse:2.0417                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:2.58069\teval-rmse:2.0411                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:2.57547\teval-rmse:2.03961                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.57096\teval-rmse:2.03927                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.56359\teval-rmse:2.03907                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.55808\teval-rmse:2.03948                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.55252\teval-rmse:2.04022                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.54863\teval-rmse:2.03953                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.5435\teval-rmse:2.03915                                                                               \n",
      "\n",
      "[51]\ttrain-rmse:2.53979\teval-rmse:2.03963                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.53479\teval-rmse:2.0401                                                                               \n",
      "\n",
      "[53]\ttrain-rmse:2.5298\teval-rmse:2.04201                                                                               \n",
      "\n",
      "[54]\ttrain-rmse:2.52517\teval-rmse:2.04314                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.52141\teval-rmse:2.04263                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.51853\teval-rmse:2.044                                                                                \n",
      "\n",
      "[57]\ttrain-rmse:2.51312\teval-rmse:2.04765                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.50971\teval-rmse:2.05072                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.50627\teval-rmse:2.05051                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.50021\teval-rmse:2.0544                                                                               \n",
      "\n",
      "[61]\ttrain-rmse:2.49603\teval-rmse:2.05512                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.49402\teval-rmse:2.05479                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.48945\teval-rmse:2.05397                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.48436\teval-rmse:2.04786                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.48143\teval-rmse:2.04808                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.47578\teval-rmse:2.04906                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[46]\ttrain-rmse:2.56359\teval-rmse:2.03907\n",
      "\n",
      "\n",
      "loss: 97774012.2122716                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.7635590772940476e-08, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.39532123507832495, 'lambda': 0.011190536895233522, 'learning_rate': 0.45, 'max_depth': 7, 'min_child_weight': 1.5902967451817016, 'n_estimators': 784.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:3.88573\teval-rmse:3.36262                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.11687\teval-rmse:2.55442                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.80103\teval-rmse:2.26403                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.66434\teval-rmse:2.1971                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.59466\teval-rmse:2.19094                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.53785\teval-rmse:2.18172                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.51078\teval-rmse:2.16986                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.47316\teval-rmse:2.16502                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.44793\teval-rmse:2.17728                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.41231\teval-rmse:2.17027                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.38264\teval-rmse:2.2029                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\ttrain-rmse:2.36502\teval-rmse:2.20356                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.34813\teval-rmse:2.20244                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.32183\teval-rmse:2.23983                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.30293\teval-rmse:2.24568                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.28787\teval-rmse:2.24333                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.27847\teval-rmse:2.27485                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.26392\teval-rmse:2.28961                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.23856\teval-rmse:2.30099                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.22401\teval-rmse:2.30731                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.21492\teval-rmse:2.32355                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.19032\teval-rmse:2.33084                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.17189\teval-rmse:2.3276                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.14547\teval-rmse:2.36684                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.13028\teval-rmse:2.36523                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.11748\teval-rmse:2.38036                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.09655\teval-rmse:2.39639                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.07641\teval-rmse:2.40442                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.47316\teval-rmse:2.16502\n",
      "\n",
      "\n",
      "loss: 384904766093.27924                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.5178833407773767, 'colsample_bytree': 0.9, 'gamma': 0.10069279623646368, 'lambda': 0.8469584102555349, 'learning_rate': 0.025, 'max_depth': 9, 'min_child_weight': 3.503186845514754, 'n_estimators': 218.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.54213\teval-rmse:5.13441                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.43534\teval-rmse:5.0259                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:5.33145\teval-rmse:4.92091                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:5.23077\teval-rmse:4.81943                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:5.13309\teval-rmse:4.72086                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:5.0382\teval-rmse:4.62474                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:4.94635\teval-rmse:4.53175                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:4.85773\teval-rmse:4.44159                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:4.77131\teval-rmse:4.3544                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:4.68789\teval-rmse:4.26941                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:4.60679\teval-rmse:4.18677                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:4.52717\teval-rmse:4.10747                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:4.44981\teval-rmse:4.03047                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:4.37626\teval-rmse:3.95578                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:4.30387\teval-rmse:3.88402                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:4.23433\teval-rmse:3.81413                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:4.16633\teval-rmse:3.74684                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:4.09996\teval-rmse:3.68111                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:4.03596\teval-rmse:3.61763                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.97399\teval-rmse:3.55615                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.91349\teval-rmse:3.49641                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.85618\teval-rmse:3.43862                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.8005\teval-rmse:3.38335                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:3.74536\teval-rmse:3.33042                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.69287\teval-rmse:3.27855                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.64118\teval-rmse:3.22898                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.59115\teval-rmse:3.18062                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.54281\teval-rmse:3.13418                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.49668\teval-rmse:3.08983                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.45095\teval-rmse:3.04654                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.40668\teval-rmse:3.00464                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.36445\teval-rmse:2.96356                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.32364\teval-rmse:2.9243                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:3.28413\teval-rmse:2.8872                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:3.24566\teval-rmse:2.85107                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.20887\teval-rmse:2.81548                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.17255\teval-rmse:2.7825                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:3.13734\teval-rmse:2.75062                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.1036\teval-rmse:2.72036                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:3.07172\teval-rmse:2.69152                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.04033\teval-rmse:2.66427                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.00968\teval-rmse:2.63664                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.98025\teval-rmse:2.61063                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.95054\teval-rmse:2.58499                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.92328\teval-rmse:2.56119                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.8959\teval-rmse:2.53867                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.86901\teval-rmse:2.51612                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.84427\teval-rmse:2.4949                                                                               \n",
      "\n",
      "[48]\ttrain-rmse:2.82119\teval-rmse:2.47487                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.79716\teval-rmse:2.45607                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.77491\teval-rmse:2.43757                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.75252\teval-rmse:2.42002                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.73172\teval-rmse:2.40333                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.7114\teval-rmse:2.38721                                                                               \n",
      "\n",
      "[54]\ttrain-rmse:2.69124\teval-rmse:2.37158                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.67156\teval-rmse:2.35538                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.65325\teval-rmse:2.34064                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.63416\teval-rmse:2.32668                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.61629\teval-rmse:2.31428                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.59932\teval-rmse:2.30105                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.58274\teval-rmse:2.28937                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.56757\teval-rmse:2.27641                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.55247\teval-rmse:2.2656                                                                               \n",
      "\n",
      "[63]\ttrain-rmse:2.53818\teval-rmse:2.25522                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.52255\teval-rmse:2.2453                                                                               \n",
      "\n",
      "[65]\ttrain-rmse:2.50979\teval-rmse:2.23544                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.49565\teval-rmse:2.22632                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.4829\teval-rmse:2.21708                                                                               \n",
      "\n",
      "[68]\ttrain-rmse:2.46933\teval-rmse:2.20898                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.45721\teval-rmse:2.20154                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:2.44501\teval-rmse:2.1939                                                                               \n",
      "\n",
      "[71]\ttrain-rmse:2.433\teval-rmse:2.18706                                                                                \n",
      "\n",
      "[72]\ttrain-rmse:2.42189\teval-rmse:2.18069                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:2.41009\teval-rmse:2.17366                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:2.39862\teval-rmse:2.16616                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:2.38755\teval-rmse:2.16096                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:2.37775\teval-rmse:2.1553                                                                               \n",
      "\n",
      "[77]\ttrain-rmse:2.36784\teval-rmse:2.14944                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:2.35762\teval-rmse:2.14373                                                                              \n",
      "\n",
      "[79]\ttrain-rmse:2.34841\teval-rmse:2.13937                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:2.33886\teval-rmse:2.13496                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:2.32988\teval-rmse:2.13059                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:2.32117\teval-rmse:2.12674                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:2.31195\teval-rmse:2.12276                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:2.30384\teval-rmse:2.11852                                                                              \n",
      "\n",
      "[85]\ttrain-rmse:2.29559\teval-rmse:2.11379                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:2.28668\teval-rmse:2.11085                                                                              \n",
      "\n",
      "[87]\ttrain-rmse:2.27934\teval-rmse:2.10708                                                                              \n",
      "\n",
      "[88]\ttrain-rmse:2.27207\teval-rmse:2.10347                                                                              \n",
      "\n",
      "[89]\ttrain-rmse:2.26526\teval-rmse:2.10025                                                                              \n",
      "\n",
      "[90]\ttrain-rmse:2.25929\teval-rmse:2.09716                                                                              \n",
      "\n",
      "[91]\ttrain-rmse:2.25214\teval-rmse:2.09468                                                                              \n",
      "\n",
      "[92]\ttrain-rmse:2.24482\teval-rmse:2.09256                                                                              \n",
      "\n",
      "[93]\ttrain-rmse:2.2379\teval-rmse:2.08998                                                                               \n",
      "\n",
      "[94]\ttrain-rmse:2.23192\teval-rmse:2.08751                                                                              \n",
      "\n",
      "[95]\ttrain-rmse:2.22511\teval-rmse:2.08549                                                                              \n",
      "\n",
      "[96]\ttrain-rmse:2.21914\teval-rmse:2.08341                                                                              \n",
      "\n",
      "[97]\ttrain-rmse:2.21284\teval-rmse:2.08175                                                                              \n",
      "\n",
      "[98]\ttrain-rmse:2.20812\teval-rmse:2.08018                                                                              \n",
      "\n",
      "[99]\ttrain-rmse:2.20302\teval-rmse:2.0789                                                                               \n",
      "\n",
      "loss: 99128318.7046641                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.609303869068855e-08, 'colsample_bytree': 0.8, 'gamma': 0.053077008319898936, 'lambda': 0.062366559786076047, 'learning_rate': 0.15000000000000002, 'max_depth': 8, 'min_child_weight': 0.3248946194072204, 'n_estimators': 273.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.01167\teval-rmse:4.58681                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.48898\teval-rmse:4.03939                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.06047\teval-rmse:3.59752                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.71005\teval-rmse:3.24324                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\ttrain-rmse:3.42326\teval-rmse:2.96053                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.19876\teval-rmse:2.73835                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.01709\teval-rmse:2.56843                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.87068\teval-rmse:2.43977                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.75496\teval-rmse:2.34612                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.66418\teval-rmse:2.2721                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.58613\teval-rmse:2.21945                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.52519\teval-rmse:2.17481                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.47746\teval-rmse:2.14703                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.43663\teval-rmse:2.1306                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.39892\teval-rmse:2.11606                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.36704\teval-rmse:2.10848                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.32945\teval-rmse:2.0999                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.29609\teval-rmse:2.09486                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.26952\teval-rmse:2.09398                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.25342\teval-rmse:2.09253                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.23326\teval-rmse:2.09094                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.21237\teval-rmse:2.08621                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.20021\teval-rmse:2.08662                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.18714\teval-rmse:2.08726                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.16688\teval-rmse:2.09108                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.14966\teval-rmse:2.09616                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.13482\teval-rmse:2.09266                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.11896\teval-rmse:2.09395                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.09957\teval-rmse:2.09549                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.08156\teval-rmse:2.09418                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.07015\teval-rmse:2.09839                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.05548\teval-rmse:2.09308                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.04283\teval-rmse:2.09106                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.03495\teval-rmse:2.09124                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.02221\teval-rmse:2.09                                                                                 \n",
      "\n",
      "[35]\ttrain-rmse:2.01375\teval-rmse:2.09103                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.00533\teval-rmse:2.09264                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.9858\teval-rmse:2.09145                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:1.96246\teval-rmse:2.09264                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:1.95248\teval-rmse:2.09349                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:1.94546\teval-rmse:2.09496                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:1.93722\teval-rmse:2.097                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[21]\ttrain-rmse:2.21237\teval-rmse:2.08621\n",
      "\n",
      "\n",
      "loss: 96998899.41287196                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.929603678969475e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.7834430837589033e-05, 'lambda': 1.7891903178526118e-06, 'learning_rate': 0.15000000000000002, 'max_depth': 7, 'min_child_weight': 0.41218269585324696, 'n_estimators': 912.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.02034\teval-rmse:4.58752                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.51063\teval-rmse:4.04254                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.09459\teval-rmse:3.60097                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.76434\teval-rmse:3.24958                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.49751\teval-rmse:2.96844                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.28763\teval-rmse:2.74529                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.12064\teval-rmse:2.57228                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.98639\teval-rmse:2.43755                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.87899\teval-rmse:2.34363                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.79981\teval-rmse:2.26634                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.7342\teval-rmse:2.2125                                                                                \n",
      "\n",
      "[11]\ttrain-rmse:2.68612\teval-rmse:2.1722                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.63834\teval-rmse:2.14244                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.60067\teval-rmse:2.12333                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.57211\teval-rmse:2.11049                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.54829\teval-rmse:2.0968                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.52438\teval-rmse:2.09869                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.4983\teval-rmse:2.09767                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.48165\teval-rmse:2.09433                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.47023\teval-rmse:2.08689                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.45737\teval-rmse:2.08702                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.44637\teval-rmse:2.08888                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.43359\teval-rmse:2.08784                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.4192\teval-rmse:2.0912                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:2.41114\teval-rmse:2.08867                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.40252\teval-rmse:2.09561                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.38872\teval-rmse:2.09562                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.38218\teval-rmse:2.09598                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.36572\teval-rmse:2.0993                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.35336\teval-rmse:2.09931                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.3404\teval-rmse:2.0966                                                                                \n",
      "\n",
      "[31]\ttrain-rmse:2.33118\teval-rmse:2.09504                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.32161\teval-rmse:2.09581                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.31265\teval-rmse:2.10208                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.30399\teval-rmse:2.10131                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.28747\teval-rmse:2.1058                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.28276\teval-rmse:2.10844                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.27087\teval-rmse:2.10038                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.26437\teval-rmse:2.10847                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.25748\teval-rmse:2.10744                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[19]\ttrain-rmse:2.47023\teval-rmse:2.08689\n",
      "\n",
      "\n",
      "loss: 97446841.18856865                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.16543715767227246, 'colsample_bytree': 0.9500000000000001, 'gamma': 5.706640219202508e-05, 'lambda': 0.03707433060864767, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 0.37183070857862716, 'n_estimators': 291.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:5.2567\teval-rmse:4.80637                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.9135\teval-rmse:4.41671                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.6155\teval-rmse:4.0773                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:4.35707\teval-rmse:3.778                                                                                 \n",
      "\n",
      "[4]\ttrain-rmse:4.13519\teval-rmse:3.51871                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.94516\teval-rmse:3.29241                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.78259\teval-rmse:3.09596                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.64437\teval-rmse:2.92827                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.52621\teval-rmse:2.783                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:3.42585\teval-rmse:2.66109                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.33986\teval-rmse:2.55561                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.26829\teval-rmse:2.46656                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.20739\teval-rmse:2.39389                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.15648\teval-rmse:2.33231                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.11344\teval-rmse:2.2839                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:3.07755\teval-rmse:2.24209                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.04624\teval-rmse:2.20949                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.01978\teval-rmse:2.17976                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.99801\teval-rmse:2.15666                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.97908\teval-rmse:2.13964                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.96374\teval-rmse:2.12556                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.94964\teval-rmse:2.11524                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.93694\teval-rmse:2.10419                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.92648\teval-rmse:2.09689                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.91684\teval-rmse:2.0888                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.90923\teval-rmse:2.08496                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.90273\teval-rmse:2.07957                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.89622\teval-rmse:2.07449                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.89119\teval-rmse:2.07132                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.88636\teval-rmse:2.06771                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.88172\teval-rmse:2.06614                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.87713\teval-rmse:2.06467                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.87302\teval-rmse:2.06286                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.86921\teval-rmse:2.06428                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.86354\teval-rmse:2.06258                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.85952\teval-rmse:2.06409                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.85636\teval-rmse:2.06942                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.85321\teval-rmse:2.06638                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.84952\teval-rmse:2.06736                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.84743\teval-rmse:2.06668                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40]\ttrain-rmse:2.84422\teval-rmse:2.06549                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.84131\teval-rmse:2.06439                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.83919\teval-rmse:2.06444                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.8373\teval-rmse:2.06458                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:2.83504\teval-rmse:2.06934                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.83155\teval-rmse:2.06815                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.82966\teval-rmse:2.06857                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.82818\teval-rmse:2.06923                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.82602\teval-rmse:2.07015                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.82395\teval-rmse:2.06971                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.82233\teval-rmse:2.0682                                                                               \n",
      "\n",
      "[51]\ttrain-rmse:2.8196\teval-rmse:2.06811                                                                               \n",
      "\n",
      "[52]\ttrain-rmse:2.81712\teval-rmse:2.06718                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.81553\teval-rmse:2.067                                                                                \n",
      "\n",
      "[54]\ttrain-rmse:2.81395\teval-rmse:2.06714                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[34]\ttrain-rmse:2.86354\teval-rmse:2.06258\n",
      "\n",
      "\n",
      "loss: 99332073.33159564                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.135266988956652e-07, 'colsample_bytree': 0.6000000000000001, 'gamma': 7.769607176377947e-06, 'lambda': 1.0231462916834264e-05, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 0.14662481149139692, 'n_estimators': 546.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.25143\teval-rmse:4.80231                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.90231\teval-rmse:4.41247                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.59993\teval-rmse:4.06911                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.3364\teval-rmse:3.76738                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:4.12321\teval-rmse:3.52035                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.92869\teval-rmse:3.28708                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.75992\teval-rmse:3.08606                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.61756\teval-rmse:2.91724                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.49408\teval-rmse:2.77085                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.39168\teval-rmse:2.64437                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.30434\teval-rmse:2.54184                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.23135\teval-rmse:2.45418                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.1698\teval-rmse:2.37875                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.11422\teval-rmse:2.31675                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.06865\teval-rmse:2.26724                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.03088\teval-rmse:2.22595                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.99655\teval-rmse:2.19249                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.9689\teval-rmse:2.16354                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.9444\teval-rmse:2.14074                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.92389\teval-rmse:2.12177                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.90659\teval-rmse:2.10762                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.89204\teval-rmse:2.09712                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.87724\teval-rmse:2.08606                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.8654\teval-rmse:2.07989                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.85596\teval-rmse:2.07344                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.84571\teval-rmse:2.06894                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.83725\teval-rmse:2.06382                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.82993\teval-rmse:2.05842                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.82327\teval-rmse:2.05652                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.81791\teval-rmse:2.0537                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.81237\teval-rmse:2.05274                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.80636\teval-rmse:2.05035                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.80194\teval-rmse:2.04842                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.79693\teval-rmse:2.04881                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.79205\teval-rmse:2.04732                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.78636\teval-rmse:2.04753                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.78277\teval-rmse:2.04639                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.77935\teval-rmse:2.04468                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.77416\teval-rmse:2.04949                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.77055\teval-rmse:2.04917                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.767\teval-rmse:2.04877                                                                                \n",
      "\n",
      "[41]\ttrain-rmse:2.76454\teval-rmse:2.04834                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.76083\teval-rmse:2.04865                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.75835\teval-rmse:2.0488                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:2.7568\teval-rmse:2.04905                                                                               \n",
      "\n",
      "[45]\ttrain-rmse:2.75515\teval-rmse:2.04934                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.75295\teval-rmse:2.04925                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.7491\teval-rmse:2.05133                                                                               \n",
      "\n",
      "[48]\ttrain-rmse:2.74687\teval-rmse:2.05303                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.744\teval-rmse:2.05517                                                                                \n",
      "\n",
      "[50]\ttrain-rmse:2.741\teval-rmse:2.05547                                                                                \n",
      "\n",
      "[51]\ttrain-rmse:2.73963\teval-rmse:2.05639                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.7362\teval-rmse:2.05574                                                                               \n",
      "\n",
      "[53]\ttrain-rmse:2.73351\teval-rmse:2.05617                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.73033\teval-rmse:2.0588                                                                               \n",
      "\n",
      "[55]\ttrain-rmse:2.72739\teval-rmse:2.05726                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.72545\teval-rmse:2.05676                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.72266\teval-rmse:2.05633                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[37]\ttrain-rmse:2.77935\teval-rmse:2.04468\n",
      "\n",
      "\n",
      "loss: 98805501.54669803                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.08056754968279825, 'colsample_bytree': 0.6000000000000001, 'gamma': 0.00026428320355300966, 'lambda': 0.021201382612745876, 'learning_rate': 0.375, 'max_depth': 7, 'min_child_weight': 0.19951989142340548, 'n_estimators': 881.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.15194\teval-rmse:3.6525                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.35955\teval-rmse:2.80951                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.96068\teval-rmse:2.41171                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.76755\teval-rmse:2.26718                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.663\teval-rmse:2.23463                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.59205\teval-rmse:2.20399                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.55322\teval-rmse:2.21693                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.52884\teval-rmse:2.21148                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.49562\teval-rmse:2.20955                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.47072\teval-rmse:2.21                                                                                  \n",
      "\n",
      "[10]\ttrain-rmse:2.4528\teval-rmse:2.21254                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.42953\teval-rmse:2.21448                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.40526\teval-rmse:2.22132                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.38197\teval-rmse:2.22104                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.36004\teval-rmse:2.22247                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.34873\teval-rmse:2.22317                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.32286\teval-rmse:2.22542                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.29473\teval-rmse:2.22714                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.28209\teval-rmse:2.23039                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.26982\teval-rmse:2.25402                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.25608\teval-rmse:2.27523                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.25033\teval-rmse:2.27463                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.23188\teval-rmse:2.29196                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.20469\teval-rmse:2.29604                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.19241\teval-rmse:2.31312                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.17988\teval-rmse:2.30865                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.59205\teval-rmse:2.20399\n",
      "\n",
      "\n",
      "loss: 97653863.75025468                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.880836411878277e-07, 'colsample_bytree': 0.6000000000000001, 'gamma': 3.052781171284727e-08, 'lambda': 0.2465711167508789, 'learning_rate': 0.47500000000000003, 'max_depth': 6, 'min_child_weight': 4.252950038375481, 'n_estimators': 144.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:3.84633\teval-rmse:3.25679                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.13125\teval-rmse:2.45012                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.85574\teval-rmse:2.1898                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.74972\teval-rmse:2.10757                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.69793\teval-rmse:2.09455                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.66906\teval-rmse:2.10956                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.6513\teval-rmse:2.1122                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:2.62818\teval-rmse:2.11613                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.60077\teval-rmse:2.11295                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.57414\teval-rmse:2.11801                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.56149\teval-rmse:2.12834                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.53548\teval-rmse:2.13205                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\ttrain-rmse:2.51423\teval-rmse:2.13577                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.49616\teval-rmse:2.13468                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.48747\teval-rmse:2.13703                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.46613\teval-rmse:2.14359                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.46006\teval-rmse:2.14376                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.44448\teval-rmse:2.14121                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.43317\teval-rmse:2.15087                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.41027\teval-rmse:2.14577                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.40053\teval-rmse:2.18441                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.38189\teval-rmse:2.18636                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.36607\teval-rmse:2.18932                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.35059\teval-rmse:2.18957                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.32859\teval-rmse:2.1904                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.69793\teval-rmse:2.09455\n",
      "\n",
      "\n",
      "loss: 106581633.2917601                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.054933645393006e-05, 'colsample_bytree': 0.75, 'gamma': 1.026888513931517e-07, 'lambda': 1.2857750643141432, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1.8008175190896443, 'n_estimators': 683.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.22013\teval-rmse:4.80398                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.83701\teval-rmse:4.41181                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.50056\teval-rmse:4.06726                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.20155\teval-rmse:3.76807                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.94082\teval-rmse:3.50777                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.70679\teval-rmse:3.27826                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.50588\teval-rmse:3.08136                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.32646\teval-rmse:2.91413                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.17324\teval-rmse:2.77321                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.03942\teval-rmse:2.64407                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.92068\teval-rmse:2.54198                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.8187\teval-rmse:2.45361                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.7296\teval-rmse:2.38315                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.65336\teval-rmse:2.32132                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.58425\teval-rmse:2.26854                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.52346\teval-rmse:2.22708                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.46864\teval-rmse:2.19065                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.42115\teval-rmse:2.16129                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.37929\teval-rmse:2.1418                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.34086\teval-rmse:2.12364                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.30307\teval-rmse:2.11343                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.27556\teval-rmse:2.1034                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.23855\teval-rmse:2.09554                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.21236\teval-rmse:2.08741                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.1901\teval-rmse:2.07878                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.17206\teval-rmse:2.0745                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.14865\teval-rmse:2.07113                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.11931\teval-rmse:2.06951                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.10299\teval-rmse:2.06614                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.08282\teval-rmse:2.06799                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.0654\teval-rmse:2.06481                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.04504\teval-rmse:2.06229                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.03585\teval-rmse:2.0641                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.01852\teval-rmse:2.06319                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.0042\teval-rmse:2.06556                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:1.99114\teval-rmse:2.06446                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.98367\teval-rmse:2.06368                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.96676\teval-rmse:2.06281                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.9503\teval-rmse:2.06445                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:1.94457\teval-rmse:2.06395                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:1.9326\teval-rmse:2.06441                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:1.91887\teval-rmse:2.06058                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:1.90454\teval-rmse:2.0629                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:1.89759\teval-rmse:2.06253                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:1.89006\teval-rmse:2.06252                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:1.87906\teval-rmse:2.0641                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:1.86867\teval-rmse:2.06416                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:1.86028\teval-rmse:2.06363                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:1.85023\teval-rmse:2.06425                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:1.83551\teval-rmse:2.06684                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:1.82516\teval-rmse:2.06295                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:1.81329\teval-rmse:2.06473                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:1.80438\teval-rmse:2.06459                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:1.80028\teval-rmse:2.06471                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:1.79545\teval-rmse:2.06518                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:1.78458\teval-rmse:2.06685                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:1.77815\teval-rmse:2.06752                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:1.76984\teval-rmse:2.06969                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:1.76126\teval-rmse:2.07135                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:1.75448\teval-rmse:2.07191                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:1.74921\teval-rmse:2.07177                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:1.7413\teval-rmse:2.07076                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[41]\ttrain-rmse:1.91887\teval-rmse:2.06058\n",
      "\n",
      "\n",
      "loss: 96955155.644661                                                                                                  \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.87317744848318e-07, 'colsample_bytree': 0.6000000000000001, 'gamma': 0.9558087706368898, 'lambda': 1.2721477724522612, 'learning_rate': 0.07500000000000001, 'max_depth': 3, 'min_child_weight': 0.20156674702456692, 'n_estimators': 345.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:5.35527\teval-rmse:4.91395                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.08841\teval-rmse:4.61363                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.84945\teval-rmse:4.34297                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.63009\teval-rmse:4.09195                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.4497\teval-rmse:3.87758                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:4.27556\teval-rmse:3.66633                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.11815\teval-rmse:3.48038                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.97706\teval-rmse:3.3113                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.8509\teval-rmse:3.16011                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.73986\teval-rmse:3.02338                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.64115\teval-rmse:2.90606                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.55438\teval-rmse:2.79927                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.47688\teval-rmse:2.70489                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.40569\teval-rmse:2.62035                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.34325\teval-rmse:2.54657                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.28891\teval-rmse:2.47978                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.23983\teval-rmse:2.42235                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.19803\teval-rmse:2.37068                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.16009\teval-rmse:2.3276                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.1261\teval-rmse:2.28987                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:3.09664\teval-rmse:2.25768                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.07149\teval-rmse:2.23036                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.04764\teval-rmse:2.20397                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.02708\teval-rmse:2.18245                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.00906\teval-rmse:2.16432                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.99435\teval-rmse:2.14814                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.9803\teval-rmse:2.13421                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.96851\teval-rmse:2.12307                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.95836\teval-rmse:2.11378                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.94837\teval-rmse:2.10478                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.93911\teval-rmse:2.09738                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.9313\teval-rmse:2.09109                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.92448\teval-rmse:2.087                                                                                \n",
      "\n",
      "[33]\ttrain-rmse:2.91782\teval-rmse:2.08187                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.91144\teval-rmse:2.07844                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.9062\teval-rmse:2.07331                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.9016\teval-rmse:2.06944                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.89623\teval-rmse:2.06726                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.8917\teval-rmse:2.06506                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:2.88753\teval-rmse:2.06466                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.88402\teval-rmse:2.06439                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.88072\teval-rmse:2.06337                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.87723\teval-rmse:2.06085                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.87455\teval-rmse:2.06073                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44]\ttrain-rmse:2.87161\teval-rmse:2.05965                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.86901\teval-rmse:2.05807                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.86728\teval-rmse:2.05845                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.86386\teval-rmse:2.05863                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.86165\teval-rmse:2.05816                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.85942\teval-rmse:2.0589                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:2.85777\teval-rmse:2.05789                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.85542\teval-rmse:2.05788                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.85338\teval-rmse:2.05664                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.85042\teval-rmse:2.05539                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.84882\teval-rmse:2.05571                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.84664\teval-rmse:2.05533                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.84482\teval-rmse:2.05542                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.84341\teval-rmse:2.05477                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.84206\teval-rmse:2.05448                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.84074\teval-rmse:2.05316                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.83907\teval-rmse:2.05353                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.83712\teval-rmse:2.05365                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.83587\teval-rmse:2.05389                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.83439\teval-rmse:2.05315                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.83356\teval-rmse:2.05241                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.83257\teval-rmse:2.05193                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.83126\teval-rmse:2.05218                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.83038\teval-rmse:2.05226                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:2.82951\teval-rmse:2.05213                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.8276\teval-rmse:2.05277                                                                               \n",
      "\n",
      "[70]\ttrain-rmse:2.82583\teval-rmse:2.05278                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:2.82429\teval-rmse:2.05492                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:2.82326\teval-rmse:2.05457                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:2.82271\teval-rmse:2.05459                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:2.82053\teval-rmse:2.05407                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:2.81924\teval-rmse:2.0546                                                                               \n",
      "\n",
      "[76]\ttrain-rmse:2.81812\teval-rmse:2.05497                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:2.81653\teval-rmse:2.05339                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:2.81513\teval-rmse:2.05443                                                                              \n",
      "\n",
      "[79]\ttrain-rmse:2.81327\teval-rmse:2.05711                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:2.81123\teval-rmse:2.05592                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:2.80995\teval-rmse:2.05556                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:2.80852\teval-rmse:2.05654                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:2.80748\teval-rmse:2.05635                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:2.80669\teval-rmse:2.05635                                                                              \n",
      "\n",
      "[85]\ttrain-rmse:2.80627\teval-rmse:2.05589                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[65]\ttrain-rmse:2.83257\teval-rmse:2.05193\n",
      "\n",
      "\n",
      "loss: 99282406.62443902                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.9877993407688964e-08, 'colsample_bytree': 0.7000000000000001, 'gamma': 8.155165847601408e-06, 'lambda': 1.7162318342848892e-06, 'learning_rate': 0.275, 'max_depth': 8, 'min_child_weight': 1.0239925052819379, 'n_estimators': 678.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.50595\teval-rmse:4.0584                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.74635\teval-rmse:3.26466                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.25588\teval-rmse:2.75863                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.9399\teval-rmse:2.45449                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.73373\teval-rmse:2.27912                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.60139\teval-rmse:2.19859                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.51563\teval-rmse:2.14331                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.45493\teval-rmse:2.12287                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.41914\teval-rmse:2.12525                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.39358\teval-rmse:2.1407                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.36884\teval-rmse:2.13984                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.33916\teval-rmse:2.16159                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.31404\teval-rmse:2.15985                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.28391\teval-rmse:2.1632                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.27073\teval-rmse:2.17556                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.23728\teval-rmse:2.19202                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.21205\teval-rmse:2.20064                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.18285\teval-rmse:2.20149                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.15286\teval-rmse:2.21485                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.13693\teval-rmse:2.21505                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.11594\teval-rmse:2.219                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:2.08798\teval-rmse:2.22063                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.07787\teval-rmse:2.23244                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.05319\teval-rmse:2.2457                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.03534\teval-rmse:2.22976                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.02509\teval-rmse:2.22756                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.01472\teval-rmse:2.22344                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.98746\teval-rmse:2.23081                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.45493\teval-rmse:2.12287\n",
      "\n",
      "\n",
      "loss: 97066568.9058495                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.5775765154825035, 'colsample_bytree': 0.75, 'gamma': 4.087679400853365e-06, 'lambda': 3.6949498838416344, 'learning_rate': 0.2, 'max_depth': 9, 'min_child_weight': 3.591382754210861, 'n_estimators': 865.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.80866\teval-rmse:4.37848                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.16578\teval-rmse:3.71186                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.6818\teval-rmse:3.22126                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.31584\teval-rmse:2.86248                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.05254\teval-rmse:2.5912                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.85534\teval-rmse:2.41982                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.71311\teval-rmse:2.30052                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.60406\teval-rmse:2.22289                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.51932\teval-rmse:2.17217                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.46034\teval-rmse:2.13418                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.40568\teval-rmse:2.11293                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.37688\teval-rmse:2.09939                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.33846\teval-rmse:2.08674                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.29513\teval-rmse:2.07795                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.27608\teval-rmse:2.07526                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.25465\teval-rmse:2.07441                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.23475\teval-rmse:2.07273                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.20963\teval-rmse:2.07104                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.18204\teval-rmse:2.06823                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.1657\teval-rmse:2.06944                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.14494\teval-rmse:2.06911                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.13443\teval-rmse:2.06928                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.11056\teval-rmse:2.07553                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.0885\teval-rmse:2.07879                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.06955\teval-rmse:2.08322                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.06019\teval-rmse:2.08686                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.03803\teval-rmse:2.09775                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.0275\teval-rmse:2.10095                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.01236\teval-rmse:2.1039                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:1.99144\teval-rmse:2.10577                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.9814\teval-rmse:2.10141                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:1.96642\teval-rmse:2.09976                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.94915\teval-rmse:2.10094                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.93669\teval-rmse:2.09854                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.92988\teval-rmse:2.09542                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.91359\teval-rmse:2.09512                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.89503\teval-rmse:2.10166                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.87405\teval-rmse:2.10025                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.8603\teval-rmse:2.10434                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[18]\ttrain-rmse:2.18204\teval-rmse:2.06823\n",
      "\n",
      "\n",
      "loss: 97196803.42990327                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.5102045510828228e-05, 'colsample_bytree': 0.8, 'gamma': 0.4437954906556408, 'lambda': 0.22176687942357057, 'learning_rate': 0.30000000000000004, 'max_depth': 8, 'min_child_weight': 0.2224607129677866, 'n_estimators': 998.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.40441\teval-rmse:3.96284                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.62594\teval-rmse:3.14395                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\ttrain-rmse:3.13461\teval-rmse:2.65817                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.8416\teval-rmse:2.39368                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.66255\teval-rmse:2.25318                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.55131\teval-rmse:2.19432                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.47017\teval-rmse:2.15829                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.41917\teval-rmse:2.14198                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.37474\teval-rmse:2.13385                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.35011\teval-rmse:2.13693                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.31056\teval-rmse:2.1414                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.28065\teval-rmse:2.1407                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.24995\teval-rmse:2.13739                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.22614\teval-rmse:2.14547                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.20562\teval-rmse:2.16099                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.17915\teval-rmse:2.16395                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.15254\teval-rmse:2.16452                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.11834\teval-rmse:2.17118                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.08572\teval-rmse:2.18069                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.06607\teval-rmse:2.18849                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.05012\teval-rmse:2.19497                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.02195\teval-rmse:2.19177                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.00998\teval-rmse:2.19353                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.98876\teval-rmse:2.19956                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.9598\teval-rmse:2.19764                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.94102\teval-rmse:2.20426                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.92856\teval-rmse:2.20423                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.91752\teval-rmse:2.2081                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.89959\teval-rmse:2.22576                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.37474\teval-rmse:2.13385\n",
      "\n",
      "\n",
      "loss: 96952777.02796224                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00013285507860472234, 'colsample_bytree': 0.65, 'gamma': 2.1824617245926206e-06, 'lambda': 0.16362375762136563, 'learning_rate': 0.2, 'max_depth': 8, 'min_child_weight': 1.0468705701015546, 'n_estimators': 788.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.8097\teval-rmse:4.37651                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.17351\teval-rmse:3.71525                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.69372\teval-rmse:3.21633                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.33883\teval-rmse:2.85732                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.0794\teval-rmse:2.61208                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.89525\teval-rmse:2.43914                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.75836\teval-rmse:2.32986                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.65659\teval-rmse:2.24579                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.57487\teval-rmse:2.19327                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.52358\teval-rmse:2.16637                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.48681\teval-rmse:2.14538                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.45027\teval-rmse:2.14223                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.41966\teval-rmse:2.15337                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.37907\teval-rmse:2.15488                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.34734\teval-rmse:2.15968                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.32852\teval-rmse:2.16185                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.31322\teval-rmse:2.16198                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.28553\teval-rmse:2.15947                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.26459\teval-rmse:2.17933                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.24085\teval-rmse:2.18545                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.2171\teval-rmse:2.19235                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.20738\teval-rmse:2.1857                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.18543\teval-rmse:2.19223                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.16461\teval-rmse:2.20226                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.14651\teval-rmse:2.20044                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.12428\teval-rmse:2.19917                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.11404\teval-rmse:2.19543                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.10616\teval-rmse:2.19749                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.08775\teval-rmse:2.19813                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.07943\teval-rmse:2.198                                                                                \n",
      "\n",
      "[30]\ttrain-rmse:2.06816\teval-rmse:2.19715                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.04456\teval-rmse:2.19035                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.45027\teval-rmse:2.14223\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 97326583.0878804                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.857773278895302e-06, 'colsample_bytree': 0.6000000000000001, 'gamma': 1.4903730069813082e-07, 'lambda': 3.0614580869365123e-06, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 6.7138898451276265, 'n_estimators': 770.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.23188\teval-rmse:4.80172                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.86342\teval-rmse:4.40803                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.54365\teval-rmse:4.06249                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.26075\teval-rmse:3.76011                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.0194\teval-rmse:3.51128                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.80856\teval-rmse:3.27881                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.62605\teval-rmse:3.08074                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.46746\teval-rmse:2.90925                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.32948\teval-rmse:2.76551                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.21627\teval-rmse:2.6416                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.11812\teval-rmse:2.53721                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.03297\teval-rmse:2.45492                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.95752\teval-rmse:2.38087                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.8941\teval-rmse:2.31993                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.83884\teval-rmse:2.27347                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.79428\teval-rmse:2.23104                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.75009\teval-rmse:2.19771                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.71571\teval-rmse:2.17022                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.68199\teval-rmse:2.15051                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.6553\teval-rmse:2.1367                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:2.6284\teval-rmse:2.12069                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.60759\teval-rmse:2.10758                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.58853\teval-rmse:2.09838                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.57016\teval-rmse:2.09095                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.55396\teval-rmse:2.08328                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.5422\teval-rmse:2.07693                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.52982\teval-rmse:2.07919                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.51885\teval-rmse:2.07843                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.50647\teval-rmse:2.07659                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.49496\teval-rmse:2.07354                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.48315\teval-rmse:2.07433                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.47358\teval-rmse:2.07258                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.46439\teval-rmse:2.07333                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.45606\teval-rmse:2.07267                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.44856\teval-rmse:2.07322                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.43881\teval-rmse:2.07184                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.43458\teval-rmse:2.07219                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.42795\teval-rmse:2.06937                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.41933\teval-rmse:2.06892                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.40731\teval-rmse:2.07151                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.399\teval-rmse:2.07321                                                                                \n",
      "\n",
      "[41]\ttrain-rmse:2.39117\teval-rmse:2.07676                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.38464\teval-rmse:2.07806                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.37831\teval-rmse:2.07929                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.37068\teval-rmse:2.07933                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.36294\teval-rmse:2.08033                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.3575\teval-rmse:2.08051                                                                               \n",
      "\n",
      "[47]\ttrain-rmse:2.35087\teval-rmse:2.08076                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.34704\teval-rmse:2.08012                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.3435\teval-rmse:2.0788                                                                                \n",
      "\n",
      "[50]\ttrain-rmse:2.33627\teval-rmse:2.0796                                                                               \n",
      "\n",
      "[51]\ttrain-rmse:2.32803\teval-rmse:2.08029                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.32093\teval-rmse:2.07962                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.31434\teval-rmse:2.07981                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.30814\teval-rmse:2.08418                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.30134\teval-rmse:2.08551                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.29842\teval-rmse:2.08632                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.29323\teval-rmse:2.08763                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.28117\teval-rmse:2.09018                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[38]\ttrain-rmse:2.41933\teval-rmse:2.06892\n",
      "\n",
      "\n",
      "loss: 97197806.91936398                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.038751734459747e-06, 'colsample_bytree': 0.8, 'gamma': 1.5854262603307414e-06, 'lambda': 0.00015174677325322433, 'learning_rate': 0.125, 'max_depth': 7, 'min_child_weight': 0.23982441910620828, 'n_estimators': 875.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.12355\teval-rmse:4.69546                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.6808\teval-rmse:4.22541                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.30366\teval-rmse:3.82357                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.98946\teval-rmse:3.49277                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.72562\teval-rmse:3.21373                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.50861\teval-rmse:2.9803                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.32955\teval-rmse:2.78943                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.18047\teval-rmse:2.63858                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.05856\teval-rmse:2.5127                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.9609\teval-rmse:2.41034                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.87616\teval-rmse:2.33628                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.8096\teval-rmse:2.27264                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.75416\teval-rmse:2.22523                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.70773\teval-rmse:2.19102                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.66534\teval-rmse:2.16082                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.63315\teval-rmse:2.1409                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.6035\teval-rmse:2.12968                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.57346\teval-rmse:2.11757                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.55079\teval-rmse:2.10833                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.52995\teval-rmse:2.10235                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.50823\teval-rmse:2.09699                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.49408\teval-rmse:2.09348                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.47872\teval-rmse:2.09072                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.45895\teval-rmse:2.10217                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.44323\teval-rmse:2.10295                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.43172\teval-rmse:2.10227                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.42087\teval-rmse:2.10064                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.41097\teval-rmse:2.10038                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.39999\teval-rmse:2.10225                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.39052\teval-rmse:2.1036                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.37543\teval-rmse:2.10503                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.36192\teval-rmse:2.10622                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.35644\teval-rmse:2.10691                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.34577\teval-rmse:2.10883                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.33446\teval-rmse:2.11717                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.32447\teval-rmse:2.10686                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.31776\teval-rmse:2.10653                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.30657\teval-rmse:2.10167                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.30235\teval-rmse:2.10213                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.29726\teval-rmse:2.10166                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.28901\teval-rmse:2.10298                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.28043\teval-rmse:2.10046                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.27282\teval-rmse:2.101                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[22]\ttrain-rmse:2.47872\teval-rmse:2.09072\n",
      "\n",
      "\n",
      "loss: 97277619.33676435                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.089332536979101e-07, 'colsample_bytree': 0.8, 'gamma': 0.0001675480776433997, 'lambda': 0.024689361498206577, 'learning_rate': 0.275, 'max_depth': 8, 'min_child_weight': 2.7735481893547864, 'n_estimators': 268.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.5015\teval-rmse:4.0556                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.75296\teval-rmse:3.25298                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.25261\teval-rmse:2.7563                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.93897\teval-rmse:2.45205                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.74085\teval-rmse:2.2733                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.61299\teval-rmse:2.18317                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.53019\teval-rmse:2.13672                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.46724\teval-rmse:2.11052                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.42689\teval-rmse:2.10748                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.39127\teval-rmse:2.09647                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:2.35257\teval-rmse:2.098                                                                                \n",
      "\n",
      "[11]\ttrain-rmse:2.32944\teval-rmse:2.11834                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.30128\teval-rmse:2.12034                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.27914\teval-rmse:2.11675                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.26675\teval-rmse:2.13648                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.24481\teval-rmse:2.15245                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.22486\teval-rmse:2.18311                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.20287\teval-rmse:2.18704                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.18146\teval-rmse:2.193                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:2.15489\teval-rmse:2.19772                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.14308\teval-rmse:2.19786                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.12997\teval-rmse:2.19008                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.11535\teval-rmse:2.19217                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.09449\teval-rmse:2.2064                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.07708\teval-rmse:2.20506                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.05762\teval-rmse:2.24869                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.04892\teval-rmse:2.24933                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.0319\teval-rmse:2.25163                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.01568\teval-rmse:2.26721                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.98568\teval-rmse:2.27269                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.39127\teval-rmse:2.09647\n",
      "\n",
      "\n",
      "loss: 97241298.15854251                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.67362125588522e-07, 'colsample_bytree': 0.75, 'gamma': 0.0019220208540810598, 'lambda': 2.2522123803049202e-06, 'learning_rate': 0.35000000000000003, 'max_depth': 6, 'min_child_weight': 4.715068040683666, 'n_estimators': 505.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.26554\teval-rmse:3.73962                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.51526\teval-rmse:2.88642                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.11076\teval-rmse:2.43744                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.9035\teval-rmse:2.22468                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.79564\teval-rmse:2.11795                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.73673\teval-rmse:2.07402                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.69474\teval-rmse:2.06994                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.66911\teval-rmse:2.06298                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.64483\teval-rmse:2.06413                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.61812\teval-rmse:2.06184                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.59865\teval-rmse:2.06797                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.58866\teval-rmse:2.07241                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.5757\teval-rmse:2.07835                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.55192\teval-rmse:2.09673                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.53208\teval-rmse:2.09148                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.51826\teval-rmse:2.09439                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.50523\teval-rmse:2.0954                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.48872\teval-rmse:2.09736                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.48076\teval-rmse:2.10198                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.4722\teval-rmse:2.1085                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:2.46465\teval-rmse:2.13969                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.45529\teval-rmse:2.14228                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.44514\teval-rmse:2.1451                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.43607\teval-rmse:2.14751                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.42545\teval-rmse:2.15874                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.41672\teval-rmse:2.15524                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.40684\teval-rmse:2.16444                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.39906\teval-rmse:2.16664                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.39451\teval-rmse:2.17456                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.38308\teval-rmse:2.18036                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.61812\teval-rmse:2.06184\n",
      "\n",
      "\n",
      "loss: 97785668.17090438                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.002220388909727193, 'colsample_bytree': 0.8500000000000001, 'gamma': 2.4482567708120344e-08, 'lambda': 0.0014162252268559675, 'learning_rate': 0.35000000000000003, 'max_depth': 5, 'min_child_weight': 0.1031844314366841, 'n_estimators': 994.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.294\teval-rmse:3.74689                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.55714\teval-rmse:2.89101                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.16592\teval-rmse:2.45178                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.96452\teval-rmse:2.23396                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.87154\teval-rmse:2.13189                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.81155\teval-rmse:2.0879                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.77358\teval-rmse:2.07478                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.74692\teval-rmse:2.06881                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.72467\teval-rmse:2.09499                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.70581\teval-rmse:2.09192                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.69209\teval-rmse:2.09104                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.67279\teval-rmse:2.10408                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.66032\teval-rmse:2.10469                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.64792\teval-rmse:2.0956                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.64236\teval-rmse:2.0974                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.62815\teval-rmse:2.11455                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.61403\teval-rmse:2.11864                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.59937\teval-rmse:2.11945                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.58376\teval-rmse:2.12419                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.57879\teval-rmse:2.12415                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.56288\teval-rmse:2.12728                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.55235\teval-rmse:2.13312                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.54517\teval-rmse:2.13636                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.53054\teval-rmse:2.13519                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.52087\teval-rmse:2.13486                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.50709\teval-rmse:2.13827                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.49854\teval-rmse:2.14083                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.4914\teval-rmse:2.15086                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.74692\teval-rmse:2.06881\n",
      "\n",
      "\n",
      "loss: 97614474.55207343                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0007183490051024483, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.006834717712890471, 'lambda': 9.181310005101604, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 2.088591845831099, 'n_estimators': 681.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.42475\teval-rmse:3.96243                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.63877\teval-rmse:3.15072                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.14393\teval-rmse:2.65812                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.83659\teval-rmse:2.38002                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.64631\teval-rmse:2.22786                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.50746\teval-rmse:2.13219                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.41167\teval-rmse:2.08726                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.34559\teval-rmse:2.07562                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.29274\teval-rmse:2.06444                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.25053\teval-rmse:2.06357                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.20906\teval-rmse:2.06054                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.1868\teval-rmse:2.05806                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.16157\teval-rmse:2.05656                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.13548\teval-rmse:2.05846                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.11234\teval-rmse:2.06758                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.08427\teval-rmse:2.05953                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.06368\teval-rmse:2.065                                                                                \n",
      "\n",
      "[17]\ttrain-rmse:2.043\teval-rmse:2.06519                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:2.00779\teval-rmse:2.07053                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.97928\teval-rmse:2.06125                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.9614\teval-rmse:2.06793                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.94272\teval-rmse:2.06807                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.9202\teval-rmse:2.06848                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.89796\teval-rmse:2.07049                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.87469\teval-rmse:2.07113                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.84882\teval-rmse:2.07487                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.82968\teval-rmse:2.06205                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.80904\teval-rmse:2.06515                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.79748\teval-rmse:2.06661                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.7674\teval-rmse:2.06877                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:1.7477\teval-rmse:2.06877                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:1.72936\teval-rmse:2.06794                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.71692\teval-rmse:2.07226                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.16157\teval-rmse:2.05656\n",
      "\n",
      "\n",
      "loss: 97435505.43103082                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.6142369975444712e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 2.1360706718182708e-07, 'lambda': 0.001359151164368664, 'learning_rate': 0.42500000000000004, 'max_depth': 9, 'min_child_weight': 0.6774816946774024, 'n_estimators': 1000.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:3.9011\teval-rmse:3.47944                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.03178\teval-rmse:2.66956                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.62485\teval-rmse:2.36656                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.41743\teval-rmse:2.29527                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.30342\teval-rmse:2.2578                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.24749\teval-rmse:2.25264                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.20065\teval-rmse:2.26587                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.13078\teval-rmse:2.26564                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.08298\teval-rmse:2.29969                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.03746\teval-rmse:2.34763                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.01056\teval-rmse:2.3477                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:1.97409\teval-rmse:2.38383                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.9406\teval-rmse:2.41254                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:1.9159\teval-rmse:2.41674                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:1.90255\teval-rmse:2.43876                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.86449\teval-rmse:2.43425                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.8473\teval-rmse:2.51442                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:1.79641\teval-rmse:2.52527                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.77079\teval-rmse:2.52638                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.75943\teval-rmse:2.51876                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.73808\teval-rmse:2.52488                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.70924\teval-rmse:2.52932                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.65525\teval-rmse:2.5296                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.63242\teval-rmse:2.54751                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.6192\teval-rmse:2.55037                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.6016\teval-rmse:2.55451                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.24749\teval-rmse:2.25264\n",
      "\n",
      "\n",
      "loss: 269376046.29676676                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.02537350547511972, 'colsample_bytree': 0.9, 'gamma': 1.0172270739026928e-08, 'lambda': 0.5801860150235877, 'learning_rate': 0.325, 'max_depth': 4, 'min_child_weight': 0.5693856387531278, 'n_estimators': 416.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.40396\teval-rmse:3.84675                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.6861\teval-rmse:2.99732                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.29264\teval-rmse:2.52555                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.07188\teval-rmse:2.28188                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.96171\teval-rmse:2.16186                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.89744\teval-rmse:2.1093                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.85943\teval-rmse:2.08612                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.83209\teval-rmse:2.0748                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.814\teval-rmse:2.06709                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:2.79835\teval-rmse:2.06604                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.78835\teval-rmse:2.06912                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.77778\teval-rmse:2.06759                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.76693\teval-rmse:2.06473                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.7581\teval-rmse:2.07646                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.75224\teval-rmse:2.07822                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.74229\teval-rmse:2.0839                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.73115\teval-rmse:2.08128                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.72277\teval-rmse:2.07909                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.71434\teval-rmse:2.08975                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.70687\teval-rmse:2.09139                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.69876\teval-rmse:2.09374                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.6893\teval-rmse:2.09168                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.68229\teval-rmse:2.09455                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.67768\teval-rmse:2.08857                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.67161\teval-rmse:2.08837                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.66869\teval-rmse:2.08852                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.66408\teval-rmse:2.08091                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.6577\teval-rmse:2.07827                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.64827\teval-rmse:2.08596                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.64171\teval-rmse:2.08486                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.63784\teval-rmse:2.08671                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.63177\teval-rmse:2.08157                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.63003\teval-rmse:2.08194                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.76693\teval-rmse:2.06473\n",
      "\n",
      "\n",
      "loss: 98066748.57578993                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0008812564311602272, 'colsample_bytree': 0.8, 'gamma': 0.02185007313524913, 'lambda': 9.934978541165437, 'learning_rate': 0.4, 'max_depth': 5, 'min_child_weight': 9.511404603830323, 'n_estimators': 665.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.12974\teval-rmse:3.54455                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.40058\teval-rmse:2.68097                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.05249\teval-rmse:2.29915                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.89706\teval-rmse:2.14735                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.82625\teval-rmse:2.09016                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.78717\teval-rmse:2.07701                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.76489\teval-rmse:2.066                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:2.74215\teval-rmse:2.06626                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.72001\teval-rmse:2.07566                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.70546\teval-rmse:2.07717                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.69351\teval-rmse:2.07402                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.67889\teval-rmse:2.07107                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.66651\teval-rmse:2.07204                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.65414\teval-rmse:2.0729                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.64401\teval-rmse:2.0773                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.632\teval-rmse:2.08017                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:2.61821\teval-rmse:2.07811                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.60985\teval-rmse:2.08095                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.60076\teval-rmse:2.07924                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.58631\teval-rmse:2.08594                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.58042\teval-rmse:2.08634                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.56641\teval-rmse:2.08513                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.55801\teval-rmse:2.08184                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.54575\teval-rmse:2.0833                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.5338\teval-rmse:2.09193                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.52942\teval-rmse:2.09918                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.52529\teval-rmse:2.1                                                                                  \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.76489\teval-rmse:2.066\n",
      "\n",
      "\n",
      "loss: 97718901.07639737                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 9.872972274174297e-05, 'colsample_bytree': 0.75, 'gamma': 0.0006759201659447623, 'lambda': 0.005448450543552845, 'learning_rate': 0.025, 'max_depth': 9, 'min_child_weight': 1.7062222940524798, 'n_estimators': 989.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.54189\teval-rmse:5.13509                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.43525\teval-rmse:5.02704                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.33181\teval-rmse:4.92199                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:5.23049\teval-rmse:4.81986                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:5.13244\teval-rmse:4.72017                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:5.03688\teval-rmse:4.62323                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.9441\teval-rmse:4.53009                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:4.85446\teval-rmse:4.43949                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:4.76775\teval-rmse:4.35223                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:4.68307\teval-rmse:4.26828                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:4.59994\teval-rmse:4.18563                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:4.5208\teval-rmse:4.10583                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:4.44368\teval-rmse:4.02849                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:4.36939\teval-rmse:3.95255                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:4.2957\teval-rmse:3.88033                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:4.22515\teval-rmse:3.80936                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:4.15683\teval-rmse:3.74159                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:4.09127\teval-rmse:3.67648                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\ttrain-rmse:4.02612\teval-rmse:3.61313                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.96291\teval-rmse:3.55195                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.90139\teval-rmse:3.49208                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.84349\teval-rmse:3.4338                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:3.78679\teval-rmse:3.37846                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.73161\teval-rmse:3.32492                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.67772\teval-rmse:3.27278                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.62611\teval-rmse:3.22377                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.5758\teval-rmse:3.17646                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:3.52609\teval-rmse:3.12974                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.47934\teval-rmse:3.0838                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:3.43341\teval-rmse:3.04087                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.38808\teval-rmse:2.99994                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.34552\teval-rmse:2.95946                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.30473\teval-rmse:2.92154                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.26493\teval-rmse:2.88492                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.2274\teval-rmse:2.84906                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:3.19061\teval-rmse:2.81523                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.15367\teval-rmse:2.78245                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.11821\teval-rmse:2.7506                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:3.08353\teval-rmse:2.7207                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:3.05059\teval-rmse:2.69156                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.01823\teval-rmse:2.66362                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.98738\teval-rmse:2.63612                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.95826\teval-rmse:2.61145                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.92827\teval-rmse:2.58633                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.89931\teval-rmse:2.56233                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.87262\teval-rmse:2.5392                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.84593\teval-rmse:2.51684                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.81976\teval-rmse:2.49425                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.796\teval-rmse:2.47515                                                                                \n",
      "\n",
      "[49]\ttrain-rmse:2.7726\teval-rmse:2.45517                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:2.74889\teval-rmse:2.43646                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.72625\teval-rmse:2.41893                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.70383\teval-rmse:2.40132                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.68293\teval-rmse:2.38551                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.66177\teval-rmse:2.36998                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.64279\teval-rmse:2.35502                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.624\teval-rmse:2.34073                                                                                \n",
      "\n",
      "[57]\ttrain-rmse:2.60453\teval-rmse:2.32739                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.58627\teval-rmse:2.31418                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.56796\teval-rmse:2.30201                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.55131\teval-rmse:2.28961                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.53597\teval-rmse:2.27861                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.52113\teval-rmse:2.26733                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.50691\teval-rmse:2.25748                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.49167\teval-rmse:2.24712                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.47819\teval-rmse:2.23787                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.46432\teval-rmse:2.22943                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.4499\teval-rmse:2.22136                                                                               \n",
      "\n",
      "[68]\ttrain-rmse:2.43704\teval-rmse:2.21277                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.4245\teval-rmse:2.20631                                                                               \n",
      "\n",
      "[70]\ttrain-rmse:2.41128\teval-rmse:2.19825                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:2.39927\teval-rmse:2.19221                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:2.38856\teval-rmse:2.18532                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:2.37842\teval-rmse:2.17851                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:2.36781\teval-rmse:2.17081                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:2.35576\teval-rmse:2.16516                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:2.346\teval-rmse:2.15946                                                                                \n",
      "\n",
      "[77]\ttrain-rmse:2.33532\teval-rmse:2.15421                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:2.3267\teval-rmse:2.14898                                                                               \n",
      "\n",
      "[79]\ttrain-rmse:2.3164\teval-rmse:2.14392                                                                               \n",
      "\n",
      "[80]\ttrain-rmse:2.306\teval-rmse:2.13902                                                                                \n",
      "\n",
      "[81]\ttrain-rmse:2.29552\teval-rmse:2.1346                                                                               \n",
      "\n",
      "[82]\ttrain-rmse:2.28693\teval-rmse:2.13077                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:2.27855\teval-rmse:2.12679                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:2.27078\teval-rmse:2.12337                                                                              \n",
      "\n",
      "[85]\ttrain-rmse:2.26338\teval-rmse:2.12027                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:2.25651\teval-rmse:2.11772                                                                              \n",
      "\n",
      "[87]\ttrain-rmse:2.24916\teval-rmse:2.11394                                                                              \n",
      "\n",
      "[88]\ttrain-rmse:2.24221\teval-rmse:2.11085                                                                              \n",
      "\n",
      "[89]\ttrain-rmse:2.23421\teval-rmse:2.10821                                                                              \n",
      "\n",
      "[90]\ttrain-rmse:2.22681\teval-rmse:2.1043                                                                               \n",
      "\n",
      "[91]\ttrain-rmse:2.2194\teval-rmse:2.1022                                                                                \n",
      "\n",
      "[92]\ttrain-rmse:2.21182\teval-rmse:2.0991                                                                               \n",
      "\n",
      "[93]\ttrain-rmse:2.20391\teval-rmse:2.09563                                                                              \n",
      "\n",
      "[94]\ttrain-rmse:2.19659\teval-rmse:2.09307                                                                              \n",
      "\n",
      "[95]\ttrain-rmse:2.18791\teval-rmse:2.09121                                                                              \n",
      "\n",
      "[96]\ttrain-rmse:2.18107\teval-rmse:2.08966                                                                              \n",
      "\n",
      "[97]\ttrain-rmse:2.17453\teval-rmse:2.08761                                                                              \n",
      "\n",
      "[98]\ttrain-rmse:2.16887\teval-rmse:2.08618                                                                              \n",
      "\n",
      "[99]\ttrain-rmse:2.16211\teval-rmse:2.0849                                                                               \n",
      "\n",
      "loss: 98999539.69811657                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.007615060501610226, 'colsample_bytree': 0.9, 'gamma': 3.0095762901848048e-05, 'lambda': 0.2062594884623929, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 0.10372631010827171, 'n_estimators': 584.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.60136\teval-rmse:4.17061                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.87261\teval-rmse:3.41064                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.36984\teval-rmse:2.90636                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.03453\teval-rmse:2.57323                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.8175\teval-rmse:2.37253                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.6634\teval-rmse:2.25541                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.55496\teval-rmse:2.18258                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.47924\teval-rmse:2.15469                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.42299\teval-rmse:2.16088                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.38254\teval-rmse:2.15427                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.34306\teval-rmse:2.15129                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.31949\teval-rmse:2.14685                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.2897\teval-rmse:2.1523                                                                                \n",
      "\n",
      "[13]\ttrain-rmse:2.27152\teval-rmse:2.16265                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.24436\teval-rmse:2.17096                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.2138\teval-rmse:2.20435                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.19432\teval-rmse:2.2119                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.16314\teval-rmse:2.21125                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.14595\teval-rmse:2.21206                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.11988\teval-rmse:2.20065                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.10589\teval-rmse:2.20485                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.07881\teval-rmse:2.21744                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.05378\teval-rmse:2.26345                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.0373\teval-rmse:2.28666                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.02424\teval-rmse:2.29404                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.01502\teval-rmse:2.29427                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.9969\teval-rmse:2.29174                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.97491\teval-rmse:2.29233                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.95441\teval-rmse:2.29128                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.94074\teval-rmse:2.29053                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.92388\teval-rmse:2.28675                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.90071\teval-rmse:2.29222                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.31949\teval-rmse:2.14685\n",
      "\n",
      "\n",
      "loss: 97148340.47104597                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.2918483838731738e-05, 'colsample_bytree': 0.65, 'gamma': 1.7240440347476953e-07, 'lambda': 3.172871837325932, 'learning_rate': 0.17500000000000002, 'max_depth': 9, 'min_child_weight': 1.2309932906628893, 'n_estimators': 432.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.90821\teval-rmse:4.48467                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.31991\teval-rmse:3.87866                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.84949\teval-rmse:3.40012                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.48369\teval-rmse:3.03833                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.19968\teval-rmse:2.77448                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.97627\teval-rmse:2.57398                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\ttrain-rmse:2.8052\teval-rmse:2.42734                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.66443\teval-rmse:2.32932                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.56174\teval-rmse:2.25683                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.48561\teval-rmse:2.20144                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.41954\teval-rmse:2.16756                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.35829\teval-rmse:2.14584                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.31359\teval-rmse:2.13002                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.26556\teval-rmse:2.12014                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.23242\teval-rmse:2.11514                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.20377\teval-rmse:2.11185                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.17627\teval-rmse:2.11219                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.14273\teval-rmse:2.11039                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.11825\teval-rmse:2.11067                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.08448\teval-rmse:2.10567                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.06132\teval-rmse:2.10198                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.04575\teval-rmse:2.1022                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.02571\teval-rmse:2.10539                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.00303\teval-rmse:2.10809                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.9922\teval-rmse:2.10992                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.98439\teval-rmse:2.1083                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.96966\teval-rmse:2.1116                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.94998\teval-rmse:2.1115                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.93904\teval-rmse:2.11611                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.92713\teval-rmse:2.11698                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.90364\teval-rmse:2.11964                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.89937\teval-rmse:2.11774                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.87935\teval-rmse:2.11763                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.86916\teval-rmse:2.11947                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.86503\teval-rmse:2.11913                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.85221\teval-rmse:2.12112                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.84293\teval-rmse:2.12387                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.82538\teval-rmse:2.12691                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.80368\teval-rmse:2.12978                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:1.7863\teval-rmse:2.12981                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:1.77786\teval-rmse:2.12956                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[20]\ttrain-rmse:2.06132\teval-rmse:2.10198\n",
      "\n",
      "\n",
      "loss: 96975542.17150818                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0003406871766999733, 'colsample_bytree': 0.75, 'gamma': 0.003603291072494592, 'lambda': 0.00018736935680597442, 'learning_rate': 0.225, 'max_depth': 8, 'min_child_weight': 2.282925919597646, 'n_estimators': 615.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.70289\teval-rmse:4.27304                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.01413\teval-rmse:3.55441                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.52763\teval-rmse:3.05687                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.1831\teval-rmse:2.71324                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.94402\teval-rmse:2.47718                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.78173\teval-rmse:2.33002                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.66537\teval-rmse:2.23217                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.58185\teval-rmse:2.18849                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.51112\teval-rmse:2.14529                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.46973\teval-rmse:2.11496                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.43383\teval-rmse:2.10304                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.40851\teval-rmse:2.10042                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.37424\teval-rmse:2.10891                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.34705\teval-rmse:2.11908                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.33443\teval-rmse:2.12069                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.30747\teval-rmse:2.11712                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.28853\teval-rmse:2.11478                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.26616\teval-rmse:2.11751                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.24736\teval-rmse:2.11433                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.22821\teval-rmse:2.11713                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.21224\teval-rmse:2.119                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:2.20423\teval-rmse:2.12094                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.18542\teval-rmse:2.1205                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.15568\teval-rmse:2.12473                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.14821\teval-rmse:2.1259                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.12974\teval-rmse:2.12453                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.12286\teval-rmse:2.1282                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.10615\teval-rmse:2.13543                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.08797\teval-rmse:2.14019                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.07665\teval-rmse:2.13941                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.06674\teval-rmse:2.14                                                                                 \n",
      "\n",
      "[31]\ttrain-rmse:2.04527\teval-rmse:2.14316                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.40851\teval-rmse:2.10042\n",
      "\n",
      "\n",
      "loss: 96649412.59146594                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0006612330543891801, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.23197008645601325, 'lambda': 0.00012840846524528896, 'learning_rate': 0.225, 'max_depth': 8, 'min_child_weight': 9.171670170659642, 'n_estimators': 933.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.70913\teval-rmse:4.26635                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.03021\teval-rmse:3.54169                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.53757\teval-rmse:3.02613                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.20219\teval-rmse:2.68089                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.96838\teval-rmse:2.43799                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.80425\teval-rmse:2.28636                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.69119\teval-rmse:2.19652                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.61153\teval-rmse:2.14039                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.55079\teval-rmse:2.1109                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.52022\teval-rmse:2.08813                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.49388\teval-rmse:2.07492                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.45718\teval-rmse:2.07022                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.43175\teval-rmse:2.05513                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.41212\teval-rmse:2.05138                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.39235\teval-rmse:2.05476                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.37082\teval-rmse:2.05075                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.349\teval-rmse:2.04829                                                                                \n",
      "\n",
      "[17]\ttrain-rmse:2.33289\teval-rmse:2.05253                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.32549\teval-rmse:2.06114                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.31225\teval-rmse:2.06242                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.30574\teval-rmse:2.06117                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.29429\teval-rmse:2.06783                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.28499\teval-rmse:2.0716                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.26767\teval-rmse:2.0741                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.25458\teval-rmse:2.0768                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.2418\teval-rmse:2.08077                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.22609\teval-rmse:2.08264                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.21948\teval-rmse:2.08602                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.21575\teval-rmse:2.08416                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.19841\teval-rmse:2.07942                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.17877\teval-rmse:2.07881                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.16593\teval-rmse:2.078                                                                                \n",
      "\n",
      "[32]\ttrain-rmse:2.15561\teval-rmse:2.07941                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.14665\teval-rmse:2.0844                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:2.13932\teval-rmse:2.08482                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.13055\teval-rmse:2.08303                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.11377\teval-rmse:2.09382                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[16]\ttrain-rmse:2.349\teval-rmse:2.04829\n",
      "\n",
      "\n",
      "loss: 97187607.77638268                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.005003856086336182, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.006628724816577201, 'lambda': 7.344286977023913e-05, 'learning_rate': 0.30000000000000004, 'max_depth': 8, 'min_child_weight': 0.6863398124408399, 'n_estimators': 618.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.40823\teval-rmse:3.96352                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.62339\teval-rmse:3.14916                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.14898\teval-rmse:2.65777                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.87111\teval-rmse:2.40251                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.7001\teval-rmse:2.26789                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.58052\teval-rmse:2.19951                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.51678\teval-rmse:2.16142                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.47598\teval-rmse:2.14877                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain-rmse:2.44469\teval-rmse:2.16063                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.40873\teval-rmse:2.16156                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.375\teval-rmse:2.17109                                                                                \n",
      "\n",
      "[11]\ttrain-rmse:2.36555\teval-rmse:2.17305                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.33494\teval-rmse:2.16462                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.30929\teval-rmse:2.20185                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.28419\teval-rmse:2.20511                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.25907\teval-rmse:2.20876                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.23346\teval-rmse:2.21649                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.20632\teval-rmse:2.22408                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.19221\teval-rmse:2.22813                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.17272\teval-rmse:2.22798                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.15111\teval-rmse:2.23491                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.12632\teval-rmse:2.23421                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.10562\teval-rmse:2.2467                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.09664\teval-rmse:2.24956                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.08341\teval-rmse:2.25046                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.07471\teval-rmse:2.25248                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.05437\teval-rmse:2.3169                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.03464\teval-rmse:2.3332                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.47598\teval-rmse:2.14877\n",
      "\n",
      "\n",
      "loss: 48849533904.135124                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00027679498671012763, 'colsample_bytree': 0.65, 'gamma': 0.01963983646579127, 'lambda': 0.0004945601895745256, 'learning_rate': 0.225, 'max_depth': 8, 'min_child_weight': 0.1412417887730363, 'n_estimators': 106.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.70792\teval-rmse:4.26062                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.02291\teval-rmse:3.5497                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.53379\teval-rmse:3.05021                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.19237\teval-rmse:2.70723                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.9455\teval-rmse:2.48788                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.77812\teval-rmse:2.34801                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.6551\teval-rmse:2.26403                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.57366\teval-rmse:2.21005                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.50685\teval-rmse:2.18311                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.45741\teval-rmse:2.1769                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.41475\teval-rmse:2.16908                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.37764\teval-rmse:2.16282                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.35107\teval-rmse:2.17391                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.31716\teval-rmse:2.16148                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.2991\teval-rmse:2.16596                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.27517\teval-rmse:2.17822                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.25347\teval-rmse:2.20613                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.23115\teval-rmse:2.20928                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.20438\teval-rmse:2.22623                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.18741\teval-rmse:2.23786                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.16876\teval-rmse:2.23861                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.15802\teval-rmse:2.23889                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.13683\teval-rmse:2.24966                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.12256\teval-rmse:2.25284                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.10693\teval-rmse:2.25616                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.09716\teval-rmse:2.26912                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.08909\teval-rmse:2.25886                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.07354\teval-rmse:2.26384                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.06598\teval-rmse:2.26794                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.04992\teval-rmse:2.2737                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.03792\teval-rmse:2.27648                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.02882\teval-rmse:2.28268                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.01404\teval-rmse:2.28511                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.98902\teval-rmse:2.28886                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.31716\teval-rmse:2.16148\n",
      "\n",
      "\n",
      "loss: 97188344.98508836                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.2718216123670682e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.8273927388097594, 'lambda': 0.0049482559010249234, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 2.7102371696542793, 'n_estimators': 424.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.61074\teval-rmse:4.16162                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.88721\teval-rmse:3.41261                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.39601\teval-rmse:2.9049                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.05892\teval-rmse:2.58271                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.84826\teval-rmse:2.37847                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.70131\teval-rmse:2.26268                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.60311\teval-rmse:2.21062                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.53019\teval-rmse:2.18006                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.48188\teval-rmse:2.18416                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.43408\teval-rmse:2.17787                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.40718\teval-rmse:2.17339                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.38434\teval-rmse:2.1715                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.36117\teval-rmse:2.18851                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.33264\teval-rmse:2.18458                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.30713\teval-rmse:2.17762                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.29416\teval-rmse:2.1763                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.26943\teval-rmse:2.17355                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.24203\teval-rmse:2.17631                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.2267\teval-rmse:2.18088                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.20334\teval-rmse:2.18828                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.18459\teval-rmse:2.18491                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.17037\teval-rmse:2.18414                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.14359\teval-rmse:2.17706                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.12931\teval-rmse:2.17681                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.11735\teval-rmse:2.17776                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.1106\teval-rmse:2.1832                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:2.104\teval-rmse:2.18315                                                                                \n",
      "\n",
      "[27]\ttrain-rmse:2.08394\teval-rmse:2.18187                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.07079\teval-rmse:2.18655                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.06479\teval-rmse:2.18376                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.04459\teval-rmse:2.19432                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.0228\teval-rmse:2.19142                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.38434\teval-rmse:2.1715\n",
      "\n",
      "\n",
      "loss: 97280867.21243337                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.7458448444745466e-06, 'colsample_bytree': 0.8, 'gamma': 0.17293205391336033, 'lambda': 1.9438533424381637e-05, 'learning_rate': 0.325, 'max_depth': 3, 'min_child_weight': 1.2494946023295548, 'n_estimators': 735.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.42929\teval-rmse:3.85915                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.73324\teval-rmse:3.03037                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.34042\teval-rmse:2.55835                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.13464\teval-rmse:2.31307                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.02746\teval-rmse:2.19367                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.96462\teval-rmse:2.13696                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.93336\teval-rmse:2.1138                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.91466\teval-rmse:2.10069                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.90069\teval-rmse:2.09411                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.88345\teval-rmse:2.08516                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.86781\teval-rmse:2.07736                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.86096\teval-rmse:2.0836                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.85447\teval-rmse:2.08065                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.84843\teval-rmse:2.08516                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.84298\teval-rmse:2.08323                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.83499\teval-rmse:2.08295                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.82798\teval-rmse:2.08198                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.8223\teval-rmse:2.08061                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.81947\teval-rmse:2.07739                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.81544\teval-rmse:2.08862                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.81027\teval-rmse:2.08581                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.80632\teval-rmse:2.0867                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.80257\teval-rmse:2.08874                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.80009\teval-rmse:2.08377                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.79635\teval-rmse:2.08464                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.79129\teval-rmse:2.08546                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\ttrain-rmse:2.78676\teval-rmse:2.08296                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.78231\teval-rmse:2.09059                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.77838\teval-rmse:2.09643                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.77384\teval-rmse:2.08765                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.77118\teval-rmse:2.08674                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.86781\teval-rmse:2.07736\n",
      "\n",
      "\n",
      "loss: 98659831.06967725                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.022382715205459175, 'colsample_bytree': 0.75, 'gamma': 0.0016278857146007283, 'lambda': 0.0004663585710130575, 'learning_rate': 0.17500000000000002, 'max_depth': 5, 'min_child_weight': 0.4811193395456752, 'n_estimators': 174.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.94527\teval-rmse:4.47712                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.40225\teval-rmse:3.86094                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.98602\teval-rmse:3.38959                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.66654\teval-rmse:3.02441                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.43357\teval-rmse:2.74996                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.2516\teval-rmse:2.5479                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:3.12289\teval-rmse:2.40111                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.02684\teval-rmse:2.29817                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.95631\teval-rmse:2.22228                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.90553\teval-rmse:2.16964                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.86228\teval-rmse:2.1325                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.83182\teval-rmse:2.10802                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.80319\teval-rmse:2.08956                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.77798\teval-rmse:2.08693                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.76139\teval-rmse:2.08246                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.74549\teval-rmse:2.0749                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.73419\teval-rmse:2.06829                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.72083\teval-rmse:2.06908                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.712\teval-rmse:2.06685                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:2.70043\teval-rmse:2.06736                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.69258\teval-rmse:2.0668                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.68635\teval-rmse:2.0635                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.6794\teval-rmse:2.06363                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.66972\teval-rmse:2.06837                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.66475\teval-rmse:2.06741                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.65976\teval-rmse:2.0659                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.65188\teval-rmse:2.06877                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.64293\teval-rmse:2.06548                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.63767\teval-rmse:2.06456                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.63082\teval-rmse:2.06379                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.62621\teval-rmse:2.06683                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.61862\teval-rmse:2.06576                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.6143\teval-rmse:2.06791                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.60781\teval-rmse:2.06676                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.60263\teval-rmse:2.06229                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.59351\teval-rmse:2.062                                                                                \n",
      "\n",
      "[36]\ttrain-rmse:2.5868\teval-rmse:2.06291                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.57961\teval-rmse:2.06698                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.57542\teval-rmse:2.07321                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.56988\teval-rmse:2.07593                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.56451\teval-rmse:2.07538                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.55912\teval-rmse:2.07736                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.5541\teval-rmse:2.07186                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:2.54956\teval-rmse:2.07172                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.54586\teval-rmse:2.0738                                                                               \n",
      "\n",
      "[45]\ttrain-rmse:2.54258\teval-rmse:2.07826                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.53726\teval-rmse:2.08034                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.53335\teval-rmse:2.08312                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.52839\teval-rmse:2.08408                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.52343\teval-rmse:2.08519                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.51845\teval-rmse:2.08524                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.51253\teval-rmse:2.08613                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.51077\teval-rmse:2.08057                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.50654\teval-rmse:2.08126                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.50359\teval-rmse:2.08216                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.49642\teval-rmse:2.08073                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[35]\ttrain-rmse:2.59351\teval-rmse:2.062\n",
      "\n",
      "\n",
      "loss: 97995514.9747357                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.000275565884032353, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.06384551363759669, 'lambda': 2.6184437530080907e-05, 'learning_rate': 0.42500000000000004, 'max_depth': 8, 'min_child_weight': 0.27416248913313485, 'n_estimators': 837.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:3.92608\teval-rmse:3.46285                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.10303\teval-rmse:2.65363                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.73108\teval-rmse:2.30893                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.54214\teval-rmse:2.21614                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.44832\teval-rmse:2.21151                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.38567\teval-rmse:2.21792                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.3465\teval-rmse:2.21791                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.30594\teval-rmse:2.19959                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.25882\teval-rmse:2.22417                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.20664\teval-rmse:2.24586                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.19436\teval-rmse:2.24626                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.16825\teval-rmse:2.27276                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.13266\teval-rmse:2.29123                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.10711\teval-rmse:2.28777                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.06769\teval-rmse:2.28535                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.05073\teval-rmse:2.29649                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.01733\teval-rmse:2.32835                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.99245\teval-rmse:2.34375                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.97856\teval-rmse:2.35154                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.9388\teval-rmse:2.36257                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.92057\teval-rmse:2.38395                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.90888\teval-rmse:2.38964                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.88888\teval-rmse:2.40846                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.86253\teval-rmse:2.41976                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.83225\teval-rmse:2.42893                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.81026\teval-rmse:2.43627                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.79872\teval-rmse:2.44987                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.783\teval-rmse:2.4521                                                                                 \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.30594\teval-rmse:2.19959\n",
      "\n",
      "\n",
      "loss: 100339545.00450218                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.0928611918830446e-06, 'colsample_bytree': 0.9, 'gamma': 0.4572377007998728, 'lambda': 0.05437537507305817, 'learning_rate': 0.30000000000000004, 'max_depth': 4, 'min_child_weight': 6.353534313966232, 'n_estimators': 939.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.48956\teval-rmse:3.94827                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.78646\teval-rmse:3.12574                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.371\teval-rmse:2.62642                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:3.13383\teval-rmse:2.35539                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.00169\teval-rmse:2.20437                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.92129\teval-rmse:2.12851                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.87713\teval-rmse:2.10526                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.85372\teval-rmse:2.09907                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.82856\teval-rmse:2.08589                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.81184\teval-rmse:2.07964                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.79817\teval-rmse:2.0784                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.78858\teval-rmse:2.07655                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.78297\teval-rmse:2.07777                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.77451\teval-rmse:2.07354                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.76763\teval-rmse:2.07485                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.76299\teval-rmse:2.07193                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.75756\teval-rmse:2.0719                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.7473\teval-rmse:2.0633                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:2.73959\teval-rmse:2.07227                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.73334\teval-rmse:2.07274                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.72715\teval-rmse:2.06956                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.72024\teval-rmse:2.06954                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.71427\teval-rmse:2.07389                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\ttrain-rmse:2.71188\teval-rmse:2.07376                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.70961\teval-rmse:2.07698                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.70542\teval-rmse:2.0743                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.70215\teval-rmse:2.0784                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.69845\teval-rmse:2.08204                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.69211\teval-rmse:2.08963                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.68802\teval-rmse:2.09219                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.68627\teval-rmse:2.08985                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.68244\teval-rmse:2.09258                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.67675\teval-rmse:2.09536                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.67255\teval-rmse:2.12141                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.66931\teval-rmse:2.14664                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.66358\teval-rmse:2.1445                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.6596\teval-rmse:2.14886                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.65477\teval-rmse:2.15145                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:2.7473\teval-rmse:2.0633\n",
      "\n",
      "\n",
      "loss: 98292952.02470452                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.211636640099186e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.015803189750014664, 'lambda': 0.0018517521998704957, 'learning_rate': 0.47500000000000003, 'max_depth': 6, 'min_child_weight': 0.8013972081131989, 'n_estimators': 352.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:3.83265\teval-rmse:3.27651                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.11818\teval-rmse:2.47731                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.83923\teval-rmse:2.21507                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.72384\teval-rmse:2.16363                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.67147\teval-rmse:2.15784                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.62793\teval-rmse:2.15689                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.59696\teval-rmse:2.18424                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.5798\teval-rmse:2.18216                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.55852\teval-rmse:2.19356                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.53716\teval-rmse:2.22594                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.52238\teval-rmse:2.23088                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.5001\teval-rmse:2.22258                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.47927\teval-rmse:2.26681                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.45239\teval-rmse:2.30696                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.42922\teval-rmse:2.31459                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.41448\teval-rmse:2.30321                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.39897\teval-rmse:2.31702                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.38403\teval-rmse:2.33222                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.36709\teval-rmse:2.33944                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.36022\teval-rmse:2.3545                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.35014\teval-rmse:2.36746                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.33862\teval-rmse:2.38132                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.32062\teval-rmse:2.42684                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.30594\teval-rmse:2.43546                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.29195\teval-rmse:2.43331                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.26842\teval-rmse:2.4343                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.62793\teval-rmse:2.15689\n",
      "\n",
      "\n",
      "loss: 22722829338.575184                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.4837839732266003e-08, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.002872083069170987, 'lambda': 0.011039585406970882, 'learning_rate': 0.375, 'max_depth': 8, 'min_child_weight': 0.1413335371903107, 'n_estimators': 510.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.12197\teval-rmse:3.65843                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.29625\teval-rmse:2.83269                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.86799\teval-rmse:2.44814                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.63481\teval-rmse:2.28522                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.51576\teval-rmse:2.20905                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.43268\teval-rmse:2.19579                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.38296\teval-rmse:2.21512                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.34997\teval-rmse:2.21309                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.32381\teval-rmse:2.21373                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.27866\teval-rmse:2.19938                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.26296\teval-rmse:2.20268                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.222\teval-rmse:2.20901                                                                                \n",
      "\n",
      "[12]\ttrain-rmse:2.19569\teval-rmse:2.20732                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.16826\teval-rmse:2.23486                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.13553\teval-rmse:2.23505                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.12156\teval-rmse:2.23198                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.10737\teval-rmse:2.25243                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.07957\teval-rmse:2.27739                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.05944\teval-rmse:2.28459                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.04904\teval-rmse:2.28367                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.02721\teval-rmse:2.28106                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.00439\teval-rmse:2.28116                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.98228\teval-rmse:2.27345                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.95626\teval-rmse:2.3065                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.92975\teval-rmse:2.3066                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.92414\teval-rmse:2.31476                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.43268\teval-rmse:2.19579\n",
      "\n",
      "\n",
      "loss: 98995966.5099969                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.002179535269122317, 'colsample_bytree': 0.8, 'gamma': 0.0004780736264847486, 'lambda': 6.213766533740466e-06, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 0.4151112023638288, 'n_estimators': 801.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.87754\teval-rmse:4.37697                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.30864\teval-rmse:3.71934                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.89014\teval-rmse:3.23232                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.59055\teval-rmse:2.87018                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.38388\teval-rmse:2.61343                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.23125\teval-rmse:2.42857                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.12819\teval-rmse:2.30926                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.05844\teval-rmse:2.23186                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.00669\teval-rmse:2.1745                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.97086\teval-rmse:2.14104                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.94332\teval-rmse:2.11821                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.92363\teval-rmse:2.10074                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.90882\teval-rmse:2.08797                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.89687\teval-rmse:2.08514                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.88516\teval-rmse:2.0799                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.87535\teval-rmse:2.07553                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.86728\teval-rmse:2.07528                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.85958\teval-rmse:2.07201                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.85277\teval-rmse:2.07012                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.84719\teval-rmse:2.06993                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.84285\teval-rmse:2.06862                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.8397\teval-rmse:2.06744                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.83579\teval-rmse:2.06912                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.83162\teval-rmse:2.06959                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.82936\teval-rmse:2.07129                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.82616\teval-rmse:2.07148                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.82177\teval-rmse:2.07117                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.81862\teval-rmse:2.07082                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.81644\teval-rmse:2.07134                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.81371\teval-rmse:2.07035                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.81184\teval-rmse:2.07329                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.80815\teval-rmse:2.07406                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.80553\teval-rmse:2.07118                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.80229\teval-rmse:2.06941                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.7993\teval-rmse:2.06777                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:2.79613\teval-rmse:2.06397                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.79422\teval-rmse:2.06461                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.79049\teval-rmse:2.05653                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.78591\teval-rmse:2.05683                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.7841\teval-rmse:2.0607                                                                                \n",
      "\n",
      "[40]\ttrain-rmse:2.78117\teval-rmse:2.06081                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.77769\teval-rmse:2.0633                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:2.77425\teval-rmse:2.06157                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.77205\teval-rmse:2.05829                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.77002\teval-rmse:2.05764                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45]\ttrain-rmse:2.76849\teval-rmse:2.05666                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.76532\teval-rmse:2.06066                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.76331\teval-rmse:2.06239                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.76217\teval-rmse:2.06454                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.75884\teval-rmse:2.06512                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.75705\teval-rmse:2.06593                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.75614\teval-rmse:2.0654                                                                               \n",
      "\n",
      "[52]\ttrain-rmse:2.75268\teval-rmse:2.06254                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.75093\teval-rmse:2.06412                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.74867\teval-rmse:2.06432                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.74616\teval-rmse:2.0649                                                                               \n",
      "\n",
      "[56]\ttrain-rmse:2.74329\teval-rmse:2.06467                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.7404\teval-rmse:2.06471                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[37]\ttrain-rmse:2.79049\teval-rmse:2.05653\n",
      "\n",
      "\n",
      "loss: 98164510.26756892                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.715157242800442e-07, 'colsample_bytree': 0.75, 'gamma': 0.0968007333268073, 'lambda': 0.000421224759071865, 'learning_rate': 0.15000000000000002, 'max_depth': 4, 'min_child_weight': 2.573100713831029, 'n_estimators': 595.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:5.05283\teval-rmse:4.58432                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.57459\teval-rmse:4.04331                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.19104\teval-rmse:3.60082                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.88236\teval-rmse:3.24493                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.64576\teval-rmse:2.95991                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.45348\teval-rmse:2.73657                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.30839\teval-rmse:2.55841                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.19598\teval-rmse:2.43289                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.10986\teval-rmse:2.32931                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.04617\teval-rmse:2.25454                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.9902\teval-rmse:2.20138                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.95194\teval-rmse:2.16154                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.92098\teval-rmse:2.1302                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.89671\teval-rmse:2.11461                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.87556\teval-rmse:2.09966                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.85959\teval-rmse:2.08835                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.84566\teval-rmse:2.08702                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.83549\teval-rmse:2.07971                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.8252\teval-rmse:2.07442                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.81705\teval-rmse:2.07978                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.80821\teval-rmse:2.07957                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.80272\teval-rmse:2.0783                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.79669\teval-rmse:2.08084                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.79094\teval-rmse:2.0916                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.78754\teval-rmse:2.09187                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.78158\teval-rmse:2.09355                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.77761\teval-rmse:2.1122                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.77514\teval-rmse:2.11404                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.7715\teval-rmse:2.11451                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.76894\teval-rmse:2.11358                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.76405\teval-rmse:2.10576                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.75937\teval-rmse:2.1046                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.75403\teval-rmse:2.10371                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.75025\teval-rmse:2.11311                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.74531\teval-rmse:2.1135                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:2.74\teval-rmse:2.11569                                                                                 \n",
      "\n",
      "[36]\ttrain-rmse:2.73718\teval-rmse:2.11558                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.73457\teval-rmse:2.11479                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.73113\teval-rmse:2.1141                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[18]\ttrain-rmse:2.8252\teval-rmse:2.07442\n",
      "\n",
      "\n",
      "loss: 98946618.84725972                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.29953773368865e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.03760203142360483, 'lambda': 3.0127132215801832e-05, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 1.3771046555780009, 'n_estimators': 733.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:5.43464\teval-rmse:5.02484                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.23151\teval-rmse:4.81351                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.03932\teval-rmse:4.61601                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.85933\teval-rmse:4.43199                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.69074\teval-rmse:4.25501                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.53299\teval-rmse:4.09475                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.38422\teval-rmse:3.94294                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:4.24556\teval-rmse:3.7985                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:4.11523\teval-rmse:3.66605                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.99346\teval-rmse:3.53913                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.87952\teval-rmse:3.42222                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.77287\teval-rmse:3.31357                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.67176\teval-rmse:3.21271                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.57963\teval-rmse:3.11735                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.49246\teval-rmse:3.02877                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.41231\teval-rmse:2.94803                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.33598\teval-rmse:2.87352                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.26625\teval-rmse:2.80226                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.19916\teval-rmse:2.73785                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.13645\teval-rmse:2.67818                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.07904\teval-rmse:2.62175                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.02758\teval-rmse:2.56977                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.97745\teval-rmse:2.52158                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.9316\teval-rmse:2.47957                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.88915\teval-rmse:2.43811                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.8489\teval-rmse:2.40357                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.81103\teval-rmse:2.3714                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.77689\teval-rmse:2.34104                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.74431\teval-rmse:2.31479                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.71449\teval-rmse:2.28991                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.6864\teval-rmse:2.26744                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.65925\teval-rmse:2.24429                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.63528\teval-rmse:2.22555                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.61157\teval-rmse:2.20836                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.58876\teval-rmse:2.19098                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.5695\teval-rmse:2.17606                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.55143\teval-rmse:2.16252                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.5328\teval-rmse:2.15105                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:2.51437\teval-rmse:2.1417                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:2.4982\teval-rmse:2.13226                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:2.48132\teval-rmse:2.12285                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.466\teval-rmse:2.11502                                                                                \n",
      "\n",
      "[42]\ttrain-rmse:2.45378\teval-rmse:2.10733                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.43826\teval-rmse:2.1017                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:2.4247\teval-rmse:2.0966                                                                                \n",
      "\n",
      "[45]\ttrain-rmse:2.41273\teval-rmse:2.09098                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.40302\teval-rmse:2.08573                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.39099\teval-rmse:2.07802                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.38167\teval-rmse:2.07419                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.37156\teval-rmse:2.07521                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.36266\teval-rmse:2.07098                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.35337\teval-rmse:2.06969                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.3448\teval-rmse:2.06455                                                                               \n",
      "\n",
      "[53]\ttrain-rmse:2.33657\teval-rmse:2.06174                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.3275\teval-rmse:2.05835                                                                               \n",
      "\n",
      "[55]\ttrain-rmse:2.32099\teval-rmse:2.0563                                                                               \n",
      "\n",
      "[56]\ttrain-rmse:2.30971\teval-rmse:2.053                                                                                \n",
      "\n",
      "[57]\ttrain-rmse:2.30147\teval-rmse:2.05223                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.29296\teval-rmse:2.0508                                                                               \n",
      "\n",
      "[59]\ttrain-rmse:2.28513\teval-rmse:2.04809                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.27957\teval-rmse:2.04768                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.27226\teval-rmse:2.047                                                                                \n",
      "\n",
      "[62]\ttrain-rmse:2.26523\teval-rmse:2.0455                                                                               \n",
      "\n",
      "[63]\ttrain-rmse:2.25873\teval-rmse:2.0446                                                                               \n",
      "\n",
      "[64]\ttrain-rmse:2.24954\teval-rmse:2.04433                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.2439\teval-rmse:2.04482                                                                               \n",
      "\n",
      "[66]\ttrain-rmse:2.23899\teval-rmse:2.04861                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67]\ttrain-rmse:2.23311\teval-rmse:2.05082                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:2.22952\teval-rmse:2.05064                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.22307\teval-rmse:2.05076                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:2.21798\teval-rmse:2.0504                                                                               \n",
      "\n",
      "[71]\ttrain-rmse:2.21364\teval-rmse:2.05096                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:2.20932\teval-rmse:2.05038                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:2.20388\teval-rmse:2.05077                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:2.19689\teval-rmse:2.05081                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:2.19168\teval-rmse:2.04969                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:2.18738\teval-rmse:2.05212                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:2.18458\teval-rmse:2.05173                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:2.17996\teval-rmse:2.05093                                                                              \n",
      "\n",
      "[79]\ttrain-rmse:2.17576\teval-rmse:2.05456                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:2.16836\teval-rmse:2.0559                                                                               \n",
      "\n",
      "[81]\ttrain-rmse:2.16163\teval-rmse:2.05591                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:2.15498\teval-rmse:2.05503                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:2.14997\teval-rmse:2.05418                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:2.14722\teval-rmse:2.0538                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[64]\ttrain-rmse:2.24954\teval-rmse:2.04433\n",
      "\n",
      "\n",
      "loss: 97412527.84966764                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.08988244701816564, 'colsample_bytree': 0.65, 'gamma': 8.779409385568275e-05, 'lambda': 0.12270793647275142, 'learning_rate': 0.5, 'max_depth': 6, 'min_child_weight': 0.29364661207359144, 'n_estimators': 214.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:3.77155\teval-rmse:3.161                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.08229\teval-rmse:2.39011                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.8352\teval-rmse:2.15857                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.73416\teval-rmse:2.13225                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.69536\teval-rmse:2.13628                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.66084\teval-rmse:2.13521                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.64481\teval-rmse:2.1288                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.61642\teval-rmse:2.15898                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.59275\teval-rmse:2.14583                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.57566\teval-rmse:2.15938                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.55484\teval-rmse:2.16891                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.53473\teval-rmse:2.15203                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.52024\teval-rmse:2.14216                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.49869\teval-rmse:2.16802                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.48109\teval-rmse:2.168                                                                                \n",
      "\n",
      "[15]\ttrain-rmse:2.46539\teval-rmse:2.17099                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.45132\teval-rmse:2.17752                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.4379\teval-rmse:2.1939                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:2.43077\teval-rmse:2.19768                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.41515\teval-rmse:2.19778                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.40118\teval-rmse:2.42601                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.3901\teval-rmse:2.44766                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.37893\teval-rmse:2.44149                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.36453\teval-rmse:2.44357                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.34579\teval-rmse:2.4412                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.33579\teval-rmse:2.43492                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.31757\teval-rmse:2.4228                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.64481\teval-rmse:2.1288\n",
      "\n",
      "\n",
      "loss: 97230626.40940778                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.01260599300882652, 'colsample_bytree': 0.8, 'gamma': 0.9870871299370907, 'lambda': 0.4833764219728304, 'learning_rate': 0.25, 'max_depth': 5, 'min_child_weight': 2.25292304923015, 'n_estimators': 637.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.65809\teval-rmse:4.15864                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.98985\teval-rmse:3.39576                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.54326\teval-rmse:2.88442                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.25826\teval-rmse:2.55787                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.08043\teval-rmse:2.35154                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.96394\teval-rmse:2.22831                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.8915\teval-rmse:2.1535                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:2.83887\teval-rmse:2.11183                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.80457\teval-rmse:2.09338                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.78038\teval-rmse:2.08226                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.75943\teval-rmse:2.08446                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.73714\teval-rmse:2.08989                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.72613\teval-rmse:2.08419                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.7152\teval-rmse:2.08688                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.70654\teval-rmse:2.09059                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.69369\teval-rmse:2.09509                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.68103\teval-rmse:2.0947                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.66916\teval-rmse:2.09216                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.65819\teval-rmse:2.09499                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.64355\teval-rmse:2.10493                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.63177\teval-rmse:2.11238                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.62223\teval-rmse:2.11639                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.61591\teval-rmse:2.1187                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.61147\teval-rmse:2.1173                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.60654\teval-rmse:2.10976                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.59781\teval-rmse:2.11728                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.59069\teval-rmse:2.12557                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.58249\teval-rmse:2.14568                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.57611\teval-rmse:2.14383                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.56841\teval-rmse:2.14424                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.78038\teval-rmse:2.08226\n",
      "\n",
      "\n",
      "loss: 98370839.53218268                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00025692281796541104, 'colsample_bytree': 0.75, 'gamma': 0.007385552107166706, 'lambda': 0.01108977950528208, 'learning_rate': 0.17500000000000002, 'max_depth': 8, 'min_child_weight': 3.6358097649280534, 'n_estimators': 554.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.91039\teval-rmse:4.4812                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.33334\teval-rmse:3.87311                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.88143\teval-rmse:3.39668                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.53077\teval-rmse:3.03403                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.26462\teval-rmse:2.75369                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.05794\teval-rmse:2.55974                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.90342\teval-rmse:2.41422                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.78201\teval-rmse:2.318                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.6922\teval-rmse:2.24529                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.62689\teval-rmse:2.19785                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.57366\teval-rmse:2.16911                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.52479\teval-rmse:2.13266                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.48253\teval-rmse:2.10985                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.44906\teval-rmse:2.10565                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.42834\teval-rmse:2.10067                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.40983\teval-rmse:2.09406                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.38429\teval-rmse:2.08829                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.36028\teval-rmse:2.08767                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.34465\teval-rmse:2.0857                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.32305\teval-rmse:2.09346                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.30777\teval-rmse:2.09906                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.29586\teval-rmse:2.09815                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.2762\teval-rmse:2.10521                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.25754\teval-rmse:2.10635                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.24473\teval-rmse:2.11142                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.23144\teval-rmse:2.11573                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.22445\teval-rmse:2.11853                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.21224\teval-rmse:2.12135                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.20523\teval-rmse:2.12109                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.18963\teval-rmse:2.12473                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.18191\teval-rmse:2.12258                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.16624\teval-rmse:2.12023                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.15618\teval-rmse:2.11448                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.14769\teval-rmse:2.10798                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.13439\teval-rmse:2.112                                                                                \n",
      "\n",
      "[35]\ttrain-rmse:2.12121\teval-rmse:2.11504                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36]\ttrain-rmse:2.10982\teval-rmse:2.11374                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.09605\teval-rmse:2.11463                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.07368\teval-rmse:2.12445                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[18]\ttrain-rmse:2.34465\teval-rmse:2.0857\n",
      "\n",
      "\n",
      "loss: 97142862.4264425                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.3000187777399792, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.0006110225009018853, 'lambda': 5.521490460845081e-05, 'learning_rate': 0.275, 'max_depth': 7, 'min_child_weight': 5.8107139046268665, 'n_estimators': 824.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.52596\teval-rmse:4.05642                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.78906\teval-rmse:3.25966                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.31211\teval-rmse:2.74714                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.02154\teval-rmse:2.4488                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.83787\teval-rmse:2.27255                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.71875\teval-rmse:2.18027                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.63164\teval-rmse:2.12605                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.56974\teval-rmse:2.11083                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.52983\teval-rmse:2.09767                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.49454\teval-rmse:2.08816                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.4678\teval-rmse:2.08657                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.44485\teval-rmse:2.09094                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.42281\teval-rmse:2.09193                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.40676\teval-rmse:2.09289                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.379\teval-rmse:2.10654                                                                                \n",
      "\n",
      "[15]\ttrain-rmse:2.35798\teval-rmse:2.11263                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.34417\teval-rmse:2.11982                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.32403\teval-rmse:2.11853                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.31305\teval-rmse:2.11085                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.29797\teval-rmse:2.10378                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.28856\teval-rmse:2.1124                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.26747\teval-rmse:2.12378                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.25486\teval-rmse:2.12546                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.24184\teval-rmse:2.13045                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.22566\teval-rmse:2.12863                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.20515\teval-rmse:2.12795                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.19616\teval-rmse:2.13322                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.18484\teval-rmse:2.13568                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.17419\teval-rmse:2.13993                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.16572\teval-rmse:2.14294                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.14766\teval-rmse:2.14464                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.4678\teval-rmse:2.08657\n",
      "\n",
      "\n",
      "loss: 97430442.173183                                                                                                  \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.6654860988270198e-06, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.24073497370276337, 'lambda': 0.09707612916372982, 'learning_rate': 0.125, 'max_depth': 3, 'min_child_weight': 0.17455322659604125, 'n_estimators': 722.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:5.16226\teval-rmse:4.69668                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.75323\teval-rmse:4.23215                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.41257\teval-rmse:3.83749                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.12679\teval-rmse:3.50142                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.89429\teval-rmse:3.22466                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.70052\teval-rmse:2.99458                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.54476\teval-rmse:2.80748                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.41772\teval-rmse:2.65334                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.31412\teval-rmse:2.52483                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.23299\teval-rmse:2.42704                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.16777\teval-rmse:2.34591                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.11326\teval-rmse:2.28274                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.07074\teval-rmse:2.23141                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.03461\teval-rmse:2.19348                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.00629\teval-rmse:2.16594                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.98322\teval-rmse:2.14193                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.9646\teval-rmse:2.12565                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.948\teval-rmse:2.10863                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:2.93501\teval-rmse:2.09925                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.92381\teval-rmse:2.09064                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.91421\teval-rmse:2.08171                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.90596\teval-rmse:2.08018                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.89905\teval-rmse:2.07826                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.89267\teval-rmse:2.07836                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.88818\teval-rmse:2.07762                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.88311\teval-rmse:2.07928                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.87782\teval-rmse:2.07461                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.87091\teval-rmse:2.07324                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.8667\teval-rmse:2.07458                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.8639\teval-rmse:2.07367                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.86043\teval-rmse:2.07301                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.85723\teval-rmse:2.07287                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.85458\teval-rmse:2.07127                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.85022\teval-rmse:2.07385                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.84812\teval-rmse:2.07517                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.84349\teval-rmse:2.07394                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.8409\teval-rmse:2.07304                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.83783\teval-rmse:2.07286                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.83595\teval-rmse:2.07408                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.83365\teval-rmse:2.07512                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.83192\teval-rmse:2.07837                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.82956\teval-rmse:2.07837                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.82682\teval-rmse:2.07984                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.82512\teval-rmse:2.07972                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.82282\teval-rmse:2.07901                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.8206\teval-rmse:2.07897                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.81768\teval-rmse:2.07617                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.81611\teval-rmse:2.07601                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.81394\teval-rmse:2.07613                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.81248\teval-rmse:2.07668                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.81077\teval-rmse:2.07728                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.80934\teval-rmse:2.0769                                                                               \n",
      "\n",
      "[52]\ttrain-rmse:2.80712\teval-rmse:2.07731                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[32]\ttrain-rmse:2.85458\teval-rmse:2.07127\n",
      "\n",
      "\n",
      "loss: 99108426.32427508                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.9910271166003584, 'colsample_bytree': 0.9, 'gamma': 3.3437089707169785e-05, 'lambda': 0.00021958589152055975, 'learning_rate': 0.375, 'max_depth': 8, 'min_child_weight': 7.58586286237163, 'n_estimators': 311.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.12605\teval-rmse:3.65208                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.30767\teval-rmse:2.78963                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.88972\teval-rmse:2.3865                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.68188\teval-rmse:2.22521                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.56853\teval-rmse:2.15402                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.49664\teval-rmse:2.12418                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.44469\teval-rmse:2.11951                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.38921\teval-rmse:2.13822                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.3533\teval-rmse:2.15902                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.32813\teval-rmse:2.16089                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.29081\teval-rmse:2.19064                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.2678\teval-rmse:2.20727                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.2456\teval-rmse:2.21196                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.22358\teval-rmse:2.21212                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.21104\teval-rmse:2.21279                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.18479\teval-rmse:2.23146                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.16665\teval-rmse:2.24523                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.14002\teval-rmse:2.25207                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.12098\teval-rmse:2.24861                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.11069\teval-rmse:2.25529                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.09195\teval-rmse:2.25907                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.06645\teval-rmse:2.26249                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.04962\teval-rmse:2.2641                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.03299\teval-rmse:2.27036                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.01308\teval-rmse:2.27257                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\ttrain-rmse:2.00594\teval-rmse:2.27785                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.99464\teval-rmse:2.27731                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.44469\teval-rmse:2.11951\n",
      "\n",
      "\n",
      "loss: 96952196.2228397                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.043077539042919985, 'colsample_bytree': 0.9, 'gamma': 1.1500799671620507e-05, 'lambda': 1.0569404317432677e-05, 'learning_rate': 0.4, 'max_depth': 4, 'min_child_weight': 4.830563864217787, 'n_estimators': 367.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.14895\teval-rmse:3.55163                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.42893\teval-rmse:2.68797                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.09836\teval-rmse:2.30255                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.95185\teval-rmse:2.15411                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.8823\teval-rmse:2.08524                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.84554\teval-rmse:2.06266                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.81475\teval-rmse:2.07431                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.79908\teval-rmse:2.07442                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.78379\teval-rmse:2.07393                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.77484\teval-rmse:2.07343                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.76317\teval-rmse:2.08818                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.7526\teval-rmse:2.08552                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.74612\teval-rmse:2.08242                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.73715\teval-rmse:2.09151                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.72423\teval-rmse:2.09749                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.71597\teval-rmse:2.09284                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.70745\teval-rmse:2.10534                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.69612\teval-rmse:2.09361                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.68994\teval-rmse:2.0945                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.68063\teval-rmse:2.09304                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.66932\teval-rmse:2.1184                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.65887\teval-rmse:2.11712                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.65448\teval-rmse:2.11569                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.64132\teval-rmse:2.12156                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.63179\teval-rmse:2.12528                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.62795\teval-rmse:2.12703                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.84554\teval-rmse:2.06266\n",
      "\n",
      "\n",
      "loss: 97693276.31550446                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.9057769413062283, 'colsample_bytree': 0.9500000000000001, 'gamma': 3.002931424720002e-05, 'lambda': 4.38927584292889e-06, 'learning_rate': 0.47500000000000003, 'max_depth': 7, 'min_child_weight': 7.488392945624981, 'n_estimators': 306.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:3.79896\teval-rmse:3.27058                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.04964\teval-rmse:2.44823                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.76587\teval-rmse:2.19798                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.63421\teval-rmse:2.10211                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.57994\teval-rmse:2.0872                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.53393\teval-rmse:2.09618                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.5156\teval-rmse:2.09986                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.49784\teval-rmse:2.1001                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.47372\teval-rmse:2.10155                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.43971\teval-rmse:2.11905                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.41213\teval-rmse:2.12345                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.3798\teval-rmse:2.12626                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.34708\teval-rmse:2.14526                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.32874\teval-rmse:2.16096                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.31785\teval-rmse:2.16334                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.30884\teval-rmse:2.18526                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.29233\teval-rmse:2.1934                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.28191\teval-rmse:2.20828                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.24786\teval-rmse:2.21871                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.2204\teval-rmse:2.23529                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.19822\teval-rmse:2.26245                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.17838\teval-rmse:2.27844                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.16005\teval-rmse:2.285                                                                                \n",
      "\n",
      "[23]\ttrain-rmse:2.1447\teval-rmse:2.27804                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.12286\teval-rmse:2.28352                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.57994\teval-rmse:2.0872\n",
      "\n",
      "\n",
      "loss: 97208567.58623286                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.0223217087329098e-08, 'colsample_bytree': 0.9, 'gamma': 6.640988225487123e-07, 'lambda': 1.162592955933414e-06, 'learning_rate': 0.375, 'max_depth': 8, 'min_child_weight': 3.978617426325512, 'n_estimators': 472.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.11984\teval-rmse:3.65275                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.29588\teval-rmse:2.80149                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.87496\teval-rmse:2.41902                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.66335\teval-rmse:2.25594                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.52423\teval-rmse:2.16883                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.43697\teval-rmse:2.16003                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.37777\teval-rmse:2.16634                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.34742\teval-rmse:2.16054                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.31585\teval-rmse:2.16457                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.29394\teval-rmse:2.16455                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.25456\teval-rmse:2.18316                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.22627\teval-rmse:2.18203                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.18889\teval-rmse:2.17781                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.1735\teval-rmse:2.18592                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.15286\teval-rmse:2.18979                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.13666\teval-rmse:2.18607                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.10534\teval-rmse:2.1924                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.08023\teval-rmse:2.19294                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.04993\teval-rmse:2.22156                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.01908\teval-rmse:2.23516                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.99844\teval-rmse:2.2455                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.98762\teval-rmse:2.24467                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.97056\teval-rmse:2.24881                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.94287\teval-rmse:2.25363                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.92585\teval-rmse:2.25055                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.9048\teval-rmse:2.26104                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.43697\teval-rmse:2.16003\n",
      "\n",
      "\n",
      "loss: 97635697.80408813                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.1674473024972392, 'colsample_bytree': 0.75, 'gamma': 4.2454441160795785e-05, 'lambda': 0.00025241876435846565, 'learning_rate': 0.325, 'max_depth': 6, 'min_child_weight': 5.093438728496403, 'n_estimators': 470.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.35751\teval-rmse:3.85279                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.60947\teval-rmse:3.00751                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.18716\teval-rmse:2.53743                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.95406\teval-rmse:2.30007                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.82367\teval-rmse:2.17508                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.74008\teval-rmse:2.12541                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.69209\teval-rmse:2.09668                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.6633\teval-rmse:2.0902                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.63586\teval-rmse:2.10113                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.61837\teval-rmse:2.10058                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.59437\teval-rmse:2.11888                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.58092\teval-rmse:2.12677                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.56517\teval-rmse:2.12632                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.54981\teval-rmse:2.12597                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.54296\teval-rmse:2.12586                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.52944\teval-rmse:2.1338                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.51786\teval-rmse:2.15386                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.49816\teval-rmse:2.15408                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.48658\teval-rmse:2.16102                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.47063\teval-rmse:2.16857                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.45637\teval-rmse:2.17212                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.44497\teval-rmse:2.18503                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.43633\teval-rmse:2.18953                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.4172\teval-rmse:2.18391                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.40732\teval-rmse:2.19229                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\ttrain-rmse:2.39863\teval-rmse:2.20258                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.39366\teval-rmse:2.206                                                                                \n",
      "\n",
      "[27]\ttrain-rmse:2.38862\teval-rmse:2.21205                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.6633\teval-rmse:2.0902\n",
      "\n",
      "\n",
      "loss: 97718266.79571615                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.951840974042153, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.00019349188507666689, 'lambda': 0.0007901035992121819, 'learning_rate': 0.45, 'max_depth': 8, 'min_child_weight': 7.942803532442134, 'n_estimators': 234.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:3.85494\teval-rmse:3.36122                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.05049\teval-rmse:2.54478                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.70903\teval-rmse:2.24453                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.53454\teval-rmse:2.15127                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.43375\teval-rmse:2.11232                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.37923\teval-rmse:2.12823                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.35045\teval-rmse:2.12364                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.31808\teval-rmse:2.12727                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.28791\teval-rmse:2.13447                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.24951\teval-rmse:2.14833                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.21877\teval-rmse:2.17219                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.20522\teval-rmse:2.17563                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.17819\teval-rmse:2.18102                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.16136\teval-rmse:2.19513                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.14826\teval-rmse:2.21171                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.12574\teval-rmse:2.25433                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.11325\teval-rmse:2.25417                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.09585\teval-rmse:2.25226                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.04883\teval-rmse:2.27136                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.01796\teval-rmse:2.29596                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.00472\teval-rmse:2.28772                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.98605\teval-rmse:2.28687                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.96859\teval-rmse:2.31167                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.95583\teval-rmse:2.31571                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.92666\teval-rmse:2.31679                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.43375\teval-rmse:2.11232\n",
      "\n",
      "\n",
      "loss: 97305553.03066957                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.8861052596761324e-08, 'colsample_bytree': 0.8500000000000001, 'gamma': 3.397177397096346e-06, 'lambda': 0.00014180028327454602, 'learning_rate': 0.35000000000000003, 'max_depth': 3, 'min_child_weight': 2.9696066931540397, 'n_estimators': 382.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.3452\teval-rmse:3.75963                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.64305\teval-rmse:2.91836                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.27201\teval-rmse:2.46852                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.08361\teval-rmse:2.24443                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.99545\teval-rmse:2.15654                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.94462\teval-rmse:2.11457                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.91894\teval-rmse:2.10296                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.90168\teval-rmse:2.10116                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.88959\teval-rmse:2.1034                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.87409\teval-rmse:2.0979                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.86596\teval-rmse:2.09513                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.85398\teval-rmse:2.09084                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.8463\teval-rmse:2.09236                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.84257\teval-rmse:2.08996                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.83483\teval-rmse:2.08945                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.83079\teval-rmse:2.08893                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.82217\teval-rmse:2.09739                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.81708\teval-rmse:2.09574                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.81215\teval-rmse:2.09514                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.80441\teval-rmse:2.09319                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.79744\teval-rmse:2.10275                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.79133\teval-rmse:2.09862                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.7863\teval-rmse:2.10225                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.78164\teval-rmse:2.09847                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.77702\teval-rmse:2.10637                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.77381\teval-rmse:2.10175                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.77082\teval-rmse:2.10122                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.76663\teval-rmse:2.10136                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.76175\teval-rmse:2.09522                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.75731\teval-rmse:2.10033                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.7524\teval-rmse:2.09838                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.75051\teval-rmse:2.11467                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.74904\teval-rmse:2.11436                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.74601\teval-rmse:2.13845                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.74216\teval-rmse:2.17932                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.74033\teval-rmse:2.17983                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.83079\teval-rmse:2.08893\n",
      "\n",
      "\n",
      "loss: 98283808.1493265                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.003319227495938492, 'colsample_bytree': 0.8, 'gamma': 1.1795093682016228e-06, 'lambda': 0.002664945335649215, 'learning_rate': 0.07500000000000001, 'max_depth': 5, 'min_child_weight': 2.066542295317188, 'n_estimators': 300.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:5.34428\teval-rmse:4.91404                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.06767\teval-rmse:4.61024                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.81607\teval-rmse:4.33312                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.58968\teval-rmse:4.08179                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.38729\teval-rmse:3.85308                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.20353\teval-rmse:3.64612                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.03857\teval-rmse:3.45902                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.89174\teval-rmse:3.29259                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.76082\teval-rmse:3.14083                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.64529\teval-rmse:3.00484                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.54021\teval-rmse:2.88582                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.44862\teval-rmse:2.77935                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.36493\teval-rmse:2.68575                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.29177\teval-rmse:2.60315                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.22709\teval-rmse:2.52926                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.17141\teval-rmse:2.46272                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.12034\teval-rmse:2.40643                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.07436\teval-rmse:2.3564                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:3.03435\teval-rmse:2.31305                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.99906\teval-rmse:2.2753                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.9682\teval-rmse:2.24462                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.9404\teval-rmse:2.21651                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.91627\teval-rmse:2.19093                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.89388\teval-rmse:2.16885                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.87511\teval-rmse:2.15206                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.85837\teval-rmse:2.13771                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.84301\teval-rmse:2.12274                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.82973\teval-rmse:2.11187                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.81768\teval-rmse:2.10244                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.80714\teval-rmse:2.09184                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.79689\teval-rmse:2.08645                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.7864\teval-rmse:2.07893                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.77752\teval-rmse:2.07416                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.76932\teval-rmse:2.07124                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.76228\teval-rmse:2.06672                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.75526\teval-rmse:2.06179                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.74974\teval-rmse:2.05754                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.74312\teval-rmse:2.05371                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.73744\teval-rmse:2.05341                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.73085\teval-rmse:2.05124                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.7262\teval-rmse:2.04904                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.72253\teval-rmse:2.04783                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.71869\teval-rmse:2.04598                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.71411\teval-rmse:2.04475                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.70989\teval-rmse:2.04419                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.70537\teval-rmse:2.04186                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.69939\teval-rmse:2.04173                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.69516\teval-rmse:2.04106                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48]\ttrain-rmse:2.69143\teval-rmse:2.0408                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:2.68812\teval-rmse:2.04194                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.68524\teval-rmse:2.04132                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.68148\teval-rmse:2.04216                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.67771\teval-rmse:2.04166                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.67356\teval-rmse:2.04383                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.66876\teval-rmse:2.04324                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.66596\teval-rmse:2.04518                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.66385\teval-rmse:2.04382                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.66132\teval-rmse:2.04399                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.65673\teval-rmse:2.04436                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.65278\teval-rmse:2.04431                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.65049\teval-rmse:2.04636                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.64711\teval-rmse:2.04762                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.64417\teval-rmse:2.04989                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.64076\teval-rmse:2.04893                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.63961\teval-rmse:2.04934                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.63833\teval-rmse:2.04893                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.63559\teval-rmse:2.04827                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.63173\teval-rmse:2.04551                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:2.62888\teval-rmse:2.046                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[48]\ttrain-rmse:2.69143\teval-rmse:2.0408\n",
      "\n",
      "\n",
      "loss: 98339987.15637448                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.4091153664958149, 'colsample_bytree': 0.65, 'gamma': 9.74581877922713e-05, 'lambda': 6.37414641880175e-05, 'learning_rate': 0.42500000000000004, 'max_depth': 8, 'min_child_weight': 1.4910652473014823, 'n_estimators': 148.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:3.94737\teval-rmse:3.44751                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.13062\teval-rmse:2.6368                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.75204\teval-rmse:2.32862                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.58204\teval-rmse:2.21728                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.50951\teval-rmse:2.18339                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.46519\teval-rmse:2.18044                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.41975\teval-rmse:2.20969                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.38708\teval-rmse:2.21982                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.35263\teval-rmse:2.25576                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.30539\teval-rmse:2.27613                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.2894\teval-rmse:2.28762                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.2765\teval-rmse:2.27616                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.24506\teval-rmse:2.29423                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.19673\teval-rmse:2.32619                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.1615\teval-rmse:2.3428                                                                                \n",
      "\n",
      "[15]\ttrain-rmse:2.14712\teval-rmse:2.34653                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.11836\teval-rmse:2.34924                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.10099\teval-rmse:2.35253                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.05385\teval-rmse:2.34206                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.01512\teval-rmse:2.35717                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.99796\teval-rmse:2.35192                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.97247\teval-rmse:2.36679                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.95077\teval-rmse:2.36864                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.91932\teval-rmse:2.37608                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.89289\teval-rmse:2.38826                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.87088\teval-rmse:2.39806                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.46519\teval-rmse:2.18044\n",
      "\n",
      "\n",
      "loss: 97181760.74047223                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0013176893001036814, 'colsample_bytree': 0.9, 'gamma': 6.41103540657257e-08, 'lambda': 1.2597428832251913e-05, 'learning_rate': 0.4, 'max_depth': 7, 'min_child_weight': 0.9230543382350624, 'n_estimators': 537.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.05485\teval-rmse:3.55362                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.25488\teval-rmse:2.68484                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.88539\teval-rmse:2.30331                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.7051\teval-rmse:2.16039                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.61974\teval-rmse:2.11676                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.56166\teval-rmse:2.1102                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.51797\teval-rmse:2.10824                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.47852\teval-rmse:2.11164                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.44984\teval-rmse:2.13457                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.42239\teval-rmse:2.16045                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.40679\teval-rmse:2.15669                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.38574\teval-rmse:2.16083                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.36967\teval-rmse:2.16013                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.35642\teval-rmse:2.1874                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.33899\teval-rmse:2.20175                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.3145\teval-rmse:2.20783                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.29688\teval-rmse:2.21029                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.26888\teval-rmse:2.22396                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.25025\teval-rmse:2.22626                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.22591\teval-rmse:2.23338                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.20958\teval-rmse:2.24213                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.19497\teval-rmse:2.24539                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.17849\teval-rmse:2.24832                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.15702\teval-rmse:2.24592                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.14836\teval-rmse:2.24618                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.13885\teval-rmse:2.25212                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.13368\teval-rmse:2.25154                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.51797\teval-rmse:2.10824\n",
      "\n",
      "\n",
      "loss: 136961318.11598444                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.07275271959333236, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.001103771708616435, 'lambda': 0.00024123337796321515, 'learning_rate': 0.5, 'max_depth': 8, 'min_child_weight': 3.388165603977954, 'n_estimators': 463.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:3.67643\teval-rmse:3.18548                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:2.91078\teval-rmse:2.39093                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.62396\teval-rmse:2.16515                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.49587\teval-rmse:2.11415                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.43421\teval-rmse:2.10685                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.37734\teval-rmse:2.1033                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.33847\teval-rmse:2.10442                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.31149\teval-rmse:2.11094                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.27378\teval-rmse:2.12433                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.24379\teval-rmse:2.1266                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.19494\teval-rmse:2.14707                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.15409\teval-rmse:2.15015                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.14173\teval-rmse:2.14779                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.12673\teval-rmse:2.1694                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.08456\teval-rmse:2.18456                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.071\teval-rmse:2.18035                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:2.04813\teval-rmse:2.20725                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.02557\teval-rmse:2.22029                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.99505\teval-rmse:2.22168                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.97297\teval-rmse:2.2422                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.93747\teval-rmse:2.24144                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.91299\teval-rmse:2.25882                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.87441\teval-rmse:2.25485                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.86369\teval-rmse:2.25636                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.85047\teval-rmse:2.26056                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.84037\teval-rmse:2.26474                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.37734\teval-rmse:2.1033\n",
      "\n",
      "\n",
      "loss: 97196143.61353402                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.671213807911606e-07, 'colsample_bytree': 0.6000000000000001, 'gamma': 0.00033371212028024763, 'lambda': 0.004740889556281283, 'learning_rate': 0.45, 'max_depth': 4, 'min_child_weight': 9.401179016675256, 'n_estimators': 253.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:3.98607\teval-rmse:3.36058                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.29531\teval-rmse:2.53068                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.02681\teval-rmse:2.22105                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.91628\teval-rmse:2.12593                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\ttrain-rmse:2.8695\teval-rmse:2.09552                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.84442\teval-rmse:2.10225                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.8259\teval-rmse:2.10157                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.81374\teval-rmse:2.10231                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.80042\teval-rmse:2.10194                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.79486\teval-rmse:2.10447                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.78424\teval-rmse:2.11043                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.77696\teval-rmse:2.11223                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.76293\teval-rmse:2.11437                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.75287\teval-rmse:2.10113                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.74822\teval-rmse:2.09553                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.74075\teval-rmse:2.10661                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.73186\teval-rmse:2.10021                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.72634\teval-rmse:2.09611                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.72076\teval-rmse:2.09615                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.71563\teval-rmse:2.09622                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.70957\teval-rmse:2.09582                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.70408\teval-rmse:2.10211                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.69914\teval-rmse:2.10678                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.69198\teval-rmse:2.10786                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.68111\teval-rmse:2.10637                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.8695\teval-rmse:2.09552\n",
      "\n",
      "\n",
      "loss: 98400841.40161155                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.18705996589383073, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.493774741305653e-05, 'lambda': 0.0010285484532882461, 'learning_rate': 0.225, 'max_depth': 9, 'min_child_weight': 5.6385925708333104, 'n_estimators': 106.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.68891\teval-rmse:4.26259                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.98434\teval-rmse:3.55304                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.46519\teval-rmse:3.04405                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.09733\teval-rmse:2.70998                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.82875\teval-rmse:2.47805                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.64402\teval-rmse:2.33088                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.50591\teval-rmse:2.22951                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.40974\teval-rmse:2.17316                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.33467\teval-rmse:2.14163                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.27326\teval-rmse:2.12486                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.22978\teval-rmse:2.11368                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.18724\teval-rmse:2.10646                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.16249\teval-rmse:2.10603                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.12039\teval-rmse:2.12023                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.09085\teval-rmse:2.11946                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.06322\teval-rmse:2.12346                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.04185\teval-rmse:2.1274                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.0238\teval-rmse:2.12992                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.0042\teval-rmse:2.13285                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.97434\teval-rmse:2.13326                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.96387\teval-rmse:2.12953                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.93974\teval-rmse:2.13108                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.9113\teval-rmse:2.1393                                                                                \n",
      "\n",
      "[23]\ttrain-rmse:1.89416\teval-rmse:2.14618                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.8856\teval-rmse:2.15293                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.86158\teval-rmse:2.15634                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.8483\teval-rmse:2.15709                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.83337\teval-rmse:2.15893                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.82206\teval-rmse:2.16212                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.80485\teval-rmse:2.16895                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.7829\teval-rmse:2.17009                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:1.77039\teval-rmse:2.17292                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.75889\teval-rmse:2.17333                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.16249\teval-rmse:2.10603\n",
      "\n",
      "\n",
      "loss: 96632516.17688264                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.19015670110873628, 'colsample_bytree': 0.7000000000000001, 'gamma': 3.2610560092842935e-07, 'lambda': 0.0008268570538317, 'learning_rate': 0.225, 'max_depth': 9, 'min_child_weight': 5.395842968655858, 'n_estimators': 100.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.69032\teval-rmse:4.26466                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.98571\teval-rmse:3.54944                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.47251\teval-rmse:3.04262                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.09843\teval-rmse:2.69846                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.82705\teval-rmse:2.46702                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.64541\teval-rmse:2.31609                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.50923\teval-rmse:2.22675                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.41377\teval-rmse:2.16608                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.3458\teval-rmse:2.13895                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.28331\teval-rmse:2.1228                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.23582\teval-rmse:2.11464                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.19085\teval-rmse:2.10462                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.15849\teval-rmse:2.09574                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.13067\teval-rmse:2.09379                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.10108\teval-rmse:2.10616                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.07748\teval-rmse:2.10691                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.03668\teval-rmse:2.11801                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.0168\teval-rmse:2.12012                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:1.98367\teval-rmse:2.13125                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.9713\teval-rmse:2.12697                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.95747\teval-rmse:2.12895                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.92961\teval-rmse:2.1393                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.91945\teval-rmse:2.14102                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.89907\teval-rmse:2.14172                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.8748\teval-rmse:2.14316                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.85002\teval-rmse:2.1482                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.83649\teval-rmse:2.13984                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.81176\teval-rmse:2.14308                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.79182\teval-rmse:2.14836                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.78791\teval-rmse:2.14979                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.77568\teval-rmse:2.15416                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.764\teval-rmse:2.15282                                                                                \n",
      "\n",
      "[32]\ttrain-rmse:1.75385\teval-rmse:2.15156                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.74684\teval-rmse:2.15418                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.13067\teval-rmse:2.09379\n",
      "\n",
      "\n",
      "loss: 96711827.97970463                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.015424885625015579, 'colsample_bytree': 0.65, 'gamma': 6.518253697678085e-06, 'lambda': 0.01886024531942054, 'learning_rate': 0.125, 'max_depth': 9, 'min_child_weight': 4.353223874508357, 'n_estimators': 393.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.10964\teval-rmse:4.69506                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.64672\teval-rmse:4.22371                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.25183\teval-rmse:3.82416                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.91734\teval-rmse:3.49016                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.63662\teval-rmse:3.21887                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.40062\teval-rmse:2.98797                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.20149\teval-rmse:2.7991                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.03251\teval-rmse:2.64252                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.89452\teval-rmse:2.5193                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.78118\teval-rmse:2.4196                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.68791\teval-rmse:2.33797                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.59982\teval-rmse:2.28045                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.52926\teval-rmse:2.22988                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.46634\teval-rmse:2.194                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:2.41834\teval-rmse:2.1616                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.37218\teval-rmse:2.13893                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.32981\teval-rmse:2.12179                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.28852\teval-rmse:2.10902                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.25001\teval-rmse:2.10122                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.22295\teval-rmse:2.09772                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.18862\teval-rmse:2.09494                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.17159\teval-rmse:2.08964                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.14914\teval-rmse:2.09192                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.12966\teval-rmse:2.09436                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24]\ttrain-rmse:2.11397\teval-rmse:2.09145                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.09862\teval-rmse:2.09092                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.08373\teval-rmse:2.09308                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.06577\teval-rmse:2.0927                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.05481\teval-rmse:2.08932                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.04305\teval-rmse:2.09011                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.02658\teval-rmse:2.08882                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.00776\teval-rmse:2.09096                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.99626\teval-rmse:2.09209                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.98862\teval-rmse:2.09051                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.98441\teval-rmse:2.09008                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.97865\teval-rmse:2.08992                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.96144\teval-rmse:2.09402                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.94943\teval-rmse:2.09396                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.92922\teval-rmse:2.09403                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:1.90756\teval-rmse:2.09637                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:1.90339\teval-rmse:2.09618                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:1.89568\teval-rmse:2.09436                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:1.89161\teval-rmse:2.09511                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:1.88206\teval-rmse:2.09865                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:1.87394\teval-rmse:2.09815                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:1.86764\teval-rmse:2.09796                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:1.86325\teval-rmse:2.09846                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:1.85067\teval-rmse:2.10249                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:1.84482\teval-rmse:2.10534                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:1.8354\teval-rmse:2.1031                                                                                \n",
      "\n",
      "[50]\ttrain-rmse:1.82353\teval-rmse:2.10367                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[30]\ttrain-rmse:2.02658\teval-rmse:2.08882\n",
      "\n",
      "\n",
      "loss: 96733856.57824978                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 9.15404960726535e-06, 'colsample_bytree': 0.6000000000000001, 'gamma': 0.0037060028716910066, 'lambda': 0.0009128271666242851, 'learning_rate': 0.15000000000000002, 'max_depth': 9, 'min_child_weight': 1.92420218403271, 'n_estimators': 650.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.99961\teval-rmse:4.58208                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.46098\teval-rmse:4.0404                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.02395\teval-rmse:3.59961                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.65919\teval-rmse:3.24945                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.36403\teval-rmse:2.97588                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.12314\teval-rmse:2.75102                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.93136\teval-rmse:2.57951                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.77563\teval-rmse:2.44388                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.64535\teval-rmse:2.33841                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.55354\teval-rmse:2.25787                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.47072\teval-rmse:2.20238                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.39441\teval-rmse:2.16062                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.33956\teval-rmse:2.12927                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.27698\teval-rmse:2.10421                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.22342\teval-rmse:2.09282                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.18955\teval-rmse:2.09586                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.14754\teval-rmse:2.08847                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.11821\teval-rmse:2.08371                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.08855\teval-rmse:2.08008                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.06311\teval-rmse:2.07842                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.03446\teval-rmse:2.07684                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.01206\teval-rmse:2.07832                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.99001\teval-rmse:2.07658                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.97371\teval-rmse:2.08022                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.95878\teval-rmse:2.07941                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.93983\teval-rmse:2.08045                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.92766\teval-rmse:2.07574                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.90802\teval-rmse:2.07932                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.89345\teval-rmse:2.08342                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.87848\teval-rmse:2.08718                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.86795\teval-rmse:2.08911                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.84952\teval-rmse:2.09049                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.84059\teval-rmse:2.0928                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:1.82516\teval-rmse:2.09665                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.81367\teval-rmse:2.09581                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.79434\teval-rmse:2.09477                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.78316\teval-rmse:2.09431                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.76208\teval-rmse:2.09607                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.74462\teval-rmse:2.09833                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:1.72343\teval-rmse:2.09954                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:1.71358\teval-rmse:2.09844                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:1.69992\teval-rmse:2.09954                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:1.6947\teval-rmse:2.09956                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:1.68192\teval-rmse:2.10286                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:1.67686\teval-rmse:2.10195                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:1.66126\teval-rmse:2.10422                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:1.65706\teval-rmse:2.10393                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[26]\ttrain-rmse:1.92766\teval-rmse:2.07574\n",
      "\n",
      "\n",
      "loss: 97079003.52027759                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.006708250940978423, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.2710353127035602e-08, 'lambda': 4.321754606370849e-05, 'learning_rate': 0.05, 'max_depth': 9, 'min_child_weight': 3.2391689146922493, 'n_estimators': 702.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.43207\teval-rmse:5.02251                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.22462\teval-rmse:4.81266                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.03026\teval-rmse:4.61624                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.84522\teval-rmse:4.42965                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.67223\teval-rmse:4.25423                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.50826\teval-rmse:4.09054                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.35505\teval-rmse:3.93797                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:4.21272\teval-rmse:3.79502                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:4.07767\teval-rmse:3.66123                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.95082\teval-rmse:3.53552                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.83517\teval-rmse:3.4179                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.7231\teval-rmse:3.30807                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.62089\teval-rmse:3.20463                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.5252\teval-rmse:3.1095                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:3.43212\teval-rmse:3.02164                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.3467\teval-rmse:2.93748                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.26439\teval-rmse:2.86132                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.191\teval-rmse:2.79261                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:3.12018\teval-rmse:2.7297                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.05277\teval-rmse:2.67005                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.99091\teval-rmse:2.61505                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.93434\teval-rmse:2.56492                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.87971\teval-rmse:2.51911                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.82698\teval-rmse:2.47853                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.77866\teval-rmse:2.43788                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.734\teval-rmse:2.40308                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:2.69177\teval-rmse:2.37107                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.65123\teval-rmse:2.34033                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.61312\teval-rmse:2.314                                                                                \n",
      "\n",
      "[29]\ttrain-rmse:2.57748\teval-rmse:2.28793                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.54696\teval-rmse:2.2656                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.51505\teval-rmse:2.24478                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.48875\teval-rmse:2.22536                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.4624\teval-rmse:2.2092                                                                                \n",
      "\n",
      "[34]\ttrain-rmse:2.43826\teval-rmse:2.19587                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.41456\teval-rmse:2.18459                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.38921\teval-rmse:2.17329                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.36586\teval-rmse:2.1626                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:2.34556\teval-rmse:2.15146                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.3255\teval-rmse:2.14393                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:2.30719\teval-rmse:2.13525                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.29112\teval-rmse:2.12795                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.27168\teval-rmse:2.12491                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.25638\teval-rmse:2.12087                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44]\ttrain-rmse:2.24092\teval-rmse:2.1161                                                                               \n",
      "\n",
      "[45]\ttrain-rmse:2.22569\teval-rmse:2.1112                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.21237\teval-rmse:2.10602                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.19901\teval-rmse:2.10209                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.18654\teval-rmse:2.09931                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.17351\teval-rmse:2.09355                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.16074\teval-rmse:2.09125                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.15037\teval-rmse:2.08758                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.13887\teval-rmse:2.08398                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.12835\teval-rmse:2.0817                                                                               \n",
      "\n",
      "[54]\ttrain-rmse:2.11637\teval-rmse:2.0804                                                                               \n",
      "\n",
      "[55]\ttrain-rmse:2.10819\teval-rmse:2.07698                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.09969\teval-rmse:2.07718                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.08838\teval-rmse:2.07512                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.0814\teval-rmse:2.07314                                                                               \n",
      "\n",
      "[59]\ttrain-rmse:2.07456\teval-rmse:2.07133                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.06717\teval-rmse:2.06949                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.06171\teval-rmse:2.06929                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.05124\teval-rmse:2.06862                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.04527\teval-rmse:2.06826                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.03615\teval-rmse:2.06716                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.02873\teval-rmse:2.06788                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.02395\teval-rmse:2.06643                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.01564\teval-rmse:2.06986                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:2.0099\teval-rmse:2.07117                                                                               \n",
      "\n",
      "[69]\ttrain-rmse:2.00494\teval-rmse:2.07138                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:1.99854\teval-rmse:2.07301                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:1.99331\teval-rmse:2.07267                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:1.98874\teval-rmse:2.07497                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:1.98428\teval-rmse:2.07057                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:1.97905\teval-rmse:2.06799                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:1.97464\teval-rmse:2.06866                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:1.96804\teval-rmse:2.06902                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:1.96372\teval-rmse:2.06824                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:1.95651\teval-rmse:2.06835                                                                              \n",
      "\n",
      "[79]\ttrain-rmse:1.94995\teval-rmse:2.06911                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:1.94678\teval-rmse:2.06978                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:1.94207\teval-rmse:2.07178                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:1.93607\teval-rmse:2.07269                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:1.9329\teval-rmse:2.07366                                                                               \n",
      "\n",
      "[84]\ttrain-rmse:1.92777\teval-rmse:2.07313                                                                              \n",
      "\n",
      "[85]\ttrain-rmse:1.92276\teval-rmse:2.07284                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:1.91457\teval-rmse:2.07337                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[66]\ttrain-rmse:2.02395\teval-rmse:2.06643\n",
      "\n",
      "\n",
      "loss: 97122911.81052928                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.06338776546362546, 'colsample_bytree': 0.65, 'gamma': 1.9587577107293263e-05, 'lambda': 0.031609424865381125, 'learning_rate': 0.225, 'max_depth': 9, 'min_child_weight': 1.1833279619965325, 'n_estimators': 584.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.68882\teval-rmse:4.2682                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.98351\teval-rmse:3.55538                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.46599\teval-rmse:3.05135                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.09684\teval-rmse:2.70696                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.83364\teval-rmse:2.48244                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.65171\teval-rmse:2.33902                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.52336\teval-rmse:2.24514                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.41864\teval-rmse:2.19635                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.34192\teval-rmse:2.1633                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.28243\teval-rmse:2.14161                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.23041\teval-rmse:2.14147                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.18791\teval-rmse:2.14767                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.14866\teval-rmse:2.14239                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.09765\teval-rmse:2.14386                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.0689\teval-rmse:2.14839                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.03957\teval-rmse:2.15694                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.01095\teval-rmse:2.15649                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.98855\teval-rmse:2.17794                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.96563\teval-rmse:2.185                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:1.93371\teval-rmse:2.18431                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.90966\teval-rmse:2.18712                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.88574\teval-rmse:2.20717                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.86694\teval-rmse:2.20621                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.83803\teval-rmse:2.20998                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.82237\teval-rmse:2.21496                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.79745\teval-rmse:2.21706                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.78252\teval-rmse:2.21151                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.77173\teval-rmse:2.208                                                                                \n",
      "\n",
      "[28]\ttrain-rmse:1.75761\teval-rmse:2.20908                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.73425\teval-rmse:2.21989                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.72112\teval-rmse:2.22721                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.23041\teval-rmse:2.14147\n",
      "\n",
      "\n",
      "loss: 96705477.92084366                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.04632172565274163, 'colsample_bytree': 0.65, 'gamma': 3.389961750316398e-06, 'lambda': 0.026706140150835965, 'learning_rate': 0.225, 'max_depth': 9, 'min_child_weight': 1.1258483230118566, 'n_estimators': 586.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.68874\teval-rmse:4.26823                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.98338\teval-rmse:3.5554                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.46585\teval-rmse:3.05138                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.09663\teval-rmse:2.70717                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.834\teval-rmse:2.48273                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.65013\teval-rmse:2.34173                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.52054\teval-rmse:2.24796                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.4148\teval-rmse:2.19581                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.33074\teval-rmse:2.15765                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.28807\teval-rmse:2.13276                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.23505\teval-rmse:2.12619                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.18316\teval-rmse:2.13715                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.14851\teval-rmse:2.13294                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.10078\teval-rmse:2.12219                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.07848\teval-rmse:2.12839                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.0533\teval-rmse:2.13236                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.03386\teval-rmse:2.13493                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.00057\teval-rmse:2.13878                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.97001\teval-rmse:2.14665                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.93868\teval-rmse:2.15503                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.92895\teval-rmse:2.15772                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.90442\teval-rmse:2.15878                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.8934\teval-rmse:2.15917                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.86454\teval-rmse:2.16696                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.85013\teval-rmse:2.17664                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.82649\teval-rmse:2.17859                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.7949\teval-rmse:2.17788                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.78116\teval-rmse:2.19141                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.75507\teval-rmse:2.19811                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.74411\teval-rmse:2.19638                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.7344\teval-rmse:2.19569                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:1.72089\teval-rmse:2.19607                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.70511\teval-rmse:2.19847                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.68926\teval-rmse:2.20011                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.10078\teval-rmse:2.12219\n",
      "\n",
      "\n",
      "loss: 96870612.14943318                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0004947726449457405, 'colsample_bytree': 0.6000000000000001, 'gamma': 1.1687294304854387e-05, 'lambda': 0.0066822255023849, 'learning_rate': 0.2, 'max_depth': 9, 'min_child_weight': 0.808060917409698, 'n_estimators': 542.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.78808\teval-rmse:4.37891                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.12799\teval-rmse:3.71768                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.62816\teval-rmse:3.22159                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.25321\teval-rmse:2.86642                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\ttrain-rmse:2.96383\teval-rmse:2.61006                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.74723\teval-rmse:2.43376                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.58821\teval-rmse:2.3028                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.46857\teval-rmse:2.22572                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.3817\teval-rmse:2.17321                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.32638\teval-rmse:2.14398                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.26339\teval-rmse:2.12671                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.21499\teval-rmse:2.11563                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.17825\teval-rmse:2.11863                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.14366\teval-rmse:2.12038                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.115\teval-rmse:2.11982                                                                                \n",
      "\n",
      "[15]\ttrain-rmse:2.09298\teval-rmse:2.1315                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.05999\teval-rmse:2.13385                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.0352\teval-rmse:2.13492                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.01297\teval-rmse:2.13966                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.98826\teval-rmse:2.14066                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.96475\teval-rmse:2.16093                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.94229\teval-rmse:2.17497                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.91077\teval-rmse:2.17651                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.88871\teval-rmse:2.18185                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.86927\teval-rmse:2.18035                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.85164\teval-rmse:2.18331                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.83402\teval-rmse:2.17829                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.80787\teval-rmse:2.18466                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.78761\teval-rmse:2.18251                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.76919\teval-rmse:2.19216                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.76091\teval-rmse:2.19384                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.74174\teval-rmse:2.2015                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.21499\teval-rmse:2.11563\n",
      "\n",
      "\n",
      "loss: 97011486.1878294                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.011966662730460889, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.8165391192712402e-05, 'lambda': 0.0019200327907546479, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 2.3755800354317747, 'n_estimators': 615.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.47978\teval-rmse:4.0524                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.68823\teval-rmse:3.26842                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.15977\teval-rmse:2.76665                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.81024\teval-rmse:2.46579                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.58369\teval-rmse:2.30477                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.43552\teval-rmse:2.20727                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.32628\teval-rmse:2.16277                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.24601\teval-rmse:2.15128                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.19535\teval-rmse:2.14661                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.15183\teval-rmse:2.15038                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.11795\teval-rmse:2.15121                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.08655\teval-rmse:2.15714                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.05066\teval-rmse:2.17783                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.00351\teval-rmse:2.17963                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.99064\teval-rmse:2.18523                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.96392\teval-rmse:2.18181                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.94183\teval-rmse:2.19145                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.92715\teval-rmse:2.19413                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.89887\teval-rmse:2.20045                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.86293\teval-rmse:2.20339                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.84813\teval-rmse:2.20369                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.82798\teval-rmse:2.2099                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.80128\teval-rmse:2.2061                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.78442\teval-rmse:2.21013                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.7651\teval-rmse:2.21988                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.73492\teval-rmse:2.2234                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.71315\teval-rmse:2.22282                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.69551\teval-rmse:2.22862                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.67385\teval-rmse:2.2307                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.19535\teval-rmse:2.14661\n",
      "\n",
      "\n",
      "loss: 96495493.5119444                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0001575374759483689, 'colsample_bytree': 0.7000000000000001, 'gamma': 6.199202402415553e-05, 'lambda': 0.00010191713577289738, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 2.3526176718299205, 'n_estimators': 698.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.47974\teval-rmse:4.05241                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.68816\teval-rmse:3.26844                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.15969\teval-rmse:2.76684                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.81017\teval-rmse:2.46614                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.58298\teval-rmse:2.30462                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.43414\teval-rmse:2.20711                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.32592\teval-rmse:2.16156                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.24614\teval-rmse:2.14988                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.19521\teval-rmse:2.14959                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.15251\teval-rmse:2.13459                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.12696\teval-rmse:2.13071                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.0904\teval-rmse:2.13071                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.05187\teval-rmse:2.15129                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.02979\teval-rmse:2.15633                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.01001\teval-rmse:2.16159                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.98377\teval-rmse:2.16352                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.9443\teval-rmse:2.16303                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:1.90358\teval-rmse:2.16927                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.89181\teval-rmse:2.17529                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.86366\teval-rmse:2.17945                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.83847\teval-rmse:2.17569                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.81228\teval-rmse:2.19043                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.79411\teval-rmse:2.19645                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.77518\teval-rmse:2.20705                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.75772\teval-rmse:2.21394                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.7361\teval-rmse:2.21813                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.7214\teval-rmse:2.22192                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.70487\teval-rmse:2.22509                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.68566\teval-rmse:2.23095                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.67107\teval-rmse:2.23555                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.64303\teval-rmse:2.24232                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.12696\teval-rmse:2.13071\n",
      "\n",
      "\n",
      "loss: 96870865.42429172                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0014264158889263027, 'colsample_bytree': 0.75, 'gamma': 0.00018621916522608046, 'lambda': 0.0024586752257273366, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 1.6304499690083143, 'n_estimators': 752.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.28587\teval-rmse:3.84678                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.44176\teval-rmse:3.02394                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.93834\teval-rmse:2.5572                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.62143\teval-rmse:2.30345                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.44049\teval-rmse:2.221                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.32317\teval-rmse:2.17883                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.23204\teval-rmse:2.16278                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.17342\teval-rmse:2.16694                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.12969\teval-rmse:2.20043                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.07987\teval-rmse:2.20444                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.04709\teval-rmse:2.20739                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:1.99762\teval-rmse:2.21081                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.9712\teval-rmse:2.21852                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:1.95279\teval-rmse:2.22065                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.91333\teval-rmse:2.22482                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.87484\teval-rmse:2.22998                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.84472\teval-rmse:2.23143                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.81273\teval-rmse:2.23881                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.78344\teval-rmse:2.24011                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.75637\teval-rmse:2.24737                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.73507\teval-rmse:2.24808                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.70564\teval-rmse:2.25878                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.64934\teval-rmse:2.27289                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\ttrain-rmse:1.63432\teval-rmse:2.2733                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.60474\teval-rmse:2.27675                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.5723\teval-rmse:2.28689                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.54556\teval-rmse:2.29669                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.23204\teval-rmse:2.16278\n",
      "\n",
      "\n",
      "loss: 96823859.27697082                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.010924799596683276, 'colsample_bytree': 0.75, 'gamma': 1.1823383367040667e-06, 'lambda': 0.0012881843314158242, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 4.093739751976016, 'n_estimators': 622.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.587\teval-rmse:4.15769                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.83508\teval-rmse:3.39651                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.30588\teval-rmse:2.879                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:2.94117\teval-rmse:2.55879                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.69181\teval-rmse:2.35414                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.52183\teval-rmse:2.22708                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.41291\teval-rmse:2.15773                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.32035\teval-rmse:2.11424                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.27156\teval-rmse:2.09432                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.22683\teval-rmse:2.07869                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.18088\teval-rmse:2.07437                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.12884\teval-rmse:2.07568                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.10201\teval-rmse:2.07451                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.06553\teval-rmse:2.0694                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.03623\teval-rmse:2.06982                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.00485\teval-rmse:2.07071                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.99275\teval-rmse:2.07227                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.97592\teval-rmse:2.08093                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.95776\teval-rmse:2.09297                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.94121\teval-rmse:2.09392                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.9273\teval-rmse:2.09346                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.89135\teval-rmse:2.08994                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.85971\teval-rmse:2.09938                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.84236\teval-rmse:2.10719                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.81834\teval-rmse:2.10719                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.80534\teval-rmse:2.10361                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.79115\teval-rmse:2.10535                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.77648\teval-rmse:2.1091                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.75469\teval-rmse:2.11801                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.73086\teval-rmse:2.12905                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.71241\teval-rmse:2.12659                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.70287\teval-rmse:2.12696                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.68616\teval-rmse:2.12573                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.66906\teval-rmse:2.12972                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.06553\teval-rmse:2.0694\n",
      "\n",
      "\n",
      "loss: 96904742.8587802                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.03190505834428611, 'colsample_bytree': 0.7000000000000001, 'gamma': 3.69933942735094e-07, 'lambda': 0.016566863325713357, 'learning_rate': 0.15000000000000002, 'max_depth': 6, 'min_child_weight': 3.0170445618765616, 'n_estimators': 773.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.03838\teval-rmse:4.58086                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.53979\teval-rmse:4.0372                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.13961\teval-rmse:3.59486                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.81479\teval-rmse:3.2386                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.55659\teval-rmse:2.95049                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.35263\teval-rmse:2.7284                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.1963\teval-rmse:2.55592                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.07171\teval-rmse:2.42748                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.97408\teval-rmse:2.32467                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.89897\teval-rmse:2.24986                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.84003\teval-rmse:2.19265                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.78912\teval-rmse:2.14458                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.75141\teval-rmse:2.10992                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.72051\teval-rmse:2.08692                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.69092\teval-rmse:2.07198                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.67097\teval-rmse:2.05875                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.6477\teval-rmse:2.04728                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.63164\teval-rmse:2.03892                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.61431\teval-rmse:2.03707                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.60366\teval-rmse:2.03502                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.58981\teval-rmse:2.03328                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.57673\teval-rmse:2.03575                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.56678\teval-rmse:2.03425                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.55282\teval-rmse:2.03491                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.54374\teval-rmse:2.03286                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.52867\teval-rmse:2.03247                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.52055\teval-rmse:2.03397                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.5122\teval-rmse:2.03482                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.50169\teval-rmse:2.03307                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.49301\teval-rmse:2.03302                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.48379\teval-rmse:2.032                                                                                \n",
      "\n",
      "[31]\ttrain-rmse:2.4718\teval-rmse:2.03494                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.4659\teval-rmse:2.03446                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.46053\teval-rmse:2.03134                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.45638\teval-rmse:2.03172                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.45246\teval-rmse:2.03109                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.44817\teval-rmse:2.03323                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.4409\teval-rmse:2.03161                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:2.43353\teval-rmse:2.03145                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.42231\teval-rmse:2.03504                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.41684\teval-rmse:2.0381                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.40589\teval-rmse:2.0424                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:2.401\teval-rmse:2.04199                                                                                \n",
      "\n",
      "[43]\ttrain-rmse:2.39438\teval-rmse:2.04094                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.38525\teval-rmse:2.03524                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.37923\teval-rmse:2.03404                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.37567\teval-rmse:2.03408                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.3678\teval-rmse:2.03393                                                                               \n",
      "\n",
      "[48]\ttrain-rmse:2.36104\teval-rmse:2.03591                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.35251\teval-rmse:2.03675                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.34742\teval-rmse:2.03723                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.3412\teval-rmse:2.03888                                                                               \n",
      "\n",
      "[52]\ttrain-rmse:2.33259\teval-rmse:2.03788                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.32788\teval-rmse:2.04221                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.32397\teval-rmse:2.04286                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.32154\teval-rmse:2.04314                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[35]\ttrain-rmse:2.45246\teval-rmse:2.03109\n",
      "\n",
      "\n",
      "loss: 97411662.49486911                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00041251943452183526, 'colsample_bytree': 0.75, 'gamma': 0.001227916604092311, 'lambda': 0.055532467883289846, 'learning_rate': 0.17500000000000002, 'max_depth': 9, 'min_child_weight': 2.3893572829315697, 'n_estimators': 513.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.89925\teval-rmse:4.47724                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.30312\teval-rmse:3.86501                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.82744\teval-rmse:3.3947                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.4568\teval-rmse:3.03045                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.16055\teval-rmse:2.76505                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.93185\teval-rmse:2.56332                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.75671\teval-rmse:2.41731                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.61817\teval-rmse:2.31876                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.51191\teval-rmse:2.25577                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.43317\teval-rmse:2.21191                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.36774\teval-rmse:2.18173                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.31766\teval-rmse:2.16253                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.26766\teval-rmse:2.15428                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.21987\teval-rmse:2.14576                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.19123\teval-rmse:2.13827                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.16283\teval-rmse:2.1274                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.12914\teval-rmse:2.1317                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\ttrain-rmse:2.09987\teval-rmse:2.12104                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.06902\teval-rmse:2.12141                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.04879\teval-rmse:2.12255                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.03492\teval-rmse:2.12377                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.01773\teval-rmse:2.12553                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.99339\teval-rmse:2.1312                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.96683\teval-rmse:2.13039                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.95148\teval-rmse:2.13                                                                                 \n",
      "\n",
      "[25]\ttrain-rmse:1.9383\teval-rmse:2.13018                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.92766\teval-rmse:2.13128                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.90481\teval-rmse:2.13933                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.89022\teval-rmse:2.13619                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.87354\teval-rmse:2.13371                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.85259\teval-rmse:2.13444                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.84693\teval-rmse:2.1335                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:1.84259\teval-rmse:2.13777                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.81622\teval-rmse:2.13969                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.80708\teval-rmse:2.13227                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.79833\teval-rmse:2.13233                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.78785\teval-rmse:2.13474                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.76477\teval-rmse:2.13844                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:2.09987\teval-rmse:2.12104\n",
      "\n",
      "\n",
      "loss: 96749590.17218435                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.003443758931733165, 'colsample_bytree': 0.7000000000000001, 'gamma': 5.690530244548645e-06, 'lambda': 0.00035632525382104697, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 1.8461191677096327, 'n_estimators': 562.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.48\teval-rmse:4.04817                                                                                  \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.69066\teval-rmse:3.25805                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.16351\teval-rmse:2.7566                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.81406\teval-rmse:2.46922                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.59373\teval-rmse:2.3034                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.44487\teval-rmse:2.21575                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.33849\teval-rmse:2.17178                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.26669\teval-rmse:2.16766                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.19542\teval-rmse:2.15916                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.16405\teval-rmse:2.15073                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.12509\teval-rmse:2.15231                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.09168\teval-rmse:2.15862                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.06238\teval-rmse:2.15226                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.03959\teval-rmse:2.15505                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.01706\teval-rmse:2.16661                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.98561\teval-rmse:2.17192                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.95891\teval-rmse:2.18421                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.92884\teval-rmse:2.18545                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.91978\teval-rmse:2.18591                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.8885\teval-rmse:2.19314                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.84529\teval-rmse:2.2016                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.81032\teval-rmse:2.21672                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.79183\teval-rmse:2.21205                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.74982\teval-rmse:2.20779                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.74286\teval-rmse:2.20678                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.72687\teval-rmse:2.20601                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.71701\teval-rmse:2.21064                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.68389\teval-rmse:2.20658                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.67093\teval-rmse:2.2064                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:1.65307\teval-rmse:2.21874                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.16405\teval-rmse:2.15073\n",
      "\n",
      "\n",
      "loss: 96842347.35804455                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.12221764715951064, 'colsample_bytree': 0.75, 'gamma': 0.004343739051077667, 'lambda': 9.496510093495078e-05, 'learning_rate': 0.2, 'max_depth': 5, 'min_child_weight': 0.6405939416723049, 'n_estimators': 847.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.85347\teval-rmse:4.36678                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.26007\teval-rmse:3.7019                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.826\teval-rmse:3.21274                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:3.50743\teval-rmse:2.84745                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.28637\teval-rmse:2.58735                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.12629\teval-rmse:2.41002                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.01578\teval-rmse:2.28621                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.93808\teval-rmse:2.20488                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.88067\teval-rmse:2.14863                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.83964\teval-rmse:2.1146                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.80709\teval-rmse:2.09081                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.78652\teval-rmse:2.07493                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.76395\teval-rmse:2.06388                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.74576\teval-rmse:2.05392                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.73193\teval-rmse:2.04893                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.71974\teval-rmse:2.05152                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.70361\teval-rmse:2.05565                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.69348\teval-rmse:2.06035                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.68432\teval-rmse:2.05894                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.67231\teval-rmse:2.05912                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.66187\teval-rmse:2.062                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:2.65691\teval-rmse:2.06099                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.64854\teval-rmse:2.06857                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.63901\teval-rmse:2.07036                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.63394\teval-rmse:2.07033                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.62552\teval-rmse:2.06675                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.61721\teval-rmse:2.07152                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.61351\teval-rmse:2.07305                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.60737\teval-rmse:2.08058                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.59628\teval-rmse:2.08244                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.59278\teval-rmse:2.08609                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.58527\teval-rmse:2.08749                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.58116\teval-rmse:2.08577                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.57029\teval-rmse:2.09076                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.56434\teval-rmse:2.08816                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[14]\ttrain-rmse:2.73193\teval-rmse:2.04893\n",
      "\n",
      "\n",
      "loss: 97854919.65181932                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.548754641478585e-05, 'colsample_bytree': 0.65, 'gamma': 0.00029571345480904114, 'lambda': 0.0040879617007759305, 'learning_rate': 0.30000000000000004, 'max_depth': 3, 'min_child_weight': 1.3763035654688596, 'n_estimators': 438.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.52235\teval-rmse:3.95541                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.83243\teval-rmse:3.14325                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.4304\teval-rmse:2.64962                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.19585\teval-rmse:2.36748                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.07433\teval-rmse:2.22566                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.99878\teval-rmse:2.14196                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.95277\teval-rmse:2.10691                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.9234\teval-rmse:2.08733                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.90329\teval-rmse:2.07578                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.88904\teval-rmse:2.07231                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.87918\teval-rmse:2.07515                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.86854\teval-rmse:2.08331                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.86063\teval-rmse:2.07994                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.85432\teval-rmse:2.0833                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.85005\teval-rmse:2.08302                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.84159\teval-rmse:2.08026                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.83141\teval-rmse:2.0782                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.82681\teval-rmse:2.07865                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.82417\teval-rmse:2.07759                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.81841\teval-rmse:2.07732                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.81358\teval-rmse:2.08298                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.80972\teval-rmse:2.07204                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.80573\teval-rmse:2.07116                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.80083\teval-rmse:2.06523                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.79695\teval-rmse:2.06136                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.7921\teval-rmse:2.06001                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\ttrain-rmse:2.78671\teval-rmse:2.06062                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.78064\teval-rmse:2.06051                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.77759\teval-rmse:2.06053                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.77381\teval-rmse:2.06352                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.77079\teval-rmse:2.06705                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.76942\teval-rmse:2.0659                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.76772\teval-rmse:2.06468                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.76429\teval-rmse:2.05862                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.75997\teval-rmse:2.05849                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.75673\teval-rmse:2.0595                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.75463\teval-rmse:2.05889                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.75173\teval-rmse:2.05873                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.74834\teval-rmse:2.06239                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.74488\teval-rmse:2.06429                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.74115\teval-rmse:2.07379                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.73902\teval-rmse:2.07298                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.73696\teval-rmse:2.07113                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.73491\teval-rmse:2.07178                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.73199\teval-rmse:2.07165                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.72958\teval-rmse:2.07346                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.72736\teval-rmse:2.07685                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.7263\teval-rmse:2.07724                                                                               \n",
      "\n",
      "[48]\ttrain-rmse:2.72572\teval-rmse:2.07734                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.72481\teval-rmse:2.07794                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.72162\teval-rmse:2.07898                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.72014\teval-rmse:2.07988                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.71632\teval-rmse:2.0792                                                                               \n",
      "\n",
      "[53]\ttrain-rmse:2.71375\teval-rmse:2.08344                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.71196\teval-rmse:2.08146                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[34]\ttrain-rmse:2.75997\teval-rmse:2.05849\n",
      "\n",
      "\n",
      "loss: 98030115.77141626                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.017921796868108547, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.9742320764347206e-06, 'lambda': 0.007407873554920913, 'learning_rate': 0.125, 'max_depth': 7, 'min_child_weight': 6.276063097721944, 'n_estimators': 891.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.12921\teval-rmse:4.69313                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.68696\teval-rmse:4.22124                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.31349\teval-rmse:3.82232                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.9994\teval-rmse:3.49044                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.73833\teval-rmse:3.20918                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.51992\teval-rmse:2.975                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:3.34062\teval-rmse:2.78684                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.19393\teval-rmse:2.63199                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.07412\teval-rmse:2.50877                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.97499\teval-rmse:2.4078                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.89614\teval-rmse:2.32528                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.83156\teval-rmse:2.25871                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.77577\teval-rmse:2.20499                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.72811\teval-rmse:2.16895                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.68657\teval-rmse:2.14095                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.65426\teval-rmse:2.11699                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.62097\teval-rmse:2.09822                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.59486\teval-rmse:2.08328                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.56834\teval-rmse:2.06994                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.54891\teval-rmse:2.06308                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.53188\teval-rmse:2.05504                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.51601\teval-rmse:2.05401                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.50204\teval-rmse:2.04971                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.49166\teval-rmse:2.04807                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.48185\teval-rmse:2.04467                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.47097\teval-rmse:2.04181                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.46016\teval-rmse:2.04054                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.44854\teval-rmse:2.04355                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.43822\teval-rmse:2.04235                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.43079\teval-rmse:2.04357                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.42047\teval-rmse:2.04588                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.40949\teval-rmse:2.04773                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.40281\teval-rmse:2.04793                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.38828\teval-rmse:2.0484                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:2.38087\teval-rmse:2.05105                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.37044\teval-rmse:2.05012                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.35842\teval-rmse:2.05245                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.34933\teval-rmse:2.05414                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.34126\teval-rmse:2.05437                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.33657\teval-rmse:2.0548                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:2.32957\teval-rmse:2.05594                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.32448\teval-rmse:2.05623                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.31835\teval-rmse:2.05498                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.31191\teval-rmse:2.05777                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.30375\teval-rmse:2.05769                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.29685\teval-rmse:2.05992                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.29393\teval-rmse:2.06351                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[26]\ttrain-rmse:2.46016\teval-rmse:2.04054\n",
      "\n",
      "\n",
      "loss: 97098151.29232247                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.2638877488972452, 'colsample_bytree': 0.75, 'gamma': 0.011828122828378734, 'lambda': 0.0016350162639268675, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 8.290213511734747, 'n_estimators': 660.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.25138\teval-rmse:4.80442                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.90314\teval-rmse:4.41496                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.60064\teval-rmse:4.07077                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.336\teval-rmse:3.76972                                                                                 \n",
      "\n",
      "[4]\ttrain-rmse:4.11004\teval-rmse:3.50658                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.91354\teval-rmse:3.27784                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.74659\teval-rmse:3.07943                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.60474\teval-rmse:2.91165                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.48376\teval-rmse:2.76685                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.38229\teval-rmse:2.64763                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.2926\teval-rmse:2.54632                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.21887\teval-rmse:2.45842                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.15552\teval-rmse:2.38689                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.10218\teval-rmse:2.32631                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.05782\teval-rmse:2.27807                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.02001\teval-rmse:2.23424                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.98613\teval-rmse:2.20082                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.95815\teval-rmse:2.17054                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.93532\teval-rmse:2.14929                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.91621\teval-rmse:2.1306                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.89805\teval-rmse:2.11336                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.88342\teval-rmse:2.10212                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.87015\teval-rmse:2.09322                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.85884\teval-rmse:2.08314                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.84925\teval-rmse:2.07403                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.84075\teval-rmse:2.06867                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.83381\teval-rmse:2.06393                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.82688\teval-rmse:2.06199                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.8207\teval-rmse:2.05838                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.81463\teval-rmse:2.05404                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.80654\teval-rmse:2.05376                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.80091\teval-rmse:2.05182                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.79624\teval-rmse:2.04792                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.79242\teval-rmse:2.04664                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.78801\teval-rmse:2.04541                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.7851\teval-rmse:2.04435                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.78102\teval-rmse:2.04376                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.77509\teval-rmse:2.04098                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.7707\teval-rmse:2.04011                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:2.7678\teval-rmse:2.03973                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:2.76363\teval-rmse:2.03823                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.76141\teval-rmse:2.03804                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.75813\teval-rmse:2.03921                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43]\ttrain-rmse:2.7554\teval-rmse:2.03843                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:2.75348\teval-rmse:2.03815                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.7518\teval-rmse:2.03803                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.75103\teval-rmse:2.0371                                                                               \n",
      "\n",
      "[47]\ttrain-rmse:2.74887\teval-rmse:2.03669                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.74447\teval-rmse:2.0377                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:2.74233\teval-rmse:2.03811                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.73873\teval-rmse:2.03867                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.73583\teval-rmse:2.03824                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.73334\teval-rmse:2.03802                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.73101\teval-rmse:2.03913                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.72943\teval-rmse:2.03898                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.72687\teval-rmse:2.04063                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.72443\teval-rmse:2.04298                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.72192\teval-rmse:2.04325                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.72054\teval-rmse:2.04311                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.71943\teval-rmse:2.04269                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.71538\teval-rmse:2.04217                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.71284\teval-rmse:2.04256                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.71172\teval-rmse:2.04261                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.70884\teval-rmse:2.04087                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.70768\teval-rmse:2.04222                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.70519\teval-rmse:2.04381                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.70259\teval-rmse:2.04344                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.69918\teval-rmse:2.04245                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[47]\ttrain-rmse:2.74887\teval-rmse:2.03669\n",
      "\n",
      "\n",
      "loss: 98534031.72078946                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.5433433029766305, 'colsample_bytree': 0.8, 'gamma': 7.005864484935433e-08, 'lambda': 1.6189451280347974e-05, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 6.907993399380315, 'n_estimators': 613.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.58796\teval-rmse:4.16202                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.86055\teval-rmse:3.39655                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.34971\teval-rmse:2.88232                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.00968\teval-rmse:2.56212                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.78794\teval-rmse:2.37401                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.63067\teval-rmse:2.26413                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.52943\teval-rmse:2.20468                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.45839\teval-rmse:2.166                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.40597\teval-rmse:2.16743                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.37182\teval-rmse:2.15736                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.33945\teval-rmse:2.15659                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.3187\teval-rmse:2.14543                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.29863\teval-rmse:2.15188                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.26743\teval-rmse:2.1606                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.24745\teval-rmse:2.16029                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.22833\teval-rmse:2.16222                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.20049\teval-rmse:2.16435                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.18553\teval-rmse:2.17964                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.17038\teval-rmse:2.17878                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.15647\teval-rmse:2.17633                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.13451\teval-rmse:2.18979                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.11708\teval-rmse:2.20322                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.10585\teval-rmse:2.21994                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.08825\teval-rmse:2.22169                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.07653\teval-rmse:2.22043                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.07107\teval-rmse:2.22587                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.05816\teval-rmse:2.22884                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.04169\teval-rmse:2.23751                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.03356\teval-rmse:2.24733                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.01674\teval-rmse:2.24725                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.00123\teval-rmse:2.25657                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.98331\teval-rmse:2.26227                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.3187\teval-rmse:2.14543\n",
      "\n",
      "\n",
      "loss: 96836604.31883058                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00011143765899090178, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.00011950949830049184, 'lambda': 5.974997340812699e-06, 'learning_rate': 0.35000000000000003, 'max_depth': 6, 'min_child_weight': 2.5915993291708896, 'n_estimators': 798.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.27142\teval-rmse:3.74751                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.51154\teval-rmse:2.89195                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.10019\teval-rmse:2.45317                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.88849\teval-rmse:2.25053                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.77685\teval-rmse:2.13205                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.71359\teval-rmse:2.08551                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.67838\teval-rmse:2.07554                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.65298\teval-rmse:2.06525                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.62686\teval-rmse:2.06698                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.60087\teval-rmse:2.07602                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.58559\teval-rmse:2.07411                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.5687\teval-rmse:2.06948                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.55769\teval-rmse:2.08281                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.53957\teval-rmse:2.08113                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.52543\teval-rmse:2.09617                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.50776\teval-rmse:2.11832                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.49214\teval-rmse:2.12599                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.47386\teval-rmse:2.1326                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.46237\teval-rmse:2.15031                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.45206\teval-rmse:2.15807                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.44086\teval-rmse:2.16925                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.42545\teval-rmse:2.14932                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.40723\teval-rmse:2.15415                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.39487\teval-rmse:2.15321                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.38353\teval-rmse:2.14832                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.36586\teval-rmse:2.16607                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.36191\teval-rmse:2.16829                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.35312\teval-rmse:2.17591                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.65298\teval-rmse:2.06525\n",
      "\n",
      "\n",
      "loss: 97555580.32627976                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0012529731589893335, 'colsample_bytree': 0.65, 'gamma': 1.4298477479819224e-05, 'lambda': 3.064191435886683e-05, 'learning_rate': 0.30000000000000004, 'max_depth': 5, 'min_child_weight': 0.9838860972332943, 'n_estimators': 331.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.48097\teval-rmse:3.94713                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.75989\teval-rmse:3.12051                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.3304\teval-rmse:2.63216                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.08769\teval-rmse:2.35102                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.94916\teval-rmse:2.20779                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.86632\teval-rmse:2.12182                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.8155\teval-rmse:2.09105                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.77969\teval-rmse:2.07416                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.75559\teval-rmse:2.05822                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.73985\teval-rmse:2.05369                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.72371\teval-rmse:2.04908                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.70771\teval-rmse:2.05245                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.69654\teval-rmse:2.04821                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.67773\teval-rmse:2.05695                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.67139\teval-rmse:2.05757                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.66278\teval-rmse:2.05446                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.65073\teval-rmse:2.05541                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.64115\teval-rmse:2.05242                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.63537\teval-rmse:2.05975                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.62634\teval-rmse:2.06561                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.61416\teval-rmse:2.07279                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.60415\teval-rmse:2.10199                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.59462\teval-rmse:2.12077                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.586\teval-rmse:2.15794                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:2.58027\teval-rmse:2.15588                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.57254\teval-rmse:2.16506                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\ttrain-rmse:2.56397\teval-rmse:2.16819                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.55519\teval-rmse:2.17034                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.54852\teval-rmse:2.16921                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.54443\teval-rmse:2.17796                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.54041\teval-rmse:2.1852                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.52805\teval-rmse:2.16932                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.52412\teval-rmse:2.17003                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.69654\teval-rmse:2.04821\n",
      "\n",
      "\n",
      "loss: 97660251.64520569                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.007609135650228906, 'colsample_bytree': 0.8, 'gamma': 6.252691332279095e-05, 'lambda': 0.0001791569699666328, 'learning_rate': 0.17500000000000002, 'max_depth': 9, 'min_child_weight': 3.8298370055083977, 'n_estimators': 491.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.89244\teval-rmse:4.48405                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.29892\teval-rmse:3.87008                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.82066\teval-rmse:3.38735                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.45554\teval-rmse:3.02335                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.16544\teval-rmse:2.74783                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.94495\teval-rmse:2.54527                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.77903\teval-rmse:2.40516                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.64163\teval-rmse:2.29895                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.54004\teval-rmse:2.23176                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.46353\teval-rmse:2.17524                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.40933\teval-rmse:2.14466                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.35983\teval-rmse:2.11946                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.31786\teval-rmse:2.10298                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.26402\teval-rmse:2.09053                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.24101\teval-rmse:2.0849                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.21667\teval-rmse:2.07836                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.18645\teval-rmse:2.07567                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.15504\teval-rmse:2.07948                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.12905\teval-rmse:2.07951                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.11619\teval-rmse:2.07814                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.09767\teval-rmse:2.07478                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.08808\teval-rmse:2.07586                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.06371\teval-rmse:2.08292                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.05012\teval-rmse:2.08491                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.03626\teval-rmse:2.08815                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.02629\teval-rmse:2.08896                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.01525\teval-rmse:2.0842                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.0037\teval-rmse:2.09216                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.98896\teval-rmse:2.08985                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.96938\teval-rmse:2.0873                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:1.95733\teval-rmse:2.09033                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.94015\teval-rmse:2.094                                                                                \n",
      "\n",
      "[32]\ttrain-rmse:1.93036\teval-rmse:2.08918                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.90792\teval-rmse:2.09575                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.90223\teval-rmse:2.09557                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.89509\teval-rmse:2.09487                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.88387\teval-rmse:2.09874                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.87488\teval-rmse:2.09807                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.86234\teval-rmse:2.10368                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:1.85435\teval-rmse:2.11122                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:1.84651\teval-rmse:2.11451                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[20]\ttrain-rmse:2.09767\teval-rmse:2.07478\n",
      "\n",
      "\n",
      "loss: 96863083.09969535                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.003776338660562635, 'colsample_bytree': 0.6000000000000001, 'gamma': 0.03587897892580192, 'lambda': 0.0005972952800559355, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 4.491577440273756, 'n_estimators': 953.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.88014\teval-rmse:4.3725                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.30854\teval-rmse:3.7154                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.89389\teval-rmse:3.22448                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.59225\teval-rmse:2.85869                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.39514\teval-rmse:2.61481                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.24297\teval-rmse:2.43107                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.1369\teval-rmse:2.29858                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.06345\teval-rmse:2.21417                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.01291\teval-rmse:2.16142                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.97744\teval-rmse:2.13161                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.95235\teval-rmse:2.10747                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.93347\teval-rmse:2.09306                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.91863\teval-rmse:2.08211                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.90282\teval-rmse:2.07739                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.8929\teval-rmse:2.07846                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.88536\teval-rmse:2.07544                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.87955\teval-rmse:2.07634                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.87173\teval-rmse:2.07204                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.86589\teval-rmse:2.07313                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.86012\teval-rmse:2.07004                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.85668\teval-rmse:2.06964                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.85379\teval-rmse:2.07245                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.84944\teval-rmse:2.06951                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.84369\teval-rmse:2.06796                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.84067\teval-rmse:2.06776                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.83735\teval-rmse:2.07286                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.83348\teval-rmse:2.07296                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.8302\teval-rmse:2.07323                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.82624\teval-rmse:2.07331                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.82149\teval-rmse:2.07245                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.81793\teval-rmse:2.07305                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.81431\teval-rmse:2.07034                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.81206\teval-rmse:2.06983                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.80655\teval-rmse:2.06994                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.80329\teval-rmse:2.06793                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.80192\teval-rmse:2.06639                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.79975\teval-rmse:2.06748                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.79595\teval-rmse:2.05885                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.79385\teval-rmse:2.06533                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.79216\teval-rmse:2.06647                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.78993\teval-rmse:2.06609                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.78768\teval-rmse:2.0657                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:2.78459\teval-rmse:2.06583                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.78339\teval-rmse:2.06584                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.78199\teval-rmse:2.06756                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.78091\teval-rmse:2.06739                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.7802\teval-rmse:2.06854                                                                               \n",
      "\n",
      "[47]\ttrain-rmse:2.77827\teval-rmse:2.07418                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.77747\teval-rmse:2.0736                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:2.77435\teval-rmse:2.07322                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.77242\teval-rmse:2.07224                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.76901\teval-rmse:2.07454                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.76648\teval-rmse:2.07106                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.76531\teval-rmse:2.07188                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.76293\teval-rmse:2.07244                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.76086\teval-rmse:2.07398                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.75901\teval-rmse:2.07734                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.75803\teval-rmse:2.07714                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[37]\ttrain-rmse:2.79595\teval-rmse:2.05885\n",
      "\n",
      "\n",
      "loss: 98426983.6191101                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.002145028584648765, 'colsample_bytree': 0.75, 'gamma': 0.002472048654036407, 'lambda': 0.00031615378817071316, 'learning_rate': 0.275, 'max_depth': 7, 'min_child_weight': 0.5188728742954274, 'n_estimators': 526.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.52784\teval-rmse:4.05045                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.79346\teval-rmse:3.24886                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.31584\teval-rmse:2.74468                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.01079\teval-rmse:2.44723                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.81994\teval-rmse:2.26761                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.6981\teval-rmse:2.18023                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\ttrain-rmse:2.61521\teval-rmse:2.13055                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.55927\teval-rmse:2.11066                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.52407\teval-rmse:2.10187                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.48796\teval-rmse:2.08586                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.46784\teval-rmse:2.08678                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.4392\teval-rmse:2.09182                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.42262\teval-rmse:2.103                                                                                \n",
      "\n",
      "[13]\ttrain-rmse:2.40549\teval-rmse:2.10705                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.37578\teval-rmse:2.12644                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.34799\teval-rmse:2.13055                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.33046\teval-rmse:2.1359                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.31537\teval-rmse:2.14109                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.305\teval-rmse:2.13848                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:2.28919\teval-rmse:2.13855                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.27559\teval-rmse:2.14038                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.26622\teval-rmse:2.15364                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.25176\teval-rmse:2.15837                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.24096\teval-rmse:2.16308                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.23158\teval-rmse:2.17104                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.21514\teval-rmse:2.16803                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.19803\teval-rmse:2.16856                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.17953\teval-rmse:2.18049                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.16765\teval-rmse:2.19829                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.15238\teval-rmse:2.20843                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.48796\teval-rmse:2.08586\n",
      "\n",
      "\n",
      "loss: 97407657.00033638                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.029333221174943584, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.0008258071141620408, 'lambda': 0.0033508393597688475, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 2.0982976999562086, 'n_estimators': 710.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.28635\teval-rmse:3.85401                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.4521\teval-rmse:3.01624                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.95837\teval-rmse:2.55687                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.67257\teval-rmse:2.32495                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.50042\teval-rmse:2.217                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.38843\teval-rmse:2.18444                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.3076\teval-rmse:2.16832                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.23748\teval-rmse:2.16376                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.20457\teval-rmse:2.16548                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.17938\teval-rmse:2.17993                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.12759\teval-rmse:2.17978                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.10452\teval-rmse:2.18275                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.06207\teval-rmse:2.18328                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.04282\teval-rmse:2.17755                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.0247\teval-rmse:2.1809                                                                                \n",
      "\n",
      "[15]\ttrain-rmse:2.00927\teval-rmse:2.18781                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.98167\teval-rmse:2.18784                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.94483\teval-rmse:2.19704                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.90157\teval-rmse:2.21344                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.88165\teval-rmse:2.20986                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.86723\teval-rmse:2.21287                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.85262\teval-rmse:2.2178                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.83101\teval-rmse:2.21788                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.79778\teval-rmse:2.21663                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.78735\teval-rmse:2.2201                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.75468\teval-rmse:2.22549                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.73438\teval-rmse:2.22606                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.69691\teval-rmse:2.23034                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.23748\teval-rmse:2.16376\n",
      "\n",
      "\n",
      "loss: 96885021.46359223                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00017421102768804846, 'colsample_bytree': 0.8, 'gamma': 1.9056950676619097e-05, 'lambda': 0.09002960054721182, 'learning_rate': 0.25, 'max_depth': 4, 'min_child_weight': 1.3824959787170492, 'n_estimators': 181.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.67787\teval-rmse:4.16183                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.02212\teval-rmse:3.40531                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.58693\teval-rmse:2.88401                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.30307\teval-rmse:2.55507                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.13201\teval-rmse:2.35812                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.01718\teval-rmse:2.23508                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.946\teval-rmse:2.16322                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:2.90169\teval-rmse:2.11938                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.8693\teval-rmse:2.08623                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.84633\teval-rmse:2.07087                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.82888\teval-rmse:2.06293                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.81677\teval-rmse:2.0627                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.80342\teval-rmse:2.05629                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.79581\teval-rmse:2.05609                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.78252\teval-rmse:2.05145                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.77108\teval-rmse:2.04874                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.76506\teval-rmse:2.04873                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.75581\teval-rmse:2.04884                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.75014\teval-rmse:2.04907                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.74057\teval-rmse:2.05984                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.7341\teval-rmse:2.0615                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:2.72358\teval-rmse:2.06167                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.7171\teval-rmse:2.06503                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.71212\teval-rmse:2.06503                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.707\teval-rmse:2.06554                                                                                \n",
      "\n",
      "[25]\ttrain-rmse:2.70426\teval-rmse:2.0633                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.70058\teval-rmse:2.06333                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.69608\teval-rmse:2.06537                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.69074\teval-rmse:2.06153                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.68772\teval-rmse:2.06048                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.68265\teval-rmse:2.05983                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.67622\teval-rmse:2.06092                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.67134\teval-rmse:2.06048                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.66501\teval-rmse:2.06261                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.65868\teval-rmse:2.06107                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.65087\teval-rmse:2.06588                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.64556\teval-rmse:2.06858                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[16]\ttrain-rmse:2.76506\teval-rmse:2.04873\n",
      "\n",
      "\n",
      "loss: 98466661.16949815                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.542842663920499e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.0003951818675507364, 'lambda': 0.3145503318948046, 'learning_rate': 0.225, 'max_depth': 6, 'min_child_weight': 5.4749285415437985, 'n_estimators': 680.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.74298\teval-rmse:4.25825                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.09323\teval-rmse:3.53618                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.63585\teval-rmse:3.02661                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.31903\teval-rmse:2.67344                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.10124\teval-rmse:2.43954                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.95804\teval-rmse:2.29074                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.86162\teval-rmse:2.19798                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.79626\teval-rmse:2.13978                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.74564\teval-rmse:2.10228                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.70372\teval-rmse:2.08476                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.67385\teval-rmse:2.05                                                                                 \n",
      "\n",
      "[11]\ttrain-rmse:2.65284\teval-rmse:2.04498                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.63401\teval-rmse:2.04264                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.61924\teval-rmse:2.03895                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.59967\teval-rmse:2.04525                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.58302\teval-rmse:2.0407                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.56415\teval-rmse:2.04481                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.55398\teval-rmse:2.04599                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.54921\teval-rmse:2.04901                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.53791\teval-rmse:2.04875                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.52805\teval-rmse:2.0489                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.52164\teval-rmse:2.0521                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.51158\teval-rmse:2.05482                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\ttrain-rmse:2.50079\teval-rmse:2.0531                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.49408\teval-rmse:2.05303                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.48897\teval-rmse:2.05547                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.48336\teval-rmse:2.06067                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.46926\teval-rmse:2.05469                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.46104\teval-rmse:2.0558                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.45224\teval-rmse:2.05556                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.43803\teval-rmse:2.04946                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.42879\teval-rmse:2.04878                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.42141\teval-rmse:2.05085                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.40658\teval-rmse:2.05222                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.61924\teval-rmse:2.03895\n",
      "\n",
      "\n",
      "loss: 97596741.89107752                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0007268295774258562, 'colsample_bytree': 0.65, 'gamma': 6.561820746046598e-07, 'lambda': 0.013623124612842135, 'learning_rate': 0.2, 'max_depth': 8, 'min_child_weight': 2.9082045448398666, 'n_estimators': 562.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.81051\teval-rmse:4.37699                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.1726\teval-rmse:3.7136                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:3.69394\teval-rmse:3.22179                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.33674\teval-rmse:2.86425                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.07641\teval-rmse:2.61314                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.88631\teval-rmse:2.43325                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.74391\teval-rmse:2.31456                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.64369\teval-rmse:2.23753                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.56058\teval-rmse:2.19573                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.51394\teval-rmse:2.15956                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.46319\teval-rmse:2.13271                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.41729\teval-rmse:2.11595                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.38525\teval-rmse:2.10364                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.34847\teval-rmse:2.09971                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.32467\teval-rmse:2.09845                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.30332\teval-rmse:2.09662                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.27682\teval-rmse:2.09468                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.26024\teval-rmse:2.09284                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.24139\teval-rmse:2.0961                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.21717\teval-rmse:2.0901                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.20784\teval-rmse:2.09337                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.19798\teval-rmse:2.09742                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.17747\teval-rmse:2.10569                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.16442\teval-rmse:2.10508                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.15454\teval-rmse:2.10472                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.13569\teval-rmse:2.10927                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.12482\teval-rmse:2.10517                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.10961\teval-rmse:2.1051                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.09145\teval-rmse:2.10928                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.07811\teval-rmse:2.10914                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.0639\teval-rmse:2.11065                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.04633\teval-rmse:2.11625                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.04125\teval-rmse:2.11639                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.02569\teval-rmse:2.12352                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.01569\teval-rmse:2.12068                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.00804\teval-rmse:2.12185                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.99941\teval-rmse:2.12854                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.98501\teval-rmse:2.12661                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.96479\teval-rmse:2.13679                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:1.9472\teval-rmse:2.15981                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[19]\ttrain-rmse:2.21717\teval-rmse:2.0901\n",
      "\n",
      "\n",
      "loss: 97179034.25773111                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.10199339806343666, 'colsample_bytree': 0.75, 'gamma': 0.00012626633133312008, 'lambda': 0.000636936289396193, 'learning_rate': 0.30000000000000004, 'max_depth': 5, 'min_child_weight': 1.757416392851372, 'n_estimators': 401.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.47248\teval-rmse:3.94849                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.75758\teval-rmse:3.12943                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.32443\teval-rmse:2.64707                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.07745\teval-rmse:2.37384                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.94084\teval-rmse:2.23022                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.85838\teval-rmse:2.16213                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.81015\teval-rmse:2.12865                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.78073\teval-rmse:2.11372                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.75793\teval-rmse:2.1255                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.74294\teval-rmse:2.11242                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.72428\teval-rmse:2.11439                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.71512\teval-rmse:2.11819                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.70621\teval-rmse:2.12837                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.69574\teval-rmse:2.13108                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.68663\teval-rmse:2.12833                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.67257\teval-rmse:2.141                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:2.66072\teval-rmse:2.14914                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.64899\teval-rmse:2.1415                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.63944\teval-rmse:2.14217                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.63216\teval-rmse:2.14355                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.62317\teval-rmse:2.14906                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.6128\teval-rmse:2.156                                                                                 \n",
      "\n",
      "[22]\ttrain-rmse:2.60637\teval-rmse:2.1564                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.59492\teval-rmse:2.16811                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.59059\teval-rmse:2.17193                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.58245\teval-rmse:2.18304                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.57656\teval-rmse:2.17855                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.56719\teval-rmse:2.18235                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.55902\teval-rmse:2.18244                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.55196\teval-rmse:2.18157                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.74294\teval-rmse:2.11242\n",
      "\n",
      "\n",
      "loss: 98312237.66267048                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.010062577245573976, 'colsample_bytree': 0.75, 'gamma': 0.011932746861244358, 'lambda': 2.7782411785101844, 'learning_rate': 0.15000000000000002, 'max_depth': 9, 'min_child_weight': 0.8392475774648485, 'n_estimators': 759.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.00874\teval-rmse:4.59299                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.48308\teval-rmse:4.04871                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.04759\teval-rmse:3.60877                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.68955\teval-rmse:3.2525                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.40057\teval-rmse:2.96426                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.16829\teval-rmse:2.73961                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.97987\teval-rmse:2.56975                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.82827\teval-rmse:2.43732                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.70813\teval-rmse:2.34242                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.61511\teval-rmse:2.26939                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.53871\teval-rmse:2.20992                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.47579\teval-rmse:2.17242                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.41482\teval-rmse:2.1483                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.37269\teval-rmse:2.12723                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.32928\teval-rmse:2.11273                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.29283\teval-rmse:2.09931                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.26028\teval-rmse:2.09365                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.23083\teval-rmse:2.08615                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.20316\teval-rmse:2.07966                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.17825\teval-rmse:2.07901                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.16253\teval-rmse:2.078                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:2.14603\teval-rmse:2.08145                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.11855\teval-rmse:2.08221                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.0933\teval-rmse:2.08844                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.0808\teval-rmse:2.08685                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.06499\teval-rmse:2.08847                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.05364\teval-rmse:2.08645                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.03341\teval-rmse:2.08227                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.02039\teval-rmse:2.08873                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.00217\teval-rmse:2.08546                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttrain-rmse:1.99312\teval-rmse:2.08657                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.97307\teval-rmse:2.08468                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.96108\teval-rmse:2.0853                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:1.9461\teval-rmse:2.0888                                                                                \n",
      "\n",
      "[34]\ttrain-rmse:1.93576\teval-rmse:2.08736                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.92691\teval-rmse:2.08842                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.92048\teval-rmse:2.0872                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:1.91189\teval-rmse:2.09154                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.89839\teval-rmse:2.09383                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:1.8905\teval-rmse:2.09372                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:1.88049\teval-rmse:2.09403                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[20]\ttrain-rmse:2.16253\teval-rmse:2.078\n",
      "\n",
      "\n",
      "loss: 96899192.33631012                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0004723067108444671, 'colsample_bytree': 0.65, 'gamma': 4.264449379589584e-06, 'lambda': 0.0011086136650398388, 'learning_rate': 0.325, 'max_depth': 3, 'min_child_weight': 8.744014108483285, 'n_estimators': 444.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.43133\teval-rmse:3.85806                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.72759\teval-rmse:3.03107                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.34352\teval-rmse:2.55887                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.13883\teval-rmse:2.31675                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.03767\teval-rmse:2.20849                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.97353\teval-rmse:2.13796                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.93721\teval-rmse:2.11181                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.91295\teval-rmse:2.10767                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.89366\teval-rmse:2.10289                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.87709\teval-rmse:2.09715                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.86813\teval-rmse:2.09748                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.86222\teval-rmse:2.10001                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.85714\teval-rmse:2.09556                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.85013\teval-rmse:2.10201                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.84061\teval-rmse:2.09852                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.83199\teval-rmse:2.10085                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.82747\teval-rmse:2.1                                                                                  \n",
      "\n",
      "[17]\ttrain-rmse:2.82343\teval-rmse:2.09987                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.81926\teval-rmse:2.10772                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.81121\teval-rmse:2.10805                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.80862\teval-rmse:2.10904                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.806\teval-rmse:2.11081                                                                                \n",
      "\n",
      "[22]\ttrain-rmse:2.80276\teval-rmse:2.13169                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.80014\teval-rmse:2.12973                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.79564\teval-rmse:2.15954                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.79172\teval-rmse:2.1544                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.78837\teval-rmse:2.15363                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.78688\teval-rmse:2.1522                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.78342\teval-rmse:2.15714                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.78057\teval-rmse:2.15359                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.77743\teval-rmse:2.14601                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.77303\teval-rmse:2.14468                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.76938\teval-rmse:2.14496                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.85714\teval-rmse:2.09556\n",
      "\n",
      "\n",
      "loss: 98909041.61315227                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0048987412695979515, 'colsample_bytree': 0.7000000000000001, 'gamma': 8.668109009802142e-06, 'lambda': 0.009071537279159353, 'learning_rate': 0.07500000000000001, 'max_depth': 8, 'min_child_weight': 3.2829246526600255, 'n_estimators': 631.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.3307\teval-rmse:4.91231                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.03793\teval-rmse:4.60641                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.77026\teval-rmse:4.33014                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.52817\teval-rmse:4.07881                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.30794\teval-rmse:3.84906                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.10564\teval-rmse:3.64292                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.92631\teval-rmse:3.45547                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.76417\teval-rmse:3.28731                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.61892\teval-rmse:3.13781                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.4881\teval-rmse:3.00559                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.37264\teval-rmse:2.88551                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.26641\teval-rmse:2.7811                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.17021\teval-rmse:2.68329                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.08427\teval-rmse:2.59723                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.00335\teval-rmse:2.52255                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.93476\teval-rmse:2.45428                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.86931\teval-rmse:2.39794                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.81216\teval-rmse:2.34914                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.76116\teval-rmse:2.30814                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.71269\teval-rmse:2.27088                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.66918\teval-rmse:2.23947                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.63337\teval-rmse:2.21181                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.59777\teval-rmse:2.18585                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.56261\teval-rmse:2.16698                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.5359\teval-rmse:2.15037                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.51252\teval-rmse:2.13273                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.48892\teval-rmse:2.11935                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.4624\teval-rmse:2.1052                                                                                \n",
      "\n",
      "[28]\ttrain-rmse:2.44266\teval-rmse:2.0949                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.42547\teval-rmse:2.08437                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.41058\teval-rmse:2.07593                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.39204\teval-rmse:2.0683                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.37968\teval-rmse:2.06091                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.36281\teval-rmse:2.05529                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.35177\teval-rmse:2.05108                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.33769\teval-rmse:2.04818                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.32548\teval-rmse:2.04478                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.31236\teval-rmse:2.03885                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.30223\teval-rmse:2.03773                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.29115\teval-rmse:2.03516                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.2799\teval-rmse:2.03372                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.27188\teval-rmse:2.03392                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.26144\teval-rmse:2.03429                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.25381\teval-rmse:2.03289                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.24873\teval-rmse:2.03213                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.2394\teval-rmse:2.03116                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.23432\teval-rmse:2.03258                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.22513\teval-rmse:2.03253                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.21918\teval-rmse:2.03275                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.20962\teval-rmse:2.0303                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:2.20545\teval-rmse:2.02949                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.19845\teval-rmse:2.03331                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.19069\teval-rmse:2.03752                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.18264\teval-rmse:2.03834                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.17372\teval-rmse:2.0389                                                                               \n",
      "\n",
      "[55]\ttrain-rmse:2.16233\teval-rmse:2.03906                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.15824\teval-rmse:2.03756                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.15286\teval-rmse:2.03725                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.14764\teval-rmse:2.03642                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.14217\teval-rmse:2.03725                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.13545\teval-rmse:2.03928                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.13007\teval-rmse:2.03907                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.12653\teval-rmse:2.03945                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.1173\teval-rmse:2.04179                                                                               \n",
      "\n",
      "[64]\ttrain-rmse:2.1103\teval-rmse:2.04252                                                                               \n",
      "\n",
      "[65]\ttrain-rmse:2.10624\teval-rmse:2.04306                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.09893\teval-rmse:2.04229                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.09413\teval-rmse:2.04063                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:2.09059\teval-rmse:2.04315                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.08236\teval-rmse:2.04272                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:2.0779\teval-rmse:2.04386                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[50]\ttrain-rmse:2.20545\teval-rmse:2.02949\n",
      "\n",
      "\n",
      "loss: 97099485.43460293                                                                                                \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.7196514225919258, 'colsample_bytree': 0.6000000000000001, 'gamma': 2.3858304020151644e-08, 'lambda': 0.001872226669629517, 'learning_rate': 0.17500000000000002, 'max_depth': 9, 'min_child_weight': 1.535661981396587, 'n_estimators': 607.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.89502\teval-rmse:4.4846                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.29809\teval-rmse:3.87955                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.82618\teval-rmse:3.40164                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.45442\teval-rmse:3.04398                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.16519\teval-rmse:2.78544                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.94588\teval-rmse:2.58377                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.77921\teval-rmse:2.43495                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.6451\teval-rmse:2.33593                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.53645\teval-rmse:2.25291                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.45687\teval-rmse:2.20465                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.39703\teval-rmse:2.16895                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.34141\teval-rmse:2.14562                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.29804\teval-rmse:2.13501                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.25427\teval-rmse:2.12593                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.21709\teval-rmse:2.12208                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.18142\teval-rmse:2.1212                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.14973\teval-rmse:2.12129                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.11605\teval-rmse:2.12971                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.0988\teval-rmse:2.1289                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:2.07139\teval-rmse:2.12624                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.05356\teval-rmse:2.12906                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.04196\teval-rmse:2.13809                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.01573\teval-rmse:2.13805                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.9869\teval-rmse:2.13697                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.97159\teval-rmse:2.15079                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.95336\teval-rmse:2.14445                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.93978\teval-rmse:2.1443                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.92789\teval-rmse:2.15101                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.91503\teval-rmse:2.1515                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:1.89058\teval-rmse:2.15006                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.87849\teval-rmse:2.14967                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.86743\teval-rmse:2.1527                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:1.85957\teval-rmse:2.15208                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.83338\teval-rmse:2.1527                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:1.82445\teval-rmse:2.15407                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.80437\teval-rmse:2.15529                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.18142\teval-rmse:2.1212\n",
      "\n",
      "\n",
      "loss: 96878771.83221024                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.20629133365993468, 'colsample_bytree': 0.8, 'gamma': 1.1266780600588105e-06, 'lambda': 4.008919343805548e-05, 'learning_rate': 0.275, 'max_depth': 7, 'min_child_weight': 0.3400025127991323, 'n_estimators': 646.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.52566\teval-rmse:4.05508                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.78782\teval-rmse:3.25693                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.31066\teval-rmse:2.74261                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.01314\teval-rmse:2.43792                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.82773\teval-rmse:2.26311                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.70061\teval-rmse:2.17861                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.61808\teval-rmse:2.12971                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.56414\teval-rmse:2.1266                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.52346\teval-rmse:2.10966                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.49382\teval-rmse:2.09649                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.47248\teval-rmse:2.0957                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.44615\teval-rmse:2.10236                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.4208\teval-rmse:2.14135                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.39549\teval-rmse:2.14658                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.36684\teval-rmse:2.15706                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.34969\teval-rmse:2.16615                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.32982\teval-rmse:2.17238                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.30533\teval-rmse:2.17038                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.29728\teval-rmse:2.1813                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.27351\teval-rmse:2.18532                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.25668\teval-rmse:2.2107                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.24632\teval-rmse:2.20924                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.23735\teval-rmse:2.18727                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.22969\teval-rmse:2.1845                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.21255\teval-rmse:2.18623                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.20165\teval-rmse:2.19389                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.19304\teval-rmse:2.20116                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.18243\teval-rmse:2.19879                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.17013\teval-rmse:2.20261                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.16349\teval-rmse:2.20288                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.14648\teval-rmse:2.21106                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.47248\teval-rmse:2.0957\n",
      "\n",
      "\n",
      "loss: 97516390.75955576                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.4428634899373185e-05, 'colsample_bytree': 0.75, 'gamma': 2.369217586880841e-05, 'lambda': 1.1058106176985296e-06, 'learning_rate': 0.1, 'max_depth': 8, 'min_child_weight': 0.7406440612531339, 'n_estimators': 485.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.22337\teval-rmse:4.80273                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.84532\teval-rmse:4.41267                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.51316\teval-rmse:4.06996                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.22029\teval-rmse:3.76942                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.96474\teval-rmse:3.50609                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.73826\teval-rmse:3.28065                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.54537\teval-rmse:3.08139                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.37667\teval-rmse:2.91333                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.23315\teval-rmse:2.76913                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.10968\teval-rmse:2.64606                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.0009\teval-rmse:2.54317                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.90429\teval-rmse:2.45363                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.82372\teval-rmse:2.37559                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.75148\teval-rmse:2.31491                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.68734\teval-rmse:2.26599                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.63259\teval-rmse:2.22278                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.58267\teval-rmse:2.18741                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.53876\teval-rmse:2.15995                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.5015\teval-rmse:2.14178                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.47114\teval-rmse:2.1261                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.43611\teval-rmse:2.10839                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.41002\teval-rmse:2.09871                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.38143\teval-rmse:2.09245                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.35655\teval-rmse:2.09368                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.33657\teval-rmse:2.08545                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.32081\teval-rmse:2.07993                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.30522\teval-rmse:2.07523                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.28889\teval-rmse:2.07571                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.27637\teval-rmse:2.07348                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.26538\teval-rmse:2.07077                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.24415\teval-rmse:2.06791                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.23137\teval-rmse:2.07001                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.22164\teval-rmse:2.06866                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.20372\teval-rmse:2.0699                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:2.19354\teval-rmse:2.08026                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.18077\teval-rmse:2.07899                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.17105\teval-rmse:2.08114                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.15689\teval-rmse:2.08587                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.14707\teval-rmse:2.08909                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.13394\teval-rmse:2.09414                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.12187\teval-rmse:2.0934                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.11457\teval-rmse:2.08984                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.10658\teval-rmse:2.08982                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.09559\teval-rmse:2.09162                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.08714\teval-rmse:2.09129                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.08204\teval-rmse:2.09021                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.07501\teval-rmse:2.08886                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.06443\teval-rmse:2.087                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48]\ttrain-rmse:2.06013\teval-rmse:2.08942                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.05223\teval-rmse:2.0922                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:2.04617\teval-rmse:2.09289                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[30]\ttrain-rmse:2.24415\teval-rmse:2.06791\n",
      "\n",
      "\n",
      "loss: 97269034.22115806                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.976812416493957e-06, 'colsample_bytree': 0.7000000000000001, 'gamma': 5.06441219981668e-05, 'lambda': 9.361224120809944e-05, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 3.659202111528995, 'n_estimators': 810.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.4501\teval-rmse:5.02269                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.26148\teval-rmse:4.81408                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.08588\teval-rmse:4.6178                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:4.9204\teval-rmse:4.43293                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:4.76634\teval-rmse:4.25841                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.62126\teval-rmse:4.09551                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.48654\teval-rmse:3.94113                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:4.36104\teval-rmse:3.79716                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:4.24485\teval-rmse:3.66247                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:4.13684\teval-rmse:3.53677                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:4.03639\teval-rmse:3.41966                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.94232\teval-rmse:3.30919                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.85604\teval-rmse:3.20633                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.77508\teval-rmse:3.11135                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.69921\teval-rmse:3.02383                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.63055\teval-rmse:2.94174                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.56635\teval-rmse:2.86587                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.50676\teval-rmse:2.79632                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.4516\teval-rmse:2.73081                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.40084\teval-rmse:2.67053                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.35446\teval-rmse:2.61577                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.31169\teval-rmse:2.56447                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.27209\teval-rmse:2.5174                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:3.23552\teval-rmse:2.47367                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.2018\teval-rmse:2.43432                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.17197\teval-rmse:2.39778                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.14391\teval-rmse:2.36495                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.11709\teval-rmse:2.33433                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.09322\teval-rmse:2.30775                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.0713\teval-rmse:2.28252                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:3.05029\teval-rmse:2.25872                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.03199\teval-rmse:2.23808                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.01504\teval-rmse:2.2184                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.99816\teval-rmse:2.20151                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.98363\teval-rmse:2.18507                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.97064\teval-rmse:2.17182                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.95825\teval-rmse:2.15908                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.94648\teval-rmse:2.1473                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:2.93572\teval-rmse:2.13691                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.92584\teval-rmse:2.12682                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.91643\teval-rmse:2.11759                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.90758\teval-rmse:2.1108                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:2.89956\teval-rmse:2.10293                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.89221\teval-rmse:2.09634                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.88518\teval-rmse:2.09008                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.87787\teval-rmse:2.08321                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.87172\teval-rmse:2.07827                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.86605\teval-rmse:2.07362                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.86042\teval-rmse:2.06842                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.85535\teval-rmse:2.0654                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:2.85098\teval-rmse:2.06202                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.84664\teval-rmse:2.05869                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.84252\teval-rmse:2.0559                                                                               \n",
      "\n",
      "[53]\ttrain-rmse:2.83856\teval-rmse:2.05332                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.83414\teval-rmse:2.0514                                                                               \n",
      "\n",
      "[55]\ttrain-rmse:2.82994\teval-rmse:2.05039                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.82602\teval-rmse:2.04818                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.82204\teval-rmse:2.04599                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.81907\teval-rmse:2.04356                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.81581\teval-rmse:2.04289                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.81275\teval-rmse:2.04194                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.80856\teval-rmse:2.04066                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.80521\teval-rmse:2.04093                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.80268\teval-rmse:2.03855                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.80029\teval-rmse:2.03911                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.7978\teval-rmse:2.03961                                                                               \n",
      "\n",
      "[66]\ttrain-rmse:2.79507\teval-rmse:2.03794                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.79259\teval-rmse:2.03642                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:2.78973\teval-rmse:2.03578                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.78691\teval-rmse:2.03534                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:2.78466\teval-rmse:2.03476                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:2.78252\teval-rmse:2.03531                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:2.78086\teval-rmse:2.03473                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:2.77929\teval-rmse:2.03364                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:2.77767\teval-rmse:2.03338                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:2.77526\teval-rmse:2.03277                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:2.77335\teval-rmse:2.03248                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:2.77159\teval-rmse:2.03266                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:2.76986\teval-rmse:2.03279                                                                              \n",
      "\n",
      "[79]\ttrain-rmse:2.76808\teval-rmse:2.03262                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:2.76544\teval-rmse:2.03308                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:2.76325\teval-rmse:2.0335                                                                               \n",
      "\n",
      "[82]\ttrain-rmse:2.7611\teval-rmse:2.03403                                                                               \n",
      "\n",
      "[83]\ttrain-rmse:2.75915\teval-rmse:2.0336                                                                               \n",
      "\n",
      "[84]\ttrain-rmse:2.75771\teval-rmse:2.03324                                                                              \n",
      "\n",
      "[85]\ttrain-rmse:2.75577\teval-rmse:2.03403                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:2.75435\teval-rmse:2.03378                                                                              \n",
      "\n",
      "[87]\ttrain-rmse:2.75241\teval-rmse:2.03355                                                                              \n",
      "\n",
      "[88]\ttrain-rmse:2.75055\teval-rmse:2.0332                                                                               \n",
      "\n",
      "[89]\ttrain-rmse:2.749\teval-rmse:2.0328                                                                                 \n",
      "\n",
      "[90]\ttrain-rmse:2.74734\teval-rmse:2.03235                                                                              \n",
      "\n",
      "[91]\ttrain-rmse:2.74553\teval-rmse:2.03197                                                                              \n",
      "\n",
      "[92]\ttrain-rmse:2.74419\teval-rmse:2.03216                                                                              \n",
      "\n",
      "[93]\ttrain-rmse:2.74322\teval-rmse:2.03254                                                                              \n",
      "\n",
      "[94]\ttrain-rmse:2.74246\teval-rmse:2.03272                                                                              \n",
      "\n",
      "[95]\ttrain-rmse:2.7411\teval-rmse:2.03284                                                                               \n",
      "\n",
      "[96]\ttrain-rmse:2.74058\teval-rmse:2.03302                                                                              \n",
      "\n",
      "[97]\ttrain-rmse:2.73961\teval-rmse:2.03335                                                                              \n",
      "\n",
      "[98]\ttrain-rmse:2.73805\teval-rmse:2.03377                                                                              \n",
      "\n",
      "[99]\ttrain-rmse:2.73566\teval-rmse:2.03387                                                                              \n",
      "\n",
      "loss: 98947408.27054739                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.05960679816578378, 'colsample_bytree': 0.65, 'gamma': 0.1251481165660638, 'lambda': 1.990360562600268e-05, 'learning_rate': 0.35000000000000003, 'max_depth': 6, 'min_child_weight': 5.926169387664764, 'n_estimators': 120.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.27435\teval-rmse:3.7459                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.51122\teval-rmse:2.89795                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.10786\teval-rmse:2.45452                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.90083\teval-rmse:2.24405                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.78887\teval-rmse:2.15351                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.7211\teval-rmse:2.11839                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.68078\teval-rmse:2.09656                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.6503\teval-rmse:2.09715                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.62071\teval-rmse:2.111                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:2.6011\teval-rmse:2.11495                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.58709\teval-rmse:2.1191                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.57273\teval-rmse:2.12331                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.55876\teval-rmse:2.13349                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.53864\teval-rmse:2.13824                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.52696\teval-rmse:2.13854                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.51277\teval-rmse:2.14799                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.49804\teval-rmse:2.15613                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\ttrain-rmse:2.49324\teval-rmse:2.15683                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.48162\teval-rmse:2.15925                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.46531\teval-rmse:2.18237                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.4535\teval-rmse:2.17949                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.4404\teval-rmse:2.18973                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.42912\teval-rmse:2.19159                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.41453\teval-rmse:2.19977                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.40654\teval-rmse:2.19901                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.39637\teval-rmse:2.19789                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.37604\teval-rmse:2.19975                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.68078\teval-rmse:2.09656\n",
      "\n",
      "\n",
      "loss: 97543402.28771205                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.4789418067237394e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 3.54998494714687e-07, 'lambda': 2.3549964439255942e-06, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 1.0716812270352665, 'n_estimators': 736.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.58404\teval-rmse:4.16956                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.83049\teval-rmse:3.41616                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.31478\teval-rmse:2.9157                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.96093\teval-rmse:2.5895                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.72634\teval-rmse:2.37921                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.56882\teval-rmse:2.26703                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.46463\teval-rmse:2.18926                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.38091\teval-rmse:2.17216                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.31768\teval-rmse:2.15574                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.25045\teval-rmse:2.16475                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.21735\teval-rmse:2.16772                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.17383\teval-rmse:2.16938                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.15056\teval-rmse:2.16196                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.12111\teval-rmse:2.17368                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.09576\teval-rmse:2.18664                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.06525\teval-rmse:2.20252                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.04032\teval-rmse:2.21506                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.02257\teval-rmse:2.21713                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.00819\teval-rmse:2.21522                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.98124\teval-rmse:2.217                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:1.95884\teval-rmse:2.2321                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.94402\teval-rmse:2.23819                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.92141\teval-rmse:2.2406                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.88736\teval-rmse:2.2457                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.8774\teval-rmse:2.2556                                                                                \n",
      "\n",
      "[25]\ttrain-rmse:1.86775\teval-rmse:2.25042                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.85067\teval-rmse:2.26109                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.84187\teval-rmse:2.23924                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.82532\teval-rmse:2.24017                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.31768\teval-rmse:2.15574\n",
      "\n",
      "\n",
      "loss: 96628421.14848422                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.5774968879646233e-06, 'colsample_bytree': 0.65, 'gamma': 2.846892487419052e-07, 'lambda': 0.04432361440894102, 'learning_rate': 0.375, 'max_depth': 9, 'min_child_weight': 1.0604108287858314, 'n_estimators': 728.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.08812\teval-rmse:3.67251                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.22285\teval-rmse:2.82469                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.75702\teval-rmse:2.40725                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.49739\teval-rmse:2.23478                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.3521\teval-rmse:2.17976                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.25618\teval-rmse:2.20404                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.17986\teval-rmse:2.19283                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.12691\teval-rmse:2.19541                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.07599\teval-rmse:2.21012                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.00827\teval-rmse:2.23797                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:1.95896\teval-rmse:2.25665                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:1.92505\teval-rmse:2.26992                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.90044\teval-rmse:2.27417                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.84442\teval-rmse:2.26324                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.82949\teval-rmse:2.26881                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.78968\teval-rmse:2.27027                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.76634\teval-rmse:2.28201                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.71729\teval-rmse:2.28222                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.707\teval-rmse:2.28599                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:1.68278\teval-rmse:2.29375                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.66125\teval-rmse:2.29546                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.64111\teval-rmse:2.30053                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.62262\teval-rmse:2.30692                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.59896\teval-rmse:2.32281                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.57038\teval-rmse:2.34045                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.3521\teval-rmse:2.17976\n",
      "\n",
      "\n",
      "loss: 97185440.44550492                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.549757086378587e-05, 'colsample_bytree': 0.6000000000000001, 'gamma': 3.6201974466427646e-08, 'lambda': 1.5401044093744473e-06, 'learning_rate': 0.125, 'max_depth': 9, 'min_child_weight': 0.4576311744645826, 'n_estimators': 965.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:5.10739\teval-rmse:4.69641                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.64446\teval-rmse:4.22733                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.25132\teval-rmse:3.8237                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.91939\teval-rmse:3.49226                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.63728\teval-rmse:3.22695                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.39656\teval-rmse:2.99618                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.19753\teval-rmse:2.80841                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.03101\teval-rmse:2.65617                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.88683\teval-rmse:2.53826                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.77418\teval-rmse:2.43339                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.68324\teval-rmse:2.35321                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.60073\teval-rmse:2.29119                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.52949\teval-rmse:2.24205                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.46583\teval-rmse:2.21584                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.41344\teval-rmse:2.19026                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.3758\teval-rmse:2.17712                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.34084\teval-rmse:2.15415                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.3062\teval-rmse:2.1405                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:2.2785\teval-rmse:2.13052                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.24917\teval-rmse:2.12414                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.21652\teval-rmse:2.11584                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.1906\teval-rmse:2.11766                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.16697\teval-rmse:2.1132                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.14846\teval-rmse:2.1125                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.1324\teval-rmse:2.10308                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.12139\teval-rmse:2.10377                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.10927\teval-rmse:2.10488                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.08758\teval-rmse:2.10497                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.07884\teval-rmse:2.10363                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.05914\teval-rmse:2.09921                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.04292\teval-rmse:2.09999                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.0285\teval-rmse:2.1006                                                                                \n",
      "\n",
      "[32]\ttrain-rmse:2.01728\teval-rmse:2.10491                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.99968\teval-rmse:2.10303                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.98674\teval-rmse:2.10693                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.97474\teval-rmse:2.10841                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.9628\teval-rmse:2.11104                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:1.95516\teval-rmse:2.11303                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.94244\teval-rmse:2.11608                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:1.93327\teval-rmse:2.12791                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:1.91833\teval-rmse:2.13426                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:1.90936\teval-rmse:2.13171                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:1.90095\teval-rmse:2.13057                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:1.8943\teval-rmse:2.12888                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:1.87999\teval-rmse:2.12819                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:1.86876\teval-rmse:2.12736                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:1.86209\teval-rmse:2.12809                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47]\ttrain-rmse:1.8507\teval-rmse:2.1302                                                                                \n",
      "\n",
      "[48]\ttrain-rmse:1.84692\teval-rmse:2.13184                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:1.84437\teval-rmse:2.13227                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[29]\ttrain-rmse:2.05914\teval-rmse:2.09921\n",
      "\n",
      "\n",
      "loss: 96918653.26461996                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.1410125274893076e-06, 'colsample_bytree': 0.6000000000000001, 'gamma': 2.0450990851612176e-06, 'lambda': 0.9419783245020564, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 0.6094602888280279, 'n_estimators': 848.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.59539\teval-rmse:4.16446                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.8608\teval-rmse:3.41123                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.34929\teval-rmse:2.90265                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.99893\teval-rmse:2.57659                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.76373\teval-rmse:2.37529                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.60116\teval-rmse:2.24718                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.49373\teval-rmse:2.19255                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.41358\teval-rmse:2.15781                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.34999\teval-rmse:2.13227                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.30715\teval-rmse:2.11523                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.274\teval-rmse:2.1133                                                                                 \n",
      "\n",
      "[11]\ttrain-rmse:2.23545\teval-rmse:2.11717                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.19448\teval-rmse:2.11496                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.16472\teval-rmse:2.117                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:2.13093\teval-rmse:2.11334                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.11534\teval-rmse:2.12546                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.08619\teval-rmse:2.12251                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.05754\teval-rmse:2.12539                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.0268\teval-rmse:2.13349                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.00423\teval-rmse:2.13868                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.98581\teval-rmse:2.14143                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.96881\teval-rmse:2.1456                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.95491\teval-rmse:2.14755                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.93628\teval-rmse:2.15385                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.90952\teval-rmse:2.15748                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.90063\teval-rmse:2.15939                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.88273\teval-rmse:2.15766                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.87461\teval-rmse:2.16295                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.85069\teval-rmse:2.16312                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.8223\teval-rmse:2.16682                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:1.80399\teval-rmse:2.16532                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.274\teval-rmse:2.1133\n",
      "\n",
      "\n",
      "loss: 96892838.79069056                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.543360775358845e-06, 'colsample_bytree': 0.7000000000000001, 'gamma': 9.863909849685326e-08, 'lambda': 5.272744718080198, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 0.40596600716039216, 'n_estimators': 778.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.61049\teval-rmse:4.16174                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.87931\teval-rmse:3.40587                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.37361\teval-rmse:2.89968                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.02294\teval-rmse:2.57356                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.78753\teval-rmse:2.35911                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.61768\teval-rmse:2.22754                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.51036\teval-rmse:2.15411                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.43221\teval-rmse:2.11975                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.3581\teval-rmse:2.09314                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.30801\teval-rmse:2.0757                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.26584\teval-rmse:2.07216                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.23551\teval-rmse:2.06452                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.19807\teval-rmse:2.07112                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.16429\teval-rmse:2.06865                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.13288\teval-rmse:2.07169                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.1006\teval-rmse:2.0757                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:2.06271\teval-rmse:2.08086                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.03273\teval-rmse:2.07695                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.99875\teval-rmse:2.07983                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.98521\teval-rmse:2.08162                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.9582\teval-rmse:2.09289                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.93289\teval-rmse:2.0959                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.91722\teval-rmse:2.09965                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.89225\teval-rmse:2.09685                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.88033\teval-rmse:2.10152                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.86956\teval-rmse:2.10119                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.85833\teval-rmse:2.10086                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.83315\teval-rmse:2.09842                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.80708\teval-rmse:2.09873                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.78156\teval-rmse:2.09971                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.76255\teval-rmse:2.10594                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.7436\teval-rmse:2.10742                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.23551\teval-rmse:2.06452\n",
      "\n",
      "\n",
      "loss: 97008898.65064894                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.819798619878914e-08, 'colsample_bytree': 0.65, 'gamma': 1.516552620480774e-07, 'lambda': 2.7604377832206028e-06, 'learning_rate': 0.225, 'max_depth': 9, 'min_child_weight': 9.840066549562895, 'n_estimators': 903.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.6978\teval-rmse:4.26441                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.99545\teval-rmse:3.54576                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.49161\teval-rmse:3.03989                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.12701\teval-rmse:2.6885                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.86669\teval-rmse:2.46834                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.68633\teval-rmse:2.31786                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.55754\teval-rmse:2.22472                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.46692\teval-rmse:2.17361                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.39449\teval-rmse:2.1418                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.34859\teval-rmse:2.11337                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.29995\teval-rmse:2.10346                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.26348\teval-rmse:2.0994                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.22962\teval-rmse:2.10476                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.19403\teval-rmse:2.10555                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.17338\teval-rmse:2.11277                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.14448\teval-rmse:2.11003                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.13277\teval-rmse:2.11248                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.11455\teval-rmse:2.11117                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.10395\teval-rmse:2.10844                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.08182\teval-rmse:2.10868                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.0564\teval-rmse:2.11314                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.05159\teval-rmse:2.11647                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.03194\teval-rmse:2.12403                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.00883\teval-rmse:2.13135                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.99214\teval-rmse:2.13045                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.97822\teval-rmse:2.13913                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.966\teval-rmse:2.13803                                                                                \n",
      "\n",
      "[27]\ttrain-rmse:1.957\teval-rmse:2.13795                                                                                \n",
      "\n",
      "[28]\ttrain-rmse:1.9468\teval-rmse:2.13836                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:1.94056\teval-rmse:2.13836                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.9217\teval-rmse:2.13896                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:1.89333\teval-rmse:2.13208                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.26348\teval-rmse:2.0994\n",
      "\n",
      "\n",
      "loss: 97062546.69837467                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.320181262975035e-07, 'colsample_bytree': 0.7000000000000001, 'gamma': 5.237833806872145e-07, 'lambda': 5.971992276765272e-06, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 7.067138068474503, 'n_estimators': 927.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.39607\teval-rmse:3.95714                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.59691\teval-rmse:3.14504                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.09078\teval-rmse:2.66423                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.7929\teval-rmse:2.39747                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.60053\teval-rmse:2.27075                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.4753\teval-rmse:2.2065                                                                                 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\ttrain-rmse:2.40421\teval-rmse:2.17216                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.35621\teval-rmse:2.15827                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.31914\teval-rmse:2.16043                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.27461\teval-rmse:2.16673                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.25502\teval-rmse:2.17038                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.23314\teval-rmse:2.17811                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.19693\teval-rmse:2.18352                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.16928\teval-rmse:2.18321                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.15243\teval-rmse:2.18689                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.12992\teval-rmse:2.19003                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.11143\teval-rmse:2.21798                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.07731\teval-rmse:2.22975                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.06171\teval-rmse:2.23234                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.04307\teval-rmse:2.23365                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.03165\teval-rmse:2.2343                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.0139\teval-rmse:2.23952                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.00259\teval-rmse:2.24629                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.9838\teval-rmse:2.25103                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.95784\teval-rmse:2.25316                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.936\teval-rmse:2.27328                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:1.91948\teval-rmse:2.27638                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.89941\teval-rmse:2.28723                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.35621\teval-rmse:2.15827\n",
      "\n",
      "\n",
      "loss: 97271792.98845318                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.154155548794043e-06, 'colsample_bytree': 0.65, 'gamma': 1.877205022014279e-08, 'lambda': 1.8742327508785213, 'learning_rate': 0.025, 'max_depth': 9, 'min_child_weight': 4.8683820015123676, 'n_estimators': 881.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.54346\teval-rmse:5.13399                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.43825\teval-rmse:5.02507                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.33635\teval-rmse:4.92036                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:5.23702\teval-rmse:4.81843                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:5.14117\teval-rmse:4.7224                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:5.04787\teval-rmse:4.62615                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.95687\teval-rmse:4.53262                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:4.86901\teval-rmse:4.44271                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:4.7843\teval-rmse:4.35596                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:4.70225\teval-rmse:4.27031                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:4.62328\teval-rmse:4.1877                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:4.54651\teval-rmse:4.10734                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:4.47114\teval-rmse:4.02976                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:4.39791\teval-rmse:3.95495                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:4.32616\teval-rmse:3.88282                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:4.25766\teval-rmse:3.81139                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:4.19037\teval-rmse:3.74286                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:4.12596\teval-rmse:3.67728                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:4.06263\teval-rmse:3.6131                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:4.00165\teval-rmse:3.55084                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.9426\teval-rmse:3.49133                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:3.88622\teval-rmse:3.43426                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.83111\teval-rmse:3.37747                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.77678\teval-rmse:3.32391                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.7246\teval-rmse:3.27236                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.67563\teval-rmse:3.22273                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.62641\teval-rmse:3.17438                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.57964\teval-rmse:3.12811                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.53427\teval-rmse:3.08225                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.49014\teval-rmse:3.03908                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.44768\teval-rmse:2.99668                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.40542\teval-rmse:2.95659                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.36685\teval-rmse:2.91725                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.32727\teval-rmse:2.87977                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.28973\teval-rmse:2.84353                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.25416\teval-rmse:2.80906                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.2192\teval-rmse:2.77652                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:3.1857\teval-rmse:2.74418                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:3.15251\teval-rmse:2.71354                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.12103\teval-rmse:2.68501                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.09071\teval-rmse:2.65696                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.06114\teval-rmse:2.63008                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.03246\teval-rmse:2.60197                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.00532\teval-rmse:2.57677                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.97837\teval-rmse:2.55179                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.95209\teval-rmse:2.52877                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.92677\teval-rmse:2.50744                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.90284\teval-rmse:2.48621                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.87951\teval-rmse:2.46679                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.85723\teval-rmse:2.44693                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.83441\teval-rmse:2.42827                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.81309\teval-rmse:2.40884                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.79323\teval-rmse:2.3914                                                                               \n",
      "\n",
      "[53]\ttrain-rmse:2.77351\teval-rmse:2.37579                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.75361\teval-rmse:2.35938                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.73549\teval-rmse:2.34443                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.71725\teval-rmse:2.33084                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.69993\teval-rmse:2.31718                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.68237\teval-rmse:2.30511                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.6657\teval-rmse:2.29243                                                                               \n",
      "\n",
      "[60]\ttrain-rmse:2.64965\teval-rmse:2.27969                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.63402\teval-rmse:2.26883                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.62003\teval-rmse:2.25665                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.60614\teval-rmse:2.24562                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.59022\teval-rmse:2.23522                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.57698\teval-rmse:2.2263                                                                               \n",
      "\n",
      "[66]\ttrain-rmse:2.56368\teval-rmse:2.21636                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.55057\teval-rmse:2.20918                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:2.53875\teval-rmse:2.19985                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.52634\teval-rmse:2.19118                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:2.51466\teval-rmse:2.18284                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:2.50342\teval-rmse:2.17583                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:2.49262\teval-rmse:2.16934                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:2.48355\teval-rmse:2.1632                                                                               \n",
      "\n",
      "[74]\ttrain-rmse:2.47455\teval-rmse:2.15768                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:2.46339\teval-rmse:2.15148                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:2.45355\teval-rmse:2.14636                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:2.44405\teval-rmse:2.14009                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:2.43498\teval-rmse:2.136                                                                                \n",
      "\n",
      "[79]\ttrain-rmse:2.42519\teval-rmse:2.13192                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:2.4157\teval-rmse:2.12676                                                                               \n",
      "\n",
      "[81]\ttrain-rmse:2.40674\teval-rmse:2.12212                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:2.3988\teval-rmse:2.11857                                                                               \n",
      "\n",
      "[83]\ttrain-rmse:2.39121\teval-rmse:2.11464                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:2.38381\teval-rmse:2.11094                                                                              \n",
      "\n",
      "[85]\ttrain-rmse:2.37657\teval-rmse:2.10696                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:2.36983\teval-rmse:2.1035                                                                               \n",
      "\n",
      "[87]\ttrain-rmse:2.36217\teval-rmse:2.10028                                                                              \n",
      "\n",
      "[88]\ttrain-rmse:2.3543\teval-rmse:2.09683                                                                               \n",
      "\n",
      "[89]\ttrain-rmse:2.34761\teval-rmse:2.09463                                                                              \n",
      "\n",
      "[90]\ttrain-rmse:2.34087\teval-rmse:2.09218                                                                              \n",
      "\n",
      "[91]\ttrain-rmse:2.33454\teval-rmse:2.08884                                                                              \n",
      "\n",
      "[92]\ttrain-rmse:2.32749\teval-rmse:2.08621                                                                              \n",
      "\n",
      "[93]\ttrain-rmse:2.32021\teval-rmse:2.08352                                                                              \n",
      "\n",
      "[94]\ttrain-rmse:2.31371\teval-rmse:2.08108                                                                              \n",
      "\n",
      "[95]\ttrain-rmse:2.3076\teval-rmse:2.07973                                                                               \n",
      "\n",
      "[96]\ttrain-rmse:2.30246\teval-rmse:2.0765                                                                               \n",
      "\n",
      "[97]\ttrain-rmse:2.29579\teval-rmse:2.07433                                                                              \n",
      "\n",
      "[98]\ttrain-rmse:2.28969\teval-rmse:2.07252                                                                              \n",
      "\n",
      "[99]\ttrain-rmse:2.28565\teval-rmse:2.07092                                                                              \n",
      "\n",
      "loss: 99143018.73558064                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.2697983569767663e-07, 'colsample_bytree': 0.6000000000000001, 'gamma': 2.9009694953111307e-06, 'lambda': 0.1754439919611871, 'learning_rate': 0.35000000000000003, 'max_depth': 9, 'min_child_weight': 0.12150160836356473, 'n_estimators': 747.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.19044\teval-rmse:3.75667                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.33595\teval-rmse:2.90363                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.85547\teval-rmse:2.46295                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.57808\teval-rmse:2.27917                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.41812\teval-rmse:2.19542                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.32094\teval-rmse:2.16669                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.25352\teval-rmse:2.15716                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.20931\teval-rmse:2.17981                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.15322\teval-rmse:2.20776                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.1014\teval-rmse:2.21521                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.04683\teval-rmse:2.22365                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.01629\teval-rmse:2.22571                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.9882\teval-rmse:2.2427                                                                                \n",
      "\n",
      "[13]\ttrain-rmse:1.95605\teval-rmse:2.24827                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.91776\teval-rmse:2.25381                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.89703\teval-rmse:2.25001                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.85981\teval-rmse:2.24717                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.82353\teval-rmse:2.24701                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.80843\teval-rmse:2.24395                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.7961\teval-rmse:2.25149                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.76946\teval-rmse:2.25508                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.74002\teval-rmse:2.25362                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.71886\teval-rmse:2.25421                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.69837\teval-rmse:2.26816                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.68423\teval-rmse:2.26693                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.63613\teval-rmse:2.27791                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.60808\teval-rmse:2.27515                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.25352\teval-rmse:2.15716\n",
      "\n",
      "\n",
      "loss: 96932815.0303969                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.03090959883187e-07, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.4220647452503724e-06, 'lambda': 8.455114331759835e-06, 'learning_rate': 0.275, 'max_depth': 5, 'min_child_weight': 0.24758738088533008, 'n_estimators': 278.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.5733\teval-rmse:4.04613                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.87388\teval-rmse:3.24438                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.43149\teval-rmse:2.74082                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.16041\teval-rmse:2.43042                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.00418\teval-rmse:2.26197                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.90698\teval-rmse:2.16822                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.84582\teval-rmse:2.11484                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.80506\teval-rmse:2.08755                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.77147\teval-rmse:2.05832                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.74905\teval-rmse:2.04273                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.73369\teval-rmse:2.03683                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.71551\teval-rmse:2.06009                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.70531\teval-rmse:2.06166                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.68766\teval-rmse:2.06308                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.67104\teval-rmse:2.05189                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.66012\teval-rmse:2.05558                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.651\teval-rmse:2.07054                                                                                \n",
      "\n",
      "[17]\ttrain-rmse:2.63956\teval-rmse:2.07047                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.63387\teval-rmse:2.0771                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.6293\teval-rmse:2.089                                                                                 \n",
      "\n",
      "[20]\ttrain-rmse:2.61678\teval-rmse:2.08668                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.6046\teval-rmse:2.099                                                                                 \n",
      "\n",
      "[22]\ttrain-rmse:2.59648\teval-rmse:2.10107                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.58655\teval-rmse:2.13315                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.57889\teval-rmse:2.13075                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.5715\teval-rmse:2.1336                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:2.563\teval-rmse:2.13286                                                                                \n",
      "\n",
      "[27]\ttrain-rmse:2.55034\teval-rmse:2.13848                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.5466\teval-rmse:2.13799                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.5393\teval-rmse:2.14338                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.53109\teval-rmse:2.14185                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.73369\teval-rmse:2.03683\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 98012487.63815553                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.112628745539116e-05, 'colsample_bytree': 0.65, 'gamma': 5.081640880673139e-08, 'lambda': 3.5052570450199007e-06, 'learning_rate': 0.17500000000000002, 'max_depth': 3, 'min_child_weight': 0.8953436986359431, 'n_estimators': 575.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.97511\teval-rmse:4.48014                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.451\teval-rmse:3.87948                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:4.05312\teval-rmse:3.40983                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.74838\teval-rmse:3.04768                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.53622\teval-rmse:2.78789                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.36495\teval-rmse:2.57828                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.23857\teval-rmse:2.42794                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.14694\teval-rmse:2.32131                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.07793\teval-rmse:2.24574                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.02888\teval-rmse:2.19437                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.99039\teval-rmse:2.15292                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.96382\teval-rmse:2.12915                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.94258\teval-rmse:2.10973                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.92537\teval-rmse:2.09527                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.91145\teval-rmse:2.0894                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.90072\teval-rmse:2.08108                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.89113\teval-rmse:2.07705                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.88348\teval-rmse:2.07335                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.87693\teval-rmse:2.07107                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.86994\teval-rmse:2.07238                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.86529\teval-rmse:2.07171                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.86184\teval-rmse:2.07288                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.85805\teval-rmse:2.06985                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.85232\teval-rmse:2.07156                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.84871\teval-rmse:2.07128                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.84046\teval-rmse:2.07005                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.83827\teval-rmse:2.06974                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.83493\teval-rmse:2.07223                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.83173\teval-rmse:2.07387                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.82977\teval-rmse:2.07347                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.82665\teval-rmse:2.07161                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.82295\teval-rmse:2.07199                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.82136\teval-rmse:2.07105                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.81812\teval-rmse:2.07259                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.81529\teval-rmse:2.07125                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.81345\teval-rmse:2.07239                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.8107\teval-rmse:2.07189                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.80654\teval-rmse:2.06723                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.80395\teval-rmse:2.06654                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.79889\teval-rmse:2.06555                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.79698\teval-rmse:2.06896                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.79364\teval-rmse:2.06832                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.79084\teval-rmse:2.06838                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.78847\teval-rmse:2.06845                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.78554\teval-rmse:2.06866                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.78486\teval-rmse:2.06868                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.78291\teval-rmse:2.06887                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.78073\teval-rmse:2.06881                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.77969\teval-rmse:2.06844                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.77816\teval-rmse:2.06763                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.77583\teval-rmse:2.06892                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.77325\teval-rmse:2.0686                                                                               \n",
      "\n",
      "[52]\ttrain-rmse:2.77027\teval-rmse:2.06516                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.76714\teval-rmse:2.06583                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.76532\teval-rmse:2.06358                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.76295\teval-rmse:2.06264                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.76152\teval-rmse:2.06262                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.75781\teval-rmse:2.06287                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.75572\teval-rmse:2.0612                                                                               \n",
      "\n",
      "[59]\ttrain-rmse:2.7535\teval-rmse:2.06299                                                                               \n",
      "\n",
      "[60]\ttrain-rmse:2.75\teval-rmse:2.06                                                                                    \n",
      "\n",
      "[61]\ttrain-rmse:2.74803\teval-rmse:2.06002                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.74575\teval-rmse:2.0588                                                                               \n",
      "\n",
      "[63]\ttrain-rmse:2.74461\teval-rmse:2.05793                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.74204\teval-rmse:2.0567                                                                               \n",
      "\n",
      "[65]\ttrain-rmse:2.74027\teval-rmse:2.05531                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.73822\teval-rmse:2.05694                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.73701\teval-rmse:2.05685                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:2.73438\teval-rmse:2.05965                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.73271\teval-rmse:2.05885                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:2.73105\teval-rmse:2.06049                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:2.7298\teval-rmse:2.06062                                                                               \n",
      "\n",
      "[72]\ttrain-rmse:2.72897\teval-rmse:2.06048                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:2.72671\teval-rmse:2.05849                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:2.72482\teval-rmse:2.05681                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:2.7232\teval-rmse:2.05318                                                                               \n",
      "\n",
      "[76]\ttrain-rmse:2.72242\teval-rmse:2.05288                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:2.71988\teval-rmse:2.0509                                                                               \n",
      "\n",
      "[78]\ttrain-rmse:2.71854\teval-rmse:2.05033                                                                              \n",
      "\n",
      "[79]\ttrain-rmse:2.71652\teval-rmse:2.05014                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:2.71371\teval-rmse:2.04877                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:2.71217\teval-rmse:2.05063                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:2.71074\teval-rmse:2.05134                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:2.70957\teval-rmse:2.04974                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:2.70727\teval-rmse:2.04972                                                                              \n",
      "\n",
      "[85]\ttrain-rmse:2.70616\teval-rmse:2.04928                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:2.70356\teval-rmse:2.04867                                                                              \n",
      "\n",
      "[87]\ttrain-rmse:2.70194\teval-rmse:2.04897                                                                              \n",
      "\n",
      "[88]\ttrain-rmse:2.70069\teval-rmse:2.0484                                                                               \n",
      "\n",
      "[89]\ttrain-rmse:2.69946\teval-rmse:2.04815                                                                              \n",
      "\n",
      "[90]\ttrain-rmse:2.69874\teval-rmse:2.04757                                                                              \n",
      "\n",
      "[91]\ttrain-rmse:2.69742\teval-rmse:2.048                                                                                \n",
      "\n",
      "[92]\ttrain-rmse:2.69529\teval-rmse:2.04811                                                                              \n",
      "\n",
      "[93]\ttrain-rmse:2.69359\teval-rmse:2.04762                                                                              \n",
      "\n",
      "[94]\ttrain-rmse:2.69278\teval-rmse:2.04733                                                                              \n",
      "\n",
      "[95]\ttrain-rmse:2.69124\teval-rmse:2.04633                                                                              \n",
      "\n",
      "[96]\ttrain-rmse:2.68954\teval-rmse:2.05135                                                                              \n",
      "\n",
      "[97]\ttrain-rmse:2.68791\teval-rmse:2.05053                                                                              \n",
      "\n",
      "[98]\ttrain-rmse:2.68725\teval-rmse:2.05101                                                                              \n",
      "\n",
      "[99]\ttrain-rmse:2.68504\teval-rmse:2.05226                                                                              \n",
      "\n",
      "loss: 98026869.09868                                                                                                   \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.35436505084480097, 'colsample_bytree': 0.75, 'gamma': 5.3483857114248834e-06, 'lambda': 0.0024242437229753367, 'learning_rate': 0.2, 'max_depth': 9, 'min_child_weight': 1.3213544691923014, 'n_estimators': 675.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.79357\teval-rmse:4.37493                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.13925\teval-rmse:3.70743                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.63957\teval-rmse:3.21328                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.26148\teval-rmse:2.85537                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.97402\teval-rmse:2.58438                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.76537\teval-rmse:2.40311                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.61355\teval-rmse:2.28811                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.49544\teval-rmse:2.221                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.40365\teval-rmse:2.18375                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.33562\teval-rmse:2.14513                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.27597\teval-rmse:2.12236                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.23004\teval-rmse:2.11171                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.19738\teval-rmse:2.1046                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.14961\teval-rmse:2.10183                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.11131\teval-rmse:2.09486                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.08051\teval-rmse:2.0964                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.05429\teval-rmse:2.09959                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.01347\teval-rmse:2.10282                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.99392\teval-rmse:2.10705                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.96782\teval-rmse:2.11212                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.95015\teval-rmse:2.11076                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.93595\teval-rmse:2.1187                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-rmse:1.91561\teval-rmse:2.11903                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.90172\teval-rmse:2.11955                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.8872\teval-rmse:2.11721                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.85974\teval-rmse:2.12392                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.85157\teval-rmse:2.12595                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.8286\teval-rmse:2.12948                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.81464\teval-rmse:2.13388                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.79625\teval-rmse:2.13827                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.76966\teval-rmse:2.14293                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.74151\teval-rmse:2.15598                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.72392\teval-rmse:2.16794                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.71442\teval-rmse:2.16823                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.70443\teval-rmse:2.17515                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[14]\ttrain-rmse:2.11131\teval-rmse:2.09486\n",
      "\n",
      "\n",
      "loss: 96633144.53417361                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.786237509387808e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 8.255517217230765e-07, 'lambda': 1.5769072566441996e-06, 'learning_rate': 0.4, 'max_depth': 7, 'min_child_weight': 1.9495379539743831, 'n_estimators': 820.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.0643\teval-rmse:3.55017                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.27355\teval-rmse:2.70447                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.8933\teval-rmse:2.33902                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.70708\teval-rmse:2.19993                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.61381\teval-rmse:2.16701                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.55378\teval-rmse:2.13882                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.51296\teval-rmse:2.14558                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.4737\teval-rmse:2.16095                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.43555\teval-rmse:2.18746                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.40193\teval-rmse:2.20634                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.38195\teval-rmse:2.22359                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.36065\teval-rmse:2.22768                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.33508\teval-rmse:2.23333                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.30702\teval-rmse:2.25812                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.29154\teval-rmse:2.25932                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.26931\teval-rmse:2.26742                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.25209\teval-rmse:2.28305                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.22547\teval-rmse:2.28504                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.21615\teval-rmse:2.29978                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.19779\teval-rmse:2.29895                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.17526\teval-rmse:2.31078                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.16154\teval-rmse:2.31193                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.1461\teval-rmse:2.33579                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.12714\teval-rmse:2.33126                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.11508\teval-rmse:2.32925                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.09485\teval-rmse:2.33518                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.55378\teval-rmse:2.13882\n",
      "\n",
      "\n",
      "loss: 97116811.8396254                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.372190229446611e-06, 'colsample_bytree': 0.6000000000000001, 'gamma': 2.449855972714927e-07, 'lambda': 0.006900416479275375, 'learning_rate': 0.15000000000000002, 'max_depth': 9, 'min_child_weight': 0.5245767961581105, 'n_estimators': 453.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.99913\teval-rmse:4.59096                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.46124\teval-rmse:4.04955                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.02\teval-rmse:3.61048                                                                                  \n",
      "\n",
      "[3]\ttrain-rmse:3.65773\teval-rmse:3.25733                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.3633\teval-rmse:2.98803                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.12436\teval-rmse:2.76397                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.93091\teval-rmse:2.59097                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.77989\teval-rmse:2.46032                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.65631\teval-rmse:2.35956                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.55764\teval-rmse:2.28185                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.47054\teval-rmse:2.22365                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.39386\teval-rmse:2.1889                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.33835\teval-rmse:2.15787                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.28291\teval-rmse:2.1356                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.23279\teval-rmse:2.12297                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.19339\teval-rmse:2.11456                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.15633\teval-rmse:2.10998                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.12769\teval-rmse:2.1046                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.09566\teval-rmse:2.10911                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.06607\teval-rmse:2.1069                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.04384\teval-rmse:2.10869                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.01784\teval-rmse:2.11873                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.99504\teval-rmse:2.12537                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.9801\teval-rmse:2.12758                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.95302\teval-rmse:2.1294                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.94062\teval-rmse:2.12823                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.92595\teval-rmse:2.13287                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.91036\teval-rmse:2.13295                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.89493\teval-rmse:2.13313                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.8743\teval-rmse:2.13651                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:1.85816\teval-rmse:2.13588                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.84415\teval-rmse:2.13472                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.83022\teval-rmse:2.13533                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.82112\teval-rmse:2.13844                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.81451\teval-rmse:2.14077                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.80887\teval-rmse:2.14378                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.80403\teval-rmse:2.14564                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.79068\teval-rmse:2.14659                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:2.12769\teval-rmse:2.1046\n",
      "\n",
      "\n",
      "loss: 96707762.95570311                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.346429841249926e-08, 'colsample_bytree': 0.65, 'gamma': 1.0976271651796019e-07, 'lambda': 0.4950568408587049, 'learning_rate': 0.325, 'max_depth': 4, 'min_child_weight': 0.7555417329957335, 'n_estimators': 420.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.40729\teval-rmse:3.84728                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.69003\teval-rmse:3.00157                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.29424\teval-rmse:2.52463                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.08272\teval-rmse:2.27763                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.97961\teval-rmse:2.16219                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.91016\teval-rmse:2.10166                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.86874\teval-rmse:2.07328                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.8486\teval-rmse:2.0616                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.82871\teval-rmse:2.05637                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.81302\teval-rmse:2.04952                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.80423\teval-rmse:2.05327                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.79163\teval-rmse:2.05894                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.78454\teval-rmse:2.0595                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.77652\teval-rmse:2.05621                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.77195\teval-rmse:2.06035                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.76518\teval-rmse:2.06304                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.7562\teval-rmse:2.06143                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.74638\teval-rmse:2.05767                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.74013\teval-rmse:2.06827                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.73461\teval-rmse:2.07615                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.72379\teval-rmse:2.07992                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.71779\teval-rmse:2.07836                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.71501\teval-rmse:2.07764                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.70833\teval-rmse:2.07627                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.70297\teval-rmse:2.07072                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.69823\teval-rmse:2.07399                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.69055\teval-rmse:2.07807                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.68495\teval-rmse:2.07889                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.67794\teval-rmse:2.07846                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.6708\teval-rmse:2.07846                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.81302\teval-rmse:2.04952\n",
      "\n",
      "\n",
      "loss: 98302257.75567983                                                                                                \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0218884168381474e-05, 'colsample_bytree': 0.8, 'gamma': 8.363831454079705e-06, 'lambda': 0.10301206991885693, 'learning_rate': 0.225, 'max_depth': 9, 'min_child_weight': 2.4631127608912577, 'n_estimators': 857.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.68247\teval-rmse:4.26356                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.97379\teval-rmse:3.54779                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.44857\teval-rmse:3.0401                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.07583\teval-rmse:2.69638                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.81207\teval-rmse:2.45729                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.62079\teval-rmse:2.3138                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.47741\teval-rmse:2.21542                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.37222\teval-rmse:2.15972                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.29125\teval-rmse:2.12182                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.23742\teval-rmse:2.10892                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.184\teval-rmse:2.0992                                                                                 \n",
      "\n",
      "[11]\ttrain-rmse:2.12955\teval-rmse:2.08864                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.09406\teval-rmse:2.08301                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.06866\teval-rmse:2.08049                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.03946\teval-rmse:2.07515                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.00596\teval-rmse:2.06568                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.98858\teval-rmse:2.06664                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.95118\teval-rmse:2.06682                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.92125\teval-rmse:2.0662                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.90855\teval-rmse:2.07038                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.89271\teval-rmse:2.07395                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.87275\teval-rmse:2.08348                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.84832\teval-rmse:2.08891                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.81974\teval-rmse:2.09066                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.8015\teval-rmse:2.09065                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.78427\teval-rmse:2.10869                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.77336\teval-rmse:2.11067                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.75842\teval-rmse:2.11038                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.73757\teval-rmse:2.11122                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.7232\teval-rmse:2.11641                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:1.70474\teval-rmse:2.11556                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.67258\teval-rmse:2.11794                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.65168\teval-rmse:2.11776                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.64674\teval-rmse:2.11578                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.63839\teval-rmse:2.11603                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.61464\teval-rmse:2.12458                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.00596\teval-rmse:2.06568\n",
      "\n",
      "\n",
      "loss: 96820307.3288721                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.14621387779057646, 'colsample_bytree': 0.75, 'gamma': 3.1832033153551386e-05, 'lambda': 0.022293672259298482, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 1.0983295399583939, 'n_estimators': 210.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.38785\teval-rmse:3.96153                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.57567\teval-rmse:3.15487                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.05562\teval-rmse:2.67117                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.72799\teval-rmse:2.40122                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.52058\teval-rmse:2.27809                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.38358\teval-rmse:2.20597                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.28959\teval-rmse:2.17707                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.22503\teval-rmse:2.16315                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.15623\teval-rmse:2.1614                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.13239\teval-rmse:2.17199                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.08774\teval-rmse:2.18169                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.04543\teval-rmse:2.19141                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.99717\teval-rmse:2.20353                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.97423\teval-rmse:2.21905                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.939\teval-rmse:2.20507                                                                                \n",
      "\n",
      "[15]\ttrain-rmse:1.9089\teval-rmse:2.22121                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:1.87559\teval-rmse:2.22715                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.83883\teval-rmse:2.23681                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.82545\teval-rmse:2.24807                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.80817\teval-rmse:2.24681                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.78858\teval-rmse:2.24356                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.76491\teval-rmse:2.24819                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.74199\teval-rmse:2.24975                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.73356\teval-rmse:2.26167                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.71681\teval-rmse:2.26432                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.71293\teval-rmse:2.26789                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.69228\teval-rmse:2.28291                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.6623\teval-rmse:2.28286                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.65516\teval-rmse:2.2811                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.15623\teval-rmse:2.1614\n",
      "\n",
      "\n",
      "loss: 100757192.30267088                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00020232047690203333, 'colsample_bytree': 0.7000000000000001, 'gamma': 4.726535838299289e-07, 'lambda': 0.25990298582506305, 'learning_rate': 0.25, 'max_depth': 6, 'min_child_weight': 1.1991245563009012, 'n_estimators': 329.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.64597\teval-rmse:4.15141                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.95868\teval-rmse:3.38775                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.49882\teval-rmse:2.87811                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.20082\teval-rmse:2.54892                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.00953\teval-rmse:2.3287                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.88272\teval-rmse:2.20547                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.79678\teval-rmse:2.13088                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.7407\teval-rmse:2.08889                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.70395\teval-rmse:2.05791                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.6784\teval-rmse:2.05037                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.65633\teval-rmse:2.04586                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.64488\teval-rmse:2.04341                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.62447\teval-rmse:2.04223                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.60483\teval-rmse:2.04062                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.58595\teval-rmse:2.0511                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.57436\teval-rmse:2.05549                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.55933\teval-rmse:2.05882                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.54176\teval-rmse:2.0605                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.52896\teval-rmse:2.06435                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.51756\teval-rmse:2.07013                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.50586\teval-rmse:2.08222                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.49799\teval-rmse:2.0819                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.48546\teval-rmse:2.08899                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.47188\teval-rmse:2.09377                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.46568\teval-rmse:2.09093                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.4619\teval-rmse:2.0922                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:2.45385\teval-rmse:2.09456                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.44497\teval-rmse:2.09974                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.43502\teval-rmse:2.09855                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.42937\teval-rmse:2.09914                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.41954\teval-rmse:2.09786                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.41212\teval-rmse:2.09218                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.4021\teval-rmse:2.09248                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.39222\teval-rmse:2.08842                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.60483\teval-rmse:2.04062\n",
      "\n",
      "\n",
      "loss: 97798035.0350779                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0009434075702153176, 'colsample_bytree': 0.65, 'gamma': 2.7601403727123894e-06, 'lambda': 0.07713457924814536, 'learning_rate': 0.42500000000000004, 'max_depth': 5, 'min_child_weight': 3.1083696990868006, 'n_estimators': 695.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.04192\teval-rmse:3.4499                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.31126\teval-rmse:2.60319                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.00379\teval-rmse:2.25655                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.87116\teval-rmse:2.13228                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.81337\teval-rmse:2.09599                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.78224\teval-rmse:2.08204                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.76047\teval-rmse:2.0888                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.73995\teval-rmse:2.08729                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain-rmse:2.71922\teval-rmse:2.09392                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.70277\teval-rmse:2.09546                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.69003\teval-rmse:2.09158                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.68348\teval-rmse:2.09119                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.6697\teval-rmse:2.09899                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.64968\teval-rmse:2.12079                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.64178\teval-rmse:2.11656                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.6311\teval-rmse:2.12495                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.62435\teval-rmse:2.12606                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.61667\teval-rmse:2.13522                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.60755\teval-rmse:2.14433                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.6036\teval-rmse:2.14761                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.59494\teval-rmse:2.1487                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.58545\teval-rmse:2.14573                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.57405\teval-rmse:2.1405                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.56166\teval-rmse:2.1476                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.55582\teval-rmse:2.15123                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.55173\teval-rmse:2.16172                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.78224\teval-rmse:2.08204\n",
      "\n",
      "\n",
      "loss: 190237185.22443688                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.034488986897179524, 'colsample_bytree': 0.7000000000000001, 'gamma': 8.780700622713492e-05, 'lambda': 0.03754169641156988, 'learning_rate': 0.375, 'max_depth': 3, 'min_child_weight': 2.735768802840893, 'n_estimators': 522.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.26192\teval-rmse:3.66099                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.55753\teval-rmse:2.81682                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.20972\teval-rmse:2.39142                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.04594\teval-rmse:2.21189                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.97143\teval-rmse:2.13719                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.9338\teval-rmse:2.10901                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.91094\teval-rmse:2.09343                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.8993\teval-rmse:2.08915                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.88056\teval-rmse:2.09592                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.86737\teval-rmse:2.08566                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.85993\teval-rmse:2.09018                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.85348\teval-rmse:2.08915                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.84799\teval-rmse:2.08394                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.83907\teval-rmse:2.0972                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.83499\teval-rmse:2.09795                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.82742\teval-rmse:2.08905                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.82363\teval-rmse:2.08546                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.8164\teval-rmse:2.07815                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.81101\teval-rmse:2.08464                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.80897\teval-rmse:2.08132                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.80388\teval-rmse:2.08602                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.79985\teval-rmse:2.08354                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.79671\teval-rmse:2.08505                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.79351\teval-rmse:2.09029                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.79105\teval-rmse:2.09718                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.78681\teval-rmse:2.09737                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.7851\teval-rmse:2.09848                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.78288\teval-rmse:2.10152                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.77801\teval-rmse:2.114                                                                                \n",
      "\n",
      "[29]\ttrain-rmse:2.77291\teval-rmse:2.10898                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.77075\teval-rmse:2.10479                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.76533\teval-rmse:2.11691                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.75867\teval-rmse:2.12018                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.75619\teval-rmse:2.11583                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.75299\teval-rmse:2.10509                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.7506\teval-rmse:2.10449                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.74389\teval-rmse:2.10215                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.73966\teval-rmse:2.10215                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:2.8164\teval-rmse:2.07815\n",
      "\n",
      "\n",
      "loss: 98268569.34103344                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.019035358908140333, 'colsample_bytree': 0.75, 'gamma': 0.00024527173044428896, 'lambda': 5.817878955115555e-05, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 2.1735933991313736, 'n_estimators': 660.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.48512\teval-rmse:4.05483                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.68732\teval-rmse:3.25832                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.1666\teval-rmse:2.7576                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:2.8214\teval-rmse:2.46507                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.59857\teval-rmse:2.29453                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.44274\teval-rmse:2.19692                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.34307\teval-rmse:2.15028                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.26535\teval-rmse:2.13454                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.21583\teval-rmse:2.12166                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.1595\teval-rmse:2.11536                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.11234\teval-rmse:2.11299                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.07093\teval-rmse:2.12051                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.05359\teval-rmse:2.12074                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.03593\teval-rmse:2.13581                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.00881\teval-rmse:2.14345                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.96994\teval-rmse:2.15601                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.94722\teval-rmse:2.16329                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.9089\teval-rmse:2.16008                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:1.8942\teval-rmse:2.16136                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.87655\teval-rmse:2.17077                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.86585\teval-rmse:2.17549                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.83985\teval-rmse:2.17976                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.81201\teval-rmse:2.18512                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.79618\teval-rmse:2.18853                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.77264\teval-rmse:2.18908                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.75724\teval-rmse:2.18948                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.73447\teval-rmse:2.18648                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.69616\teval-rmse:2.19194                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.67935\teval-rmse:2.19929                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.64037\teval-rmse:2.20855                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.60406\teval-rmse:2.21328                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.11234\teval-rmse:2.11299\n",
      "\n",
      "\n",
      "loss: 96865837.22357582                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.237302761313452e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.3329051990606955e-05, 'lambda': 0.0035151821855032286, 'learning_rate': 0.17500000000000002, 'max_depth': 7, 'min_child_weight': 1.660243906536826, 'n_estimators': 369.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.91921\teval-rmse:4.47992                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.34748\teval-rmse:3.87071                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.90347\teval-rmse:3.39447                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.56456\teval-rmse:3.03379                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.30687\teval-rmse:2.75834                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.10902\teval-rmse:2.55137                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.96193\teval-rmse:2.40344                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.84933\teval-rmse:2.2969                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.76359\teval-rmse:2.22455                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.69812\teval-rmse:2.1679                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.64651\teval-rmse:2.12798                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.61075\teval-rmse:2.10591                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.57902\teval-rmse:2.08934                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.53912\teval-rmse:2.07747                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.51753\teval-rmse:2.07366                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.49973\teval-rmse:2.06807                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.47985\teval-rmse:2.07003                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.45743\teval-rmse:2.07149                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.44029\teval-rmse:2.07044                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.42341\teval-rmse:2.07085                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.40826\teval-rmse:2.0708                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.39878\teval-rmse:2.07318                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.38499\teval-rmse:2.07553                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.36876\teval-rmse:2.06754                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24]\ttrain-rmse:2.3567\teval-rmse:2.06595                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.34274\teval-rmse:2.06981                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.33258\teval-rmse:2.07228                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.31798\teval-rmse:2.07774                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.30915\teval-rmse:2.07529                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.29728\teval-rmse:2.08009                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.28921\teval-rmse:2.07887                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.28344\teval-rmse:2.07793                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.27789\teval-rmse:2.07727                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.26394\teval-rmse:2.0777                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:2.25017\teval-rmse:2.08579                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.23572\teval-rmse:2.10613                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.22725\teval-rmse:2.10949                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.21382\teval-rmse:2.10777                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.20839\teval-rmse:2.11134                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.20065\teval-rmse:2.11224                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.1883\teval-rmse:2.11018                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.17327\teval-rmse:2.11053                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.16351\teval-rmse:2.11542                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.15386\teval-rmse:2.11607                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.14422\teval-rmse:2.11641                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[24]\ttrain-rmse:2.3567\teval-rmse:2.06595\n",
      "\n",
      "\n",
      "loss: 97471038.0559934                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.800864291575032e-08, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.782166258269953e-07, 'lambda': 0.0001427426276350411, 'learning_rate': 0.15000000000000002, 'max_depth': 4, 'min_child_weight': 0.9422947081785178, 'n_estimators': 713.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.05734\teval-rmse:4.58612                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.57749\teval-rmse:4.04505                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.19294\teval-rmse:3.60559                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.88595\teval-rmse:3.24738                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.64779\teval-rmse:2.9609                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.45755\teval-rmse:2.73867                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.31279\teval-rmse:2.5681                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.20115\teval-rmse:2.43932                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.11456\teval-rmse:2.3388                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.04949\teval-rmse:2.26606                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.9988\teval-rmse:2.2041                                                                                \n",
      "\n",
      "[11]\ttrain-rmse:2.95874\teval-rmse:2.15545                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.9255\teval-rmse:2.12037                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.89832\teval-rmse:2.09746                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.87746\teval-rmse:2.08352                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.86069\teval-rmse:2.07062                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.84742\teval-rmse:2.06213                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.83621\teval-rmse:2.05782                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.82592\teval-rmse:2.05224                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.81692\teval-rmse:2.05013                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.80803\teval-rmse:2.05099                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.8001\teval-rmse:2.04717                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.79355\teval-rmse:2.04648                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.78817\teval-rmse:2.04537                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.78156\teval-rmse:2.04282                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.77406\teval-rmse:2.04315                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.76989\teval-rmse:2.04264                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.76573\teval-rmse:2.04055                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.76116\teval-rmse:2.04181                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.75594\teval-rmse:2.04515                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.75176\teval-rmse:2.04547                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.74906\teval-rmse:2.04676                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.7453\teval-rmse:2.04569                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.73959\teval-rmse:2.04591                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.73595\teval-rmse:2.04555                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.73273\teval-rmse:2.04569                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.73059\teval-rmse:2.04553                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.72559\teval-rmse:2.03888                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.72098\teval-rmse:2.03826                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.71784\teval-rmse:2.04131                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.71441\teval-rmse:2.04172                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.71189\teval-rmse:2.04102                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.70916\teval-rmse:2.04286                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.70539\teval-rmse:2.0473                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:2.70379\teval-rmse:2.04677                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.7018\teval-rmse:2.04884                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.69816\teval-rmse:2.05183                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.6948\teval-rmse:2.05341                                                                               \n",
      "\n",
      "[48]\ttrain-rmse:2.68926\teval-rmse:2.05106                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.68521\teval-rmse:2.0522                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:2.68137\teval-rmse:2.05301                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.67895\teval-rmse:2.05293                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.67484\teval-rmse:2.05152                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.67059\teval-rmse:2.05412                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.66721\teval-rmse:2.05247                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.66391\teval-rmse:2.05052                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.66067\teval-rmse:2.0504                                                                               \n",
      "\n",
      "[57]\ttrain-rmse:2.65737\teval-rmse:2.05048                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.65277\teval-rmse:2.04717                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[38]\ttrain-rmse:2.72098\teval-rmse:2.03826\n",
      "\n",
      "\n",
      "loss: 98201654.50405625                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0025281068199377835, 'colsample_bytree': 0.8, 'gamma': 9.312735112311751e-07, 'lambda': 0.0006089125868329399, 'learning_rate': 0.2, 'max_depth': 9, 'min_child_weight': 4.252213443682082, 'n_estimators': 980.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.78926\teval-rmse:4.36657                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.12977\teval-rmse:3.70352                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.62155\teval-rmse:3.19976                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.25033\teval-rmse:2.83905                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.96303\teval-rmse:2.58435                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.75588\teval-rmse:2.40408                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.60561\teval-rmse:2.28688                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.4892\teval-rmse:2.21418                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.39525\teval-rmse:2.17152                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.32361\teval-rmse:2.15743                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.26036\teval-rmse:2.15203                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.20349\teval-rmse:2.14428                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.16539\teval-rmse:2.13747                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.13026\teval-rmse:2.13637                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.09426\teval-rmse:2.13246                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.08282\teval-rmse:2.12949                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.05678\teval-rmse:2.12986                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.03323\teval-rmse:2.13519                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.00946\teval-rmse:2.13312                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.98619\teval-rmse:2.13495                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.95984\teval-rmse:2.13755                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.9479\teval-rmse:2.13817                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.92628\teval-rmse:2.14173                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.90688\teval-rmse:2.13701                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.88832\teval-rmse:2.14265                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.87954\teval-rmse:2.14777                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.86904\teval-rmse:2.14742                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.8517\teval-rmse:2.14817                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.82983\teval-rmse:2.14259                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.82097\teval-rmse:2.142                                                                                \n",
      "\n",
      "[30]\ttrain-rmse:1.80816\teval-rmse:2.14328                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.79734\teval-rmse:2.14309                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.78345\teval-rmse:2.14329                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.76639\teval-rmse:2.15261                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.75812\teval-rmse:2.15664                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.75205\teval-rmse:2.15816                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.08282\teval-rmse:2.12949\n",
      "\n",
      "\n",
      "loss: 96572365.13863423                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0022848657323595077, 'colsample_bytree': 0.8500000000000001, 'gamma': 4.021729697162181e-08, 'lambda': 0.0003154551636172473, 'learning_rate': 0.2, 'max_depth': 9, 'min_child_weight': 4.466265478665211, 'n_estimators': 977.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.78902\teval-rmse:4.37254                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.13223\teval-rmse:3.70646                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.6337\teval-rmse:3.21551                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.2571\teval-rmse:2.86485                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.97807\teval-rmse:2.6057                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.7685\teval-rmse:2.42619                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.61962\teval-rmse:2.30817                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.50425\teval-rmse:2.23174                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.41535\teval-rmse:2.18186                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.35181\teval-rmse:2.1478                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.30395\teval-rmse:2.12842                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.26064\teval-rmse:2.12192                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.22574\teval-rmse:2.11896                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.18888\teval-rmse:2.11716                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.16802\teval-rmse:2.11312                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.14692\teval-rmse:2.11235                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.11065\teval-rmse:2.1081                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.07698\teval-rmse:2.10564                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.058\teval-rmse:2.10403                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:2.03855\teval-rmse:2.10936                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.02837\teval-rmse:2.11273                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.00645\teval-rmse:2.11679                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.98455\teval-rmse:2.12218                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.971\teval-rmse:2.12705                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:1.94636\teval-rmse:2.12912                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.93188\teval-rmse:2.13428                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.92287\teval-rmse:2.1349                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.91212\teval-rmse:2.1424                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.9013\teval-rmse:2.14327                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:1.86692\teval-rmse:2.14977                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.85744\teval-rmse:2.15018                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.84414\teval-rmse:2.15285                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.83078\teval-rmse:2.15632                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.80837\teval-rmse:2.17501                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.80315\teval-rmse:2.1753                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:1.79129\teval-rmse:2.17611                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.78075\teval-rmse:2.17783                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.77209\teval-rmse:2.17935                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.7552\teval-rmse:2.19744                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[18]\ttrain-rmse:2.058\teval-rmse:2.10403\n",
      "\n",
      "\n",
      "loss: 96890719.22673869                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0017296755864759528, 'colsample_bytree': 0.8, 'gamma': 1.1301932693215224e-08, 'lambda': 0.14230390893902908, 'learning_rate': 0.125, 'max_depth': 6, 'min_child_weight': 1.4756652713280607, 'n_estimators': 917.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.13454\teval-rmse:4.69452                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.70209\teval-rmse:4.22295                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.33495\teval-rmse:3.8219                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:4.02905\teval-rmse:3.48438                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.77597\teval-rmse:3.20481                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.56745\teval-rmse:2.97379                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.39615\teval-rmse:2.78055                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.2557\teval-rmse:2.62685                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.13852\teval-rmse:2.49671                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.04287\teval-rmse:2.392                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.96549\teval-rmse:2.30891                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.90606\teval-rmse:2.2495                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.85451\teval-rmse:2.1976                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.81142\teval-rmse:2.1606                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.77568\teval-rmse:2.13204                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.74498\teval-rmse:2.10885                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.72077\teval-rmse:2.09265                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.69618\teval-rmse:2.08166                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.67505\teval-rmse:2.07193                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.65896\teval-rmse:2.0615                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.64277\teval-rmse:2.0506                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.629\teval-rmse:2.046                                                                                  \n",
      "\n",
      "[22]\ttrain-rmse:2.61462\teval-rmse:2.04267                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.60221\teval-rmse:2.04228                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.59062\teval-rmse:2.0408                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.58231\teval-rmse:2.04169                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.57296\teval-rmse:2.03848                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.5615\teval-rmse:2.03526                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.55319\teval-rmse:2.03663                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.54389\teval-rmse:2.03257                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.53595\teval-rmse:2.0321                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.52748\teval-rmse:2.03085                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.51927\teval-rmse:2.02779                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.51003\teval-rmse:2.02985                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.5046\teval-rmse:2.02798                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:2.49525\teval-rmse:2.02714                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.49059\teval-rmse:2.02856                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.48437\teval-rmse:2.03311                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.4768\teval-rmse:2.03456                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:2.47015\teval-rmse:2.03626                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.46212\teval-rmse:2.03735                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.45645\teval-rmse:2.03705                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.44812\teval-rmse:2.03993                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.44274\teval-rmse:2.04038                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.43863\teval-rmse:2.04043                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.43382\teval-rmse:2.04074                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.42831\teval-rmse:2.04254                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.42432\teval-rmse:2.04258                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.42007\teval-rmse:2.04328                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.415\teval-rmse:2.044                                                                                  \n",
      "\n",
      "[50]\ttrain-rmse:2.40821\teval-rmse:2.04348                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.39975\teval-rmse:2.0463                                                                               \n",
      "\n",
      "[52]\ttrain-rmse:2.39126\teval-rmse:2.04565                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.3886\teval-rmse:2.04565                                                                               \n",
      "\n",
      "[54]\ttrain-rmse:2.38105\teval-rmse:2.04751                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.37618\teval-rmse:2.04955                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[35]\ttrain-rmse:2.49525\teval-rmse:2.02714\n",
      "\n",
      "\n",
      "loss: 97715212.15652516                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.9152122609395075e-06, 'colsample_bytree': 0.8500000000000001, 'gamma': 9.23964401559918e-08, 'lambda': 2.124092255261899e-05, 'learning_rate': 0.30000000000000004, 'max_depth': 5, 'min_child_weight': 0.2950593068998401, 'n_estimators': 994.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.47033\teval-rmse:3.95146                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.75491\teval-rmse:3.12265                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.32738\teval-rmse:2.63248                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.08196\teval-rmse:2.35855                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.93664\teval-rmse:2.20759                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.8537\teval-rmse:2.13012                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.80478\teval-rmse:2.08522                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.77131\teval-rmse:2.06742                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.7471\teval-rmse:2.05714                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.7305\teval-rmse:2.05117                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.71458\teval-rmse:2.05714                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.70476\teval-rmse:2.05103                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.68547\teval-rmse:2.05643                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.67489\teval-rmse:2.07101                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.66841\teval-rmse:2.07077                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.65677\teval-rmse:2.06642                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.64422\teval-rmse:2.06962                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.63112\teval-rmse:2.06474                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\ttrain-rmse:2.62323\teval-rmse:2.07113                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.60979\teval-rmse:2.09282                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.59938\teval-rmse:2.09339                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.58722\teval-rmse:2.08909                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.58143\teval-rmse:2.08928                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.57175\teval-rmse:2.08774                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.56524\teval-rmse:2.08634                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.55473\teval-rmse:2.11642                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.55016\teval-rmse:2.1244                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.54358\teval-rmse:2.12032                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.53731\teval-rmse:2.12268                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.5311\teval-rmse:2.12353                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.52118\teval-rmse:2.13796                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.51746\teval-rmse:2.13833                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.70476\teval-rmse:2.05103\n",
      "\n",
      "\n",
      "loss: 98322551.98708414                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0058886400467085855, 'colsample_bytree': 0.8, 'gamma': 4.135068643440707e-07, 'lambda': 0.0005014372259731122, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 4.151466913305408, 'n_estimators': 877.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.21416\teval-rmse:4.80232                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.83033\teval-rmse:4.40943                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.49055\teval-rmse:4.06675                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.19128\teval-rmse:3.76809                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.92502\teval-rmse:3.50514                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.69296\teval-rmse:3.2768                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.49029\teval-rmse:3.08207                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.31429\teval-rmse:2.91294                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.16204\teval-rmse:2.76918                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.03056\teval-rmse:2.64697                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.9101\teval-rmse:2.54737                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.80728\teval-rmse:2.46448                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.72172\teval-rmse:2.39193                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.64269\teval-rmse:2.33486                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.57647\teval-rmse:2.28676                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.52099\teval-rmse:2.24596                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.46354\teval-rmse:2.21346                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.40783\teval-rmse:2.18634                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.36768\teval-rmse:2.16274                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.32593\teval-rmse:2.1521                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.2887\teval-rmse:2.13792                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.25951\teval-rmse:2.12689                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.23477\teval-rmse:2.11846                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.20942\teval-rmse:2.11146                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.18631\teval-rmse:2.1026                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.16388\teval-rmse:2.0976                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.13817\teval-rmse:2.09                                                                                 \n",
      "\n",
      "[27]\ttrain-rmse:2.11528\teval-rmse:2.08921                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.0988\teval-rmse:2.08609                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.07716\teval-rmse:2.08376                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.05678\teval-rmse:2.08377                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.04837\teval-rmse:2.08235                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.03976\teval-rmse:2.08189                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.02752\teval-rmse:2.08327                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.02084\teval-rmse:2.08381                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.01302\teval-rmse:2.08345                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.00617\teval-rmse:2.08362                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.99926\teval-rmse:2.08387                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.98745\teval-rmse:2.0813                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:1.97761\teval-rmse:2.08263                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:1.96747\teval-rmse:2.08287                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:1.95208\teval-rmse:2.08228                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:1.9416\teval-rmse:2.08394                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:1.92881\teval-rmse:2.08321                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:1.91399\teval-rmse:2.08294                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:1.90715\teval-rmse:2.08311                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:1.89578\teval-rmse:2.0852                                                                               \n",
      "\n",
      "[47]\ttrain-rmse:1.88279\teval-rmse:2.08607                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:1.87456\teval-rmse:2.08898                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:1.86799\teval-rmse:2.0898                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:1.85689\teval-rmse:2.09116                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:1.84841\teval-rmse:2.09325                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:1.84203\teval-rmse:2.09346                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:1.83685\teval-rmse:2.09276                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:1.83148\teval-rmse:2.09279                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:1.81981\teval-rmse:2.0966                                                                               \n",
      "\n",
      "[56]\ttrain-rmse:1.81526\teval-rmse:2.09835                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:1.80892\teval-rmse:2.09915                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:1.79968\teval-rmse:2.09937                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[38]\ttrain-rmse:1.98745\teval-rmse:2.0813\n",
      "\n",
      "\n",
      "loss: 96971740.64595796                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00034064745059567776, 'colsample_bytree': 0.8500000000000001, 'gamma': 8.861993348650698e-07, 'lambda': 1.2585790926051021e-05, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 5.212973762593079, 'n_estimators': 785.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.87665\teval-rmse:4.37651                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.30846\teval-rmse:3.71586                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.88963\teval-rmse:3.22754                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.58966\teval-rmse:2.86197                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.38321\teval-rmse:2.60516                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.23055\teval-rmse:2.426                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:3.12912\teval-rmse:2.30413                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.05574\teval-rmse:2.22045                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.00366\teval-rmse:2.16543                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.96935\teval-rmse:2.1288                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.93931\teval-rmse:2.11196                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.92125\teval-rmse:2.09713                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.90537\teval-rmse:2.0879                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.89344\teval-rmse:2.0823                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.88284\teval-rmse:2.07828                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.87528\teval-rmse:2.07335                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.86913\teval-rmse:2.07393                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.8626\teval-rmse:2.07313                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.85654\teval-rmse:2.07459                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.85043\teval-rmse:2.07401                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.84316\teval-rmse:2.07609                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.84063\teval-rmse:2.07469                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.83559\teval-rmse:2.07259                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.83209\teval-rmse:2.06919                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.82752\teval-rmse:2.07124                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.82488\teval-rmse:2.07087                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.82113\teval-rmse:2.07164                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.81785\teval-rmse:2.07297                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.81477\teval-rmse:2.07333                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.81312\teval-rmse:2.07221                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.81132\teval-rmse:2.07582                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.80781\teval-rmse:2.07524                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.80394\teval-rmse:2.07531                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.79958\teval-rmse:2.07675                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.79677\teval-rmse:2.07383                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.79523\teval-rmse:2.07818                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.79281\teval-rmse:2.08077                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.79124\teval-rmse:2.08051                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.78834\teval-rmse:2.0806                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:2.78453\teval-rmse:2.08197                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.78201\teval-rmse:2.0812                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.77992\teval-rmse:2.08253                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.77775\teval-rmse:2.08305                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.7746\teval-rmse:2.08099                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[23]\ttrain-rmse:2.83209\teval-rmse:2.06919\n",
      "\n",
      "\n",
      "loss: 98833009.05647849                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.010789618363106487, 'colsample_bytree': 0.8, 'gamma': 1.8516910020126989e-06, 'lambda': 0.014114154094106605, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 6.402844672344345, 'n_estimators': 943.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.28606\teval-rmse:3.84912                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.45408\teval-rmse:3.00064                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.95815\teval-rmse:2.52251                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.6554\teval-rmse:2.28935                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.48859\teval-rmse:2.16969                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.37445\teval-rmse:2.10731                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.30246\teval-rmse:2.08855                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.22909\teval-rmse:2.0982                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.18083\teval-rmse:2.08785                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.15293\teval-rmse:2.08717                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.11668\teval-rmse:2.08815                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.06778\teval-rmse:2.09972                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.03611\teval-rmse:2.10748                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.01659\teval-rmse:2.11429                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.99528\teval-rmse:2.11946                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.96282\teval-rmse:2.12569                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.94927\teval-rmse:2.1242                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:1.93598\teval-rmse:2.1299                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:1.9215\teval-rmse:2.13694                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.90933\teval-rmse:2.14237                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.89436\teval-rmse:2.14204                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.85979\teval-rmse:2.15484                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.83353\teval-rmse:2.15906                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.80372\teval-rmse:2.15695                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.78007\teval-rmse:2.16032                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.75251\teval-rmse:2.18427                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.73084\teval-rmse:2.18587                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.71757\teval-rmse:2.18661                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.71198\teval-rmse:2.18541                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.68024\teval-rmse:2.18873                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.15293\teval-rmse:2.08717\n",
      "\n",
      "\n",
      "loss: 97273441.43568467                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0001224513543796606, 'colsample_bytree': 0.9, 'gamma': 2.2389960315253293e-08, 'lambda': 8.382527489626388e-05, 'learning_rate': 0.225, 'max_depth': 7, 'min_child_weight': 0.5939765812504444, 'n_estimators': 839.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.71803\teval-rmse:4.26671                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.04443\teval-rmse:3.54641                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.56591\teval-rmse:3.03398                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.2372\teval-rmse:2.67766                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.01152\teval-rmse:2.4432                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.85285\teval-rmse:2.29091                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.74427\teval-rmse:2.20051                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.66607\teval-rmse:2.14441                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.61162\teval-rmse:2.12511                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.56598\teval-rmse:2.10459                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.52414\teval-rmse:2.09907                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.49994\teval-rmse:2.08962                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.47416\teval-rmse:2.0868                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.44867\teval-rmse:2.10195                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.43363\teval-rmse:2.09956                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.42051\teval-rmse:2.10176                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.39902\teval-rmse:2.09645                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.37818\teval-rmse:2.09444                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.36718\teval-rmse:2.11867                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.34615\teval-rmse:2.12106                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.33119\teval-rmse:2.1266                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.3166\teval-rmse:2.15193                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.29683\teval-rmse:2.17287                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.27595\teval-rmse:2.17542                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.26412\teval-rmse:2.18077                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.25676\teval-rmse:2.18246                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.23976\teval-rmse:2.18993                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.23012\teval-rmse:2.1995                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.22116\teval-rmse:2.19675                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.21767\teval-rmse:2.18466                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.20161\teval-rmse:2.18272                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.19144\teval-rmse:2.19862                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.18494\teval-rmse:2.17819                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.47416\teval-rmse:2.0868\n",
      "\n",
      "\n",
      "loss: 97208584.12191223                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.9088508145470404e-05, 'colsample_bytree': 0.8, 'gamma': 4.8073855228872066e-06, 'lambda': 0.0007316736240460636, 'learning_rate': 0.375, 'max_depth': 4, 'min_child_weight': 1.9068444376539773, 'n_estimators': 899.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.23198\teval-rmse:3.64462                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.5151\teval-rmse:2.78619                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.15669\teval-rmse:2.36348                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.99068\teval-rmse:2.18112                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.90839\teval-rmse:2.1135                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.86158\teval-rmse:2.08592                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.8362\teval-rmse:2.07246                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.8165\teval-rmse:2.0684                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.80206\teval-rmse:2.06824                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.78899\teval-rmse:2.07353                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.78329\teval-rmse:2.07319                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.77518\teval-rmse:2.08471                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.76206\teval-rmse:2.08215                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.75253\teval-rmse:2.09256                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.74897\teval-rmse:2.09313                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.74412\teval-rmse:2.08793                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.73015\teval-rmse:2.08504                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.7206\teval-rmse:2.08549                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.71082\teval-rmse:2.08157                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.70519\teval-rmse:2.08505                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.69647\teval-rmse:2.09669                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.6847\teval-rmse:2.12484                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.67586\teval-rmse:2.13244                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.66898\teval-rmse:2.13383                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.66369\teval-rmse:2.15329                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.65843\teval-rmse:2.15427                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.6495\teval-rmse:2.15227                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.64576\teval-rmse:2.15244                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.64066\teval-rmse:2.1522                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.80206\teval-rmse:2.06824\n",
      "\n",
      "\n",
      "loss: 98541292.91060594                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.000514956253655507, 'colsample_bytree': 0.75, 'gamma': 1.5667995810928674e-08, 'lambda': 4.42231096547982e-06, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 0.6631469358878956, 'n_estimators': 599.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.47528\teval-rmse:4.06434                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.69063\teval-rmse:3.26856                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.17686\teval-rmse:2.77657                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.83831\teval-rmse:2.48181                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.62004\teval-rmse:2.31587                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.47384\teval-rmse:2.22716                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.37332\teval-rmse:2.18696                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.295\teval-rmse:2.18796                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.23887\teval-rmse:2.17188                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.20879\teval-rmse:2.15496                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.18185\teval-rmse:2.15349                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.15339\teval-rmse:2.15832                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.12382\teval-rmse:2.15338                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.08287\teval-rmse:2.16806                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\ttrain-rmse:2.05504\teval-rmse:2.17661                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.01683\teval-rmse:2.17888                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.97942\teval-rmse:2.18256                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.95868\teval-rmse:2.18778                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.94249\teval-rmse:2.18828                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.9217\teval-rmse:2.2043                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:1.89994\teval-rmse:2.21133                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.87558\teval-rmse:2.21557                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.85417\teval-rmse:2.22783                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.827\teval-rmse:2.22811                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:1.81739\teval-rmse:2.23209                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.78664\teval-rmse:2.23397                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.77347\teval-rmse:2.2346                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.75964\teval-rmse:2.23694                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.74397\teval-rmse:2.23846                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.72647\teval-rmse:2.22295                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.69979\teval-rmse:2.23016                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.68004\teval-rmse:2.23574                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.66893\teval-rmse:2.2439                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.12382\teval-rmse:2.15338\n",
      "\n",
      "\n",
      "loss: 96344398.52934225                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0006006128101930516, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.0006091008943141617, 'lambda': 4.25631656666477e-06, 'learning_rate': 0.4, 'max_depth': 6, 'min_child_weight': 0.23332912444662343, 'n_estimators': 489.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.08388\teval-rmse:3.54489                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.32662\teval-rmse:2.68497                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.9738\teval-rmse:2.29261                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.81275\teval-rmse:2.14483                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.73078\teval-rmse:2.08879                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.6757\teval-rmse:2.07467                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.6488\teval-rmse:2.06428                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.62902\teval-rmse:2.06287                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.60942\teval-rmse:2.05893                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.58347\teval-rmse:2.0636                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.55828\teval-rmse:2.0682                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.53447\teval-rmse:2.05782                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.5186\teval-rmse:2.05435                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.49966\teval-rmse:2.07766                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.48659\teval-rmse:2.08681                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.47204\teval-rmse:2.09803                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.45653\teval-rmse:2.11729                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.44148\teval-rmse:2.12481                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.42832\teval-rmse:2.12921                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.4189\teval-rmse:2.13936                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.40823\teval-rmse:2.14579                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.38911\teval-rmse:2.14347                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.37585\teval-rmse:2.14888                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.3703\teval-rmse:2.14976                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.34966\teval-rmse:2.16832                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.34258\teval-rmse:2.17422                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.33204\teval-rmse:2.20001                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.32191\teval-rmse:2.21727                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.31769\teval-rmse:2.21544                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.30361\teval-rmse:2.22944                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.29715\teval-rmse:2.23226                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.2853\teval-rmse:2.24946                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.27391\teval-rmse:2.28571                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.5186\teval-rmse:2.05435\n",
      "\n",
      "\n",
      "loss: 97994070.9706082                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.002759038951624627, 'colsample_bytree': 0.75, 'gamma': 1.5714627207456993e-08, 'lambda': 4.387019977643907e-05, 'learning_rate': 0.05, 'max_depth': 9, 'min_child_weight': 0.20628528933968512, 'n_estimators': 605.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:5.4314\teval-rmse:5.02437                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.22329\teval-rmse:4.81553                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.02857\teval-rmse:4.61675                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.84412\teval-rmse:4.43004                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.6717\teval-rmse:4.2565                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:4.50662\teval-rmse:4.09381                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.3529\teval-rmse:3.93913                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:4.20821\teval-rmse:3.79752                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:4.074\teval-rmse:3.66187                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:3.94826\teval-rmse:3.53664                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.82696\teval-rmse:3.42028                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.71528\teval-rmse:3.31209                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.61003\teval-rmse:3.20939                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.51289\teval-rmse:3.11276                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.42006\teval-rmse:3.02612                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.33407\teval-rmse:2.94499                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.2528\teval-rmse:2.86908                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:3.17712\teval-rmse:2.79978                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.10454\teval-rmse:2.73542                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.0381\teval-rmse:2.67697                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.97491\teval-rmse:2.62293                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.91788\teval-rmse:2.57377                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.86433\teval-rmse:2.52653                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.81117\teval-rmse:2.4862                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.76054\teval-rmse:2.44624                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.71567\teval-rmse:2.4094                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.67218\teval-rmse:2.37881                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.63376\teval-rmse:2.34837                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.59744\teval-rmse:2.31926                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.56383\teval-rmse:2.29115                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.53224\teval-rmse:2.26976                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.49748\teval-rmse:2.25156                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.46854\teval-rmse:2.23354                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.4407\teval-rmse:2.21542                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:2.41532\teval-rmse:2.19948                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.39282\teval-rmse:2.18589                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.37109\teval-rmse:2.17378                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.3508\teval-rmse:2.16255                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:2.32939\teval-rmse:2.14977                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.31051\teval-rmse:2.14277                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.29274\teval-rmse:2.136                                                                                \n",
      "\n",
      "[41]\ttrain-rmse:2.27596\teval-rmse:2.12696                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.2546\teval-rmse:2.11922                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:2.2386\teval-rmse:2.11276                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:2.22327\teval-rmse:2.10843                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.21125\teval-rmse:2.1024                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.19642\teval-rmse:2.09727                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.18345\teval-rmse:2.0943                                                                               \n",
      "\n",
      "[48]\ttrain-rmse:2.17424\teval-rmse:2.08943                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.16236\teval-rmse:2.08676                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.15006\teval-rmse:2.08569                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.13836\teval-rmse:2.08602                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.12507\teval-rmse:2.08228                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.11488\teval-rmse:2.08061                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.10256\teval-rmse:2.07702                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.09312\teval-rmse:2.07476                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.08494\teval-rmse:2.07317                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.0741\teval-rmse:2.07191                                                                               \n",
      "\n",
      "[58]\ttrain-rmse:2.06777\teval-rmse:2.07125                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.05903\teval-rmse:2.06903                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.04811\teval-rmse:2.0701                                                                               \n",
      "\n",
      "[61]\ttrain-rmse:2.0413\teval-rmse:2.06823                                                                               \n",
      "\n",
      "[62]\ttrain-rmse:2.03391\teval-rmse:2.06902                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.02504\teval-rmse:2.06958                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.01642\teval-rmse:2.06813                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.00844\teval-rmse:2.07018                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.00359\teval-rmse:2.07109                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67]\ttrain-rmse:1.99857\teval-rmse:2.0721                                                                               \n",
      "\n",
      "[68]\ttrain-rmse:1.99199\teval-rmse:2.07333                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:1.98547\teval-rmse:2.07439                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:1.97755\teval-rmse:2.07265                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:1.97354\teval-rmse:2.07269                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:1.96926\teval-rmse:2.07322                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:1.9648\teval-rmse:2.0728                                                                                \n",
      "\n",
      "[74]\ttrain-rmse:1.95605\teval-rmse:2.07191                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:1.95133\teval-rmse:2.07202                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:1.94583\teval-rmse:2.07192                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:1.94191\teval-rmse:2.07221                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:1.9367\teval-rmse:2.07309                                                                               \n",
      "\n",
      "[79]\ttrain-rmse:1.9292\teval-rmse:2.07445                                                                               \n",
      "\n",
      "[80]\ttrain-rmse:1.92122\teval-rmse:2.07601                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:1.91729\teval-rmse:2.07658                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:1.91311\teval-rmse:2.07737                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:1.90514\teval-rmse:2.07724                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:1.89922\teval-rmse:2.07724                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[64]\ttrain-rmse:2.01642\teval-rmse:2.06813\n",
      "\n",
      "\n",
      "loss: 97078545.53914696                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0009857769665218852, 'colsample_bytree': 0.8, 'gamma': 2.8169458229941976e-08, 'lambda': 8.8547327178409e-06, 'learning_rate': 0.35000000000000003, 'max_depth': 5, 'min_child_weight': 0.17096149136427283, 'n_estimators': 566.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.28995\teval-rmse:3.74745                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.55147\teval-rmse:2.8905                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.15398\teval-rmse:2.4391                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.95934\teval-rmse:2.22582                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.8557\teval-rmse:2.126                                                                                  \n",
      "\n",
      "[5]\ttrain-rmse:2.79386\teval-rmse:2.08065                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.75647\teval-rmse:2.06803                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.72791\teval-rmse:2.06177                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.70845\teval-rmse:2.08291                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.69516\teval-rmse:2.08374                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.67549\teval-rmse:2.08186                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.66147\teval-rmse:2.09416                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.65505\teval-rmse:2.0924                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.64233\teval-rmse:2.11195                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.63218\teval-rmse:2.11055                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.62414\teval-rmse:2.12115                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.61508\teval-rmse:2.12984                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.5983\teval-rmse:2.12895                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.59281\teval-rmse:2.13486                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.58143\teval-rmse:2.13529                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.56988\teval-rmse:2.14843                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.5594\teval-rmse:2.17362                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.55006\teval-rmse:2.19276                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.54164\teval-rmse:2.19965                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.52902\teval-rmse:2.20315                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.51917\teval-rmse:2.21615                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.50916\teval-rmse:2.25425                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.50243\teval-rmse:2.24971                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.72791\teval-rmse:2.06177\n",
      "\n",
      "\n",
      "loss: 98064431.08807209                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.008806642629763049, 'colsample_bytree': 0.75, 'gamma': 1.7624075630520655e-07, 'lambda': 0.009361416137787302, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 3.5308579094831547, 'n_estimators': 402.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.28342\teval-rmse:3.86544                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.45945\teval-rmse:3.04052                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.9581\teval-rmse:2.58353                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.67394\teval-rmse:2.34175                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.51077\teval-rmse:2.23476                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.40472\teval-rmse:2.19573                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.33702\teval-rmse:2.17374                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.28654\teval-rmse:2.16207                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.25494\teval-rmse:2.16947                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.21754\teval-rmse:2.17672                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.19075\teval-rmse:2.19693                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.16197\teval-rmse:2.2147                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.13396\teval-rmse:2.19771                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.11051\teval-rmse:2.20156                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.08582\teval-rmse:2.21174                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.0729\teval-rmse:2.21612                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.03744\teval-rmse:2.2136                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.02061\teval-rmse:2.22023                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.98958\teval-rmse:2.22639                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.97138\teval-rmse:2.23233                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.95242\teval-rmse:2.2372                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.91614\teval-rmse:2.25084                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.90272\teval-rmse:2.25247                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.88035\teval-rmse:2.25494                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.871\teval-rmse:2.26799                                                                                \n",
      "\n",
      "[25]\ttrain-rmse:1.8558\teval-rmse:2.27283                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.83181\teval-rmse:2.27861                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.80156\teval-rmse:2.28013                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.28654\teval-rmse:2.16207\n",
      "\n",
      "\n",
      "loss: 96515010.07717374                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.004621653895684595, 'colsample_bytree': 0.75, 'gamma': 7.400040474596663e-08, 'lambda': 0.9005002335278081, 'learning_rate': 0.45, 'max_depth': 3, 'min_child_weight': 0.3634091240544827, 'n_estimators': 256.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.0166\teval-rmse:3.37346                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.3509\teval-rmse:2.56008                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.08455\teval-rmse:2.23561                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.98086\teval-rmse:2.1225                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.937\teval-rmse:2.08816                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.91156\teval-rmse:2.08114                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.89445\teval-rmse:2.08223                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.87909\teval-rmse:2.08974                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.87422\teval-rmse:2.08671                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.86523\teval-rmse:2.07988                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.85749\teval-rmse:2.0791                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.85209\teval-rmse:2.08699                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.84342\teval-rmse:2.08569                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.83622\teval-rmse:2.09277                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.83247\teval-rmse:2.09168                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.82578\teval-rmse:2.08626                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.81673\teval-rmse:2.08816                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.81243\teval-rmse:2.08613                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.80835\teval-rmse:2.09583                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.79843\teval-rmse:2.08504                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.79225\teval-rmse:2.08117                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.78669\teval-rmse:2.0742                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.78252\teval-rmse:2.07241                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.77738\teval-rmse:2.07417                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.77365\teval-rmse:2.06726                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.76724\teval-rmse:2.06382                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.76253\teval-rmse:2.07276                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.76014\teval-rmse:2.07411                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.75533\teval-rmse:2.07867                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.7522\teval-rmse:2.07435                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.74799\teval-rmse:2.07585                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.74375\teval-rmse:2.07269                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.73833\teval-rmse:2.07338                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.73507\teval-rmse:2.07562                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.72948\teval-rmse:2.07837                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.72658\teval-rmse:2.08023                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.72346\teval-rmse:2.08279                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.718\teval-rmse:2.07734                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38]\ttrain-rmse:2.71487\teval-rmse:2.07794                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.71156\teval-rmse:2.07737                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.70428\teval-rmse:2.06421                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.69957\teval-rmse:2.06358                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.69552\teval-rmse:2.06287                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.69332\teval-rmse:2.06265                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.68954\teval-rmse:2.07726                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.68715\teval-rmse:2.09186                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.68417\teval-rmse:2.08518                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.68097\teval-rmse:2.09215                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.67831\teval-rmse:2.13769                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.67433\teval-rmse:2.13854                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.67157\teval-rmse:2.13857                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.66847\teval-rmse:2.14177                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.66309\teval-rmse:2.13915                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.66181\teval-rmse:2.10913                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.66036\teval-rmse:2.10847                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.65677\teval-rmse:2.11507                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.65336\teval-rmse:2.11878                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.65153\teval-rmse:2.15144                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.64778\teval-rmse:2.17463                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.6437\teval-rmse:2.17621                                                                               \n",
      "\n",
      "[60]\ttrain-rmse:2.64087\teval-rmse:2.18261                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.63863\teval-rmse:2.17821                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.63566\teval-rmse:2.17407                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.63436\teval-rmse:2.17915                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[43]\ttrain-rmse:2.69332\teval-rmse:2.06265\n",
      "\n",
      "\n",
      "loss: 97931034.43323764                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0077858651809582435, 'colsample_bytree': 0.75, 'gamma': 5.11150463196902e-08, 'lambda': 5.014350649652515, 'learning_rate': 0.35000000000000003, 'max_depth': 9, 'min_child_weight': 0.6765689092315843, 'n_estimators': 403.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.2241\teval-rmse:3.76518                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.40524\teval-rmse:2.9222                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.95254\teval-rmse:2.48023                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.69399\teval-rmse:2.27935                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.54708\teval-rmse:2.18713                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.43413\teval-rmse:2.14791                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.36481\teval-rmse:2.1282                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.30451\teval-rmse:2.12731                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.2533\teval-rmse:2.13077                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.21749\teval-rmse:2.13852                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.17852\teval-rmse:2.15384                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.13918\teval-rmse:2.15749                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.11632\teval-rmse:2.16522                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.09286\teval-rmse:2.16722                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.06279\teval-rmse:2.16973                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.03438\teval-rmse:2.17585                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.99477\teval-rmse:2.1825                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:1.96023\teval-rmse:2.18307                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.92413\teval-rmse:2.20199                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.88471\teval-rmse:2.22263                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.8633\teval-rmse:2.24119                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.8418\teval-rmse:2.24963                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.82539\teval-rmse:2.25752                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.81116\teval-rmse:2.258                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:1.80603\teval-rmse:2.2546                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.78664\teval-rmse:2.25518                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.76106\teval-rmse:2.25302                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.75235\teval-rmse:2.24994                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.30451\teval-rmse:2.12731\n",
      "\n",
      "\n",
      "loss: 96597361.34545061                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.013856677394607584, 'colsample_bytree': 0.75, 'gamma': 1.4687963597485274e-07, 'lambda': 0.4022764030309711, 'learning_rate': 0.42500000000000004, 'max_depth': 7, 'min_child_weight': 3.5242934983333765, 'n_estimators': 360.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:3.97017\teval-rmse:3.45349                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.20273\teval-rmse:2.61052                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.86855\teval-rmse:2.27402                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.69779\teval-rmse:2.17015                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.62453\teval-rmse:2.13637                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.56883\teval-rmse:2.12113                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.53254\teval-rmse:2.1352                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.48902\teval-rmse:2.1605                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.47182\teval-rmse:2.16475                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.4556\teval-rmse:2.16011                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.43712\teval-rmse:2.1597                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.41348\teval-rmse:2.15204                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.3928\teval-rmse:2.18123                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.36955\teval-rmse:2.19075                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.35629\teval-rmse:2.20487                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.33603\teval-rmse:2.21421                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.31875\teval-rmse:2.22985                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.3086\teval-rmse:2.2311                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:2.28487\teval-rmse:2.22621                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.26579\teval-rmse:2.25512                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.25816\teval-rmse:2.25264                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.241\teval-rmse:2.255                                                                                  \n",
      "\n",
      "[22]\ttrain-rmse:2.23269\teval-rmse:2.24871                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.22297\teval-rmse:2.26565                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.21879\teval-rmse:2.26844                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.19878\teval-rmse:2.2639                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.56883\teval-rmse:2.12113\n",
      "\n",
      "\n",
      "loss: 97280391.49605842                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.051000275840076444, 'colsample_bytree': 0.75, 'gamma': 1.3542007657444835e-08, 'lambda': 0.009557014665380349, 'learning_rate': 0.47500000000000003, 'max_depth': 9, 'min_child_weight': 0.43367714623810794, 'n_estimators': 544.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:3.71566\teval-rmse:3.2933                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:2.88756\teval-rmse:2.53111                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.54802\teval-rmse:2.29719                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.38791\teval-rmse:2.25523                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.30844\teval-rmse:2.24414                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.26741\teval-rmse:2.25349                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.2079\teval-rmse:2.29734                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.14486\teval-rmse:2.31268                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.11012\teval-rmse:2.34856                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.08021\teval-rmse:2.38064                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.01581\teval-rmse:2.39302                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:1.98159\teval-rmse:2.38986                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.9578\teval-rmse:2.39296                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:1.92666\teval-rmse:2.40519                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.88739\teval-rmse:2.43651                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.86501\teval-rmse:2.43415                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.82572\teval-rmse:2.47502                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.80347\teval-rmse:2.49286                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.7915\teval-rmse:2.50916                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.75804\teval-rmse:2.53827                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.74173\teval-rmse:2.55637                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.71235\teval-rmse:2.55152                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.67202\teval-rmse:2.55638                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.65524\teval-rmse:2.55804                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.64188\teval-rmse:2.55715                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.30844\teval-rmse:2.24414\n",
      "\n",
      "\n",
      "loss: 179056730.12059325                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00025141748592861157, 'colsample_bytree': 0.75, 'gamma': 2.601224975821826e-07, 'lambda': 0.7257238210112138, 'learning_rate': 0.4, 'max_depth': 4, 'min_child_weight': 0.5560954273116524, 'n_estimators': 329.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.14375\teval-rmse:3.54865                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.43324\teval-rmse:2.69149                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.09981\teval-rmse:2.30309                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.94986\teval-rmse:2.15369                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.87727\teval-rmse:2.09571                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.84582\teval-rmse:2.07076                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.82818\teval-rmse:2.06504                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.80614\teval-rmse:2.08064                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.78853\teval-rmse:2.07408                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.77223\teval-rmse:2.07021                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.75773\teval-rmse:2.06726                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.75187\teval-rmse:2.07184                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.74572\teval-rmse:2.07419                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.73326\teval-rmse:2.08073                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.73025\teval-rmse:2.09578                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.72189\teval-rmse:2.11716                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.71072\teval-rmse:2.12651                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.70043\teval-rmse:2.12264                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.69488\teval-rmse:2.12471                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.68606\teval-rmse:2.14185                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.68111\teval-rmse:2.18069                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.67842\teval-rmse:2.18457                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.67226\teval-rmse:2.16421                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.66573\teval-rmse:2.16573                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.66229\teval-rmse:2.16896                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.65752\teval-rmse:2.16362                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.6508\teval-rmse:2.17461                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.82818\teval-rmse:2.06504\n",
      "\n",
      "\n",
      "loss: 98057225.53975223                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.02383431423931391, 'colsample_bytree': 0.75, 'gamma': 0.0018304815632140402, 'lambda': 1.4655680166972287, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.31125401781234047, 'n_estimators': 380.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.29835\teval-rmse:3.85833                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.47555\teval-rmse:3.04052                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.98522\teval-rmse:2.60464                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.69108\teval-rmse:2.36958                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.53433\teval-rmse:2.24965                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.41818\teval-rmse:2.2131                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.35021\teval-rmse:2.19209                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.29567\teval-rmse:2.18438                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.259\teval-rmse:2.18502                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:2.22316\teval-rmse:2.18616                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.17143\teval-rmse:2.19097                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.14053\teval-rmse:2.19552                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.11399\teval-rmse:2.21734                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.07176\teval-rmse:2.22881                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.04481\teval-rmse:2.23708                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.02745\teval-rmse:2.23583                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.00277\teval-rmse:2.22666                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.97662\teval-rmse:2.23369                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.94499\teval-rmse:2.22827                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.91003\teval-rmse:2.23239                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.87464\teval-rmse:2.24533                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.85419\teval-rmse:2.25422                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.83088\teval-rmse:2.25366                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.80347\teval-rmse:2.24625                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.79414\teval-rmse:2.24654                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.77363\teval-rmse:2.24355                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.75225\teval-rmse:2.2494                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.74118\teval-rmse:2.24932                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.29567\teval-rmse:2.18438\n",
      "\n",
      "\n",
      "loss: 97004495.30540669                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0012877987618658642, 'colsample_bytree': 0.8, 'gamma': 3.742827079225617e-08, 'lambda': 0.06685905282673309, 'learning_rate': 0.375, 'max_depth': 6, 'min_child_weight': 1.7199320854567381, 'n_estimators': 505.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.17269\teval-rmse:3.64603                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.41423\teval-rmse:2.79002                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.02777\teval-rmse:2.3753                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.83854\teval-rmse:2.19733                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.74928\teval-rmse:2.11085                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.68733\teval-rmse:2.09198                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.64037\teval-rmse:2.0889                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.61334\teval-rmse:2.09016                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.5906\teval-rmse:2.08536                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.57247\teval-rmse:2.08944                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.55368\teval-rmse:2.09276                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.53737\teval-rmse:2.09259                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.52556\teval-rmse:2.0978                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.51133\teval-rmse:2.10106                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.5025\teval-rmse:2.09902                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.49192\teval-rmse:2.096                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:2.47507\teval-rmse:2.10496                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.45899\teval-rmse:2.10437                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.43594\teval-rmse:2.10847                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.4209\teval-rmse:2.12116                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.40202\teval-rmse:2.119                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:2.39159\teval-rmse:2.12374                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.37828\teval-rmse:2.12925                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.36903\teval-rmse:2.13223                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.35404\teval-rmse:2.14228                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.33848\teval-rmse:2.19195                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.33238\teval-rmse:2.19047                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.32783\teval-rmse:2.1882                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.32392\teval-rmse:2.19706                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.5906\teval-rmse:2.08536\n",
      "\n",
      "\n",
      "loss: 97899297.78698434                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.03891393562517085, 'colsample_bytree': 0.8, 'gamma': 1.25419982110625e-07, 'lambda': 0.0049542675354259475, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 0.7207356611292639, 'n_estimators': 461.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.4729\teval-rmse:4.0672                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.69478\teval-rmse:3.29366                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.16651\teval-rmse:2.82173                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.84082\teval-rmse:2.54042                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.62657\teval-rmse:2.38747                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.48269\teval-rmse:2.29558                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.37446\teval-rmse:2.27129                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.30024\teval-rmse:2.25564                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.25094\teval-rmse:2.2549                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.21165\teval-rmse:2.24497                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.1796\teval-rmse:2.24385                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.14347\teval-rmse:2.24222                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.1108\teval-rmse:2.22912                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.072\teval-rmse:2.23466                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:2.05126\teval-rmse:2.23752                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.0167\teval-rmse:2.24144                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:1.9915\teval-rmse:2.26152                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:1.95624\teval-rmse:2.26657                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.92691\teval-rmse:2.27912                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.91174\teval-rmse:2.27882                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.88907\teval-rmse:2.27388                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.87085\teval-rmse:2.27248                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.84286\teval-rmse:2.27608                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.82827\teval-rmse:2.27399                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.80724\teval-rmse:2.28681                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.79208\teval-rmse:2.28557                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\ttrain-rmse:1.77198\teval-rmse:2.33408                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.75436\teval-rmse:2.35755                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.73251\teval-rmse:2.36733                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.70401\teval-rmse:2.37133                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.68585\teval-rmse:2.36813                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.67237\teval-rmse:2.37187                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.64215\teval-rmse:2.38177                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.1108\teval-rmse:2.22912\n",
      "\n",
      "\n",
      "loss: 101911169.19880275                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.08985944564748555, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.005932172638906732, 'lambda': 0.027958155322026293, 'learning_rate': 0.30000000000000004, 'max_depth': 5, 'min_child_weight': 0.37968371452206123, 'n_estimators': 591.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.47014\teval-rmse:3.94983                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.75204\teval-rmse:3.12622                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.32193\teval-rmse:2.63042                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.07693\teval-rmse:2.35792                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.94053\teval-rmse:2.21562                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.85566\teval-rmse:2.14996                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.80712\teval-rmse:2.11023                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.77619\teval-rmse:2.09552                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.75191\teval-rmse:2.0846                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.7309\teval-rmse:2.08058                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.71226\teval-rmse:2.08223                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.69783\teval-rmse:2.10394                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.68308\teval-rmse:2.11669                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.67442\teval-rmse:2.12358                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.66127\teval-rmse:2.12643                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.65185\teval-rmse:2.12291                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.64168\teval-rmse:2.12709                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.6291\teval-rmse:2.12494                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.62085\teval-rmse:2.13078                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.61253\teval-rmse:2.13194                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.60659\teval-rmse:2.14571                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.60248\teval-rmse:2.13793                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.59362\teval-rmse:2.12954                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.58295\teval-rmse:2.12826                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.57967\teval-rmse:2.13146                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.56776\teval-rmse:2.13206                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.56113\teval-rmse:2.13084                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.55297\teval-rmse:2.12035                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.54458\teval-rmse:2.13079                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.53654\teval-rmse:2.14027                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.7309\teval-rmse:2.08058\n",
      "\n",
      "\n",
      "loss: 97968183.90947475                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.46952115276615347, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.1223634258805445e-08, 'lambda': 0.0016134249469497235, 'learning_rate': 0.45, 'max_depth': 9, 'min_child_weight': 0.5070949688988933, 'n_estimators': 631.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:3.81\teval-rmse:3.37486                                                                                  \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:2.96171\teval-rmse:2.57704                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.58831\teval-rmse:2.31219                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.4189\teval-rmse:2.28447                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.32942\teval-rmse:2.27225                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.26504\teval-rmse:2.25632                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.19875\teval-rmse:2.28066                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.13275\teval-rmse:2.30871                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.06854\teval-rmse:2.36583                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.00968\teval-rmse:2.38429                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:1.97456\teval-rmse:2.40186                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:1.92812\teval-rmse:2.4106                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:1.9006\teval-rmse:2.44385                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:1.87921\teval-rmse:2.45303                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.86715\teval-rmse:2.44862                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.81598\teval-rmse:2.45441                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.78022\teval-rmse:2.49583                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.73754\teval-rmse:2.51505                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.71639\teval-rmse:2.51168                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.66883\teval-rmse:2.52218                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.64432\teval-rmse:2.53418                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.62885\teval-rmse:2.52511                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.59841\teval-rmse:2.53116                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.58302\teval-rmse:2.53438                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.56791\teval-rmse:2.55212                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.54349\teval-rmse:2.55736                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.26504\teval-rmse:2.25632\n",
      "\n",
      "\n",
      "loss: 100482279.03456257                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.26873259638722946, 'colsample_bytree': 0.75, 'gamma': 4.262611943988702e-05, 'lambda': 0.04271653639170716, 'learning_rate': 0.35000000000000003, 'max_depth': 3, 'min_child_weight': 2.807789217674765, 'n_estimators': 476.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.34389\teval-rmse:3.75887                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.64237\teval-rmse:2.91857                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.27143\teval-rmse:2.46537                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.0823\teval-rmse:2.24552                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.99243\teval-rmse:2.15194                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.94143\teval-rmse:2.10725                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.91762\teval-rmse:2.08566                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.89895\teval-rmse:2.07813                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.88641\teval-rmse:2.0973                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.87557\teval-rmse:2.08564                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.86926\teval-rmse:2.09029                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.86255\teval-rmse:2.08735                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.85648\teval-rmse:2.08406                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.85078\teval-rmse:2.08691                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.84195\teval-rmse:2.08306                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.8324\teval-rmse:2.07965                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.82674\teval-rmse:2.08139                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.81941\teval-rmse:2.07646                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.81376\teval-rmse:2.07675                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.81077\teval-rmse:2.08479                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.806\teval-rmse:2.08723                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:2.80156\teval-rmse:2.07761                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.79715\teval-rmse:2.07672                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.79135\teval-rmse:2.07494                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.78483\teval-rmse:2.07167                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.7814\teval-rmse:2.07119                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.77713\teval-rmse:2.07421                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.77254\teval-rmse:2.08817                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.77029\teval-rmse:2.09384                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.76655\teval-rmse:2.09158                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.7644\teval-rmse:2.09171                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.75921\teval-rmse:2.08966                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.75624\teval-rmse:2.0889                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.75427\teval-rmse:2.087                                                                                \n",
      "\n",
      "[34]\ttrain-rmse:2.75011\teval-rmse:2.11333                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.74707\teval-rmse:2.11422                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.74489\teval-rmse:2.11608                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.74224\teval-rmse:2.1133                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:2.73893\teval-rmse:2.11436                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.73634\teval-rmse:2.11395                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.73118\teval-rmse:2.11154                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.72974\teval-rmse:2.10439                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.7282\teval-rmse:2.10102                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:2.72682\teval-rmse:2.10317                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.72511\teval-rmse:2.07275                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.72232\teval-rmse:2.07849                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[25]\ttrain-rmse:2.7814\teval-rmse:2.07119\n",
      "\n",
      "\n",
      "loss: 98259898.4491884                                                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.003607924491185188, 'colsample_bytree': 0.8, 'gamma': 8.820793941740158e-07, 'lambda': 0.0022439919182034736, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 3.779323976895853, 'n_estimators': 424.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.37941\teval-rmse:3.96485                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.57972\teval-rmse:3.16017                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.07226\teval-rmse:2.69367                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.76844\teval-rmse:2.43188                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.58701\teval-rmse:2.29647                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.46208\teval-rmse:2.22457                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.36632\teval-rmse:2.20235                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.29917\teval-rmse:2.18076                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.26422\teval-rmse:2.17925                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.22422\teval-rmse:2.18559                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.19388\teval-rmse:2.19907                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.17635\teval-rmse:2.2078                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.14732\teval-rmse:2.20489                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.11984\teval-rmse:2.21549                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.10811\teval-rmse:2.2196                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.09881\teval-rmse:2.23516                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.06312\teval-rmse:2.24679                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.02412\teval-rmse:2.25554                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.98099\teval-rmse:2.26771                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.95732\teval-rmse:2.27513                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.93222\teval-rmse:2.28002                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.91061\teval-rmse:2.2765                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.90356\teval-rmse:2.28075                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.88376\teval-rmse:2.28429                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.86686\teval-rmse:2.28991                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.84977\teval-rmse:2.28867                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.83946\teval-rmse:2.29188                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.81932\teval-rmse:2.29011                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.78852\teval-rmse:2.29925                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.26422\teval-rmse:2.17925\n",
      "\n",
      "\n",
      "loss: 103972049.3134068                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0016514264079047244, 'colsample_bytree': 0.8, 'gamma': 6.30331970858109e-07, 'lambda': 0.0002282299028069304, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 8.344553879246149, 'n_estimators': 343.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.59255\teval-rmse:4.15763                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.86865\teval-rmse:3.39369                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.36303\teval-rmse:2.87538                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.02592\teval-rmse:2.54749                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.80031\teval-rmse:2.32222                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.653\teval-rmse:2.20858                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:2.55551\teval-rmse:2.14482                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.48334\teval-rmse:2.11488                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.42836\teval-rmse:2.09754                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.40088\teval-rmse:2.09207                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.36504\teval-rmse:2.0956                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.33465\teval-rmse:2.09508                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.30761\teval-rmse:2.09391                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.27396\teval-rmse:2.10895                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.25782\teval-rmse:2.11282                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.24424\teval-rmse:2.11362                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.21779\teval-rmse:2.11025                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.19143\teval-rmse:2.10613                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.16317\teval-rmse:2.11694                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.12981\teval-rmse:2.12504                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.11933\teval-rmse:2.13386                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.11389\teval-rmse:2.12842                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.09849\teval-rmse:2.13353                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.07972\teval-rmse:2.12566                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.06596\teval-rmse:2.1274                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.0516\teval-rmse:2.12645                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.04538\teval-rmse:2.1275                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.02946\teval-rmse:2.1332                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.02344\teval-rmse:2.13769                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.00183\teval-rmse:2.15718                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.40088\teval-rmse:2.09207\n",
      "\n",
      "\n",
      "loss: 96976371.85253124                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0005717326644748218, 'colsample_bytree': 0.8, 'gamma': 2.038929947751483e-07, 'lambda': 0.00322993073635365, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 4.800554890050748, 'n_estimators': 286.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.48148\teval-rmse:4.06211                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.71089\teval-rmse:3.28086                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.19256\teval-rmse:2.78258                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.86769\teval-rmse:2.48674                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.65949\teval-rmse:2.32223                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.51644\teval-rmse:2.23876                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.43985\teval-rmse:2.18513                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.37923\teval-rmse:2.17329                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.33681\teval-rmse:2.16222                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.30649\teval-rmse:2.15366                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.2694\teval-rmse:2.1646                                                                                \n",
      "\n",
      "[11]\ttrain-rmse:2.2408\teval-rmse:2.15908                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.2032\teval-rmse:2.17366                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.17628\teval-rmse:2.18307                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.16416\teval-rmse:2.18877                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.12947\teval-rmse:2.21264                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.11683\teval-rmse:2.21447                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.10129\teval-rmse:2.21558                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.07499\teval-rmse:2.21632                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.05089\teval-rmse:2.21997                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.02698\teval-rmse:2.22577                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.01779\teval-rmse:2.22437                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.99945\teval-rmse:2.21962                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.97801\teval-rmse:2.22739                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.96358\teval-rmse:2.22369                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.95912\teval-rmse:2.22649                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.93905\teval-rmse:2.22696                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.9199\teval-rmse:2.23548                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.90665\teval-rmse:2.23981                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.87721\teval-rmse:2.2465                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.30649\teval-rmse:2.15366\n",
      "\n",
      "\n",
      "loss: 97438651.51372643                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.008779470494699836, 'colsample_bytree': 0.75, 'gamma': 7.899547834100455e-06, 'lambda': 0.018398838742192416, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 7.528238565375328, 'n_estimators': 174.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.49582\teval-rmse:4.06175                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.71513\teval-rmse:3.26386                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.20947\teval-rmse:2.75406                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.89041\teval-rmse:2.43926                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.68169\teval-rmse:2.26819                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.53288\teval-rmse:2.17944                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.43641\teval-rmse:2.13237                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.37654\teval-rmse:2.10349                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.33551\teval-rmse:2.08846                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.3126\teval-rmse:2.08397                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.28071\teval-rmse:2.08375                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.25014\teval-rmse:2.08261                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.22873\teval-rmse:2.08432                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.2079\teval-rmse:2.08582                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.18474\teval-rmse:2.08878                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.15271\teval-rmse:2.10051                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.12724\teval-rmse:2.11647                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\ttrain-rmse:2.10413\teval-rmse:2.12496                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.06855\teval-rmse:2.12402                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.05293\teval-rmse:2.13428                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.03142\teval-rmse:2.14069                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.01394\teval-rmse:2.15133                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.00002\teval-rmse:2.1594                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.99341\teval-rmse:2.15856                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.97303\teval-rmse:2.1658                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.95195\teval-rmse:2.15942                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.94107\teval-rmse:2.15526                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.91683\teval-rmse:2.15991                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.89393\teval-rmse:2.16018                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.88058\teval-rmse:2.16018                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.86639\teval-rmse:2.17258                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.844\teval-rmse:2.17832                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.25014\teval-rmse:2.08261\n",
      "\n",
      "\n",
      "loss: 96780470.92631045                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0007690710133087128, 'colsample_bytree': 0.8, 'gamma': 2.499203202501217e-06, 'lambda': 0.0014001488143800778, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 2.561817248203937, 'n_estimators': 192.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.27684\teval-rmse:3.85323                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.44513\teval-rmse:3.00409                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.94839\teval-rmse:2.5363                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.65989\teval-rmse:2.29108                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.48143\teval-rmse:2.17465                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.36168\teval-rmse:2.12456                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.29819\teval-rmse:2.10243                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.24699\teval-rmse:2.09521                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.21877\teval-rmse:2.08954                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.18956\teval-rmse:2.10793                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.15356\teval-rmse:2.12295                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.13591\teval-rmse:2.15206                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.08301\teval-rmse:2.16766                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.04937\teval-rmse:2.15363                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.03342\teval-rmse:2.15564                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.0146\teval-rmse:2.15976                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:1.97854\teval-rmse:2.16226                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.95001\teval-rmse:2.16201                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.91943\teval-rmse:2.17644                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.89744\teval-rmse:2.19866                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.86279\teval-rmse:2.19438                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.83303\teval-rmse:2.21376                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.80728\teval-rmse:2.22472                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.78917\teval-rmse:2.22279                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.78173\teval-rmse:2.23579                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.76643\teval-rmse:2.2456                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.75893\teval-rmse:2.24892                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.74543\teval-rmse:2.24763                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.73014\teval-rmse:2.24503                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.21877\teval-rmse:2.08954\n",
      "\n",
      "\n",
      "loss: 96400034.55430898                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0008292880309597161, 'colsample_bytree': 0.75, 'gamma': 2.323073230316088e-05, 'lambda': 0.005666887934074847, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 2.299394451780618, 'n_estimators': 135.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.27897\teval-rmse:3.8519                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.44334\teval-rmse:3.01883                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.95042\teval-rmse:2.5625                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.66351\teval-rmse:2.32999                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.50276\teval-rmse:2.22068                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.4075\teval-rmse:2.1734                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:2.33169\teval-rmse:2.15086                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.27158\teval-rmse:2.15313                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.227\teval-rmse:2.14776                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:2.18119\teval-rmse:2.14759                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.13876\teval-rmse:2.16805                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.11452\teval-rmse:2.17624                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.08949\teval-rmse:2.18079                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.06695\teval-rmse:2.18637                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.02563\teval-rmse:2.19972                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.99764\teval-rmse:2.20429                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.97582\teval-rmse:2.21506                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.95395\teval-rmse:2.22449                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.9115\teval-rmse:2.22695                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.8883\teval-rmse:2.23676                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.8671\teval-rmse:2.23368                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.85385\teval-rmse:2.2374                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.84098\teval-rmse:2.23979                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.81065\teval-rmse:2.2416                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.79643\teval-rmse:2.24162                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.79015\teval-rmse:2.23389                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.77186\teval-rmse:2.26234                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.75385\teval-rmse:2.26561                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.73499\teval-rmse:2.26422                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.69745\teval-rmse:2.28027                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.18119\teval-rmse:2.14759\n",
      "\n",
      "\n",
      "loss: 96375809.14459583                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0001511785344145334, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.00016474534285367839, 'lambda': 0.005932501870173654, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.8393123096675539, 'n_estimators': 138.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.27497\teval-rmse:3.86582                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.44298\teval-rmse:3.05353                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.94439\teval-rmse:2.60454                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.65269\teval-rmse:2.39077                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.47222\teval-rmse:2.32778                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.35948\teval-rmse:2.29025                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.26832\teval-rmse:2.29871                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.21053\teval-rmse:2.29998                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.16565\teval-rmse:2.28472                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.14603\teval-rmse:2.28788                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.11285\teval-rmse:2.31713                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.07987\teval-rmse:2.32113                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.05443\teval-rmse:2.31683                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.00736\teval-rmse:2.34106                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.98242\teval-rmse:2.35913                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.96415\teval-rmse:2.36112                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.93248\teval-rmse:2.36396                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.91317\teval-rmse:2.3703                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:1.90181\teval-rmse:2.37438                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.87729\teval-rmse:2.38946                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.85267\teval-rmse:2.3926                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.82421\teval-rmse:2.4062                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.81015\teval-rmse:2.41064                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.78354\teval-rmse:2.41908                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.75331\teval-rmse:2.41859                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.74099\teval-rmse:2.42096                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.71323\teval-rmse:2.43394                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.70012\teval-rmse:2.4531                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.67908\teval-rmse:2.45965                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.16565\teval-rmse:2.28472\n",
      "\n",
      "\n",
      "loss: 100219315.56006493                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00038017683259986267, 'colsample_bytree': 0.75, 'gamma': 6.732626754190497e-05, 'lambda': 0.00011520468848613996, 'learning_rate': 0.375, 'max_depth': 9, 'min_child_weight': 1.538557709961944, 'n_estimators': 199.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.0918\teval-rmse:3.66848                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:3.24238\teval-rmse:2.82603                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.79361\teval-rmse:2.42523                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.53892\teval-rmse:2.30748                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.39289\teval-rmse:2.24645                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.30345\teval-rmse:2.22528                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.26653\teval-rmse:2.2257                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.22937\teval-rmse:2.21839                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.17156\teval-rmse:2.2144                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.10519\teval-rmse:2.25389                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.08588\teval-rmse:2.27454                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.06336\teval-rmse:2.28645                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.01761\teval-rmse:2.28445                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.98897\teval-rmse:2.29727                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.96239\teval-rmse:2.3003                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:1.93396\teval-rmse:2.32752                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.90806\teval-rmse:2.34425                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.87881\teval-rmse:2.35297                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.85103\teval-rmse:2.38563                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.82989\teval-rmse:2.38805                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.80674\teval-rmse:2.39269                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.79108\teval-rmse:2.39273                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.77003\teval-rmse:2.41222                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.72152\teval-rmse:2.41746                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.7086\teval-rmse:2.43781                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.69646\teval-rmse:2.44022                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.67959\teval-rmse:2.45539                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.63948\teval-rmse:2.47595                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.61861\teval-rmse:2.48259                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.17156\teval-rmse:2.2144\n",
      "\n",
      "\n",
      "loss: 96756804.01514791                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0008386659735518614, 'colsample_bytree': 0.8, 'gamma': 0.0011484463286091993, 'lambda': 0.0011904891015151254, 'learning_rate': 0.35000000000000003, 'max_depth': 9, 'min_child_weight': 1.2813410524178759, 'n_estimators': 241.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.17622\teval-rmse:3.75509                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.33096\teval-rmse:2.90341                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.84521\teval-rmse:2.4775                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.5798\teval-rmse:2.28507                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.40899\teval-rmse:2.20239                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.29346\teval-rmse:2.17117                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.23012\teval-rmse:2.15784                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.18664\teval-rmse:2.15606                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.13234\teval-rmse:2.16737                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.1018\teval-rmse:2.17254                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.07039\teval-rmse:2.18296                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.03932\teval-rmse:2.19204                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.01517\teval-rmse:2.20277                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.9884\teval-rmse:2.2035                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:1.95295\teval-rmse:2.20188                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.93375\teval-rmse:2.20611                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.90972\teval-rmse:2.20138                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.87751\teval-rmse:2.2044                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:1.86042\teval-rmse:2.22043                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.81507\teval-rmse:2.23762                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.79459\teval-rmse:2.23906                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.77305\teval-rmse:2.25893                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.75323\teval-rmse:2.26705                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.74549\teval-rmse:2.26654                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.7075\teval-rmse:2.30029                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.67416\teval-rmse:2.30131                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.66459\teval-rmse:2.30208                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.65162\teval-rmse:2.30159                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.18664\teval-rmse:2.15606\n",
      "\n",
      "\n",
      "loss: 96829223.67219058                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.850880569558067e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.9508053387660046e-05, 'lambda': 0.001086396840447511, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 2.325348312123242, 'n_estimators': 118.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.38599\teval-rmse:3.94956                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.57547\teval-rmse:3.139                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:3.074\teval-rmse:2.65538                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:2.76505\teval-rmse:2.38501                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.55972\teval-rmse:2.24103                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.43011\teval-rmse:2.18295                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.34669\teval-rmse:2.15705                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.28278\teval-rmse:2.14502                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.2381\teval-rmse:2.14452                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.19553\teval-rmse:2.14139                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.16228\teval-rmse:2.14769                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.13451\teval-rmse:2.16048                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.10812\teval-rmse:2.18087                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.07321\teval-rmse:2.18898                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.0539\teval-rmse:2.19279                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.03329\teval-rmse:2.20232                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.01599\teval-rmse:2.20053                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.97579\teval-rmse:2.21366                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.96061\teval-rmse:2.2195                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.93716\teval-rmse:2.23538                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.91601\teval-rmse:2.24125                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.90287\teval-rmse:2.24486                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.89176\teval-rmse:2.26769                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.87064\teval-rmse:2.26181                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.8544\teval-rmse:2.26136                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.82998\teval-rmse:2.26557                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.79655\teval-rmse:2.28897                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.77946\teval-rmse:2.28852                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.77276\teval-rmse:2.29122                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.75344\teval-rmse:2.29976                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.19553\teval-rmse:2.14139\n",
      "\n",
      "\n",
      "loss: 96629158.21206516                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.9788388547075618e-05, 'colsample_bytree': 0.75, 'gamma': 2.671744269092096e-05, 'lambda': 0.00030513593265281885, 'learning_rate': 0.4, 'max_depth': 7, 'min_child_weight': 2.036573651538066, 'n_estimators': 148.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.06313\teval-rmse:3.55088                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.27945\teval-rmse:2.6811                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.90043\teval-rmse:2.29171                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.71711\teval-rmse:2.14269                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.62645\teval-rmse:2.09553                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.56574\teval-rmse:2.07322                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.52467\teval-rmse:2.08909                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.48192\teval-rmse:2.09126                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.45734\teval-rmse:2.08597                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.43326\teval-rmse:2.09027                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.40597\teval-rmse:2.08713                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.38761\teval-rmse:2.08809                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.35886\teval-rmse:2.07175                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.33254\teval-rmse:2.10416                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.31827\teval-rmse:2.11936                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.29965\teval-rmse:2.12784                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.27636\teval-rmse:2.14616                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.25278\teval-rmse:2.15581                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.23342\teval-rmse:2.16264                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.21532\teval-rmse:2.2091                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.19173\teval-rmse:2.21349                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.18354\teval-rmse:2.22903                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.1688\teval-rmse:2.24401                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.1551\teval-rmse:2.2392                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:2.14939\teval-rmse:2.2385                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\ttrain-rmse:2.1257\teval-rmse:2.25759                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.11763\teval-rmse:2.25286                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.09475\teval-rmse:2.2658                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.08931\teval-rmse:2.27024                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.08125\teval-rmse:2.27554                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.07287\teval-rmse:2.27816                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.05798\teval-rmse:2.28304                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.04635\teval-rmse:2.28844                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.35886\teval-rmse:2.07175\n",
      "\n",
      "\n",
      "loss: 97371782.76265976                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00020425754841760588, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.00013775239437876689, 'lambda': 0.00044588780178409095, 'learning_rate': 0.30000000000000004, 'max_depth': 8, 'min_child_weight': 1.0025309538139902, 'n_estimators': 226.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.40134\teval-rmse:3.95508                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.62282\teval-rmse:3.13172                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.13553\teval-rmse:2.63316                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.85555\teval-rmse:2.35328                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.68834\teval-rmse:2.2049                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.56681\teval-rmse:2.12432                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.48515\teval-rmse:2.07895                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.43587\teval-rmse:2.05631                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.39982\teval-rmse:2.06035                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.37417\teval-rmse:2.06221                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.33724\teval-rmse:2.07157                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.30811\teval-rmse:2.0654                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.28029\teval-rmse:2.07248                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.24794\teval-rmse:2.08822                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.22277\teval-rmse:2.08529                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.19607\teval-rmse:2.08975                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.17503\teval-rmse:2.0955                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.14673\teval-rmse:2.10524                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.12265\teval-rmse:2.11239                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.08872\teval-rmse:2.12169                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.07351\teval-rmse:2.12799                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.05433\teval-rmse:2.12935                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.03666\teval-rmse:2.12767                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.01736\teval-rmse:2.13051                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.97985\teval-rmse:2.14378                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.96804\teval-rmse:2.14459                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.95523\teval-rmse:2.14318                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.93556\teval-rmse:2.14708                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.43587\teval-rmse:2.05631\n",
      "\n",
      "\n",
      "loss: 97108443.8244555                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.934919250109991e-05, 'colsample_bytree': 0.8, 'gamma': 0.000255730889615251, 'lambda': 0.00017451310308762196, 'learning_rate': 0.375, 'max_depth': 9, 'min_child_weight': 2.4512235848833672, 'n_estimators': 188.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.08519\teval-rmse:3.67048                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.23187\teval-rmse:2.81672                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.76775\teval-rmse:2.3962                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.52501\teval-rmse:2.22555                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.37751\teval-rmse:2.18323                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.28155\teval-rmse:2.16797                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.23138\teval-rmse:2.17566                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.19723\teval-rmse:2.18963                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.14772\teval-rmse:2.21102                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.09459\teval-rmse:2.21894                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.07213\teval-rmse:2.21619                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.04992\teval-rmse:2.2255                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:1.9971\teval-rmse:2.24145                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:1.96635\teval-rmse:2.23502                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.94745\teval-rmse:2.23756                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.9136\teval-rmse:2.25923                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:1.88913\teval-rmse:2.27353                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.86565\teval-rmse:2.28498                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.83405\teval-rmse:2.28482                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.80709\teval-rmse:2.30455                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.78422\teval-rmse:2.30988                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.76152\teval-rmse:2.31612                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.73747\teval-rmse:2.32017                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.7088\teval-rmse:2.33759                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.67153\teval-rmse:2.35911                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.64277\teval-rmse:2.35956                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.28155\teval-rmse:2.16797\n",
      "\n",
      "\n",
      "loss: 96887783.13372189                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0047054361848612196, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.0785153073119919e-05, 'lambda': 0.004268369411044554, 'learning_rate': 0.35000000000000003, 'max_depth': 4, 'min_child_weight': 3.093060300001161, 'n_estimators': 130.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.3199\teval-rmse:3.74479                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.59837\teval-rmse:2.88699                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.21315\teval-rmse:2.44278                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.01962\teval-rmse:2.23047                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.92368\teval-rmse:2.12478                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.87422\teval-rmse:2.08438                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.84465\teval-rmse:2.07874                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.82797\teval-rmse:2.07094                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.80788\teval-rmse:2.06404                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.79678\teval-rmse:2.05596                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.78821\teval-rmse:2.05552                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.77859\teval-rmse:2.06033                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.77162\teval-rmse:2.10192                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.76303\teval-rmse:2.10387                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.75754\teval-rmse:2.10786                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.7503\teval-rmse:2.10784                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.7433\teval-rmse:2.11104                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.73336\teval-rmse:2.10569                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.72681\teval-rmse:2.10299                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.71883\teval-rmse:2.10292                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.71109\teval-rmse:2.105                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:2.70127\teval-rmse:2.10278                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.69612\teval-rmse:2.10497                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.68952\teval-rmse:2.09617                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.67934\teval-rmse:2.10011                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.67692\teval-rmse:2.09945                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.67326\teval-rmse:2.09975                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.66877\teval-rmse:2.10548                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.66386\teval-rmse:2.10837                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.65493\teval-rmse:2.09977                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.64968\teval-rmse:2.09521                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.78821\teval-rmse:2.05552\n",
      "\n",
      "\n",
      "loss: 98114948.3491544                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.3953410096325915e-05, 'colsample_bytree': 0.75, 'gamma': 9.02966584856586e-05, 'lambda': 0.0019181024634077055, 'learning_rate': 0.42500000000000004, 'max_depth': 9, 'min_child_weight': 1.8178376599668926, 'n_estimators': 156.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:3.89604\teval-rmse:3.46924                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.04107\teval-rmse:2.67033                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.632\teval-rmse:2.34372                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:2.43806\teval-rmse:2.26084                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.32676\teval-rmse:2.22721                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.258\teval-rmse:2.24467                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:2.22595\teval-rmse:2.25653                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.17263\teval-rmse:2.29116                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.12165\teval-rmse:2.30867                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.10029\teval-rmse:2.31734                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:2.05437\teval-rmse:2.34987                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.02231\teval-rmse:2.34663                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.00838\teval-rmse:2.34682                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.97419\teval-rmse:2.35498                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.96311\teval-rmse:2.35554                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.91371\teval-rmse:2.36438                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.89054\teval-rmse:2.38266                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.86598\teval-rmse:2.40713                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.84593\teval-rmse:2.41366                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.81451\teval-rmse:2.41498                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.79916\teval-rmse:2.43222                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.75464\teval-rmse:2.4418                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.74687\teval-rmse:2.44148                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.70067\teval-rmse:2.45062                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.68972\teval-rmse:2.45606                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.32676\teval-rmse:2.22721\n",
      "\n",
      "\n",
      "loss: 99248111.26956752                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0017295951269761254, 'colsample_bytree': 0.9, 'gamma': 2.5641341333880806e-06, 'lambda': 0.01122543747886641, 'learning_rate': 0.325, 'max_depth': 6, 'min_child_weight': 1.1543334824662947, 'n_estimators': 531.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.35681\teval-rmse:3.8408                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.59585\teval-rmse:2.9963                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.17491\teval-rmse:2.52849                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.94162\teval-rmse:2.29738                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.81687\teval-rmse:2.186                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.73909\teval-rmse:2.13573                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.6907\teval-rmse:2.1131                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:2.65144\teval-rmse:2.11959                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.62507\teval-rmse:2.1049                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.601\teval-rmse:2.10756                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.58227\teval-rmse:2.10985                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.56261\teval-rmse:2.10152                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.54717\teval-rmse:2.10024                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.53597\teval-rmse:2.10205                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.52159\teval-rmse:2.11351                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.50375\teval-rmse:2.14191                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.48762\teval-rmse:2.15716                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.46552\teval-rmse:2.15356                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.45212\teval-rmse:2.15858                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.43713\teval-rmse:2.16091                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.42294\teval-rmse:2.16222                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.41476\teval-rmse:2.17143                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.40218\teval-rmse:2.17402                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.38593\teval-rmse:2.16858                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.37772\teval-rmse:2.1729                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.36351\teval-rmse:2.1783                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.35135\teval-rmse:2.16943                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.33066\teval-rmse:2.16837                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.31545\teval-rmse:2.16952                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.30566\teval-rmse:2.17599                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.29939\teval-rmse:2.18999                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.29087\teval-rmse:2.18955                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.27565\teval-rmse:2.19956                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.54717\teval-rmse:2.10024\n",
      "\n",
      "\n",
      "loss: 97525440.8865814                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0003644548297464547, 'colsample_bytree': 0.8, 'gamma': 4.489372792933308e-05, 'lambda': 3.382402896691599e-05, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 2.14425292793565, 'n_estimators': 100.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.47774\teval-rmse:4.0613                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.70742\teval-rmse:3.2724                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.18863\teval-rmse:2.77845                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.85935\teval-rmse:2.49885                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.65183\teval-rmse:2.3314                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.51071\teval-rmse:2.23907                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.42096\teval-rmse:2.19466                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.34999\teval-rmse:2.18149                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.30139\teval-rmse:2.17048                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.27194\teval-rmse:2.16031                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.24171\teval-rmse:2.16536                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.22479\teval-rmse:2.16449                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.17154\teval-rmse:2.15571                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.13592\teval-rmse:2.15371                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.11813\teval-rmse:2.15761                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.09832\teval-rmse:2.16683                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.07034\teval-rmse:2.17533                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.03563\teval-rmse:2.19069                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.99983\teval-rmse:2.20229                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.9756\teval-rmse:2.20829                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.96147\teval-rmse:2.21799                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.9488\teval-rmse:2.21956                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.93702\teval-rmse:2.21945                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.91645\teval-rmse:2.22205                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.90027\teval-rmse:2.23212                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.87691\teval-rmse:2.23729                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.87089\teval-rmse:2.23604                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.85989\teval-rmse:2.23946                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.85066\teval-rmse:2.24607                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.82468\teval-rmse:2.26269                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.79845\teval-rmse:2.26953                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.78438\teval-rmse:2.27635                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.76163\teval-rmse:2.27589                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.75315\teval-rmse:2.27191                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.13592\teval-rmse:2.15371\n",
      "\n",
      "\n",
      "loss: 98835296.98259401                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.001088671075018845, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.0004575770440893463, 'lambda': 0.024487014438400085, 'learning_rate': 0.25, 'max_depth': 5, 'min_child_weight': 0.8845434491449176, 'n_estimators': 551.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.66417\teval-rmse:4.15559                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.99371\teval-rmse:3.39494                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.54705\teval-rmse:2.89474                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.25939\teval-rmse:2.56188                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.07641\teval-rmse:2.34402                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.95196\teval-rmse:2.22865                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.87783\teval-rmse:2.15177                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.8309\teval-rmse:2.11262                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.798\teval-rmse:2.08553                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:2.77228\teval-rmse:2.07231                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.75681\teval-rmse:2.0611                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.74131\teval-rmse:2.06075                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.72589\teval-rmse:2.05127                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.71181\teval-rmse:2.05236                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.70029\teval-rmse:2.05181                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.69005\teval-rmse:2.05258                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.6771\teval-rmse:2.0532                                                                                \n",
      "\n",
      "[17]\ttrain-rmse:2.66575\teval-rmse:2.04886                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.6555\teval-rmse:2.07475                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.64356\teval-rmse:2.07627                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.63382\teval-rmse:2.07511                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.62981\teval-rmse:2.07509                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.61922\teval-rmse:2.07594                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.60799\teval-rmse:2.06831                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.60233\teval-rmse:2.07401                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.59921\teval-rmse:2.07445                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.59251\teval-rmse:2.07773                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.58547\teval-rmse:2.0762                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.57943\teval-rmse:2.06712                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29]\ttrain-rmse:2.57253\teval-rmse:2.06795                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.56665\teval-rmse:2.07901                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.55937\teval-rmse:2.08569                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.55474\teval-rmse:2.08438                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.54235\teval-rmse:2.08705                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.53492\teval-rmse:2.07682                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.52839\teval-rmse:2.07879                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.52267\teval-rmse:2.07778                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.51272\teval-rmse:2.07709                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:2.66575\teval-rmse:2.04886\n",
      "\n",
      "\n",
      "loss: 97907415.9722435                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.017359841290115873, 'colsample_bytree': 0.75, 'gamma': 1.5697622327876722e-06, 'lambda': 0.0007874321953336989, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 1.4055604505098602, 'n_estimators': 688.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.28445\teval-rmse:3.86419                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.45898\teval-rmse:3.03651                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.95513\teval-rmse:2.59153                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.66101\teval-rmse:2.37644                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.48493\teval-rmse:2.25317                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.36789\teval-rmse:2.22371                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.29712\teval-rmse:2.20587                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.22507\teval-rmse:2.19476                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.17241\teval-rmse:2.20693                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.14737\teval-rmse:2.20791                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.11737\teval-rmse:2.21838                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.0782\teval-rmse:2.21155                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.02735\teval-rmse:2.22092                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.00023\teval-rmse:2.23507                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.96827\teval-rmse:2.27844                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.93763\teval-rmse:2.26461                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.92435\teval-rmse:2.27676                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.88264\teval-rmse:2.28486                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.86787\teval-rmse:2.28384                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.85085\teval-rmse:2.29274                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.83179\teval-rmse:2.28665                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.81401\teval-rmse:2.29512                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.80251\teval-rmse:2.2999                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.76395\teval-rmse:2.30158                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.75739\teval-rmse:2.3151                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.7398\teval-rmse:2.3156                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:1.71944\teval-rmse:2.32137                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.69587\teval-rmse:2.32293                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.22507\teval-rmse:2.19476\n",
      "\n",
      "\n",
      "loss: 96612333.30903427                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0006124928197984926, 'colsample_bytree': 0.7000000000000001, 'gamma': 3.447393678590628e-06, 'lambda': 0.00742708426663467, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 2.6888655305645037, 'n_estimators': 645.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.48571\teval-rmse:4.0526                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.70486\teval-rmse:3.26653                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.19292\teval-rmse:2.76297                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.85234\teval-rmse:2.4697                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.6283\teval-rmse:2.29747                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.47777\teval-rmse:2.21096                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.3779\teval-rmse:2.18049                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.30506\teval-rmse:2.1526                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.25586\teval-rmse:2.14935                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.20865\teval-rmse:2.14128                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.17765\teval-rmse:2.14489                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.15576\teval-rmse:2.14752                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.125\teval-rmse:2.15171                                                                                \n",
      "\n",
      "[13]\ttrain-rmse:2.09261\teval-rmse:2.15689                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.05764\teval-rmse:2.15169                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.03132\teval-rmse:2.15067                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.00059\teval-rmse:2.17181                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.97387\teval-rmse:2.18004                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.959\teval-rmse:2.19045                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:1.94256\teval-rmse:2.20161                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.91987\teval-rmse:2.19971                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.88947\teval-rmse:2.20452                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.8641\teval-rmse:2.20614                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.83862\teval-rmse:2.20947                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.81246\teval-rmse:2.21217                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.80294\teval-rmse:2.21193                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.78019\teval-rmse:2.21355                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.76982\teval-rmse:2.21387                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.74568\teval-rmse:2.21336                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.72769\teval-rmse:2.21845                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.20865\teval-rmse:2.14128\n",
      "\n",
      "\n",
      "loss: 96729818.14397609                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0001264001684977881, 'colsample_bytree': 0.8500000000000001, 'gamma': 5.4254702375015e-06, 'lambda': 0.013534021648207752, 'learning_rate': 0.225, 'max_depth': 3, 'min_child_weight': 0.258183965786107, 'n_estimators': 313.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.78522\teval-rmse:4.27184                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.17774\teval-rmse:3.56174                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.75327\teval-rmse:3.06343                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.46355\teval-rmse:2.70713                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.27582\teval-rmse:2.47387                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.14405\teval-rmse:2.31766                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.06194\teval-rmse:2.2242                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.0066\teval-rmse:2.17074                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.9673\teval-rmse:2.13198                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.94197\teval-rmse:2.10984                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.92224\teval-rmse:2.09596                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.90651\teval-rmse:2.08278                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.89437\teval-rmse:2.07859                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.88467\teval-rmse:2.0796                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.87246\teval-rmse:2.07438                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.8662\teval-rmse:2.07478                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.86149\teval-rmse:2.07435                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.85518\teval-rmse:2.07196                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.8507\teval-rmse:2.06964                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.84453\teval-rmse:2.06646                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.8392\teval-rmse:2.06629                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.8369\teval-rmse:2.06944                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.8327\teval-rmse:2.0705                                                                                \n",
      "\n",
      "[23]\ttrain-rmse:2.82822\teval-rmse:2.07364                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.82482\teval-rmse:2.07395                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.82206\teval-rmse:2.07417                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.81955\teval-rmse:2.07313                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.81629\teval-rmse:2.07268                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.81262\teval-rmse:2.07548                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.80937\teval-rmse:2.07371                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.80746\teval-rmse:2.07632                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.8028\teval-rmse:2.07549                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.80041\teval-rmse:2.07445                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.79554\teval-rmse:2.07784                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.79096\teval-rmse:2.086                                                                                \n",
      "\n",
      "[35]\ttrain-rmse:2.7879\teval-rmse:2.09099                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.78583\teval-rmse:2.09302                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.78397\teval-rmse:2.09474                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.78063\teval-rmse:2.09617                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.77964\teval-rmse:2.09518                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.77628\teval-rmse:2.09207                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[20]\ttrain-rmse:2.8392\teval-rmse:2.06629\n",
      "\n",
      "\n",
      "loss: 98454630.71018848                                                                                                \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0030728628924141113, 'colsample_bytree': 0.75, 'gamma': 0.0006982834001346122, 'lambda': 0.12049495169932656, 'learning_rate': 0.30000000000000004, 'max_depth': 7, 'min_child_weight': 1.5388920773290395, 'n_estimators': 165.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.42733\teval-rmse:3.95901                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.66748\teval-rmse:3.1395                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.20563\teval-rmse:2.65103                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.93271\teval-rmse:2.37476                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.76934\teval-rmse:2.23584                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.67359\teval-rmse:2.15363                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.61709\teval-rmse:2.11464                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.56902\teval-rmse:2.09758                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.53343\teval-rmse:2.09279                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.50845\teval-rmse:2.09027                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.46532\teval-rmse:2.099                                                                                \n",
      "\n",
      "[11]\ttrain-rmse:2.44394\teval-rmse:2.09409                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.40811\teval-rmse:2.14575                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.39341\teval-rmse:2.16056                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.37158\teval-rmse:2.16691                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.34169\teval-rmse:2.2111                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.33023\teval-rmse:2.21983                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.31083\teval-rmse:2.22473                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.29723\teval-rmse:2.22988                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.28174\teval-rmse:2.24089                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.26533\teval-rmse:2.24981                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.24555\teval-rmse:2.26325                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.2283\teval-rmse:2.31833                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.21424\teval-rmse:2.31664                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.20148\teval-rmse:2.32801                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.18588\teval-rmse:2.3223                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.17921\teval-rmse:2.32732                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.1561\teval-rmse:2.31782                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.14359\teval-rmse:2.327                                                                                \n",
      "\n",
      "[29]\ttrain-rmse:2.13153\teval-rmse:2.32703                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.50845\teval-rmse:2.09027\n",
      "\n",
      "\n",
      "loss: 97367933.34871934                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00021953023630114495, 'colsample_bytree': 0.8, 'gamma': 1.894147105838022e-05, 'lambda': 0.0026910308575550557, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 1.2680118746084392, 'n_estimators': 674.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.60016\teval-rmse:4.16622                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.88004\teval-rmse:3.41768                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.38099\teval-rmse:2.91579                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.05322\teval-rmse:2.58668                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.83047\teval-rmse:2.3843                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.67843\teval-rmse:2.25928                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.58475\teval-rmse:2.20134                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.51302\teval-rmse:2.16949                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.46288\teval-rmse:2.15207                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.42332\teval-rmse:2.1317                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.39104\teval-rmse:2.12428                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.36038\teval-rmse:2.14079                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.33792\teval-rmse:2.14196                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.31262\teval-rmse:2.1421                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.28842\teval-rmse:2.14787                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.26713\teval-rmse:2.14512                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.24349\teval-rmse:2.14517                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.21217\teval-rmse:2.15024                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.18196\teval-rmse:2.15607                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.15918\teval-rmse:2.16087                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.14026\teval-rmse:2.16614                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.12931\teval-rmse:2.17638                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.1122\teval-rmse:2.17923                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.09947\teval-rmse:2.1782                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.08996\teval-rmse:2.19694                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.08316\teval-rmse:2.20618                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.06581\teval-rmse:2.2092                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.04802\teval-rmse:2.2039                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.03149\teval-rmse:2.21664                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.00819\teval-rmse:2.22045                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.98904\teval-rmse:2.22672                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.39104\teval-rmse:2.12428\n",
      "\n",
      "\n",
      "loss: 96835390.94455242                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00047693587323830914, 'colsample_bytree': 0.75, 'gamma': 3.349521924892092e-05, 'lambda': 6.705312122433328e-05, 'learning_rate': 0.4, 'max_depth': 4, 'min_child_weight': 3.2833841041303167, 'n_estimators': 578.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.14656\teval-rmse:3.5445                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.43628\teval-rmse:2.69142                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.09841\teval-rmse:2.3093                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.95267\teval-rmse:2.15653                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.8794\teval-rmse:2.10412                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.8367\teval-rmse:2.0862                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:2.81877\teval-rmse:2.08048                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.80319\teval-rmse:2.09437                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.78775\teval-rmse:2.09553                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.78225\teval-rmse:2.1012                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.76961\teval-rmse:2.11188                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.75928\teval-rmse:2.1335                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.75154\teval-rmse:2.11985                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.74048\teval-rmse:2.12579                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.72934\teval-rmse:2.1294                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.72042\teval-rmse:2.12938                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.71515\teval-rmse:2.12937                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.71062\teval-rmse:2.15408                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.70378\teval-rmse:2.14965                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.69527\teval-rmse:2.17518                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.68883\teval-rmse:2.18683                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.68388\teval-rmse:2.21529                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.67953\teval-rmse:2.21622                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.66845\teval-rmse:2.26645                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.66242\teval-rmse:2.2655                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.65977\teval-rmse:2.26424                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.65325\teval-rmse:2.28484                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.81877\teval-rmse:2.08048\n",
      "\n",
      "\n",
      "loss: 97562642.8492775                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0008167811632439351, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.002607592502891589, 'lambda': 0.056176370119538674, 'learning_rate': 0.35000000000000003, 'max_depth': 9, 'min_child_weight': 0.7711832734550037, 'n_estimators': 499.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.18814\teval-rmse:3.75986                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.34167\teval-rmse:2.94615                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.8738\teval-rmse:2.52493                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.60412\teval-rmse:2.33904                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.44891\teval-rmse:2.25521                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.35744\teval-rmse:2.21821                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.2906\teval-rmse:2.20582                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.23307\teval-rmse:2.23307                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.19414\teval-rmse:2.24128                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.14991\teval-rmse:2.23897                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.12037\teval-rmse:2.23999                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.09288\teval-rmse:2.2763                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.06126\teval-rmse:2.2739                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.03767\teval-rmse:2.29243                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.99914\teval-rmse:2.28174                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.97805\teval-rmse:2.29248                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.94847\teval-rmse:2.32515                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.9189\teval-rmse:2.36168                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:1.89691\teval-rmse:2.3744                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\ttrain-rmse:1.87065\teval-rmse:2.3789                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.85322\teval-rmse:2.38836                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.82613\teval-rmse:2.39446                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.80706\teval-rmse:2.39329                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.77489\teval-rmse:2.4103                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.73914\teval-rmse:2.41549                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.72822\teval-rmse:2.41789                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.72156\teval-rmse:2.41624                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.2906\teval-rmse:2.20582\n",
      "\n",
      "\n",
      "loss: 96902470.12109892                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.024384029648701306, 'colsample_bytree': 0.8, 'gamma': 0.00019709575827953852, 'lambda': 0.03465669734884267, 'learning_rate': 0.225, 'max_depth': 6, 'min_child_weight': 0.6529048118940263, 'n_estimators': 606.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.73433\teval-rmse:4.26044                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.08435\teval-rmse:3.53891                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.62568\teval-rmse:3.02934                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.30614\teval-rmse:2.67853                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.09453\teval-rmse:2.45904                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.9497\teval-rmse:2.31127                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.8514\teval-rmse:2.20873                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.78316\teval-rmse:2.14843                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.73583\teval-rmse:2.11762                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.70011\teval-rmse:2.09876                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.66751\teval-rmse:2.08904                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.64796\teval-rmse:2.08332                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.62948\teval-rmse:2.07471                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.6058\teval-rmse:2.07231                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.58961\teval-rmse:2.07373                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.5713\teval-rmse:2.06777                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.55687\teval-rmse:2.07364                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.54533\teval-rmse:2.07186                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.53359\teval-rmse:2.07463                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.51919\teval-rmse:2.08263                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.50788\teval-rmse:2.07855                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.4976\teval-rmse:2.0745                                                                                \n",
      "\n",
      "[22]\ttrain-rmse:2.48407\teval-rmse:2.07767                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.47599\teval-rmse:2.07774                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.46841\teval-rmse:2.0755                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.46373\teval-rmse:2.07577                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.45798\teval-rmse:2.0726                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.44532\teval-rmse:2.08755                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.4354\teval-rmse:2.0903                                                                                \n",
      "\n",
      "[29]\ttrain-rmse:2.42618\teval-rmse:2.08929                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.41966\teval-rmse:2.09255                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.40809\teval-rmse:2.09006                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.40063\teval-rmse:2.09645                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.39373\teval-rmse:2.09373                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.38042\teval-rmse:2.09419                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.3751\teval-rmse:2.09588                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.5713\teval-rmse:2.06777\n",
      "\n",
      "\n",
      "loss: 97771948.349943                                                                                                  \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.006443736649183624, 'colsample_bytree': 0.9500000000000001, 'gamma': 6.873701512098872e-06, 'lambda': 9.663230748121528, 'learning_rate': 0.375, 'max_depth': 9, 'min_child_weight': 2.554634457231691, 'n_estimators': 754.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.14066\teval-rmse:3.65432                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.31807\teval-rmse:2.80314                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.87804\teval-rmse:2.37664                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.63709\teval-rmse:2.18926                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.50631\teval-rmse:2.1198                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.42881\teval-rmse:2.08152                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.34293\teval-rmse:2.08808                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.29537\teval-rmse:2.08606                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.23487\teval-rmse:2.09122                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.17782\teval-rmse:2.10556                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.15061\teval-rmse:2.10981                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.10555\teval-rmse:2.12094                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.06824\teval-rmse:2.12076                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.04572\teval-rmse:2.13158                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.02196\teval-rmse:2.14344                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.98879\teval-rmse:2.15255                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.96454\teval-rmse:2.15802                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.91972\teval-rmse:2.16097                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.90202\teval-rmse:2.1611                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.88091\teval-rmse:2.17232                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.86157\teval-rmse:2.17872                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.84895\teval-rmse:2.18063                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.83827\teval-rmse:2.18691                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.81812\teval-rmse:2.18993                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.79043\teval-rmse:2.20207                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.76494\teval-rmse:2.20887                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.42881\teval-rmse:2.08152\n",
      "\n",
      "\n",
      "loss: 97261884.16746455                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.36682562464725e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.0295734548436605e-05, 'lambda': 0.0013877241346949576, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.986164193524268, 'n_estimators': 268.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.27175\teval-rmse:3.86392                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.44479\teval-rmse:3.05083                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.94281\teval-rmse:2.59285                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.66189\teval-rmse:2.38252                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.48156\teval-rmse:2.29654                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.36376\teval-rmse:2.2357                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.29464\teval-rmse:2.23787                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.227\teval-rmse:2.24339                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.18852\teval-rmse:2.26015                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.14979\teval-rmse:2.26114                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.10983\teval-rmse:2.26683                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.07937\teval-rmse:2.27206                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.04833\teval-rmse:2.28444                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.01569\teval-rmse:2.28863                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.99841\teval-rmse:2.2963                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:1.9683\teval-rmse:2.31034                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:1.93272\teval-rmse:2.32723                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.89989\teval-rmse:2.3656                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:1.87882\teval-rmse:2.36544                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.86914\teval-rmse:2.36847                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.84891\teval-rmse:2.37868                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.82789\teval-rmse:2.39714                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.81135\teval-rmse:2.40064                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.79816\teval-rmse:2.39536                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.7827\teval-rmse:2.39318                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.75957\teval-rmse:2.41453                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.36376\teval-rmse:2.2357\n",
      "\n",
      "\n",
      "loss: 106227407.22663826                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0003116773863993299, 'colsample_bytree': 0.65, 'gamma': 6.607789811993295e-05, 'lambda': 0.2404443948499915, 'learning_rate': 0.30000000000000004, 'max_depth': 5, 'min_child_weight': 1.6543873629340902, 'n_estimators': 208.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.47924\teval-rmse:3.94908                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.75887\teval-rmse:3.12436                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.32653\teval-rmse:2.63201                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.08617\teval-rmse:2.35429                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.94747\teval-rmse:2.21411                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.8703\teval-rmse:2.14253                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.81707\teval-rmse:2.11183                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.78625\teval-rmse:2.09451                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain-rmse:2.75941\teval-rmse:2.09153                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.73904\teval-rmse:2.07747                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.72416\teval-rmse:2.08259                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.71649\teval-rmse:2.08138                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.70363\teval-rmse:2.08268                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.68998\teval-rmse:2.08838                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.68226\teval-rmse:2.09761                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.66867\teval-rmse:2.09874                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.65642\teval-rmse:2.10848                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.64493\teval-rmse:2.11495                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.63418\teval-rmse:2.11972                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.62584\teval-rmse:2.12152                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.61491\teval-rmse:2.12355                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.60868\teval-rmse:2.11504                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.60009\teval-rmse:2.11231                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.59025\teval-rmse:2.11198                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.58301\teval-rmse:2.12197                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.5731\teval-rmse:2.11682                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.56899\teval-rmse:2.12043                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.55864\teval-rmse:2.12244                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.554\teval-rmse:2.13594                                                                                \n",
      "\n",
      "[29]\ttrain-rmse:2.5418\teval-rmse:2.1326                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.73904\teval-rmse:2.07747\n",
      "\n",
      "\n",
      "loss: 97921676.4986527                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.013309809502165789, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.5618570612502473, 'lambda': 0.00044826285874025084, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 2.890941268294301, 'n_estimators': 659.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.28626\teval-rmse:3.85407                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.45207\teval-rmse:3.01676                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.9583\teval-rmse:2.56028                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.67177\teval-rmse:2.33114                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.50068\teval-rmse:2.22996                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.38285\teval-rmse:2.20003                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.30295\teval-rmse:2.17284                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.25743\teval-rmse:2.1664                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.21346\teval-rmse:2.18362                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.1887\teval-rmse:2.1874                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.15778\teval-rmse:2.18864                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.12784\teval-rmse:2.19036                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.09181\teval-rmse:2.21049                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.05788\teval-rmse:2.21771                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.04481\teval-rmse:2.21655                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.01928\teval-rmse:2.21714                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.98925\teval-rmse:2.22343                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.94879\teval-rmse:2.23179                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.93554\teval-rmse:2.23646                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.90837\teval-rmse:2.2222                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.88722\teval-rmse:2.22116                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.86364\teval-rmse:2.23384                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.84437\teval-rmse:2.24239                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.81218\teval-rmse:2.24464                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.79746\teval-rmse:2.25049                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.77826\teval-rmse:2.24798                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.75789\teval-rmse:2.25024                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.73323\teval-rmse:2.25747                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.25743\teval-rmse:2.1664\n",
      "\n",
      "\n",
      "loss: 97044203.12666082                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.8005622715784283e-05, 'colsample_bytree': 0.75, 'gamma': 0.0003409031841847319, 'lambda': 0.003825080876259727, 'learning_rate': 0.275, 'max_depth': 3, 'min_child_weight': 0.4684613353550551, 'n_estimators': 625.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.60459\teval-rmse:4.06325                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.93895\teval-rmse:3.28022                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.52009\teval-rmse:2.77451                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.26484\teval-rmse:2.46922                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.11543\teval-rmse:2.28571                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.02372\teval-rmse:2.18619                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.97115\teval-rmse:2.13507                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.93934\teval-rmse:2.11319                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.91621\teval-rmse:2.09669                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.90162\teval-rmse:2.08468                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.88534\teval-rmse:2.08116                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.87685\teval-rmse:2.07838                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.86902\teval-rmse:2.07288                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.86214\teval-rmse:2.07054                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.85668\teval-rmse:2.06789                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.85006\teval-rmse:2.06558                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.84261\teval-rmse:2.06754                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.83762\teval-rmse:2.06076                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.83306\teval-rmse:2.06051                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.8281\teval-rmse:2.06381                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.82366\teval-rmse:2.06738                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.81827\teval-rmse:2.07194                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.81554\teval-rmse:2.07174                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.81208\teval-rmse:2.07648                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.809\teval-rmse:2.07757                                                                                \n",
      "\n",
      "[25]\ttrain-rmse:2.80497\teval-rmse:2.07741                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.79877\teval-rmse:2.08464                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.7958\teval-rmse:2.09846                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.7923\teval-rmse:2.10264                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.78743\teval-rmse:2.10132                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.78466\teval-rmse:2.09951                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.78085\teval-rmse:2.09413                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.77803\teval-rmse:2.09447                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.77675\teval-rmse:2.09309                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.77369\teval-rmse:2.09701                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.77238\teval-rmse:2.09566                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.7694\teval-rmse:2.09443                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.76493\teval-rmse:2.09093                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.76016\teval-rmse:2.09059                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[18]\ttrain-rmse:2.83306\teval-rmse:2.06051\n",
      "\n",
      "\n",
      "loss: 98639815.68401654                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.638494167442745e-05, 'colsample_bytree': 0.8, 'gamma': 1.385044486886977e-05, 'lambda': 1.0310041211564556e-06, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 1.8847786008818852, 'n_estimators': 435.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.02325\teval-rmse:3.56485                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.21139\teval-rmse:2.70823                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.79825\teval-rmse:2.35881                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.58589\teval-rmse:2.19393                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.49064\teval-rmse:2.1469                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.41425\teval-rmse:2.15176                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.36283\teval-rmse:2.15413                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.31429\teval-rmse:2.17483                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.26349\teval-rmse:2.21023                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.21816\teval-rmse:2.21986                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.2092\teval-rmse:2.22329                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.1833\teval-rmse:2.23365                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.15448\teval-rmse:2.29246                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.11939\teval-rmse:2.31315                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.10672\teval-rmse:2.30856                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.08147\teval-rmse:2.30924                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.05136\teval-rmse:2.31183                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.01951\teval-rmse:2.32665                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.99107\teval-rmse:2.32259                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.97527\teval-rmse:2.33003                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.95908\teval-rmse:2.3453                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.92853\teval-rmse:2.35261                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.91982\teval-rmse:2.34851                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\ttrain-rmse:1.90189\teval-rmse:2.351                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:1.87481\teval-rmse:2.36737                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.49064\teval-rmse:2.1469\n",
      "\n",
      "\n",
      "loss: 96819169.39893015                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0022031290570947632, 'colsample_bytree': 0.7000000000000001, 'gamma': 2.3883502829312044e-05, 'lambda': 0.000221739517074013, 'learning_rate': 0.5, 'max_depth': 7, 'min_child_weight': 2.3174109024304332, 'n_estimators': 716.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:3.73781\teval-rmse:3.17903                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.02843\teval-rmse:2.4694                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.76373\teval-rmse:2.26103                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.66537\teval-rmse:2.25375                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.61891\teval-rmse:2.24058                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.58771\teval-rmse:2.2488                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.55054\teval-rmse:2.31422                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.53994\teval-rmse:2.32804                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.50804\teval-rmse:2.41715                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.4723\teval-rmse:2.43751                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.45201\teval-rmse:2.45763                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.42319\teval-rmse:2.46089                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.41092\teval-rmse:2.4739                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.37953\teval-rmse:2.47283                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.36259\teval-rmse:2.47747                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.3367\teval-rmse:2.49104                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.31388\teval-rmse:2.52232                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.30147\teval-rmse:2.54374                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.28542\teval-rmse:2.55244                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.26702\teval-rmse:2.55282                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.25588\teval-rmse:2.54595                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.24409\teval-rmse:2.57341                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.23042\teval-rmse:2.58121                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.22222\teval-rmse:2.59542                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.21516\teval-rmse:2.60047                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.61891\teval-rmse:2.24058\n",
      "\n",
      "\n",
      "loss: 158046205.35999167                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.1335827081988857e-05, 'colsample_bytree': 0.75, 'gamma': 3.664359120413052e-06, 'lambda': 1.5050359408820669e-05, 'learning_rate': 0.47500000000000003, 'max_depth': 9, 'min_child_weight': 4.031717326482925, 'n_estimators': 519.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:3.7306\teval-rmse:3.28442                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:2.91878\teval-rmse:2.50471                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.57932\teval-rmse:2.2293                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.42759\teval-rmse:2.16385                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.36055\teval-rmse:2.14957                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.32081\teval-rmse:2.15668                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.27485\teval-rmse:2.18647                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.25351\teval-rmse:2.20887                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.22191\teval-rmse:2.21352                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.18385\teval-rmse:2.24618                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.14078\teval-rmse:2.28315                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.09341\teval-rmse:2.29095                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.06942\teval-rmse:2.31253                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.0411\teval-rmse:2.32818                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.02909\teval-rmse:2.33062                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.00256\teval-rmse:2.34555                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.97065\teval-rmse:2.36412                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.94371\teval-rmse:2.3876                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:1.91191\teval-rmse:2.4002                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.89299\teval-rmse:2.40766                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.87039\teval-rmse:2.41719                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.83246\teval-rmse:2.42998                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.8191\teval-rmse:2.43761                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.7976\teval-rmse:2.43918                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.78833\teval-rmse:2.45484                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.36055\teval-rmse:2.14957\n",
      "\n",
      "\n",
      "loss: 2577183100.529621                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0046489250844192484, 'colsample_bytree': 0.8, 'gamma': 0.00012054528119403555, 'lambda': 2.0219363646938676e-06, 'learning_rate': 0.35000000000000003, 'max_depth': 4, 'min_child_weight': 5.734705300398327, 'n_estimators': 258.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.31568\teval-rmse:3.74491                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.59658\teval-rmse:2.8873                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.21268\teval-rmse:2.44851                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.02042\teval-rmse:2.22803                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.92812\teval-rmse:2.13029                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.87912\teval-rmse:2.09142                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.85086\teval-rmse:2.07294                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.82705\teval-rmse:2.06256                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.81097\teval-rmse:2.05655                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.79759\teval-rmse:2.04388                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.78698\teval-rmse:2.05032                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.78115\teval-rmse:2.0491                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.77576\teval-rmse:2.03891                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.76698\teval-rmse:2.04591                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.76265\teval-rmse:2.04506                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.75501\teval-rmse:2.04996                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.7448\teval-rmse:2.04208                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.7377\teval-rmse:2.04241                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.734\teval-rmse:2.04111                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:2.72588\teval-rmse:2.03767                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.71932\teval-rmse:2.05839                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.71066\teval-rmse:2.05706                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.70374\teval-rmse:2.05626                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.69771\teval-rmse:2.05823                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.69292\teval-rmse:2.06081                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.68935\teval-rmse:2.04897                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.68199\teval-rmse:2.03471                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.67943\teval-rmse:2.03936                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.67273\teval-rmse:2.04111                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.66852\teval-rmse:2.04705                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.66588\teval-rmse:2.04413                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.66154\teval-rmse:2.04109                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.65566\teval-rmse:2.04515                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.64457\teval-rmse:2.04439                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.63948\teval-rmse:2.05914                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.63395\teval-rmse:2.05064                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.62773\teval-rmse:2.04933                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.62044\teval-rmse:2.04334                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.6159\teval-rmse:2.04526                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:2.61056\teval-rmse:2.04227                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.60687\teval-rmse:2.0439                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.60369\teval-rmse:2.04577                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.60027\teval-rmse:2.04508                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.59677\teval-rmse:2.04548                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.59374\teval-rmse:2.04716                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.59131\teval-rmse:2.0553                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.58417\teval-rmse:2.05493                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[26]\ttrain-rmse:2.68199\teval-rmse:2.03471\n",
      "\n",
      "\n",
      "loss: 97938190.97113581                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0011404583606253712, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.0009975339453577956, 'lambda': 0.01776245244706652, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 2.0219127236743755, 'n_estimators': 768.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.57853\teval-rmse:4.15793                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.83087\teval-rmse:3.39742                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.3042\teval-rmse:2.88709                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.93722\teval-rmse:2.55939                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.68898\teval-rmse:2.36102                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-rmse:2.52473\teval-rmse:2.24023                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.40574\teval-rmse:2.18597                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.32875\teval-rmse:2.15328                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.2672\teval-rmse:2.13367                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.22869\teval-rmse:2.12706                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.17842\teval-rmse:2.11658                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.15122\teval-rmse:2.11968                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.11554\teval-rmse:2.12245                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.08444\teval-rmse:2.12133                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.05314\teval-rmse:2.13202                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.00612\teval-rmse:2.1365                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:1.97193\teval-rmse:2.14473                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.94807\teval-rmse:2.14439                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.91181\teval-rmse:2.15088                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.89453\teval-rmse:2.14941                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.86844\teval-rmse:2.16565                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.85034\teval-rmse:2.17024                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.83115\teval-rmse:2.17787                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.79766\teval-rmse:2.18858                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.7889\teval-rmse:2.18895                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.76363\teval-rmse:2.19241                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.75721\teval-rmse:2.19142                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.73569\teval-rmse:2.19218                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.72936\teval-rmse:2.19502                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.70945\teval-rmse:2.20193                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.69902\teval-rmse:2.20328                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.17842\teval-rmse:2.11658\n",
      "\n",
      "\n",
      "loss: 97264748.1368227                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.227303180893681e-06, 'colsample_bytree': 0.65, 'gamma': 0.0359739424052715, 'lambda': 0.005680924610548264, 'learning_rate': 0.225, 'max_depth': 6, 'min_child_weight': 1.1350969869503633, 'n_estimators': 294.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.7376\teval-rmse:4.26491                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.09035\teval-rmse:3.5461                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.63387\teval-rmse:3.03419                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.31782\teval-rmse:2.67958                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.10699\teval-rmse:2.45646                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.96112\teval-rmse:2.29998                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.8606\teval-rmse:2.20698                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.79214\teval-rmse:2.15178                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.74329\teval-rmse:2.11898                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.70833\teval-rmse:2.09461                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.68346\teval-rmse:2.07646                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.65578\teval-rmse:2.06707                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.64242\teval-rmse:2.05475                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.62006\teval-rmse:2.05598                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.60263\teval-rmse:2.05807                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.58701\teval-rmse:2.0606                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.57034\teval-rmse:2.06146                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.55239\teval-rmse:2.06384                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.53708\teval-rmse:2.06661                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.5286\teval-rmse:2.06988                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.52115\teval-rmse:2.07166                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.51164\teval-rmse:2.07596                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.5055\teval-rmse:2.07621                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.4973\teval-rmse:2.07987                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.49123\teval-rmse:2.07958                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.48721\teval-rmse:2.08438                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.47781\teval-rmse:2.07679                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.46955\teval-rmse:2.0827                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.4586\teval-rmse:2.08504                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.44472\teval-rmse:2.09069                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.43932\teval-rmse:2.09384                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.43272\teval-rmse:2.09518                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.42421\teval-rmse:2.09485                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.64242\teval-rmse:2.05475\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 98043193.78739831                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0666404238877132, 'colsample_bytree': 0.75, 'gamma': 1.645882327670727e-06, 'lambda': 0.1707114658620701, 'learning_rate': 0.42500000000000004, 'max_depth': 9, 'min_child_weight': 0.5849327224397853, 'n_estimators': 236.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:3.90638\teval-rmse:3.47427                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.06675\teval-rmse:2.64426                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.66165\teval-rmse:2.33288                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.46873\teval-rmse:2.22384                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.34845\teval-rmse:2.26485                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.27342\teval-rmse:2.26553                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.23849\teval-rmse:2.27656                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.19266\teval-rmse:2.29647                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.15216\teval-rmse:2.30935                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.12708\teval-rmse:2.31402                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.07572\teval-rmse:2.31364                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.03206\teval-rmse:2.31388                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.00231\teval-rmse:2.3136                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:1.96642\teval-rmse:2.33334                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.93624\teval-rmse:2.33922                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.91858\teval-rmse:2.34451                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.89757\teval-rmse:2.35663                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.86792\teval-rmse:2.35504                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.80986\teval-rmse:2.34384                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.76279\teval-rmse:2.37351                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.74599\teval-rmse:2.37425                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.71705\teval-rmse:2.3783                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.69028\teval-rmse:2.38428                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.66123\teval-rmse:2.39138                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[3]\ttrain-rmse:2.46873\teval-rmse:2.22384\n",
      "\n",
      "\n",
      "loss: 129578164.14659064                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00011448238344968981, 'colsample_bytree': 0.9, 'gamma': 5.607727743318759e-05, 'lambda': 5.1997932785136014e-05, 'learning_rate': 0.30000000000000004, 'max_depth': 5, 'min_child_weight': 4.697886054695575, 'n_estimators': 449.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.4703\teval-rmse:3.95146                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.74628\teval-rmse:3.11624                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.32008\teval-rmse:2.62401                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.07846\teval-rmse:2.34509                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.94318\teval-rmse:2.19888                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.85811\teval-rmse:2.12847                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.80704\teval-rmse:2.08843                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.77518\teval-rmse:2.06539                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.74901\teval-rmse:2.05276                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.7335\teval-rmse:2.04474                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.71933\teval-rmse:2.04865                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.70242\teval-rmse:2.04527                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.69298\teval-rmse:2.04756                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.68319\teval-rmse:2.04915                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.67684\teval-rmse:2.05039                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.6685\teval-rmse:2.05295                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.65353\teval-rmse:2.05299                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.63952\teval-rmse:2.05113                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.63206\teval-rmse:2.05173                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.62542\teval-rmse:2.05362                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.61829\teval-rmse:2.05621                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.6061\teval-rmse:2.06357                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.60052\teval-rmse:2.06874                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.58853\teval-rmse:2.06383                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.58012\teval-rmse:2.06246                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.57045\teval-rmse:2.07007                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.5621\teval-rmse:2.07116                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.55381\teval-rmse:2.07109                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.54737\teval-rmse:2.07226                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.53805\teval-rmse:2.0716                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.7335\teval-rmse:2.04474\n",
      "\n",
      "\n",
      "loss: 98203586.47844803                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0016794906111612378, 'colsample_bytree': 0.7000000000000001, 'gamma': 4.519362648890936e-07, 'lambda': 0.0008363391055878511, 'learning_rate': 0.17500000000000002, 'max_depth': 9, 'min_child_weight': 1.3157403924107587, 'n_estimators': 598.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.89448\teval-rmse:4.48312                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.29232\teval-rmse:3.87666                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.81808\teval-rmse:3.40889                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.44571\teval-rmse:3.04972                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.16144\teval-rmse:2.77788                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.94096\teval-rmse:2.59316                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.77624\teval-rmse:2.45169                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.63842\teval-rmse:2.35231                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.53397\teval-rmse:2.27952                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.45327\teval-rmse:2.22702                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.39648\teval-rmse:2.18425                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.33295\teval-rmse:2.16455                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.28852\teval-rmse:2.14694                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.23367\teval-rmse:2.14625                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.21265\teval-rmse:2.14599                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.18384\teval-rmse:2.15021                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.16013\teval-rmse:2.14599                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.12872\teval-rmse:2.15709                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.10219\teval-rmse:2.16131                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.08355\teval-rmse:2.16637                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.06538\teval-rmse:2.16802                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.05462\teval-rmse:2.17346                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.03042\teval-rmse:2.18479                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.01163\teval-rmse:2.19252                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.98911\teval-rmse:2.19155                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.98199\teval-rmse:2.19439                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.95897\teval-rmse:2.21226                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.94774\teval-rmse:2.2177                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.93439\teval-rmse:2.21909                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.92108\teval-rmse:2.22667                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.90653\teval-rmse:2.22741                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.88922\teval-rmse:2.22749                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.87666\teval-rmse:2.23483                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.86704\teval-rmse:2.23844                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.84843\teval-rmse:2.24668                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.83577\teval-rmse:2.24603                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.82746\teval-rmse:2.24908                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[16]\ttrain-rmse:2.16013\teval-rmse:2.14599\n",
      "\n",
      "\n",
      "loss: 96800684.19353153                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00016556679693336795, 'colsample_bytree': 0.75, 'gamma': 1.2289452838225396e-06, 'lambda': 0.00013240069782748123, 'learning_rate': 0.375, 'max_depth': 3, 'min_child_weight': 2.193939827265524, 'n_estimators': 793.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.26\teval-rmse:3.66006                                                                                  \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.55957\teval-rmse:2.8109                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.21176\teval-rmse:2.38706                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.0472\teval-rmse:2.20285                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.96947\teval-rmse:2.11614                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.92846\teval-rmse:2.08864                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.90685\teval-rmse:2.08893                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.88981\teval-rmse:2.08926                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.87748\teval-rmse:2.08469                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.86811\teval-rmse:2.09044                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.85385\teval-rmse:2.08228                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.84848\teval-rmse:2.08035                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.84103\teval-rmse:2.08344                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.83211\teval-rmse:2.08703                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\ttrain-rmse:2.82234\teval-rmse:2.08858                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.8158\teval-rmse:2.08829                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.80959\teval-rmse:2.09232                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.80547\teval-rmse:2.09348                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.80058\teval-rmse:2.09449                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.79594\teval-rmse:2.114                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:2.79029\teval-rmse:2.11273                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.78319\teval-rmse:2.11215                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.77877\teval-rmse:2.11148                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.77506\teval-rmse:2.11015                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.77215\teval-rmse:2.10716                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.76912\teval-rmse:2.10851                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.7653\teval-rmse:2.12565                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.76186\teval-rmse:2.12321                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.7576\teval-rmse:2.1524                                                                                \n",
      "\n",
      "[29]\ttrain-rmse:2.75403\teval-rmse:2.14378                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.75201\teval-rmse:2.14432                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.74936\teval-rmse:2.14511                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.84848\teval-rmse:2.08035\n",
      "\n",
      "\n",
      "loss: 98775832.52015142                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0002608733829935646, 'colsample_bytree': 0.7000000000000001, 'gamma': 4.482007752388877e-06, 'lambda': 0.3650966863703572, 'learning_rate': 0.45, 'max_depth': 9, 'min_child_weight': 1.741957964821734, 'n_estimators': 381.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:3.83465\teval-rmse:3.38534                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.00114\teval-rmse:2.6351                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.64742\teval-rmse:2.37252                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.48618\teval-rmse:2.29625                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.42027\teval-rmse:2.27561                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.3652\teval-rmse:2.27852                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.33081\teval-rmse:2.27014                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.29066\teval-rmse:2.30929                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.25738\teval-rmse:2.36842                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.20716\teval-rmse:2.36559                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.17441\teval-rmse:2.41999                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.15513\teval-rmse:2.42709                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.11753\teval-rmse:2.42972                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.07461\teval-rmse:2.47493                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.06542\teval-rmse:2.50964                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.02184\teval-rmse:2.50588                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.9999\teval-rmse:2.52036                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:1.96248\teval-rmse:2.51966                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.91956\teval-rmse:2.55014                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.90131\teval-rmse:2.55671                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.87241\teval-rmse:2.56192                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.85308\teval-rmse:2.55636                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.81401\teval-rmse:2.57037                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.78065\teval-rmse:2.57331                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.7657\teval-rmse:2.58256                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.74951\teval-rmse:2.59906                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.73256\teval-rmse:2.61187                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.33081\teval-rmse:2.27014\n",
      "\n",
      "\n",
      "loss: 238290166.91669208                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0031912101461572737, 'colsample_bytree': 0.8, 'gamma': 0.0004927753574606749, 'lambda': 0.000316387968545048, 'learning_rate': 0.275, 'max_depth': 7, 'min_child_weight': 3.788958692325842, 'n_estimators': 733.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.52364\teval-rmse:4.06033                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.78779\teval-rmse:3.26023                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.31358\teval-rmse:2.75535                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.01784\teval-rmse:2.45191                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.83659\teval-rmse:2.28472                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.72532\teval-rmse:2.19339                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.65081\teval-rmse:2.1437                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.59285\teval-rmse:2.11539                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.5579\teval-rmse:2.10359                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.52923\teval-rmse:2.08648                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.51206\teval-rmse:2.08304                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.49223\teval-rmse:2.08526                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.46791\teval-rmse:2.07445                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.45168\teval-rmse:2.08698                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.42906\teval-rmse:2.09256                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.40406\teval-rmse:2.08516                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.38246\teval-rmse:2.08955                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.35988\teval-rmse:2.09103                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.34086\teval-rmse:2.10017                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.31906\teval-rmse:2.10526                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.30515\teval-rmse:2.10875                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.28467\teval-rmse:2.11496                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.27001\teval-rmse:2.10736                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.25202\teval-rmse:2.10755                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.2304\teval-rmse:2.11794                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.2235\teval-rmse:2.12032                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.21249\teval-rmse:2.11307                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.18346\teval-rmse:2.11788                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.17739\teval-rmse:2.11755                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.17311\teval-rmse:2.13216                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.15998\teval-rmse:2.14113                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.14933\teval-rmse:2.14493                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.13548\teval-rmse:2.14217                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.46791\teval-rmse:2.07445\n",
      "\n",
      "\n",
      "loss: 97207366.51689672                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.03438363590929843, 'colsample_bytree': 0.75, 'gamma': 2.103274790506105e-06, 'lambda': 2.802816613532695e-05, 'learning_rate': 0.2, 'max_depth': 9, 'min_child_weight': 0.3317333605254371, 'n_estimators': 567.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.78417\teval-rmse:4.37677                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.12586\teval-rmse:3.71382                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.62767\teval-rmse:3.22674                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.24425\teval-rmse:2.883                                                                                 \n",
      "\n",
      "[4]\ttrain-rmse:2.96508\teval-rmse:2.63563                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.75719\teval-rmse:2.46609                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.60254\teval-rmse:2.3577                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.482\teval-rmse:2.28679                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.39419\teval-rmse:2.22958                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.33266\teval-rmse:2.20223                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.27995\teval-rmse:2.1927                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.23963\teval-rmse:2.17607                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.20139\teval-rmse:2.17195                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.17024\teval-rmse:2.18486                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.1448\teval-rmse:2.18411                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.11085\teval-rmse:2.20268                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.08329\teval-rmse:2.20861                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.05078\teval-rmse:2.21491                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.02995\teval-rmse:2.21542                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.0132\teval-rmse:2.21737                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.99407\teval-rmse:2.20761                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.97223\teval-rmse:2.21938                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.95408\teval-rmse:2.22261                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.92739\teval-rmse:2.2226                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.90693\teval-rmse:2.22482                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.89436\teval-rmse:2.2239                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.88618\teval-rmse:2.23456                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.86065\teval-rmse:2.23803                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.84278\teval-rmse:2.24763                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.81838\teval-rmse:2.25665                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.79265\teval-rmse:2.25451                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.77661\teval-rmse:2.25597                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.76215\teval-rmse:2.26122                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.20139\teval-rmse:2.17195\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 96660810.55998948                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0005024059528094314, 'colsample_bytree': 0.8, 'gamma': 4.130340691528777e-05, 'lambda': 0.0019502249465372715, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 0.8906989003908573, 'n_estimators': 112.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.60011\teval-rmse:4.16584                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.87977\teval-rmse:3.41742                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.3775\teval-rmse:2.92623                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.04521\teval-rmse:2.61157                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.82065\teval-rmse:2.41152                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.66858\teval-rmse:2.28743                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.57343\teval-rmse:2.2504                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.49849\teval-rmse:2.202                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.44712\teval-rmse:2.18744                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.41248\teval-rmse:2.17924                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.37454\teval-rmse:2.16604                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.33767\teval-rmse:2.15854                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.31837\teval-rmse:2.16561                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.28514\teval-rmse:2.16267                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.27141\teval-rmse:2.16819                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.24994\teval-rmse:2.20122                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.22462\teval-rmse:2.21889                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.20593\teval-rmse:2.21647                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.17811\teval-rmse:2.22516                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.1479\teval-rmse:2.2335                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:2.12975\teval-rmse:2.24276                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.11713\teval-rmse:2.24077                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.10257\teval-rmse:2.24397                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.08631\teval-rmse:2.24885                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.07611\teval-rmse:2.25156                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.06788\teval-rmse:2.25527                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.04927\teval-rmse:2.25893                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.03424\teval-rmse:2.27093                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.01484\teval-rmse:2.22276                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.99598\teval-rmse:2.22928                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.98838\teval-rmse:2.23365                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.97614\teval-rmse:2.23472                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.33767\teval-rmse:2.15854\n",
      "\n",
      "\n",
      "loss: 97858586.60208969                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.11371205803879544, 'colsample_bytree': 0.65, 'gamma': 0.0017465726384384432, 'lambda': 0.07794058022680675, 'learning_rate': 0.35000000000000003, 'max_depth': 4, 'min_child_weight': 0.11787229587170021, 'n_estimators': 641.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.32086\teval-rmse:3.74606                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.59712\teval-rmse:2.89226                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.22547\teval-rmse:2.45062                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.0386\teval-rmse:2.23412                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.94895\teval-rmse:2.13353                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.88854\teval-rmse:2.09538                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.85719\teval-rmse:2.07432                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.83868\teval-rmse:2.07154                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.82235\teval-rmse:2.06257                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.81054\teval-rmse:2.05928                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.80238\teval-rmse:2.06214                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.79307\teval-rmse:2.05504                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.78182\teval-rmse:2.05304                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.77125\teval-rmse:2.05337                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.76768\teval-rmse:2.05354                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.76133\teval-rmse:2.06202                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.74838\teval-rmse:2.06075                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.7424\teval-rmse:2.07605                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.73397\teval-rmse:2.10813                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.72731\teval-rmse:2.1119                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.71926\teval-rmse:2.11268                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.71063\teval-rmse:2.09576                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.70514\teval-rmse:2.0891                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.69794\teval-rmse:2.08818                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.69169\teval-rmse:2.0906                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.68365\teval-rmse:2.09229                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.67683\teval-rmse:2.09374                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.67219\teval-rmse:2.09405                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.6647\teval-rmse:2.08976                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.65852\teval-rmse:2.08741                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.6555\teval-rmse:2.08131                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.65385\teval-rmse:2.07814                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.64998\teval-rmse:2.07922                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.78182\teval-rmse:2.05304\n",
      "\n",
      "\n",
      "loss: 97637311.13445903                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0007333674556183321, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.022072783531960516, 'lambda': 0.04652011228836727, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 1.461477119156196, 'n_estimators': 697.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.37455\teval-rmse:3.96152                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.56543\teval-rmse:3.16006                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.05887\teval-rmse:2.67372                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.75461\teval-rmse:2.42299                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.56481\teval-rmse:2.29739                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.44348\teval-rmse:2.23115                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.36548\teval-rmse:2.20613                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.3063\teval-rmse:2.19249                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.26025\teval-rmse:2.20284                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.23263\teval-rmse:2.2224                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.19293\teval-rmse:2.23892                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.16342\teval-rmse:2.25067                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.13198\teval-rmse:2.26186                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.10436\teval-rmse:2.28546                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.07778\teval-rmse:2.31586                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.06136\teval-rmse:2.32102                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.03358\teval-rmse:2.34612                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.00968\teval-rmse:2.36227                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.98168\teval-rmse:2.36806                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.95177\teval-rmse:2.396                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:1.93851\teval-rmse:2.43759                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.89079\teval-rmse:2.44416                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.86849\teval-rmse:2.46131                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.85858\teval-rmse:2.45183                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.83874\teval-rmse:2.46033                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.82482\teval-rmse:2.46142                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.80728\teval-rmse:2.46954                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.76821\teval-rmse:2.46782                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.3063\teval-rmse:2.19249\n",
      "\n",
      "\n",
      "loss: 96958968.73775868                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.006296438524024784, 'colsample_bytree': 0.7000000000000001, 'gamma': 6.9941899862347465e-06, 'lambda': 0.002640899517551096, 'learning_rate': 0.35000000000000003, 'max_depth': 6, 'min_child_weight': 6.641038990731693, 'n_estimators': 187.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.27333\teval-rmse:3.74152                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.51337\teval-rmse:2.88701                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.10836\teval-rmse:2.43168                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.90056\teval-rmse:2.22367                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.79416\teval-rmse:2.1178                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.73609\teval-rmse:2.08041                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.69975\teval-rmse:2.06056                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.67653\teval-rmse:2.06789                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.65263\teval-rmse:2.06998                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.63209\teval-rmse:2.06917                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.62024\teval-rmse:2.07179                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.60098\teval-rmse:2.07517                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\ttrain-rmse:2.58081\teval-rmse:2.07203                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.56467\teval-rmse:2.06645                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.55339\teval-rmse:2.07766                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.54288\teval-rmse:2.0826                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.52677\teval-rmse:2.09988                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.51239\teval-rmse:2.10425                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.49767\teval-rmse:2.12657                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.48754\teval-rmse:2.12742                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.47235\teval-rmse:2.13429                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.45356\teval-rmse:2.144                                                                                \n",
      "\n",
      "[22]\ttrain-rmse:2.43576\teval-rmse:2.15242                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.42453\teval-rmse:2.15022                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.41692\teval-rmse:2.15561                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.40446\teval-rmse:2.16057                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.39738\teval-rmse:2.16176                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.69975\teval-rmse:2.06056\n",
      "\n",
      "\n",
      "loss: 97617013.67889924                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.02129457675742274, 'colsample_bytree': 0.75, 'gamma': 7.746852591973281e-05, 'lambda': 0.0013392372206686503, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 3.4075909147256835, 'n_estimators': 471.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.48137\teval-rmse:4.06033                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.70252\teval-rmse:3.27813                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.18543\teval-rmse:2.78365                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.84886\teval-rmse:2.50295                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.63267\teval-rmse:2.35923                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.49487\teval-rmse:2.26957                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.39359\teval-rmse:2.23382                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.32447\teval-rmse:2.21264                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.26902\teval-rmse:2.20673                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.22856\teval-rmse:2.19218                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.18042\teval-rmse:2.19898                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.15801\teval-rmse:2.20347                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.13543\teval-rmse:2.20137                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.09938\teval-rmse:2.21659                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.08874\teval-rmse:2.22864                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.05783\teval-rmse:2.24713                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.03819\teval-rmse:2.2709                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.00563\teval-rmse:2.27381                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.99829\teval-rmse:2.26981                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.98268\teval-rmse:2.26871                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.96662\teval-rmse:2.272                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:1.95104\teval-rmse:2.26973                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.91987\teval-rmse:2.27197                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.91109\teval-rmse:2.27397                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.89986\teval-rmse:2.27924                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.87747\teval-rmse:2.28072                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.85524\teval-rmse:2.28685                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.83791\teval-rmse:2.28315                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.8119\teval-rmse:2.29391                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:1.78872\teval-rmse:2.30378                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.22856\teval-rmse:2.19218\n",
      "\n",
      "\n",
      "loss: 96810209.88665387                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.9596204293322365e-05, 'colsample_bytree': 0.8, 'gamma': 1.3928148598745187e-05, 'lambda': 8.07996397920146e-06, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 5.188815292105516, 'n_estimators': 537.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.29416\teval-rmse:3.85777                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.48615\teval-rmse:3.02186                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.00704\teval-rmse:2.56985                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.73663\teval-rmse:2.33203                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.57927\teval-rmse:2.24072                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.47201\teval-rmse:2.18886                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.39282\teval-rmse:2.16558                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.35826\teval-rmse:2.16073                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.32449\teval-rmse:2.16962                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.27661\teval-rmse:2.1808                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.2308\teval-rmse:2.18948                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.21788\teval-rmse:2.19486                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.19767\teval-rmse:2.20776                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.16838\teval-rmse:2.19823                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.1474\teval-rmse:2.20149                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.12589\teval-rmse:2.20866                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.10316\teval-rmse:2.21328                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.07069\teval-rmse:2.23245                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.03588\teval-rmse:2.25085                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.01164\teval-rmse:2.25217                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.99711\teval-rmse:2.24788                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.97568\teval-rmse:2.25983                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.95205\teval-rmse:2.26306                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.94142\teval-rmse:2.26499                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.93288\teval-rmse:2.27233                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.91486\teval-rmse:2.27753                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.89768\teval-rmse:2.27235                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.88718\teval-rmse:2.2671                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.35826\teval-rmse:2.16073\n",
      "\n",
      "\n",
      "loss: 103972739.332461                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.9001811453804583e-06, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.0002105725712420021, 'lambda': 0.008094717843985617, 'learning_rate': 0.375, 'max_depth': 5, 'min_child_weight': 3.060024455196886, 'n_estimators': 583.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.20949\teval-rmse:3.64674                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.46766\teval-rmse:2.77965                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.09987\teval-rmse:2.3595                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.92398\teval-rmse:2.18055                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.83433\teval-rmse:2.08521                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.78662\teval-rmse:2.05343                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.75372\teval-rmse:2.04321                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.7376\teval-rmse:2.04207                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.71769\teval-rmse:2.04785                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.69981\teval-rmse:2.046                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.68835\teval-rmse:2.04104                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.6752\teval-rmse:2.04538                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.66498\teval-rmse:2.06249                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.65099\teval-rmse:2.0688                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.64385\teval-rmse:2.06997                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.63633\teval-rmse:2.09951                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.61969\teval-rmse:2.1002                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.60711\teval-rmse:2.09694                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.59758\teval-rmse:2.09963                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.5894\teval-rmse:2.10476                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.5833\teval-rmse:2.10835                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.57299\teval-rmse:2.1023                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.56117\teval-rmse:2.11341                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.5488\teval-rmse:2.11209                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.54216\teval-rmse:2.1266                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.5336\teval-rmse:2.12603                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.52623\teval-rmse:2.12676                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.51518\teval-rmse:2.13425                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.51039\teval-rmse:2.12421                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.50401\teval-rmse:2.12324                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.49914\teval-rmse:2.12208                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.68835\teval-rmse:2.04104\n",
      "\n",
      "\n",
      "loss: 99150996.56141941                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.013227485315624078, 'colsample_bytree': 0.65, 'gamma': 3.051714779919901e-07, 'lambda': 0.012678834290054494, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 0.7044143939051278, 'n_estimators': 409.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.58713\teval-rmse:4.15614                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.84189\teval-rmse:3.41147                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.33174\teval-rmse:2.90312                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.98056\teval-rmse:2.57994                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.72566\teval-rmse:2.39619                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.56707\teval-rmse:2.2682                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.44994\teval-rmse:2.2157                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.36499\teval-rmse:2.18015                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.30423\teval-rmse:2.16226                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.25935\teval-rmse:2.15111                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.21844\teval-rmse:2.15473                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.17987\teval-rmse:2.15491                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.15654\teval-rmse:2.15755                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.11262\teval-rmse:2.16686                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.08299\teval-rmse:2.17488                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.05499\teval-rmse:2.20138                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.02839\teval-rmse:2.21597                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.99691\teval-rmse:2.21032                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.96066\teval-rmse:2.20962                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.91778\teval-rmse:2.22385                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.89799\teval-rmse:2.23053                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.87774\teval-rmse:2.23815                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.85801\teval-rmse:2.24943                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.84397\teval-rmse:2.2463                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.82212\teval-rmse:2.24887                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.81262\teval-rmse:2.24744                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.79395\teval-rmse:2.25233                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.77404\teval-rmse:2.26117                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.74907\teval-rmse:2.26253                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.73765\teval-rmse:2.26838                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.25935\teval-rmse:2.15111\n",
      "\n",
      "\n",
      "loss: 96988231.12539041                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.493069166763895e-05, 'colsample_bytree': 0.75, 'gamma': 5.735788120855489e-08, 'lambda': 0.0005039739297763827, 'learning_rate': 0.225, 'max_depth': 3, 'min_child_weight': 2.618031295778391, 'n_estimators': 826.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.78522\teval-rmse:4.27184                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.17774\teval-rmse:3.56174                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.7552\teval-rmse:3.05537                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.46393\teval-rmse:2.70625                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.2739\teval-rmse:2.47109                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.14138\teval-rmse:2.31562                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.0585\teval-rmse:2.22149                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.00366\teval-rmse:2.16681                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.96478\teval-rmse:2.12798                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.9392\teval-rmse:2.10729                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.92034\teval-rmse:2.09524                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.90522\teval-rmse:2.08363                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.89468\teval-rmse:2.07586                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.88445\teval-rmse:2.06851                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.87123\teval-rmse:2.06425                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.86502\teval-rmse:2.0641                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.85754\teval-rmse:2.06498                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.85056\teval-rmse:2.06341                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.8466\teval-rmse:2.06202                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.84089\teval-rmse:2.06042                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.8379\teval-rmse:2.06211                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.83397\teval-rmse:2.05844                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.83032\teval-rmse:2.06093                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.82788\teval-rmse:2.06036                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.82599\teval-rmse:2.05864                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.82257\teval-rmse:2.05892                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.81909\teval-rmse:2.05992                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.81595\teval-rmse:2.06038                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.81371\teval-rmse:2.06271                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.81087\teval-rmse:2.06245                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.80806\teval-rmse:2.06576                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.80507\teval-rmse:2.06514                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.80234\teval-rmse:2.06411                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.79991\teval-rmse:2.06112                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.79698\teval-rmse:2.06981                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.7927\teval-rmse:2.07482                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.79046\teval-rmse:2.07548                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.78621\teval-rmse:2.06807                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.78386\teval-rmse:2.06752                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.78114\teval-rmse:2.06721                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.77808\teval-rmse:2.06362                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.77697\teval-rmse:2.0636                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[21]\ttrain-rmse:2.83397\teval-rmse:2.05844\n",
      "\n",
      "\n",
      "loss: 98850489.18247783                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0019642604174344826, 'colsample_bytree': 0.75, 'gamma': 0.00994763881522369, 'lambda': 2.4187100470021012, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 1.0282308617686116, 'n_estimators': 343.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.39635\teval-rmse:3.96133                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.59678\teval-rmse:3.13758                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.09306\teval-rmse:2.6542                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.78137\teval-rmse:2.39575                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.59543\teval-rmse:2.2527                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.47227\teval-rmse:2.17953                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.3653\teval-rmse:2.1471                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:2.29839\teval-rmse:2.14264                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.2499\teval-rmse:2.13633                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.2199\teval-rmse:2.13243                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.17066\teval-rmse:2.13655                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.14588\teval-rmse:2.1406                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.0944\teval-rmse:2.15462                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.07754\teval-rmse:2.1559                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.05701\teval-rmse:2.16054                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.03674\teval-rmse:2.17308                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.0054\teval-rmse:2.18859                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:1.97445\teval-rmse:2.19195                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.95393\teval-rmse:2.19474                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.92303\teval-rmse:2.19933                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.90121\teval-rmse:2.20481                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.87098\teval-rmse:2.22289                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.85353\teval-rmse:2.2321                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.81334\teval-rmse:2.23915                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.77832\teval-rmse:2.2473                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.7676\teval-rmse:2.25197                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.75206\teval-rmse:2.25351                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.74347\teval-rmse:2.25313                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.72394\teval-rmse:2.25191                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.717\teval-rmse:2.26122                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.2199\teval-rmse:2.13243\n",
      "\n",
      "\n",
      "loss: 96978950.66448623                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.049530892702719286, 'colsample_bytree': 0.8, 'gamma': 0.004904986059817188, 'lambda': 0.02958094713648336, 'learning_rate': 0.42500000000000004, 'max_depth': 7, 'min_child_weight': 1.2653595194116134, 'n_estimators': 551.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:3.96854\teval-rmse:3.46185                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.19534\teval-rmse:2.60652                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.84555\teval-rmse:2.2605                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.68546\teval-rmse:2.15829                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.60633\teval-rmse:2.13672                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.56167\teval-rmse:2.12096                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.52316\teval-rmse:2.12359                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.4977\teval-rmse:2.13959                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.4697\teval-rmse:2.16075                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.44308\teval-rmse:2.16722                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:2.41438\teval-rmse:2.17052                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.38409\teval-rmse:2.18229                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.36403\teval-rmse:2.18582                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.33808\teval-rmse:2.184                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:2.32913\teval-rmse:2.18228                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.28974\teval-rmse:2.21214                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.27295\teval-rmse:2.26191                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.24317\teval-rmse:2.26343                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.21543\teval-rmse:2.27189                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.19269\teval-rmse:2.27665                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.18266\teval-rmse:2.28858                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.16776\teval-rmse:2.29156                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.13912\teval-rmse:2.30749                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.12816\teval-rmse:2.30674                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.10959\teval-rmse:2.31534                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.10332\teval-rmse:2.31765                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.56167\teval-rmse:2.12096\n",
      "\n",
      "\n",
      "loss: 97511775.19318663                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0012381623395995099, 'colsample_bytree': 0.9500000000000001, 'gamma': 3.0437111108514255e-05, 'lambda': 0.0047151147551134035, 'learning_rate': 0.325, 'max_depth': 8, 'min_child_weight': 0.3695980718351249, 'n_estimators': 617.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.30032\teval-rmse:3.85484                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.49309\teval-rmse:3.00875                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.01903\teval-rmse:2.54112                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.76222\teval-rmse:2.30482                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.60296\teval-rmse:2.20226                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.51241\teval-rmse:2.14437                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.45125\teval-rmse:2.13546                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.38649\teval-rmse:2.1246                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.35094\teval-rmse:2.13067                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.31325\teval-rmse:2.13546                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.28772\teval-rmse:2.14225                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.26069\teval-rmse:2.14906                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.23424\teval-rmse:2.18512                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.20392\teval-rmse:2.19744                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.19062\teval-rmse:2.19199                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.16202\teval-rmse:2.20641                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.14562\teval-rmse:2.20758                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.1154\teval-rmse:2.2186                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:2.08968\teval-rmse:2.22655                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.07311\teval-rmse:2.22256                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.05678\teval-rmse:2.23569                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.02676\teval-rmse:2.24138                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.01455\teval-rmse:2.24539                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.00444\teval-rmse:2.27258                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.9974\teval-rmse:2.28783                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.99012\teval-rmse:2.28743                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.9707\teval-rmse:2.29553                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.95429\teval-rmse:2.31125                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.38649\teval-rmse:2.1246\n",
      "\n",
      "\n",
      "loss: 96903538.89500077                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0038083455928453985, 'colsample_bytree': 0.6000000000000001, 'gamma': 6.105646947848523e-07, 'lambda': 8.302590294452046e-05, 'learning_rate': 0.4, 'max_depth': 4, 'min_child_weight': 0.5358107677913919, 'n_estimators': 670.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.14849\teval-rmse:3.55133                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.43015\teval-rmse:2.70077                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.10685\teval-rmse:2.32314                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.9646\teval-rmse:2.1865                                                                                 \n",
      "\n",
      "[4]\ttrain-rmse:2.90451\teval-rmse:2.12165                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.87\teval-rmse:2.10169                                                                                  \n",
      "\n",
      "[6]\ttrain-rmse:2.84645\teval-rmse:2.09667                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.82742\teval-rmse:2.09385                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.81105\teval-rmse:2.09273                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.79921\teval-rmse:2.08643                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.78905\teval-rmse:2.0901                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.77574\teval-rmse:2.08294                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.76902\teval-rmse:2.07714                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.76044\teval-rmse:2.08835                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.75821\teval-rmse:2.09091                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.75091\teval-rmse:2.12111                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.74295\teval-rmse:2.12148                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.736\teval-rmse:2.12048                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:2.73104\teval-rmse:2.12139                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.72527\teval-rmse:2.13114                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.71658\teval-rmse:2.11117                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.71429\teval-rmse:2.10929                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.70844\teval-rmse:2.13314                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.70424\teval-rmse:2.13599                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.6986\teval-rmse:2.13503                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.69413\teval-rmse:2.14408                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.686\teval-rmse:2.15057                                                                                \n",
      "\n",
      "[27]\ttrain-rmse:2.67596\teval-rmse:2.15509                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.66975\teval-rmse:2.15141                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.66341\teval-rmse:2.15012                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.65821\teval-rmse:2.14677                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.65276\teval-rmse:2.151                                                                                \n",
      "\n",
      "[32]\ttrain-rmse:2.64405\teval-rmse:2.15176                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.76902\teval-rmse:2.07714\n",
      "\n",
      "\n",
      "loss: 99309125.76161528                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.186661623528935e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 2.6901329871575708e-06, 'lambda': 0.00015788982397048644, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 1.6598552188233824, 'n_estimators': 314.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.48215\teval-rmse:4.06139                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.69255\teval-rmse:3.25789                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.16798\teval-rmse:2.7672                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.82625\teval-rmse:2.47485                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.61049\teval-rmse:2.3131                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.45271\teval-rmse:2.23703                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.35241\teval-rmse:2.1874                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.27191\teval-rmse:2.1703                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.21053\teval-rmse:2.16239                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.18829\teval-rmse:2.15323                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.16396\teval-rmse:2.20719                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.12702\teval-rmse:2.20866                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.09764\teval-rmse:2.20237                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.07433\teval-rmse:2.20159                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.03313\teval-rmse:2.2128                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.00069\teval-rmse:2.21023                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.95209\teval-rmse:2.21107                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.91317\teval-rmse:2.20552                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.88685\teval-rmse:2.2189                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.86864\teval-rmse:2.20994                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.82677\teval-rmse:2.21382                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.81202\teval-rmse:2.22841                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.78437\teval-rmse:2.24091                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.77302\teval-rmse:2.24198                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.7532\teval-rmse:2.23604                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.73542\teval-rmse:2.23645                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.7008\teval-rmse:2.2398                                                                                \n",
      "\n",
      "[27]\ttrain-rmse:1.68658\teval-rmse:2.23733                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.67949\teval-rmse:2.23469                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.656\teval-rmse:2.24714                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.18829\teval-rmse:2.15323\n",
      "\n",
      "\n",
      "loss: 96977158.80828652                                                                                                \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.00947449269798399, 'colsample_bytree': 0.8, 'gamma': 9.21249287516547e-06, 'lambda': 0.003106188153901637, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 0.6285141901951591, 'n_estimators': 283.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.58097\teval-rmse:4.17144                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.84127\teval-rmse:3.42145                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.31833\teval-rmse:2.91866                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.97011\teval-rmse:2.59787                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.73569\teval-rmse:2.40807                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.57479\teval-rmse:2.30277                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.45562\teval-rmse:2.24517                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.38108\teval-rmse:2.21012                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.32053\teval-rmse:2.21107                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.28576\teval-rmse:2.19789                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.23811\teval-rmse:2.22182                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.1928\teval-rmse:2.24691                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.16792\teval-rmse:2.26466                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.12436\teval-rmse:2.30666                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.10241\teval-rmse:2.31663                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.08001\teval-rmse:2.31544                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.06021\teval-rmse:2.31549                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.0278\teval-rmse:2.315                                                                                 \n",
      "\n",
      "[18]\ttrain-rmse:2.00953\teval-rmse:2.31479                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.98707\teval-rmse:2.33402                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.97332\teval-rmse:2.3404                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.94839\teval-rmse:2.36083                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.93072\teval-rmse:2.37401                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.90834\teval-rmse:2.37855                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.89479\teval-rmse:2.38243                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.87061\teval-rmse:2.39561                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.85672\teval-rmse:2.39438                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.83479\teval-rmse:2.39323                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.82803\teval-rmse:2.39855                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.81777\teval-rmse:2.39866                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.28576\teval-rmse:2.19789\n",
      "\n",
      "\n",
      "loss: 96793624.63263433                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00027919032892392376, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.05803930663724677, 'lambda': 4.554847598428583e-06, 'learning_rate': 0.17500000000000002, 'max_depth': 6, 'min_child_weight': 6.133836392849514, 'n_estimators': 492.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.93155\teval-rmse:4.47476                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.37502\teval-rmse:3.86469                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.94298\teval-rmse:3.38375                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.61363\teval-rmse:3.01636                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.36911\teval-rmse:2.74275                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.18163\teval-rmse:2.53605                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.04428\teval-rmse:2.3872                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.94326\teval-rmse:2.2797                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.86103\teval-rmse:2.19992                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.80788\teval-rmse:2.14686                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.76592\teval-rmse:2.11272                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.733\teval-rmse:2.08482                                                                                \n",
      "\n",
      "[12]\ttrain-rmse:2.7022\teval-rmse:2.06964                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.67511\teval-rmse:2.07176                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.65457\teval-rmse:2.06852                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.63841\teval-rmse:2.06283                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.61908\teval-rmse:2.06233                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.6031\teval-rmse:2.05802                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.58723\teval-rmse:2.06117                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.58022\teval-rmse:2.06471                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.57008\teval-rmse:2.06246                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.55911\teval-rmse:2.06683                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.55169\teval-rmse:2.06615                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.54059\teval-rmse:2.06623                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.53587\teval-rmse:2.06841                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.53194\teval-rmse:2.06932                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.52616\teval-rmse:2.07681                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.51414\teval-rmse:2.07652                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.50889\teval-rmse:2.07817                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.49895\teval-rmse:2.08186                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.49337\teval-rmse:2.0828                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.48773\teval-rmse:2.08661                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.48152\teval-rmse:2.0903                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.46735\teval-rmse:2.09749                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.46434\teval-rmse:2.09804                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.45563\teval-rmse:2.10072                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.45133\teval-rmse:2.10121                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.44493\teval-rmse:2.10353                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:2.6031\teval-rmse:2.05802\n",
      "\n",
      "\n",
      "loss: 97819915.61419262                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.6601841550647065, 'colsample_bytree': 0.75, 'gamma': 0.0001274561053790251, 'lambda': 2.3539317942376172e-05, 'learning_rate': 0.35000000000000003, 'max_depth': 9, 'min_child_weight': 0.1893898944084797, 'n_estimators': 510.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.18568\teval-rmse:3.76389                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.34062\teval-rmse:2.93249                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.86511\teval-rmse:2.51797                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.58098\teval-rmse:2.33142                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.42178\teval-rmse:2.24354                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.3021\teval-rmse:2.18683                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.24627\teval-rmse:2.19233                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.21228\teval-rmse:2.19587                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.16595\teval-rmse:2.2077                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.13388\teval-rmse:2.23617                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.1047\teval-rmse:2.23306                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.06787\teval-rmse:2.23251                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.01951\teval-rmse:2.22969                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.99011\teval-rmse:2.2359                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:1.9706\teval-rmse:2.23967                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:1.94727\teval-rmse:2.23347                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.93472\teval-rmse:2.24246                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.89228\teval-rmse:2.23879                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.86612\teval-rmse:2.25078                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.8443\teval-rmse:2.26121                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.82713\teval-rmse:2.2561                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.80436\teval-rmse:2.26374                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.77886\teval-rmse:2.27598                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.73724\teval-rmse:2.3169                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.72412\teval-rmse:2.31773                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.69001\teval-rmse:2.32414                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.3021\teval-rmse:2.18683\n",
      "\n",
      "\n",
      "loss: 96365623.95773037                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.2320277566076196e-06, 'colsample_bytree': 0.8, 'gamma': 0.00028434570808896157, 'lambda': 1.4828169246905042e-06, 'learning_rate': 0.47500000000000003, 'max_depth': 5, 'min_child_weight': 0.14498005056696495, 'n_estimators': 165.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:3.87155\teval-rmse:3.26095                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.18254\teval-rmse:2.46058                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.9283\teval-rmse:2.19059                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.82064\teval-rmse:2.14485                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.77473\teval-rmse:2.14795                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.74738\teval-rmse:2.14785                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.72711\teval-rmse:2.13287                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.71406\teval-rmse:2.13722                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.69978\teval-rmse:2.13527                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.68597\teval-rmse:2.13708                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.67535\teval-rmse:2.15044                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.6674\teval-rmse:2.14637                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.65697\teval-rmse:2.14201                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\ttrain-rmse:2.64264\teval-rmse:2.17252                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.62884\teval-rmse:2.17357                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.61841\teval-rmse:2.18067                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.61441\teval-rmse:2.17642                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.60897\teval-rmse:2.17791                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.5919\teval-rmse:2.17829                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.58282\teval-rmse:2.18253                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.57682\teval-rmse:2.19764                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.56495\teval-rmse:2.1908                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.55794\teval-rmse:2.19883                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.54821\teval-rmse:2.20025                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.54006\teval-rmse:2.20748                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.53183\teval-rmse:2.2048                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.52449\teval-rmse:2.21269                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.72711\teval-rmse:2.13287\n",
      "\n",
      "\n",
      "loss: 100941901.51667798                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.408539514965506e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.0012420016581917682, 'lambda': 1.1664848828090412e-05, 'learning_rate': 0.4, 'max_depth': 9, 'min_child_weight': 0.22012241670584148, 'n_estimators': 246.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:3.98001\teval-rmse:3.5666                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.12096\teval-rmse:2.71029                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.69527\teval-rmse:2.34594                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.4703\teval-rmse:2.2161                                                                                 \n",
      "\n",
      "[4]\ttrain-rmse:2.35042\teval-rmse:2.19141                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.27003\teval-rmse:2.22528                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.21385\teval-rmse:2.23373                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.16074\teval-rmse:2.23504                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.12506\teval-rmse:2.2387                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.07518\teval-rmse:2.26245                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.03735\teval-rmse:2.27029                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.00274\teval-rmse:2.2627                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:1.96386\teval-rmse:2.29478                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.9335\teval-rmse:2.31321                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:1.91409\teval-rmse:2.30411                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.89386\teval-rmse:2.30011                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.86047\teval-rmse:2.3138                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:1.82588\teval-rmse:2.32136                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.78905\teval-rmse:2.33845                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.76566\teval-rmse:2.3662                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.72316\teval-rmse:2.41916                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.69069\teval-rmse:2.4505                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.66282\teval-rmse:2.45051                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.64326\teval-rmse:2.43201                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.63106\teval-rmse:2.43608                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.35042\teval-rmse:2.19141\n",
      "\n",
      "\n",
      "loss: 98292847.68922937                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.100693526100673e-07, 'colsample_bytree': 0.75, 'gamma': 0.0035838620435637816, 'lambda': 3.535867260503627e-06, 'learning_rate': 0.45, 'max_depth': 3, 'min_child_weight': 0.17204941709255248, 'n_estimators': 131.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.01955\teval-rmse:3.37189                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.354\teval-rmse:2.55939                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:3.08551\teval-rmse:2.23757                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.98057\teval-rmse:2.13137                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.93678\teval-rmse:2.10159                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.91146\teval-rmse:2.096                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:2.8959\teval-rmse:2.09449                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.88\teval-rmse:2.10326                                                                                  \n",
      "\n",
      "[8]\ttrain-rmse:2.87257\teval-rmse:2.10059                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.86041\teval-rmse:2.09639                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.85261\teval-rmse:2.10054                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.84796\teval-rmse:2.09967                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.83894\teval-rmse:2.09996                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.83216\teval-rmse:2.10312                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.82846\teval-rmse:2.10847                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.82116\teval-rmse:2.12464                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.81387\teval-rmse:2.12142                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.80984\teval-rmse:2.12148                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.80561\teval-rmse:2.12342                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.79999\teval-rmse:2.13558                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.79239\teval-rmse:2.13746                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.7843\teval-rmse:2.13013                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.78039\teval-rmse:2.13434                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.77395\teval-rmse:2.12791                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.76854\teval-rmse:2.13316                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.76509\teval-rmse:2.13436                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.76341\teval-rmse:2.13446                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.8959\teval-rmse:2.09449\n",
      "\n",
      "\n",
      "loss: 509655525.3867307                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.617317301526076, 'colsample_bytree': 0.8, 'gamma': 0.0007909015757232262, 'lambda': 2.1371020157479306e-05, 'learning_rate': 0.42500000000000004, 'max_depth': 9, 'min_child_weight': 0.10995785349579638, 'n_estimators': 101.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:3.89145\teval-rmse:3.47978                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.0459\teval-rmse:2.65269                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.65053\teval-rmse:2.31874                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.43239\teval-rmse:2.23532                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.33498\teval-rmse:2.20562                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.26189\teval-rmse:2.23013                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.21452\teval-rmse:2.2573                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.18126\teval-rmse:2.27093                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.13183\teval-rmse:2.30276                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.08924\teval-rmse:2.33236                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.02624\teval-rmse:2.3399                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.01008\teval-rmse:2.33186                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.97249\teval-rmse:2.35275                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.94085\teval-rmse:2.35697                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.91525\teval-rmse:2.36113                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.90127\teval-rmse:2.37582                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.87831\teval-rmse:2.3692                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:1.84091\teval-rmse:2.36979                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.7968\teval-rmse:2.372                                                                                 \n",
      "\n",
      "[19]\ttrain-rmse:1.7639\teval-rmse:2.41232                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.74768\teval-rmse:2.41834                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.68117\teval-rmse:2.44646                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.65852\teval-rmse:2.46157                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.62957\teval-rmse:2.46267                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.59772\teval-rmse:2.46358                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.33498\teval-rmse:2.20562\n",
      "\n",
      "\n",
      "loss: 105331393.66630411                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.627507856846771e-07, 'colsample_bytree': 0.75, 'gamma': 0.00014121125385822673, 'lambda': 6.998941299713655e-06, 'learning_rate': 0.375, 'max_depth': 7, 'min_child_weight': 0.30387216329674477, 'n_estimators': 225.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.14416\teval-rmse:3.65436                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.35742\teval-rmse:2.79591                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.96017\teval-rmse:2.40461                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.76648\teval-rmse:2.22221                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.6556\teval-rmse:2.14274                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.59069\teval-rmse:2.11162                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.55265\teval-rmse:2.11002                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.51568\teval-rmse:2.13103                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.49127\teval-rmse:2.15392                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.47636\teval-rmse:2.16114                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.44712\teval-rmse:2.15928                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.41563\teval-rmse:2.16198                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.38371\teval-rmse:2.17062                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\ttrain-rmse:2.36627\teval-rmse:2.14345                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.34884\teval-rmse:2.15004                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.33638\teval-rmse:2.16655                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.32324\teval-rmse:2.17671                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.30214\teval-rmse:2.19402                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.27661\teval-rmse:2.21205                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.2562\teval-rmse:2.22439                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.24125\teval-rmse:2.22309                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.21107\teval-rmse:2.23185                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.19933\teval-rmse:2.23666                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.17929\teval-rmse:2.24483                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.16875\teval-rmse:2.25039                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.16536\teval-rmse:2.25262                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.14389\teval-rmse:2.24775                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.55265\teval-rmse:2.11002\n",
      "\n",
      "\n",
      "loss: 99020070.43041888                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.912119526862339e-06, 'colsample_bytree': 0.9, 'gamma': 0.0004482857584353225, 'lambda': 2.5145859683678918e-06, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 0.15699115515447687, 'n_estimators': 215.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.20601\teval-rmse:3.75712                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.38711\teval-rmse:2.91509                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.92922\teval-rmse:2.48469                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.68674\teval-rmse:2.27607                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.54237\teval-rmse:2.23594                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.46343\teval-rmse:2.22514                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.40004\teval-rmse:2.21414                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.34808\teval-rmse:2.21548                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.29482\teval-rmse:2.21781                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.25751\teval-rmse:2.21988                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.22286\teval-rmse:2.24475                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.19417\teval-rmse:2.24205                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.16282\teval-rmse:2.25119                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.13185\teval-rmse:2.26113                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.10281\teval-rmse:2.26194                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.08562\teval-rmse:2.28526                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.06011\teval-rmse:2.32779                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.04159\teval-rmse:2.34326                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.02112\teval-rmse:2.35692                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.00144\teval-rmse:2.37484                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.98529\teval-rmse:2.37811                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.95221\teval-rmse:2.38276                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.92951\teval-rmse:2.41143                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.9214\teval-rmse:2.38313                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.89492\teval-rmse:2.38412                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.88899\teval-rmse:2.37959                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.87962\teval-rmse:2.37674                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.40004\teval-rmse:2.21414\n",
      "\n",
      "\n",
      "loss: 97093148.6654453                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.1220007251493336e-07, 'colsample_bytree': 0.8, 'gamma': 0.2914441590479368, 'lambda': 5.89505856045787e-06, 'learning_rate': 0.375, 'max_depth': 9, 'min_child_weight': 0.24119496750903044, 'n_estimators': 366.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.07915\teval-rmse:3.66686                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.22105\teval-rmse:2.81697                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.76801\teval-rmse:2.40696                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.51966\teval-rmse:2.23461                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.38637\teval-rmse:2.16941                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.29919\teval-rmse:2.14165                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.26473\teval-rmse:2.13425                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.21998\teval-rmse:2.15697                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.19127\teval-rmse:2.19087                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.14209\teval-rmse:2.2363                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.09587\teval-rmse:2.26574                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.07911\teval-rmse:2.28609                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.03881\teval-rmse:2.28465                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.00798\teval-rmse:2.24315                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.96699\teval-rmse:2.28845                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.95367\teval-rmse:2.30051                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.93383\teval-rmse:2.31614                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.87737\teval-rmse:2.32442                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.86458\teval-rmse:2.32164                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.84867\teval-rmse:2.3463                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.82437\teval-rmse:2.32098                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.79369\teval-rmse:2.34879                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.77158\teval-rmse:2.35911                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.72967\teval-rmse:2.36226                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.69768\teval-rmse:2.37271                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.69054\teval-rmse:2.38083                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.66783\teval-rmse:2.39654                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.26473\teval-rmse:2.13425\n",
      "\n",
      "\n",
      "loss: 104955697.22171377                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.21159258025202665, 'colsample_bytree': 0.75, 'gamma': 0.007801737947758578, 'lambda': 2.2639724064657344e-05, 'learning_rate': 0.325, 'max_depth': 4, 'min_child_weight': 0.19865091138388005, 'n_estimators': 390.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.404\teval-rmse:3.84505                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.6916\teval-rmse:3.00548                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.28612\teval-rmse:2.53729                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.07128\teval-rmse:2.2986                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.96026\teval-rmse:2.18418                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.89828\teval-rmse:2.12378                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.86428\teval-rmse:2.09018                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.84239\teval-rmse:2.07914                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.81929\teval-rmse:2.064                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:2.80605\teval-rmse:2.06968                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.79085\teval-rmse:2.07073                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.782\teval-rmse:2.06481                                                                                \n",
      "\n",
      "[12]\ttrain-rmse:2.7738\teval-rmse:2.06064                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.76782\teval-rmse:2.06043                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.76385\teval-rmse:2.05944                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.75691\teval-rmse:2.05592                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.74736\teval-rmse:2.06571                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.7416\teval-rmse:2.06002                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.73733\teval-rmse:2.05989                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.72836\teval-rmse:2.06242                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.71981\teval-rmse:2.07068                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.71144\teval-rmse:2.06915                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.70491\teval-rmse:2.06516                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.69538\teval-rmse:2.06162                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.69169\teval-rmse:2.06165                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.68645\teval-rmse:2.06685                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.67798\teval-rmse:2.10749                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.66923\teval-rmse:2.11557                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.66529\teval-rmse:2.1157                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.65522\teval-rmse:2.11073                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.65125\teval-rmse:2.10951                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.6472\teval-rmse:2.10957                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.64216\teval-rmse:2.11156                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.63265\teval-rmse:2.1202                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:2.627\teval-rmse:2.1271                                                                                 \n",
      "\n",
      "[35]\ttrain-rmse:2.62226\teval-rmse:2.12309                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.75691\teval-rmse:2.05592\n",
      "\n",
      "\n",
      "loss: 98366715.01143081                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.845759754233215, 'colsample_bytree': 0.8500000000000001, 'gamma': 8.20208796844956e-05, 'lambda': 4.598111278288266e-06, 'learning_rate': 0.5, 'max_depth': 9, 'min_child_weight': 0.13229586361725987, 'n_estimators': 317.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:3.62531\teval-rmse:3.22838                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:2.81666\teval-rmse:2.46409                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.49557\teval-rmse:2.28777                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.32319\teval-rmse:2.32295                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.23396\teval-rmse:2.33153                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.19604\teval-rmse:2.34391                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.15\teval-rmse:2.38279                                                                                  \n",
      "\n",
      "[7]\ttrain-rmse:2.09018\teval-rmse:2.40257                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.04181\teval-rmse:2.53715                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:1.96748\teval-rmse:2.54607                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:1.93169\teval-rmse:2.54277                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:1.90276\teval-rmse:2.55977                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.85249\teval-rmse:2.55316                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.81577\teval-rmse:2.52471                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.76211\teval-rmse:2.55097                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.71345\teval-rmse:2.57198                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.69765\teval-rmse:2.52457                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.65725\teval-rmse:2.51759                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.62913\teval-rmse:2.51585                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.57982\teval-rmse:2.55134                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.56221\teval-rmse:2.55828                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.53098\teval-rmse:2.58888                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.50639\teval-rmse:2.61115                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[2]\ttrain-rmse:2.49557\teval-rmse:2.28777\n",
      "\n",
      "\n",
      "loss: 135708440.8611241                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.873322268600806e-06, 'colsample_bytree': 0.8, 'gamma': 0.002504688228554234, 'lambda': 3.0907021828538545e-06, 'learning_rate': 0.325, 'max_depth': 6, 'min_child_weight': 0.41150219625674817, 'n_estimators': 147.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.35376\teval-rmse:3.84524                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.60122\teval-rmse:2.99996                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.17358\teval-rmse:2.53809                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.94186\teval-rmse:2.29687                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.81766\teval-rmse:2.19572                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.73733\teval-rmse:2.13221                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.69708\teval-rmse:2.10476                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.66463\teval-rmse:2.12627                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.6293\teval-rmse:2.12019                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.60967\teval-rmse:2.12262                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.58964\teval-rmse:2.12694                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.57499\teval-rmse:2.12396                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.55633\teval-rmse:2.14806                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.54375\teval-rmse:2.18849                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.52972\teval-rmse:2.20217                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.51929\teval-rmse:2.2054                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.50655\teval-rmse:2.22641                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.48617\teval-rmse:2.219                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:2.46386\teval-rmse:2.22166                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.4509\teval-rmse:2.23167                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.43385\teval-rmse:2.23278                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.42188\teval-rmse:2.23671                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.41016\teval-rmse:2.23467                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.39327\teval-rmse:2.23667                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.37654\teval-rmse:2.24524                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.36513\teval-rmse:2.24393                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.3558\teval-rmse:2.24039                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.69708\teval-rmse:2.10476\n",
      "\n",
      "\n",
      "loss: 97954781.59807852                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.935224763614906e-08, 'colsample_bytree': 0.75, 'gamma': 9.053703051615059e-08, 'lambda': 4.363518902046154e-05, 'learning_rate': 0.35000000000000003, 'max_depth': 9, 'min_child_weight': 0.19083524034324184, 'n_estimators': 201.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.18505\teval-rmse:3.76309                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.33989\teval-rmse:2.93228                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.86077\teval-rmse:2.53523                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.58262\teval-rmse:2.33357                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.41789\teval-rmse:2.25895                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.2996\teval-rmse:2.25089                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.23459\teval-rmse:2.24658                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.18562\teval-rmse:2.24109                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.15313\teval-rmse:2.24385                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.11685\teval-rmse:2.2407                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.07634\teval-rmse:2.24637                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.03464\teval-rmse:2.26214                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.99401\teval-rmse:2.2676                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:1.96388\teval-rmse:2.27783                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.94605\teval-rmse:2.27029                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.9075\teval-rmse:2.27774                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:1.89215\teval-rmse:2.27658                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.87511\teval-rmse:2.28866                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.85558\teval-rmse:2.28347                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.83907\teval-rmse:2.29976                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.82127\teval-rmse:2.30568                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.79295\teval-rmse:2.30274                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.76099\teval-rmse:2.30768                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.71495\teval-rmse:2.31484                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.70325\teval-rmse:2.33316                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.68094\teval-rmse:2.33362                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.65071\teval-rmse:2.3385                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.62946\teval-rmse:2.34484                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.6039\teval-rmse:2.38351                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:1.59321\teval-rmse:2.38646                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.11685\teval-rmse:2.2407\n",
      "\n",
      "\n",
      "loss: 96811358.92718071                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.435759883106457e-05, 'colsample_bytree': 0.75, 'gamma': 4.5437822696249e-05, 'lambda': 1.5733698927348526e-05, 'learning_rate': 0.4, 'max_depth': 9, 'min_child_weight': 0.28174246676436676, 'n_estimators': 264.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:3.98748\teval-rmse:3.57072                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.12848\teval-rmse:2.72404                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.70865\teval-rmse:2.36261                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.48605\teval-rmse:2.22394                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.37184\teval-rmse:2.21599                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.29997\teval-rmse:2.18799                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.24792\teval-rmse:2.22656                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.21353\teval-rmse:2.21474                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.17029\teval-rmse:2.24872                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.13537\teval-rmse:2.25487                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.09839\teval-rmse:2.26485                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.07365\teval-rmse:2.26549                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.06238\teval-rmse:2.26731                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.03573\teval-rmse:2.24224                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.00383\teval-rmse:2.24274                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.97066\teval-rmse:2.26032                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.95117\teval-rmse:2.28085                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.92285\teval-rmse:2.30478                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.89169\teval-rmse:2.32061                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.86119\teval-rmse:2.36237                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.84971\teval-rmse:2.37053                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.79282\teval-rmse:2.37226                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.75344\teval-rmse:2.3985                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.72207\teval-rmse:2.41511                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.69338\teval-rmse:2.40914                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.66591\teval-rmse:2.43493                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.29997\teval-rmse:2.18799\n",
      "\n",
      "\n",
      "loss: 96616611.42548797                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.9925117806613895e-06, 'colsample_bytree': 0.8, 'gamma': 0.00011827655955873765, 'lambda': 1.3218669930764953e-06, 'learning_rate': 0.375, 'max_depth': 5, 'min_child_weight': 0.2633037230805711, 'n_estimators': 344.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.20411\teval-rmse:3.64647                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.46835\teval-rmse:2.78678                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.10113\teval-rmse:2.36434                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.93083\teval-rmse:2.18352                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.83539\teval-rmse:2.10781                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.78481\teval-rmse:2.07389                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.75811\teval-rmse:2.06501                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.73305\teval-rmse:2.06249                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.71101\teval-rmse:2.07402                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.69831\teval-rmse:2.07762                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.6858\teval-rmse:2.07633                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.67208\teval-rmse:2.07334                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.65425\teval-rmse:2.07942                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.63831\teval-rmse:2.07948                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.63462\teval-rmse:2.07788                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.6232\teval-rmse:2.08893                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.60949\teval-rmse:2.09671                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.59654\teval-rmse:2.09431                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.58566\teval-rmse:2.09003                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.57765\teval-rmse:2.09734                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.56956\teval-rmse:2.10265                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.56199\teval-rmse:2.10522                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.55572\teval-rmse:2.10839                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.54414\teval-rmse:2.11482                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.54037\teval-rmse:2.12307                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.53327\teval-rmse:2.14751                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.52172\teval-rmse:2.15907                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.50799\teval-rmse:2.16444                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.73305\teval-rmse:2.06249\n",
      "\n",
      "\n",
      "loss: 97802476.86828151                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.3593195132062695e-08, 'colsample_bytree': 0.75, 'gamma': 2.1921470857540562e-05, 'lambda': 1.0689546468316242e-06, 'learning_rate': 0.30000000000000004, 'max_depth': 3, 'min_child_weight': 0.12553445143737393, 'n_estimators': 180.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.51614\teval-rmse:3.96088                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.83301\teval-rmse:3.15143                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.42746\teval-rmse:2.65722                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.19105\teval-rmse:2.37287                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.06349\teval-rmse:2.22796                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.98584\teval-rmse:2.14885                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.94661\teval-rmse:2.10677                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.92073\teval-rmse:2.08676                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.90252\teval-rmse:2.07822                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.89128\teval-rmse:2.07138                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.88034\teval-rmse:2.06486                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.86955\teval-rmse:2.05918                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.86109\teval-rmse:2.06771                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.85621\teval-rmse:2.06582                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.8519\teval-rmse:2.06625                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.84573\teval-rmse:2.06743                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.83977\teval-rmse:2.07063                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.83516\teval-rmse:2.07417                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.82843\teval-rmse:2.07257                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.82605\teval-rmse:2.07085                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.8199\teval-rmse:2.06856                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.81388\teval-rmse:2.06908                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.80854\teval-rmse:2.0681                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.80554\teval-rmse:2.0686                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.80134\teval-rmse:2.07615                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.7975\teval-rmse:2.07616                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.79416\teval-rmse:2.07472                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.78711\teval-rmse:2.08084                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.78466\teval-rmse:2.08265                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.77987\teval-rmse:2.08148                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.77779\teval-rmse:2.08351                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.77524\teval-rmse:2.08354                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.86955\teval-rmse:2.05918\n",
      "\n",
      "\n",
      "loss: 98345981.58603507                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00010398965847405308, 'colsample_bytree': 0.8, 'gamma': 1.823296492372347e-08, 'lambda': 3.1684489212778445e-05, 'learning_rate': 0.35000000000000003, 'max_depth': 9, 'min_child_weight': 0.7795222529646644, 'n_estimators': 445.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.17508\teval-rmse:3.76718                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.3285\teval-rmse:2.95711                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.85182\teval-rmse:2.54879                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.59324\teval-rmse:2.36712                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.42359\teval-rmse:2.28614                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.33387\teval-rmse:2.26058                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.26277\teval-rmse:2.28458                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.21743\teval-rmse:2.29146                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.18194\teval-rmse:2.28935                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.14014\teval-rmse:2.28947                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.0989\teval-rmse:2.30812                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.09122\teval-rmse:2.30926                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.0601\teval-rmse:2.30475                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.01712\teval-rmse:2.34274                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.98812\teval-rmse:2.35442                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.95468\teval-rmse:2.3699                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:1.92779\teval-rmse:2.37763                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.91027\teval-rmse:2.37195                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.87009\teval-rmse:2.38478                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.84154\teval-rmse:2.39106                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.81607\teval-rmse:2.41099                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.79352\teval-rmse:2.44083                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.78183\teval-rmse:2.44457                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.75866\teval-rmse:2.44809                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.74599\teval-rmse:2.45908                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.73361\teval-rmse:2.46313                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.33387\teval-rmse:2.26058\n",
      "\n",
      "\n",
      "loss: 29750229222.803493                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.6092228957750794e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.0250697361155948, 'lambda': 1.0573924013356035e-05, 'learning_rate': 0.42500000000000004, 'max_depth': 7, 'min_child_weight': 0.48700417790816486, 'n_estimators': 418.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:3.96412\teval-rmse:3.46631                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.19307\teval-rmse:2.62052                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.84523\teval-rmse:2.27703                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.68579\teval-rmse:2.17853                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.61693\teval-rmse:2.12922                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.56696\teval-rmse:2.10634                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.52414\teval-rmse:2.12761                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.50299\teval-rmse:2.16222                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.46809\teval-rmse:2.1886                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.43784\teval-rmse:2.21953                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.41846\teval-rmse:2.22734                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.39137\teval-rmse:2.288                                                                                \n",
      "\n",
      "[12]\ttrain-rmse:2.37041\teval-rmse:2.28315                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.35445\teval-rmse:2.31026                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.3256\teval-rmse:2.31731                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.29992\teval-rmse:2.33376                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.283\teval-rmse:2.31972                                                                                \n",
      "\n",
      "[17]\ttrain-rmse:2.24666\teval-rmse:2.31759                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.23171\teval-rmse:2.32735                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.20823\teval-rmse:2.33446                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.19379\teval-rmse:2.33776                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.17432\teval-rmse:2.35266                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.16032\teval-rmse:2.36441                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\ttrain-rmse:2.14502\teval-rmse:2.36667                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.11129\teval-rmse:2.38127                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.09763\teval-rmse:2.38624                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.56696\teval-rmse:2.10634\n",
      "\n",
      "\n",
      "loss: 97252731.49979666                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.4963571050794634e-06, 'colsample_bytree': 0.75, 'gamma': 0.0002019378477349522, 'lambda': 2.0254960728473964e-06, 'learning_rate': 0.45, 'max_depth': 8, 'min_child_weight': 0.10282497470047293, 'n_estimators': 512.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:3.8469\teval-rmse:3.37368                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.04707\teval-rmse:2.55744                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.71816\teval-rmse:2.27216                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.5803\teval-rmse:2.19024                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.49728\teval-rmse:2.16928                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.45799\teval-rmse:2.16543                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.41512\teval-rmse:2.1828                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.37141\teval-rmse:2.22124                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.3383\teval-rmse:2.2344                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:2.31434\teval-rmse:2.24039                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.26549\teval-rmse:2.24985                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.24399\teval-rmse:2.28079                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.22358\teval-rmse:2.34748                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.19786\teval-rmse:2.30046                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.17399\teval-rmse:2.3175                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.15104\teval-rmse:2.32271                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.12304\teval-rmse:2.34491                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.08662\teval-rmse:2.35334                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.06583\teval-rmse:2.37372                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.03865\teval-rmse:2.38389                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.02114\teval-rmse:2.36647                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.99064\teval-rmse:2.37767                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.95876\teval-rmse:2.44419                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.94269\teval-rmse:2.45933                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.92649\teval-rmse:2.48183                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.89619\teval-rmse:2.51587                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.45799\teval-rmse:2.16543\n",
      "\n",
      "\n",
      "loss: 97137598.41022411                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.457730168412233e-07, 'colsample_bytree': 0.9, 'gamma': 0.0006171492080685422, 'lambda': 7.176949259879046e-05, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 1.1754251314984163, 'n_estimators': 120.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.27119\teval-rmse:3.87383                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.43308\teval-rmse:3.05126                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.93405\teval-rmse:2.59282                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.644\teval-rmse:2.37654                                                                                 \n",
      "\n",
      "[4]\ttrain-rmse:2.4605\teval-rmse:2.2761                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.34943\teval-rmse:2.22229                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.25657\teval-rmse:2.20802                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.18327\teval-rmse:2.2065                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.13727\teval-rmse:2.21626                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.10037\teval-rmse:2.22212                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.05677\teval-rmse:2.24047                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.03489\teval-rmse:2.24604                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.01044\teval-rmse:2.24876                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.98705\teval-rmse:2.25356                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.94819\teval-rmse:2.24861                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.92548\teval-rmse:2.24912                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.89277\teval-rmse:2.27152                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.84793\teval-rmse:2.28877                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.82848\teval-rmse:2.29679                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.81146\teval-rmse:2.30308                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.79245\teval-rmse:2.30384                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.77072\teval-rmse:2.309                                                                                \n",
      "\n",
      "[22]\ttrain-rmse:1.75335\teval-rmse:2.33025                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.73925\teval-rmse:2.33773                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.72564\teval-rmse:2.34122                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.70733\teval-rmse:2.33822                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.6992\teval-rmse:2.33126                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.67801\teval-rmse:2.33912                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.18327\teval-rmse:2.2065\n",
      "\n",
      "\n",
      "loss: 96928765.43579963                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0001607337748980023, 'colsample_bytree': 0.8, 'gamma': 5.3072427814036305e-06, 'lambda': 0.00012367534795164998, 'learning_rate': 0.4, 'max_depth': 4, 'min_child_weight': 0.15797347592767544, 'n_estimators': 283.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.14214\teval-rmse:3.54853                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.43152\teval-rmse:2.69148                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.09814\teval-rmse:2.29975                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.95059\teval-rmse:2.15145                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.87848\teval-rmse:2.0938                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.85202\teval-rmse:2.07638                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.83503\teval-rmse:2.07373                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.81697\teval-rmse:2.06892                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.79707\teval-rmse:2.09649                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.78143\teval-rmse:2.09318                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.77115\teval-rmse:2.0947                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.76646\teval-rmse:2.10494                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.75614\teval-rmse:2.09366                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.74944\teval-rmse:2.11041                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.74609\teval-rmse:2.11107                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.73853\teval-rmse:2.11647                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.72939\teval-rmse:2.13531                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.72277\teval-rmse:2.14719                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.71727\teval-rmse:2.14713                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.70885\teval-rmse:2.14935                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.6989\teval-rmse:2.2469                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:2.69088\teval-rmse:2.24358                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.6868\teval-rmse:2.23767                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.68079\teval-rmse:2.23356                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.67564\teval-rmse:2.24515                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.67051\teval-rmse:2.25251                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.66116\teval-rmse:2.25622                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.65651\teval-rmse:2.26732                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.81697\teval-rmse:2.06892\n",
      "\n",
      "\n",
      "loss: 98060540.50481114                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.3075492429820102e-07, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.00034528154800102505, 'lambda': 0.0002682334544267205, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 4.223141681803784, 'n_estimators': 459.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.38973\teval-rmse:3.95378                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.57593\teval-rmse:3.13339                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.06137\teval-rmse:2.64893                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.74998\teval-rmse:2.38023                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.5571\teval-rmse:2.2491                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.42381\teval-rmse:2.19073                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.33084\teval-rmse:2.16285                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.26097\teval-rmse:2.13739                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.20549\teval-rmse:2.12928                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.17214\teval-rmse:2.12354                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.15014\teval-rmse:2.13007                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.12311\teval-rmse:2.14349                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.09073\teval-rmse:2.14697                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.05448\teval-rmse:2.1409                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.03703\teval-rmse:2.15222                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.01647\teval-rmse:2.15017                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.9767\teval-rmse:2.15521                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:1.94354\teval-rmse:2.15453                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.92351\teval-rmse:2.16776                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\ttrain-rmse:1.91019\teval-rmse:2.17395                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.89414\teval-rmse:2.19078                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.87233\teval-rmse:2.1876                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.84683\teval-rmse:2.19157                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.81789\teval-rmse:2.19466                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.79609\teval-rmse:2.19805                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.7715\teval-rmse:2.2055                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:1.75467\teval-rmse:2.21037                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.72229\teval-rmse:2.21306                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.71683\teval-rmse:2.21089                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.70742\teval-rmse:2.21198                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.17214\teval-rmse:2.12354\n",
      "\n",
      "\n",
      "loss: 96908601.76147042                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0004693202257668747, 'colsample_bytree': 0.75, 'gamma': 0.08393215388115195, 'lambda': 0.0006810891831630089, 'learning_rate': 0.47500000000000003, 'max_depth': 6, 'min_child_weight': 9.188977358127909, 'n_estimators': 814.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:3.83755\teval-rmse:3.26009                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.1352\teval-rmse:2.45784                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.85858\teval-rmse:2.18582                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.75848\teval-rmse:2.10934                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.71226\teval-rmse:2.07851                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.68586\teval-rmse:2.07037                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.64888\teval-rmse:2.06722                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.61888\teval-rmse:2.10214                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.60719\teval-rmse:2.10677                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.58155\teval-rmse:2.09954                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.55989\teval-rmse:2.10925                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.5484\teval-rmse:2.10702                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.52638\teval-rmse:2.11685                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.50683\teval-rmse:2.14101                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.49341\teval-rmse:2.16636                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.48394\teval-rmse:2.18217                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.47124\teval-rmse:2.1764                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.4603\teval-rmse:2.18291                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.44725\teval-rmse:2.19868                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.42711\teval-rmse:2.21985                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.42006\teval-rmse:2.22417                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.40864\teval-rmse:2.2356                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.39752\teval-rmse:2.25143                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.38921\teval-rmse:2.25504                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.3819\teval-rmse:2.25412                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.37434\teval-rmse:2.25864                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.3644\teval-rmse:2.25499                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.64888\teval-rmse:2.06722\n",
      "\n",
      "\n",
      "loss: 97479272.11459665                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.07306587370145495, 'colsample_bytree': 0.8, 'gamma': 3.4566808738395365e-05, 'lambda': 1.4872525981840291e-05, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 0.4435521909421018, 'n_estimators': 198.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.47287\teval-rmse:4.06725                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.69471\teval-rmse:3.29398                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.16642\teval-rmse:2.82233                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.84077\teval-rmse:2.54071                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.62643\teval-rmse:2.38822                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.48261\teval-rmse:2.29648                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.37472\teval-rmse:2.2726                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.3007\teval-rmse:2.25753                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.25186\teval-rmse:2.256                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:2.21251\teval-rmse:2.24681                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.18297\teval-rmse:2.24708                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.15869\teval-rmse:2.25166                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.12829\teval-rmse:2.24685                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.09673\teval-rmse:2.25291                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.07611\teval-rmse:2.27001                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.0556\teval-rmse:2.28565                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.03507\teval-rmse:2.29185                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.02124\teval-rmse:2.30259                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.99689\teval-rmse:2.28746                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.96873\teval-rmse:2.29154                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.95147\teval-rmse:2.29909                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.94328\teval-rmse:2.29172                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.92894\teval-rmse:2.30329                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.89121\teval-rmse:2.31841                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.86604\teval-rmse:2.34415                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.85802\teval-rmse:2.34459                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.8482\teval-rmse:2.34353                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.82457\teval-rmse:2.3695                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.80144\teval-rmse:2.3648                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:1.78358\teval-rmse:2.37909                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.21251\teval-rmse:2.24681\n",
      "\n",
      "\n",
      "loss: 97064241.8863297                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0007572696191669466, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.0312115848335004e-08, 'lambda': 0.00010344202758098513, 'learning_rate': 0.375, 'max_depth': 9, 'min_child_weight': 0.829736220694718, 'n_estimators': 300.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.08086\teval-rmse:3.67136                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.22522\teval-rmse:2.83019                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.76347\teval-rmse:2.43429                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.51833\teval-rmse:2.28772                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.37234\teval-rmse:2.26226                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.28984\teval-rmse:2.24074                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.23663\teval-rmse:2.24398                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.18717\teval-rmse:2.26055                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.15762\teval-rmse:2.27581                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.12359\teval-rmse:2.28977                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.0788\teval-rmse:2.28172                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.05729\teval-rmse:2.28179                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.02559\teval-rmse:2.27917                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.00128\teval-rmse:2.303                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:1.95651\teval-rmse:2.30807                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.93141\teval-rmse:2.31892                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.90445\teval-rmse:2.33913                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.88524\teval-rmse:2.34343                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.87056\teval-rmse:2.36045                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.8538\teval-rmse:2.3592                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:1.8317\teval-rmse:2.36822                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.79378\teval-rmse:2.38668                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.77434\teval-rmse:2.38923                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.76542\teval-rmse:2.41679                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.73362\teval-rmse:2.41811                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.71277\teval-rmse:2.42531                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.28984\teval-rmse:2.24074\n",
      "\n",
      "\n",
      "loss: 109514264.54717317                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.0966901931485226e-08, 'colsample_bytree': 0.75, 'gamma': 1.1482650438695366e-05, 'lambda': 0.00019984791839384794, 'learning_rate': 0.35000000000000003, 'max_depth': 5, 'min_child_weight': 0.35342897520643507, 'n_estimators': 163.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.29538\teval-rmse:3.74506                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.5591\teval-rmse:2.87994                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.16548\teval-rmse:2.43651                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.96416\teval-rmse:2.22677                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.86531\teval-rmse:2.1406                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.806\teval-rmse:2.09793                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:2.77033\teval-rmse:2.08588                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.74578\teval-rmse:2.06807                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.7242\teval-rmse:2.07312                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.71066\teval-rmse:2.07171                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:2.69751\teval-rmse:2.07752                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.68413\teval-rmse:2.08539                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.67204\teval-rmse:2.08211                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.6612\teval-rmse:2.08535                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.6548\teval-rmse:2.09373                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.64301\teval-rmse:2.09926                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.63647\teval-rmse:2.09814                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.6218\teval-rmse:2.09835                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.6111\teval-rmse:2.08244                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.60258\teval-rmse:2.09636                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.59442\teval-rmse:2.10219                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.58249\teval-rmse:2.1013                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.57927\teval-rmse:2.09885                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.5701\teval-rmse:2.10243                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.56506\teval-rmse:2.11165                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.55146\teval-rmse:2.1408                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.54133\teval-rmse:2.144                                                                                \n",
      "\n",
      "[27]\ttrain-rmse:2.52624\teval-rmse:2.13941                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.74578\teval-rmse:2.06807\n",
      "\n",
      "\n",
      "loss: 11417130113418.94                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.15317280857176882, 'colsample_bytree': 0.75, 'gamma': 2.926772403066345e-08, 'lambda': 5.268986189831473e-05, 'learning_rate': 0.2, 'max_depth': 9, 'min_child_weight': 2.854613457200337, 'n_estimators': 102.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.78688\teval-rmse:4.37079                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.13197\teval-rmse:3.70579                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.63494\teval-rmse:3.2096                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.2599\teval-rmse:2.85502                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.98667\teval-rmse:2.59585                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.77878\teval-rmse:2.42435                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.6307\teval-rmse:2.29954                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.51492\teval-rmse:2.22155                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.42686\teval-rmse:2.16494                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.3582\teval-rmse:2.13287                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.30989\teval-rmse:2.11552                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.27627\teval-rmse:2.1031                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.2418\teval-rmse:2.10135                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.21162\teval-rmse:2.1027                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.18763\teval-rmse:2.10999                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.15876\teval-rmse:2.13343                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.14079\teval-rmse:2.13558                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.11042\teval-rmse:2.14422                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.08209\teval-rmse:2.15336                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.07242\teval-rmse:2.15211                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.04526\teval-rmse:2.16285                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.0353\teval-rmse:2.16507                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.01443\teval-rmse:2.16347                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.98966\teval-rmse:2.17942                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.97923\teval-rmse:2.17972                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.96807\teval-rmse:2.17868                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.96063\teval-rmse:2.18048                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.94105\teval-rmse:2.18342                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.92917\teval-rmse:2.1886                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:1.90857\teval-rmse:2.1911                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:1.89798\teval-rmse:2.19389                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.88421\teval-rmse:2.19761                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.85861\teval-rmse:2.2                                                                                  \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.2418\teval-rmse:2.10135\n",
      "\n",
      "\n",
      "loss: 96734167.13282003                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.44586687955313875, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.1184700110427492e-06, 'lambda': 0.00036620132889436717, 'learning_rate': 0.30000000000000004, 'max_depth': 3, 'min_child_weight': 0.3879794967798516, 'n_estimators': 244.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.51973\teval-rmse:3.95965                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.83129\teval-rmse:3.15274                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.42549\teval-rmse:2.65802                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.19266\teval-rmse:2.37484                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.06691\teval-rmse:2.23601                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.99241\teval-rmse:2.1555                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.9532\teval-rmse:2.10925                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.92872\teval-rmse:2.09629                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.90788\teval-rmse:2.08361                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.89351\teval-rmse:2.07462                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.88032\teval-rmse:2.06781                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.87347\teval-rmse:2.06799                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.86555\teval-rmse:2.06305                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.8582\teval-rmse:2.07037                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.85435\teval-rmse:2.07031                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.84863\teval-rmse:2.07353                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.84523\teval-rmse:2.07254                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.84084\teval-rmse:2.06496                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.83663\teval-rmse:2.0663                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.8313\teval-rmse:2.06726                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.82495\teval-rmse:2.06505                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.8224\teval-rmse:2.07373                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.81799\teval-rmse:2.07488                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.81201\teval-rmse:2.08131                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.8087\teval-rmse:2.09082                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.80403\teval-rmse:2.09084                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.80087\teval-rmse:2.12117                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.79691\teval-rmse:2.12059                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.79018\teval-rmse:2.12076                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.78266\teval-rmse:2.11953                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.77993\teval-rmse:2.12245                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.77587\teval-rmse:2.12148                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.77334\teval-rmse:2.12094                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.86555\teval-rmse:2.06305\n",
      "\n",
      "\n",
      "loss: 98632668.14214002                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.030224928121089567, 'colsample_bytree': 0.8, 'gamma': 9.425674247826203e-05, 'lambda': 5.8596583383516875e-06, 'learning_rate': 0.42500000000000004, 'max_depth': 9, 'min_child_weight': 1.9511093778946842, 'n_estimators': 357.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:3.89326\teval-rmse:3.47175                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.02956\teval-rmse:2.63472                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.62475\teval-rmse:2.32062                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.43453\teval-rmse:2.20696                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.31374\teval-rmse:2.18619                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.24763\teval-rmse:2.18689                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.18622\teval-rmse:2.24132                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.16067\teval-rmse:2.24234                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.10449\teval-rmse:2.24766                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.07103\teval-rmse:2.24511                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.02682\teval-rmse:2.23848                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.00299\teval-rmse:2.24127                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.96698\teval-rmse:2.28895                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.91613\teval-rmse:2.29702                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.88582\teval-rmse:2.32789                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.83811\teval-rmse:2.34149                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.78502\teval-rmse:2.35447                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.76969\teval-rmse:2.35981                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.73771\teval-rmse:2.37245                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.71457\teval-rmse:2.37999                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.68423\teval-rmse:2.39469                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.66382\teval-rmse:2.38328                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.65564\teval-rmse:2.39885                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.62657\teval-rmse:2.39611                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.60132\teval-rmse:2.42355                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.31374\teval-rmse:2.18619\n",
      "\n",
      "\n",
      "loss: 96577678.74487579                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.2867960158910628, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.014801564133971115, 'lambda': 2.9134370113978232e-05, 'learning_rate': 0.325, 'max_depth': 7, 'min_child_weight': 0.20959753157508362, 'n_estimators': 532.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.32813\teval-rmse:3.84888                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.55166\teval-rmse:3.02182                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.10602\teval-rmse:2.56002                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.8655\teval-rmse:2.32376                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.73274\teval-rmse:2.20435                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.64881\teval-rmse:2.16258                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.5896\teval-rmse:2.1411                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:2.55007\teval-rmse:2.12969                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.52114\teval-rmse:2.14867                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.50071\teval-rmse:2.15127                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.47321\teval-rmse:2.15032                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.44604\teval-rmse:2.15705                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.42577\teval-rmse:2.18247                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.40243\teval-rmse:2.17364                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.39106\teval-rmse:2.17601                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.37742\teval-rmse:2.18757                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.36045\teval-rmse:2.23963                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.32989\teval-rmse:2.27032                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.31948\teval-rmse:2.29521                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.29297\teval-rmse:2.30899                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.28003\teval-rmse:2.31416                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.26864\teval-rmse:2.3257                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.25887\teval-rmse:2.34064                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.24714\teval-rmse:2.34265                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.23529\teval-rmse:2.37046                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.22141\teval-rmse:2.38828                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.19555\teval-rmse:2.3967                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.18667\teval-rmse:2.39712                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.55007\teval-rmse:2.12969\n",
      "\n",
      "\n",
      "loss: 97973655.59687993                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.002795095732764754, 'colsample_bytree': 0.75, 'gamma': 6.894159601396781e-07, 'lambda': 1.0006858568161088e-06, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 7.212274948624719, 'n_estimators': 713.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.61062\teval-rmse:4.16127                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.90142\teval-rmse:3.4006                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.4169\teval-rmse:2.89042                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.08647\teval-rmse:2.5735                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.87683\teval-rmse:2.36571                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.73911\teval-rmse:2.25467                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.64824\teval-rmse:2.18856                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.58865\teval-rmse:2.1483                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.53031\teval-rmse:2.13523                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.49847\teval-rmse:2.12068                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.46545\teval-rmse:2.11676                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.44479\teval-rmse:2.12728                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.42769\teval-rmse:2.13009                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.40612\teval-rmse:2.13974                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.3861\teval-rmse:2.1466                                                                                \n",
      "\n",
      "[15]\ttrain-rmse:2.36997\teval-rmse:2.15671                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.34315\teval-rmse:2.16383                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.32189\teval-rmse:2.1734                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.31089\teval-rmse:2.1699                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.29059\teval-rmse:2.1893                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.28391\teval-rmse:2.18985                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.27376\teval-rmse:2.19323                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.26047\teval-rmse:2.19524                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.2471\teval-rmse:2.20639                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.24124\teval-rmse:2.20836                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.23387\teval-rmse:2.21318                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.2253\teval-rmse:2.21436                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.21738\teval-rmse:2.21212                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.20037\teval-rmse:2.22014                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.18568\teval-rmse:2.22231                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.17011\teval-rmse:2.23046                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.46545\teval-rmse:2.11676\n",
      "\n",
      "\n",
      "loss: 97193111.2385727                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.06298769237148e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.0012286879369035723, 'lambda': 8.790068925332202e-06, 'learning_rate': 0.225, 'max_depth': 4, 'min_child_weight': 1.0717435588644888, 'n_estimators': 432.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.77004\teval-rmse:4.26075                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.14626\teval-rmse:3.54781                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.71087\teval-rmse:3.03897                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.41364\teval-rmse:2.68514                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.22008\teval-rmse:2.4541                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.08412\teval-rmse:2.30342                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.99944\teval-rmse:2.20608                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.94179\teval-rmse:2.14824                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.90077\teval-rmse:2.11297                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.87145\teval-rmse:2.08925                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.85449\teval-rmse:2.07797                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.836\teval-rmse:2.07261                                                                                \n",
      "\n",
      "[12]\ttrain-rmse:2.81877\teval-rmse:2.06718                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.80692\teval-rmse:2.06452                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.79824\teval-rmse:2.06721                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.78956\teval-rmse:2.06882                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.78171\teval-rmse:2.06405                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.77532\teval-rmse:2.06563                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.76797\teval-rmse:2.06691                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.76115\teval-rmse:2.06639                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.75609\teval-rmse:2.06823                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.75215\teval-rmse:2.07049                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.74733\teval-rmse:2.05478                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.74188\teval-rmse:2.05556                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.73705\teval-rmse:2.0587                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.73381\teval-rmse:2.06091                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.72781\teval-rmse:2.07399                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.72298\teval-rmse:2.07896                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.71438\teval-rmse:2.0672                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.70895\teval-rmse:2.06594                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.70688\teval-rmse:2.07082                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.70302\teval-rmse:2.06972                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.7002\teval-rmse:2.06869                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.69313\teval-rmse:2.06648                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.6895\teval-rmse:2.07747                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:2.68713\teval-rmse:2.08397                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.68289\teval-rmse:2.08531                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.67874\teval-rmse:2.08329                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.67443\teval-rmse:2.08037                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.67232\teval-rmse:2.06546                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.66653\teval-rmse:2.07166                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.66403\teval-rmse:2.07154                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.66016\teval-rmse:2.07826                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[22]\ttrain-rmse:2.74733\teval-rmse:2.05478\n",
      "\n",
      "\n",
      "loss: 98582127.82998806                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00035029283366292064, 'colsample_bytree': 0.8, 'gamma': 3.6454833081585896e-06, 'lambda': 0.10402780116974501, 'learning_rate': 0.4, 'max_depth': 9, 'min_child_weight': 0.1844575542968198, 'n_estimators': 864.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:3.98334\teval-rmse:3.57714                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.12397\teval-rmse:2.72757                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.69324\teval-rmse:2.33419                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.46907\teval-rmse:2.18698                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\ttrain-rmse:2.37067\teval-rmse:2.14029                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.28781\teval-rmse:2.14592                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.25565\teval-rmse:2.15647                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.2085\teval-rmse:2.19729                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.16472\teval-rmse:2.20569                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.1134\teval-rmse:2.21715                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.06833\teval-rmse:2.22372                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.05241\teval-rmse:2.22693                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.00966\teval-rmse:2.22484                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.97551\teval-rmse:2.2382                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:1.92826\teval-rmse:2.24399                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.90593\teval-rmse:2.24581                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.87583\teval-rmse:2.24771                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.83492\teval-rmse:2.25321                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.82274\teval-rmse:2.26303                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.81016\teval-rmse:2.27294                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.79677\teval-rmse:2.28517                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.76942\teval-rmse:2.28446                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.75264\teval-rmse:2.2851                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.7226\teval-rmse:2.29194                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.6705\teval-rmse:2.3203                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.37067\teval-rmse:2.14029\n",
      "\n",
      "\n",
      "loss: 234273834.5204142                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00021222668432124036, 'colsample_bytree': 0.75, 'gamma': 0.0015930545011013618, 'lambda': 0.02035898773156539, 'learning_rate': 0.35000000000000003, 'max_depth': 9, 'min_child_weight': 0.3252296964502416, 'n_estimators': 223.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.18494\teval-rmse:3.76328                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.34032\teval-rmse:2.93144                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.85693\teval-rmse:2.5221                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.58983\teval-rmse:2.34818                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.42278\teval-rmse:2.26692                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.31565\teval-rmse:2.24221                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.23414\teval-rmse:2.22304                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.18161\teval-rmse:2.22114                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.12344\teval-rmse:2.22671                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.10015\teval-rmse:2.22403                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.06452\teval-rmse:2.22644                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.03306\teval-rmse:2.23205                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.98671\teval-rmse:2.23584                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.96566\teval-rmse:2.22665                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.94369\teval-rmse:2.23801                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.91807\teval-rmse:2.25068                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:1.87432\teval-rmse:2.27745                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.82866\teval-rmse:2.28105                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.80057\teval-rmse:2.29448                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.77657\teval-rmse:2.30013                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.75851\teval-rmse:2.30416                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.73916\teval-rmse:2.3088                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.71716\teval-rmse:2.32297                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.68837\teval-rmse:2.33279                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.65425\teval-rmse:2.36325                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.64064\teval-rmse:2.36475                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.61869\teval-rmse:2.36825                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.6008\teval-rmse:2.36727                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.18161\teval-rmse:2.22114\n",
      "\n",
      "\n",
      "loss: 96857963.77961266                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0014122011062757216, 'colsample_bytree': 0.7000000000000001, 'gamma': 3.587419869845102e-07, 'lambda': 0.0010375034083298378, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 0.5677697310686577, 'n_estimators': 475.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.48017\teval-rmse:4.06839                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.69901\teval-rmse:3.29416                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.18146\teval-rmse:2.79689                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.85232\teval-rmse:2.5061                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.64004\teval-rmse:2.35645                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.4928\teval-rmse:2.26974                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.39434\teval-rmse:2.23041                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.33615\teval-rmse:2.21158                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.28376\teval-rmse:2.20626                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.23906\teval-rmse:2.19584                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.19699\teval-rmse:2.20408                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.14248\teval-rmse:2.22781                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.109\teval-rmse:2.23841                                                                                \n",
      "\n",
      "[13]\ttrain-rmse:2.08587\teval-rmse:2.23772                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.05594\teval-rmse:2.24877                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.02986\teval-rmse:2.24883                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.01355\teval-rmse:2.27463                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.99455\teval-rmse:2.2734                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:1.96529\teval-rmse:2.27855                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.94159\teval-rmse:2.28093                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.9337\teval-rmse:2.28423                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:1.91417\teval-rmse:2.2844                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.89907\teval-rmse:2.29123                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.87989\teval-rmse:2.29383                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.86542\teval-rmse:2.29805                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.84705\teval-rmse:2.30565                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.82546\teval-rmse:2.30484                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.81051\teval-rmse:2.3063                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.79295\teval-rmse:2.31237                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.76702\teval-rmse:2.3327                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.23906\teval-rmse:2.19584\n",
      "\n",
      "\n",
      "loss: 96851451.26971091                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.005137873272126413, 'colsample_bytree': 0.8, 'gamma': 1.6787956150121783e-05, 'lambda': 2.644696012863675e-06, 'learning_rate': 0.375, 'max_depth': 6, 'min_child_weight': 2.2213312475448634, 'n_estimators': 649.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.17793\teval-rmse:3.64278                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.42212\teval-rmse:2.78745                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.04703\teval-rmse:2.36245                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.86105\teval-rmse:2.19932                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.75907\teval-rmse:2.11546                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.70427\teval-rmse:2.10541                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.67769\teval-rmse:2.09818                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.65301\teval-rmse:2.1138                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.63065\teval-rmse:2.11847                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.60749\teval-rmse:2.12107                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.58828\teval-rmse:2.12767                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.57804\teval-rmse:2.13438                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.56486\teval-rmse:2.1372                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.54652\teval-rmse:2.15892                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.53544\teval-rmse:2.16891                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.52343\teval-rmse:2.17                                                                                 \n",
      "\n",
      "[16]\ttrain-rmse:2.50899\teval-rmse:2.16658                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.49247\teval-rmse:2.16506                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.48545\teval-rmse:2.15838                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.4683\teval-rmse:2.17838                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.45601\teval-rmse:2.18345                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.44057\teval-rmse:2.19                                                                                 \n",
      "\n",
      "[22]\ttrain-rmse:2.43284\teval-rmse:2.19791                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.41896\teval-rmse:2.20978                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.40411\teval-rmse:2.20662                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.39454\teval-rmse:2.20615                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.38828\teval-rmse:2.21936                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.67769\teval-rmse:2.09818\n",
      "\n",
      "\n",
      "loss: 104599526.33143513                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.744506226592729e-05, 'colsample_bytree': 0.75, 'gamma': 2.3216879480398995e-06, 'lambda': 3.892132400425101e-05, 'learning_rate': 0.30000000000000004, 'max_depth': 5, 'min_child_weight': 1.4461040172063515, 'n_estimators': 140.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.47304\teval-rmse:3.95076                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.75889\teval-rmse:3.12205                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.32344\teval-rmse:2.63348                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.07898\teval-rmse:2.35856                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.94156\teval-rmse:2.20673                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.86105\teval-rmse:2.13081                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.81103\teval-rmse:2.09111                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.77956\teval-rmse:2.06711                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.75139\teval-rmse:2.05426                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.73303\teval-rmse:2.05064                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.71397\teval-rmse:2.05232                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.70279\teval-rmse:2.05701                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.68722\teval-rmse:2.05365                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.67234\teval-rmse:2.0712                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.66766\teval-rmse:2.07376                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.65613\teval-rmse:2.07911                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.64676\teval-rmse:2.08888                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.63538\teval-rmse:2.08502                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.62865\teval-rmse:2.08296                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.62257\teval-rmse:2.08029                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.61392\teval-rmse:2.08845                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.60548\teval-rmse:2.07723                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.59718\teval-rmse:2.06845                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.58823\teval-rmse:2.07206                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.58168\teval-rmse:2.07891                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.57494\teval-rmse:2.07841                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.56404\teval-rmse:2.07861                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.55066\teval-rmse:2.07933                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.54358\teval-rmse:2.08463                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.53913\teval-rmse:2.08696                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.73303\teval-rmse:2.05064\n",
      "\n",
      "\n",
      "loss: 98114930.55462793                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.017495905798550013, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.0033949537513691445, 'lambda': 4.367179975474682e-06, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.11151608849157026, 'n_estimators': 755.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.27257\teval-rmse:3.8662                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.43398\teval-rmse:3.0218                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.92439\teval-rmse:2.57978                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.62709\teval-rmse:2.35746                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.45074\teval-rmse:2.25141                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.33953\teval-rmse:2.21161                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.2475\teval-rmse:2.18222                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.2011\teval-rmse:2.19975                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.13377\teval-rmse:2.19319                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.09618\teval-rmse:2.17381                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.07276\teval-rmse:2.19577                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.04533\teval-rmse:2.19522                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:1.99663\teval-rmse:2.21923                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:1.97935\teval-rmse:2.22459                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:1.94034\teval-rmse:2.22892                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:1.91746\teval-rmse:2.2358                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:1.88599\teval-rmse:2.24426                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.86465\teval-rmse:2.24517                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.83977\teval-rmse:2.25894                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.8326\teval-rmse:2.26427                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:1.79566\teval-rmse:2.26607                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.76204\teval-rmse:2.26954                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.71582\teval-rmse:2.2778                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.67926\teval-rmse:2.27541                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.65039\teval-rmse:2.27995                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.62713\teval-rmse:2.28728                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.60324\teval-rmse:2.2869                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.57362\teval-rmse:2.28572                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.56226\teval-rmse:2.28887                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.53932\teval-rmse:2.29072                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.09618\teval-rmse:2.17381\n",
      "\n",
      "\n",
      "loss: 96791087.8856585                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.868794409146058e-06, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.2981632286319805e-07, 'lambda': 0.006525352922895886, 'learning_rate': 0.15000000000000002, 'max_depth': 3, 'min_child_weight': 0.9120672800295205, 'n_estimators': 566.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:5.06586\teval-rmse:4.5888                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.59591\teval-rmse:4.04974                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.22064\teval-rmse:3.61172                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.9203\teval-rmse:3.25687                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.68774\teval-rmse:2.9779                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.50051\teval-rmse:2.75733                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.35971\teval-rmse:2.58675                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.25011\teval-rmse:2.4537                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.16558\teval-rmse:2.35089                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.10296\teval-rmse:2.27607                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.05427\teval-rmse:2.22038                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.01481\teval-rmse:2.17754                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.98724\teval-rmse:2.14894                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.96255\teval-rmse:2.12694                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.9432\teval-rmse:2.1137                                                                                \n",
      "\n",
      "[15]\ttrain-rmse:2.92771\teval-rmse:2.1007                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.91487\teval-rmse:2.09245                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.90379\teval-rmse:2.08436                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.89443\teval-rmse:2.08371                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.88601\teval-rmse:2.08292                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.87997\teval-rmse:2.08245                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.87392\teval-rmse:2.08385                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.86926\teval-rmse:2.08306                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.86553\teval-rmse:2.07941                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.86284\teval-rmse:2.07891                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.85718\teval-rmse:2.0776                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.85172\teval-rmse:2.07586                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.84933\teval-rmse:2.07471                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.84447\teval-rmse:2.0712                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.84087\teval-rmse:2.0724                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.83688\teval-rmse:2.07466                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.83412\teval-rmse:2.07409                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.83175\teval-rmse:2.07326                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.82661\teval-rmse:2.07307                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.82362\teval-rmse:2.07109                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.82025\teval-rmse:2.07185                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.8173\teval-rmse:2.07207                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.81495\teval-rmse:2.07139                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.81241\teval-rmse:2.07238                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.81047\teval-rmse:2.07256                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.80876\teval-rmse:2.07262                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.80703\teval-rmse:2.0731                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:2.80455\teval-rmse:2.0714                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:2.80361\teval-rmse:2.07135                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.80158\teval-rmse:2.07143                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.80054\teval-rmse:2.06917                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.79742\teval-rmse:2.06719                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.79499\teval-rmse:2.06614                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.793\teval-rmse:2.06473                                                                                \n",
      "\n",
      "[49]\ttrain-rmse:2.79038\teval-rmse:2.06478                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.78841\teval-rmse:2.06488                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.78637\teval-rmse:2.06685                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.78431\teval-rmse:2.06315                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.78259\teval-rmse:2.06402                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.78137\teval-rmse:2.06559                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.78034\teval-rmse:2.06676                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.77933\teval-rmse:2.06674                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57]\ttrain-rmse:2.77708\teval-rmse:2.06953                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.77531\teval-rmse:2.06879                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.77383\teval-rmse:2.06855                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.77193\teval-rmse:2.07035                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.76957\teval-rmse:2.07296                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.76777\teval-rmse:2.07275                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.76629\teval-rmse:2.0716                                                                               \n",
      "\n",
      "[64]\ttrain-rmse:2.76552\teval-rmse:2.07011                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.7648\teval-rmse:2.07137                                                                               \n",
      "\n",
      "[66]\ttrain-rmse:2.76335\teval-rmse:2.07118                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.76157\teval-rmse:2.0688                                                                               \n",
      "\n",
      "[68]\ttrain-rmse:2.7593\teval-rmse:2.06937                                                                               \n",
      "\n",
      "[69]\ttrain-rmse:2.75698\teval-rmse:2.06742                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:2.75618\teval-rmse:2.06755                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:2.75451\teval-rmse:2.06811                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:2.75269\teval-rmse:2.06963                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[52]\ttrain-rmse:2.78431\teval-rmse:2.06315\n",
      "\n",
      "\n",
      "loss: 98629274.82268094                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.10783985851203522, 'colsample_bytree': 0.8, 'gamma': 6.657472124455296e-05, 'lambda': 0.6929038945731903, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 3.627710654153907, 'n_estimators': 376.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.48702\teval-rmse:4.06159                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.71044\teval-rmse:3.25775                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.19332\teval-rmse:2.76571                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.86212\teval-rmse:2.46873                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.64939\teval-rmse:2.29241                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.50434\teval-rmse:2.19713                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.39898\teval-rmse:2.14512                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.32484\teval-rmse:2.1277                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.27879\teval-rmse:2.1134                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.22227\teval-rmse:2.11059                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.18591\teval-rmse:2.11182                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.15626\teval-rmse:2.11399                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.13354\teval-rmse:2.12246                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.11384\teval-rmse:2.12721                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.08834\teval-rmse:2.12839                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.05592\teval-rmse:2.12221                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.02408\teval-rmse:2.12814                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.99933\teval-rmse:2.13045                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.98019\teval-rmse:2.13361                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.96389\teval-rmse:2.13578                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.94534\teval-rmse:2.13439                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.92786\teval-rmse:2.13083                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.90737\teval-rmse:2.14179                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.89644\teval-rmse:2.13494                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.8799\teval-rmse:2.14043                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.87451\teval-rmse:2.14389                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.85597\teval-rmse:2.13448                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.84522\teval-rmse:2.14259                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.82622\teval-rmse:2.14016                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.8052\teval-rmse:2.14563                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.22227\teval-rmse:2.11059\n",
      "\n",
      "\n",
      "loss: 97224800.42875655                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.9275504503566546, 'colsample_bytree': 0.75, 'gamma': 1.4934537632403927e-06, 'lambda': 1.6881084097797039e-06, 'learning_rate': 0.45, 'max_depth': 7, 'min_child_weight': 1.7863346568968421, 'n_estimators': 507.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:3.89083\teval-rmse:3.36166                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.13166\teval-rmse:2.53709                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.81409\teval-rmse:2.23617                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.67585\teval-rmse:2.17739                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.60535\teval-rmse:2.15771                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.56311\teval-rmse:2.16192                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.50119\teval-rmse:2.16675                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.47566\teval-rmse:2.16859                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.45244\teval-rmse:2.18515                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.42633\teval-rmse:2.22326                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.39963\teval-rmse:2.23005                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.38019\teval-rmse:2.22938                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.35282\teval-rmse:2.24103                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.32382\teval-rmse:2.26123                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.31082\teval-rmse:2.27515                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.28891\teval-rmse:2.27591                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.26825\teval-rmse:2.2878                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.22941\teval-rmse:2.2964                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.20976\teval-rmse:2.29583                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.19873\teval-rmse:2.30442                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.17824\teval-rmse:2.3099                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.16046\teval-rmse:2.33983                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.1483\teval-rmse:2.36603                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.12396\teval-rmse:2.37498                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.10833\teval-rmse:2.38945                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.60535\teval-rmse:2.15771\n",
      "\n",
      "\n",
      "loss: 96873947.90598266                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0006344878828485952, 'colsample_bytree': 0.8, 'gamma': 2.3813494504544064e-07, 'lambda': 7.498184227543571e-05, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 0.6856526449947801, 'n_estimators': 333.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.20809\teval-rmse:3.75978                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.39554\teval-rmse:2.9521                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.94269\teval-rmse:2.53344                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.68814\teval-rmse:2.3196                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.54943\teval-rmse:2.2326                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.46387\teval-rmse:2.21257                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.40686\teval-rmse:2.18337                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.36768\teval-rmse:2.18045                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.33278\teval-rmse:2.18263                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.3056\teval-rmse:2.17961                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.2713\teval-rmse:2.19991                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.25542\teval-rmse:2.1962                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.22773\teval-rmse:2.19468                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.20455\teval-rmse:2.20256                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.1825\teval-rmse:2.20891                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.16854\teval-rmse:2.2235                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.15397\teval-rmse:2.22581                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.12409\teval-rmse:2.23335                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.11076\teval-rmse:2.25151                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.08482\teval-rmse:2.25761                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.05651\teval-rmse:2.26696                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.03731\teval-rmse:2.25784                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.02024\teval-rmse:2.28568                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.99561\teval-rmse:2.28899                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.97707\teval-rmse:2.30245                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.94648\teval-rmse:2.30632                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.93247\teval-rmse:2.31253                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.89826\teval-rmse:2.36784                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.87528\teval-rmse:2.40104                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.84984\teval-rmse:2.39677                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.3056\teval-rmse:2.17961\n",
      "\n",
      "\n",
      "loss: 101047320.44964415                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.374164174582624e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.0008249288738552725, 'lambda': 2.1109454226794446e-05, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 3.189947685466338, 'n_estimators': 685.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.58774\teval-rmse:4.16136                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.83963\teval-rmse:3.40384                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.32168\teval-rmse:2.89641                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\ttrain-rmse:2.96785\teval-rmse:2.57306                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.73921\teval-rmse:2.378                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.56806\teval-rmse:2.26673                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.46348\teval-rmse:2.19972                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.37846\teval-rmse:2.15929                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.30827\teval-rmse:2.14022                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.2719\teval-rmse:2.13168                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.2372\teval-rmse:2.14604                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.19679\teval-rmse:2.13971                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.16718\teval-rmse:2.14685                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.12033\teval-rmse:2.15349                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.08699\teval-rmse:2.15681                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.06529\teval-rmse:2.16041                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.04161\teval-rmse:2.16689                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.01733\teval-rmse:2.17253                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.00377\teval-rmse:2.17866                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.98291\teval-rmse:2.19324                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.96827\teval-rmse:2.19076                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.95517\teval-rmse:2.19481                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.92111\teval-rmse:2.21392                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.90322\teval-rmse:2.21854                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.88715\teval-rmse:2.21861                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.87095\teval-rmse:2.21446                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.84067\teval-rmse:2.20282                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.82452\teval-rmse:2.20388                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.81121\teval-rmse:2.20025                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.80419\teval-rmse:2.2057                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.2719\teval-rmse:2.13168\n",
      "\n",
      "\n",
      "loss: 96854736.92026345                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00014893509053118503, 'colsample_bytree': 0.75, 'gamma': 0.00018353944811142368, 'lambda': 0.0006301212314435087, 'learning_rate': 0.375, 'max_depth': 4, 'min_child_weight': 5.246371372820932, 'n_estimators': 587.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.22809\teval-rmse:3.64631                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.51426\teval-rmse:2.79484                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.15475\teval-rmse:2.38574                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.99068\teval-rmse:2.20107                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.91236\teval-rmse:2.12606                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.87046\teval-rmse:2.10385                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.84549\teval-rmse:2.09526                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.82887\teval-rmse:2.11319                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.81115\teval-rmse:2.10699                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.79808\teval-rmse:2.11114                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.78783\teval-rmse:2.11171                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.77759\teval-rmse:2.11815                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.77116\teval-rmse:2.11232                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.76391\teval-rmse:2.12068                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.76004\teval-rmse:2.1188                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.75252\teval-rmse:2.10344                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.74308\teval-rmse:2.10245                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.73509\teval-rmse:2.09039                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.72844\teval-rmse:2.09094                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.72217\teval-rmse:2.10111                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.71695\teval-rmse:2.10824                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.71147\teval-rmse:2.12367                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.70734\teval-rmse:2.12318                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.70261\teval-rmse:2.13523                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.70086\teval-rmse:2.13238                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.69235\teval-rmse:2.13279                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.68852\teval-rmse:2.18068                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.68617\teval-rmse:2.16727                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.68401\teval-rmse:2.17798                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.68022\teval-rmse:2.17036                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.67789\teval-rmse:2.16994                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.67359\teval-rmse:2.1978                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.66901\teval-rmse:2.19844                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.66134\teval-rmse:2.16939                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.65431\teval-rmse:2.16532                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.64862\teval-rmse:2.16402                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.64787\teval-rmse:2.16427                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.64207\teval-rmse:2.15963                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:2.73509\teval-rmse:2.09039\n",
      "\n",
      "\n",
      "loss: 98279602.77767208                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0065998453809685605, 'colsample_bytree': 0.8, 'gamma': 5.252652945336912e-05, 'lambda': 6.526778171602842, 'learning_rate': 0.225, 'max_depth': 9, 'min_child_weight': 4.626109069322522, 'n_estimators': 486.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:4.71419\teval-rmse:4.27327                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.03569\teval-rmse:3.55819                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.54315\teval-rmse:3.04436                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.19931\teval-rmse:2.68869                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.95253\teval-rmse:2.45889                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.77623\teval-rmse:2.30898                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.65637\teval-rmse:2.21301                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.55796\teval-rmse:2.15526                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.48654\teval-rmse:2.11298                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.43048\teval-rmse:2.09372                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.37909\teval-rmse:2.08117                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.3428\teval-rmse:2.07152                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.30878\teval-rmse:2.07224                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.26537\teval-rmse:2.06756                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.24432\teval-rmse:2.06597                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.22152\teval-rmse:2.0611                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.19257\teval-rmse:2.06924                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.16875\teval-rmse:2.07127                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.15805\teval-rmse:2.07482                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.1397\teval-rmse:2.07736                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.11639\teval-rmse:2.08041                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.1056\teval-rmse:2.08116                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.0841\teval-rmse:2.08733                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.05486\teval-rmse:2.08139                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.04442\teval-rmse:2.08536                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.03612\teval-rmse:2.08949                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.02968\teval-rmse:2.0901                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.00888\teval-rmse:2.09913                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.99052\teval-rmse:2.10471                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.9718\teval-rmse:2.10737                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:1.95682\teval-rmse:2.11254                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.94026\teval-rmse:2.11099                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.93412\teval-rmse:2.11288                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.92555\teval-rmse:2.11086                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.92088\teval-rmse:2.11039                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.91177\teval-rmse:2.10983                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.22152\teval-rmse:2.0611\n",
      "\n",
      "\n",
      "loss: 97261410.77809052                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.183417338533243e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 2.354857346199096e-05, 'lambda': 0.01081763516229841, 'learning_rate': 0.42500000000000004, 'max_depth': 6, 'min_child_weight': 2.450698957487485, 'n_estimators': 268.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:3.99951\teval-rmse:3.46239                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.2511\teval-rmse:2.61869                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.91693\teval-rmse:2.28726                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.77617\teval-rmse:2.14858                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.70344\teval-rmse:2.08605                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.65911\teval-rmse:2.07796                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.61669\teval-rmse:2.08992                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.58954\teval-rmse:2.09812                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.55961\teval-rmse:2.11172                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.54364\teval-rmse:2.11884                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.53306\teval-rmse:2.11705                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\ttrain-rmse:2.51571\teval-rmse:2.11937                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.49985\teval-rmse:2.13012                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.47673\teval-rmse:2.13366                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.46609\teval-rmse:2.13491                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.44935\teval-rmse:2.13019                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.43508\teval-rmse:2.12386                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.41635\teval-rmse:2.12397                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.40408\teval-rmse:2.14945                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.37906\teval-rmse:2.15595                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.36303\teval-rmse:2.16328                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.35283\teval-rmse:2.16604                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.33703\teval-rmse:2.18169                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.32369\teval-rmse:2.19611                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.30814\teval-rmse:2.1977                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.30134\teval-rmse:2.20304                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.65911\teval-rmse:2.07796\n",
      "\n",
      "\n",
      "loss: 97651000.26567484                                                                                                \n",
      "100%|████████████████████████████████████████████████| 250/250 [1:13:29<00:00, 13.91s/it, best loss: 96344398.52934225]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.000514956253655507,\n",
       " 'colsample_bytree': 0.75,\n",
       " 'eta': 0.275,\n",
       " 'gamma': 1.5667995810928674e-08,\n",
       " 'lambda': 4.42231096547982e-06,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 0.6631469358878956,\n",
       " 'n_estimators': 599.0,\n",
       " 'subsample': 0.7000000000000001}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "\n",
    "    evals = [(d_train_sales, 'train'), (d_val_sales, 'eval')]\n",
    "    evals_result = {}\n",
    "\n",
    "    model = xgb.train(params, \n",
    "              d_train_sales, \n",
    "              num_boost_round=1000, \n",
    "              evals=evals,\n",
    "              early_stopping_rounds=20,\n",
    "              evals_result=evals_result)\n",
    "    \n",
    "    d_pred = np.exp(model.predict(d_val))\n",
    "    loss = mean_squared_error(d_pred, df_val_Y['Clicks'].values)\n",
    "    print(f'loss: {loss}')\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "def optimize(random_state=71):\n",
    "    \n",
    "    space = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 1000, 1),\n",
    "        'learning_rate': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "        'max_depth':  hp.choice('max_depth', np.arange(3, 10, dtype=int)),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', np.log(0.1), np.log(10)),\n",
    "        'subsample': hp.quniform('subsample', 0.6, 0.95, 0.05),\n",
    "        'gamma': hp.loguniform('gamma', np.log(1e-8), np.log(1.0)),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.6, 0.95, 0.05),\n",
    "        'alpha': hp.loguniform('alpha', np.log(1e-8), np.log(1.0)),\n",
    "        'lambda': hp.loguniform('lambda', np.log(1e-6), np.log(10.0)),\n",
    "        'nthread': 4,\n",
    "        'seed': random_state\n",
    "    }\n",
    "    best = fmin(score, space, \n",
    "                algo=tpe.suggest, \n",
    "                max_evals=250)\n",
    "    return best\n",
    "optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:4.54984\teval-rmse:4.04855\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.\n",
      "[1]\ttrain-rmse:3.83364\teval-rmse:3.24523\n",
      "[2]\ttrain-rmse:3.38642\teval-rmse:2.75248\n",
      "[3]\ttrain-rmse:3.10232\teval-rmse:2.43787\n",
      "[4]\ttrain-rmse:2.9311\teval-rmse:2.2665\n",
      "[5]\ttrain-rmse:2.82373\teval-rmse:2.17134\n",
      "[6]\ttrain-rmse:2.76357\teval-rmse:2.11501\n",
      "[7]\ttrain-rmse:2.71294\teval-rmse:2.0867\n",
      "[8]\ttrain-rmse:2.67229\teval-rmse:2.07375\n",
      "[9]\ttrain-rmse:2.64308\teval-rmse:2.07018\n",
      "[10]\ttrain-rmse:2.62224\teval-rmse:2.06408\n",
      "[11]\ttrain-rmse:2.59651\teval-rmse:2.07274\n",
      "[12]\ttrain-rmse:2.58388\teval-rmse:2.07926\n",
      "[13]\ttrain-rmse:2.56046\teval-rmse:2.07907\n",
      "[14]\ttrain-rmse:2.54909\teval-rmse:2.07931\n",
      "[15]\ttrain-rmse:2.53459\teval-rmse:2.08176\n",
      "[16]\ttrain-rmse:2.52524\teval-rmse:2.08472\n",
      "[17]\ttrain-rmse:2.51174\teval-rmse:2.09007\n",
      "[18]\ttrain-rmse:2.50019\teval-rmse:2.1053\n",
      "[19]\ttrain-rmse:2.49471\teval-rmse:2.10542\n",
      "[20]\ttrain-rmse:2.48068\teval-rmse:2.10325\n",
      "[21]\ttrain-rmse:2.46941\teval-rmse:2.08771\n",
      "[22]\ttrain-rmse:2.45248\teval-rmse:2.0843\n",
      "[23]\ttrain-rmse:2.44407\teval-rmse:2.08996\n",
      "[24]\ttrain-rmse:2.43625\teval-rmse:2.08492\n",
      "[25]\ttrain-rmse:2.42462\teval-rmse:2.08909\n",
      "[26]\ttrain-rmse:2.40886\teval-rmse:2.0916\n",
      "[27]\ttrain-rmse:2.40105\teval-rmse:2.10282\n",
      "[28]\ttrain-rmse:2.3901\teval-rmse:2.09791\n",
      "[29]\ttrain-rmse:2.38349\teval-rmse:2.10087\n",
      "[30]\ttrain-rmse:2.37277\teval-rmse:2.10046\n",
      "Stopping. Best iteration:\n",
      "[10]\ttrain-rmse:2.62224\teval-rmse:2.06408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_jobs': -1,\n",
    "    'reg_alpha': 10,\n",
    "    'reg_lambda':10,\n",
    "}\n",
    "\n",
    "params = {'alpha': 0.000514956253655507,\n",
    " 'colsample_bytree': 0.75,\n",
    " 'eta': 0.275,\n",
    " 'gamma': 1.5667995810928674e-08,\n",
    " 'lambda': 4.42231096547982e-06,\n",
    " 'max_depth': 6,\n",
    " 'min_child_weight': 0.6631469358878956,\n",
    " 'n_estimators': 599.0,\n",
    " 'subsample': 0.7000000000000001}\n",
    "\n",
    "evals = [(d_train_sales, 'train'), (d_val_sales, 'eval')]\n",
    "evals_result = {}\n",
    "\n",
    "model = xgb.train(params, \n",
    "          d_train_sales, \n",
    "          num_boost_round=1000, \n",
    "          evals=evals,\n",
    "          early_stopping_rounds=20,\n",
    "          evals_result=evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_metric = evals_result['train']['rmse']\n",
    "plt.plot(train_metric, label='train rmse')\n",
    "eval_metric = evals_result['eval']['rmse']\n",
    "plt.plot(eval_metric, label='eval rmse')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('rounds')\n",
    "plt.ylabel('rmse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_metric = evals_result['train']['rmse']\n",
    "plt.plot(train_metric, label='train rmse')\n",
    "eval_metric = evals_result['eval']['rmse']\n",
    "plt.plot(eval_metric, label='eval rmse')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('rounds')\n",
    "plt.ylabel('rmse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_pred_log = model.predict(d_val)\n",
    "d_pred = np.exp(d_pred_log)\n",
    "\n",
    "#plt.plot(d_pred)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(df_val_Y['Clicks'].values, label='real')\n",
    "plt.plot(d_pred, label='pred')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_pred_log = model.predict(d_val)\n",
    "d_pred = np.exp(d_pred_log)\n",
    "\n",
    "#plt.plot(d_pred)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(df_val_Y['Clicks'].values, label='real')\n",
    "plt.plot(d_pred, label='pred')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x2160 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax = plt.subplots(figsize=(15,30))\n",
    "xgb.plot_importance(model, ax=ax, importance_type='gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Clicks_0',\n",
       " 'Cost_0',\n",
       " 'Impressions_0',\n",
       " 'Audience_3',\n",
       " 'Clicks_4',\n",
       " 'CpcBid_3',\n",
       " 'Audience_4',\n",
       " 'Clicks_3',\n",
       " 'Audience_2',\n",
       " 'Cost_4',\n",
       " 'Reach_4',\n",
       " 'CpcBid_1',\n",
       " 'Audience_1',\n",
       " 'Reach_2',\n",
       " 'Reach_1',\n",
       " 'Audience_0',\n",
       " 'Reach_0',\n",
       " 'CpcBid_Y',\n",
       " 'Impressions_4',\n",
       " 'Impressions_3',\n",
       " 'UnitsKodateKen_1',\n",
       " 'Reach_3',\n",
       " 'Cost_2',\n",
       " 'OverallCompetitionWin_3',\n",
       " 'Impressions_1',\n",
       " 'CampaignId',\n",
       " 'CpcBid_2',\n",
       " 'Cost_3',\n",
       " 'OverallCompetitionWin_4',\n",
       " 'Impressions_2',\n",
       " 'Cost_1',\n",
       " 'OverallCompetitionWin_2',\n",
       " 'OverallCompetitionWin_1',\n",
       " 'Clicks_1',\n",
       " 'CpcBid_4',\n",
       " 'SalesRyutsu_2',\n",
       " 'MarketId',\n",
       " 'Clicks_2',\n",
       " 'OverallCompetitionWin_0',\n",
       " 'UnitsRent_2',\n",
       " 'CategoryId',\n",
       " 'CpcBid_0',\n",
       " 'SalesMansionBkn_4',\n",
       " 'SalesRyutsu_3',\n",
       " 'UnitsRyutsu_4',\n",
       " 'UnitsRyutsu_2',\n",
       " 'UnitsRyutsu_3',\n",
       " 'SalesRyutsu_4',\n",
       " 'UnitsSck_4',\n",
       " 'UnitsKodateBkn_4',\n",
       " 'UnitsRyutsu_1',\n",
       " 'AdvertiserId',\n",
       " 'SalesMansionBkn_1',\n",
       " 'SalesKodateKen_3',\n",
       " 'SalesSck_3',\n",
       " 'UnitsRyutsu_0',\n",
       " 'SalesRent_2',\n",
       " 'SalesRyutsu_1',\n",
       " 'SalesKodateKen_0',\n",
       " 'UnitsRent_1',\n",
       " 'UnitsKodateKen_2',\n",
       " 'UnitsRent_0',\n",
       " 'UnitsKodateKen_3',\n",
       " 'UnitsMansionBkn_3',\n",
       " 'UnitsSck_3',\n",
       " 'UnitsRent_4',\n",
       " 'UnitsSck_2',\n",
       " 'UnitsMansionBkn_4',\n",
       " 'SalesMansionBkn_3',\n",
       " 'UnitsMansionKen_2',\n",
       " 'SalesKodateKen_1',\n",
       " 'UnitsMansionBkn_1',\n",
       " 'UnitsKodateBkn_3',\n",
       " 'UnitsRent_3',\n",
       " 'UnitsMansionBkn_0',\n",
       " 'SalesRyutsu_0',\n",
       " 'UnitsKodateBkn_0',\n",
       " 'SalesKodateBkn_0',\n",
       " 'SalesMansionBkn_2',\n",
       " 'UnitsKodateBkn_2',\n",
       " 'UnitsSck_1',\n",
       " 'UnitsSck_0',\n",
       " 'UnitsMansionBkn_2',\n",
       " 'SalesSck_1',\n",
       " 'UnitsKodateKen_0',\n",
       " 'SalesRent_3',\n",
       " 'SalesKodateBkn_4',\n",
       " 'SalesRent_4',\n",
       " 'UnitsKodateBkn_1',\n",
       " 'SalesRent_0',\n",
       " 'SalesMansionBkn_0',\n",
       " 'SalesSck_0',\n",
       " 'SalesRent_1',\n",
       " 'SalesKodateBkn_1',\n",
       " 'SalesKodateBkn_2',\n",
       " 'UnitsMansionKen_3',\n",
       " 'SalesKodateKen_4',\n",
       " 'SalesKodateBkn_3',\n",
       " 'UnitsMansionKen_4',\n",
       " 'SalesMansionKen_3',\n",
       " 'UnitsMansionKen_0',\n",
       " 'UnitsKodateKen_4',\n",
       " 'SalesKodateKen_2',\n",
       " 'SalesSck_4',\n",
       " 'UnitsMansionKen_1',\n",
       " 'SalesSck_2']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = model.get_score(importance_type='gain')\n",
    "sorted(m, key=lambda x: m[x], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

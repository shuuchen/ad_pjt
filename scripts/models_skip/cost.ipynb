{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ読込"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = '../data/two_years_each/val_1/consistent'\n",
    "\n",
    "df_train_X = pd.read_excel(os.path.join(in_dir, 'train_X.xlsx'), header=0, index_col=0)\n",
    "df_train_Y = pd.read_excel(os.path.join(in_dir, 'train_Y.xlsx'), header=0, index_col=0)\n",
    "\n",
    "df_val_X = pd.read_excel(os.path.join(in_dir, 'val_X.xlsx'), header=0, index_col=0)\n",
    "df_val_Y = pd.read_excel(os.path.join(in_dir, 'val_Y.xlsx'), header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目的変数の分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dushu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xt03Hd55/H3o5FG96slx7Z8T5wEJyGmvoTdlrRAS0MvSdomJQlbwpZttt3mj909220oLbsnhXOge/ak27NZIC0BQjGBwoH6UBcTAiS0EMdyYmzLjm3Zli1ZvkjWXbKu8+wf8xsxTEbSyJLm+nmdM0czv9s8Mx7PM9+7uTsiIiJFmQ5ARESygxKCiIgASggiIhJQQhAREUAJQUREAkoIIiICKCGIiEhACUFERAAlBBERCRRnOoCFaGxs9I0bN2Y6DBGRnHLw4MEed2+a77icSggbN26kpaUl02GIiOQUMzuXynGqMhIREUAJQUREAkoIIiICKCGIiEhACUFERAAlBBERCSghiIgIoIQgInlCywEvXk4NTBMRSebvfniGv9p3gm3r6vj5Gxt57O7NlIdDmQ4r56iEICI57Uz3MH+17wQ331DFtYlpnvruST71g7ZMh5WTlBBEJGf9/Svn+P3Pt1Bk8JtvXcPDu9azY0M93z/RnenQcpISgojkrAPtvbRfHeHXbl9NdVkJAL90SxNHLgxwZWgsw9HlHiUEEclJxy8OsvfIRTY3VbJ9Q/3M9l+6ZSUAL5/syVRoOUsJQURyTu/IBH/wXAvlJSF+d8c6zGxm321ramiqLuUHJ65kMMLcpIQgIjllcjrCf/rSQa4MjfPv3r6BmqCqKMbM+MWbm3j5ZDdT05EMRZmblBBEJGe4Ox/5xhFeOdPLJ3/nDtbWVyQ97p23rGRwbIpDHf1pjjC3aRyCiGS93fvPA/D9E1d44dhl3nXrSq5NzP7r/xe2NBIqMn5wopsdGxvSFWbOUwlBRHLCkQsDvHDsMm9bV8e7b10557G15SX83Po6Xjqp7qcLoRKCiOSEH5y4wqqaMn7rbc0/04icKFaaqAwXc/BcN1/4UTsloSIeuWt9ukLNWSohiEjW6xuZ4OLAGG9bX0dxKLWvrXUNFUQcuvqvLXN0+SOld9bM7jGzE2bWZmZPJNl/t5m9ZmZTZvZA3PZ3mtmhuNuYmd0f7Pu8mZ2N27dt6V6WiOSTYxcHAdi6uiblc9bWlwPQ0aeEkKp5q4zMLAQ8DfwK0AkcMLM97n4s7rDzwAeB/xZ/rrt/H9gWXKcBaAO+E3fIn7j71xbzAkQk/x27OMgNNaWsqCpN+ZzqshLqykvo6B1dxsjySyolhF1Am7ufcfcJ4HngvvgD3L3d3Q8Dc3X6fQD4Z3fXv46IpKx3ZIL2npEFlQ5i1taX09mnr5xUpZIQmoGOuMedwbaFegj4csK2j5vZYTN7ysxST/0iUjBePH4ZB7auqV3wuesaKugbnWR4fGrpA8tDqSSEZM35C1qJwsxWA3cA++I2fxi4FdgJNAB/Osu5j5lZi5m1dHerC5lIofnOscvUlZewprZswefGBq51qtooJakkhE5gXdzjtUDXAp/nd4FvuPtkbIO7X/SoceBzRKum3sTdn3H3He6+o6mpaYFPKyK5bGxympdPdvOW1TVzdjWdTXNdOYYallOVSkI4AGwxs01mFiZa9bNngc/zMAnVRUGpAYv+K98PHF3gNUUkz/2ko5/xqQhbVlZd1/nh4iJuqClTO0KK5k0I7j4FPE60uuc48FV3bzWzJ83sXgAz22lmncCDwGfMrDV2vpltJFrCeCnh0l8ysyPAEaAR+NjiX46I5JOWc30ArF+RfM6iVKxrKKejb1RrLqcgpZHK7r4X2Juw7aNx9w8QrUpKdm47SRqh3f1dCwlURArPwXN93LSyiorw9U+qsLa+ggPtfZztGWFz0/WVNAqFRiqLSFaKRJyW9l52bqyf/+A5rG+Ili5eP6+ZT+ejhCAiWamte5jBsSm2b1jcbKVN1aWUlRRx8HzfEkWWv5QQRCQrHWjvBWDHhsWVEIrMWFdfwWvnlBDmo4QgIlnpYHsfjVVhNiyiQTlm/YoKTlweYnBscv6DC5gSgohkpZZzfezY0HBd4w8SbWioxB0OqR1hTkoIIpJ1rgyOcb53lB2LbFCOWVtfTpFFey3J7JQQRCTrxMYfbF9k+0FMWUmIW1bV8JoaluekhCAiWedQRz/h4iJuu44J7WazfUMdr5/vZzqiAWqzUUIQkaxzuLOft6yuIVy8dF9R2zfUMzw+xcnLQ0t2zXyjNZVFJGvs3n+eiDuvn+9n27q6mfWRl8L29dHxDAfP9fGW61hboRCohCAiWaV3eILxqQjNdeVLet11DeU0VoXVjjAHJQQRySqd/dGpqpvrlzYhmBlb19TyxkVVGc1GCUFEssqFvlGKi4yV1QtfEGc+t66qpq17mKnpuVb7LVxKCCKSVS70j7G6toxQ0eIHpCW6dVU1E1MR2q+OLPm184ESgohkjYg7XQPXaK5f/HQVydyyqhqA46o2SkoJQUSyRs/QOBNTEdYucYNyzE0rqwgVGScuKSEko4QgIlnjwjI1KMeUFofY3FjJG5cGl+X6uU7jEEQka1zov0ZJyGiqLl3ya8fGNJSHQxw81zfz+JG71i/5c+UqlRBEJGtc6LvGmtpyipZghtPZrKopo290krHJ6WV7jlyVUkIws3vM7ISZtZnZE0n2321mr5nZlJk9kLBv2swOBbc9cds3mdl+MztlZl8xs/DiX46I5Kqp6UjQoLw81UUxq2qi3VkvD44t6/PkonkTgpmFgKeB9wJbgYfNbGvCYeeBDwK7k1zimrtvC273xm3/JPCUu28B+oAPXUf8IpInTnePMDntSz5COdENtdGEcEkJ4U1SKSHsAtrc/Yy7TwDPA/fFH+Du7e5+GEhptIdFV7x4F/C1YNMXgPtTjlpE8s7hzujiNcudEOrKSygtLuLSgBJColQSQjPQEfe4M9iWqjIzazGzV8ws9qW/Auh396n5rmlmjwXnt3R3dy/gaUUklxy9MEC4uIjGZWhQjmdmrKopUwkhiVQSQrLWnYVMKL7e3XcAjwB/bWY3LuSa7v6Mu+9w9x1NTU0LeFoRySWHLwwse4NyzKraMi4PjuGutRHipZIQOoF1cY/XAl2pPoG7dwV/zwA/AN4G9AB1Zhbr9rqga4pIfpmcjnCsa5DmuqWfvyiZxqpSxiYjjE6op1G8VBLCAWBL0CsoDDwE7JnnHADMrN7MSoP7jcDPA8c8mpa/D8R6JD0K/ONCgxeR/HDq8nB0yutlmrIiUV1FCQD91ybT8ny5Yt6EENTzPw7sA44DX3X3VjN70szuBTCznWbWCTwIfMbMWoPT3wK0mNlPiCaAT7j7sWDfnwL/1czaiLYpfHYpX5iI5I6jFwYAlm3KikR15dFe7gOjSgjxUhqp7O57gb0J2z4ad/8A0WqfxPN+BNwxyzXPEO3BJCIF7vCFfqpKi2moSs9wpNqZEsJEWp4vV2iksohk3JHOAW5vrklLgzJAZThEcZGphJBACUFEMmpiKsLxi0O8dW1d2p7TzKgtL1EbQgIlBBHJqJOXh5iYjnB7c21an7e2ooQBJYSfoYQgIhnVdmUYiK5mlk515WH6R9WGEE8JQUQy6kz3MEUGG1akp8tpTG15CUNjU0xqfeUZSggiklGne0ZYW19BaXEorc9bV1GCo1lP4ykhiEhGnekeYXNTZdqft6482vW0q18JIUYJQUQyJhJxzvYMc2NTVdqfuzZICBcHrqX9ubOVEoKIZMzFwTHGJiMZKSHEBqfF1nEWJQQRyaAz3dEeRpsb019CKC0OUV4S4qKqjGYoIYhIxpwOupzemIESAkQblrtUQpihhCAiGXOmZ4Sq0mKalnlRnNnUlpeoyihOSpPbiYgspd37zwPwo7ar1JaX8OVXO+Y5Y3nUlpfwxqWhjDx3NlIJQUQypnt4PGOlA4C6ijAD1yYZHp+a/+ACoIQgIhkxMRVh4NokjWma8jqZ2FiEi6o2ApQQRCRDeobHgehylpkSG4vQNaCeRqCEICIZEksIma0yio1WVgkBlBBEJEO6g4SwojJzCaGqLNqvpntoPGMxZJOUEoKZ3WNmJ8yszcyeSLL/bjN7zcymzOyBuO3bzOzHZtZqZofN7H1x+z5vZmfN7FBw27Y0L0lEcsHV4QnqyksIF2fud2lxURF1FSVKCIF5u52aWQh4GvgVoBM4YGZ73P1Y3GHngQ8C/y3h9FHgA+5+yszWAAfNbJ+79wf7/8Tdv7bYFyEiuefq8Hja1lCeS2NV6Uz1VaFLJTXvAtrc/Yy7TwDPA/fFH+Du7e5+GIgkbD/p7qeC+13AFaBpSSIXkZzWOzLBisrMJ4SmqlKVEAKpJIRmIH7USGewbUHMbBcQBk7Hbf54UJX0lJllriJRRNJqfHKakYlpGioynxAaq1VCiEklIViSbb6QJzGz1cAXgX/v7rFSxIeBW4GdQAPwp7Oc+5iZtZhZS3d390KeVkSyVG+wdGVDBrucxqiE8FOpJIROYF3c47VAV6pPYGY1wD8Bf+7ur8S2u/tFjxoHPke0aupN3P0Zd9/h7juamlTbJJIPrg4HCSELqowaq8OMTEwzOqHRyqkkhAPAFjPbZGZh4CFgTyoXD47/BvCcu/9Dwr7VwV8D7geOLiRwEcldfUEJIVvaEAB6hiYyHEnmzZsQ3H0KeBzYBxwHvururWb2pJndC2BmO82sE3gQ+IyZtQan/y5wN/DBJN1Lv2RmR4AjQCPwsSV9ZSKSta6OTFBeEqKsJL3rKCcTGxjXPazRyinNdurue4G9Cds+Gnf/ANGqpMTz/h74+1mu+a4FRSoieaN3ZIIVWdDlFH46dUa3SggaqSwi6dc7MpEV7QcAK2dKCGpYVkIQkbSamo7QPzqRFV1OIdqwbQY96mmkhCAi6dXVP0bEs6OHEUBxqIiGirBKCCghiEiane8dBciKaStiGqtKVUJACUFE0uxc7wiQ2VlOEzVVl6qEgBKCiKTZ+aujFBcZ1WXZs6R7Y1VY01eghCAiaXa+d5T6ijBFlmxWnMxoqo5OX+G+oFl58o4Sgoik1bmro1nToBzTVF3K2GSEkYnpTIeSUUoIIpI27s753tGsalCG+MFphV1tpIQgImnTMzzB8PhUVsxhFC82fUWhtyMoIYhI2rRdGQZ++gWcLVRCiFJCEJG0aeuOJoSV1WUZjuRnzUxwp4QgIpIebZeHqCotpiaLupwCQa8nVRkpIYhI2rR1D3Pjyiosi7qcAoSKjBVaOU0JQUTSp+3KMDc1VWU6jKQaq7S2cnaV20Qkbw2OTXJ5cJybVmZXQti9/zwQnYX1jUtDM48fuWt9JsPKCJUQRCQtTgc9jLItIcRUlxUzNFbY6yorIYhIWrRlfUIoYXhsqqCnr0gpIZjZPWZ2wszazOyJJPvvNrPXzGzKzB5I2PeomZ0Kbo/Gbd9uZkeCa/6NZVsrk4gsqbbuYcKhItbVl2c6lKSqy4qZdme0gKevmDchmFkIeBp4L7AVeNjMtiYcdh74ILA74dwG4H8AdwG7gP9hZvXB7k8BjwFbgts91/0qRCTrtV0eZlNjJcWh7KyYqCqNNqkWcrVRKv8yu4A2dz/j7hPA88B98Qe4e7u7HwYiCef+KvCCu/e6ex/wAnCPma0Gatz9xx4tnz0H3L/YFyMi2autezhrq4sgWmUEMDQ+meFIMieVhNAMdMQ97gy2pWK2c5uD+9dzTRHJMWOT03T0jnJjFieE2GA5lRDmlqxuP9VWl9nOTfmaZvaYmbWYWUt3d3eKTysi2eRszwgRz94GZYgrISghzKkTWBf3eC3QleL1Zzu3M7g/7zXd/Rl33+HuO5qamlJ8WhHJJrEeRluyOCGEi4soLS5iaExVRnM5AGwxs01mFgYeAvakeP19wHvMrD5oTH4PsM/dLwJDZvb2oHfRB4B/vI74RSQHnLg0RKjI2NRYmelQ5lRVWthjEeZNCO4+BTxO9Mv9OPBVd281syfN7F4AM9tpZp3Ag8BnzKw1OLcX+EuiSeUA8GSwDeCPgL8D2oDTwD8v6SsTkaxxtGuALSurKCsJZTqUOVWXlRR0Qkhp6gp33wvsTdj20bj7B/jZKqD4454Fnk2yvQW4fSHBikhuOnphkF+8OfurfKvLiunqv5bpMDJGcxmJyLLZvf88g2OT9AyPMz41PTNPULaqKSvmxHjhlhCyc4SIiOSN2C/u1bXZOUI5XlVZCRNTEcanCnO0shKCiCyrrv4xANbUZtcqaclUB2MRhgu0HUEJQUSWVVf/NRqrwpRmeYMy/DQhDCohiIgsva6BazlRXQTxg9MKcyyCEoKILJvRiSn6RydprsuNhFBT4BPcKSGIyLKZaT/IkYRQHg4RMmO4QHsaKSGIyLKJ9TDKhQZlADOjqqxYVUYiIkuta+AadeUlVJTmzpCnQl5KUwlBRJbNhb5rOVNdFFPI01coIYjIsrgyNMbVkQk2rKjIdCgLUl2qKiMRkSV14GwfABtXZPcMp4mqy4oZmZhmcjpxAcj8p4QgIsviQHsvJSHLySojgJ7h8QxHkn5KCCKyLF4928v6hgpCRckWSMxesdHKlweVEEREFm3g2iTHLw2yMcsXxEmmriJaQujsG81wJOmnhCAiS+61c3245177AUBDRRiAzr7CWxdBCUFEltz+s9H2g3X1udXDCKC0JERFOERHr0oIIiKLdqC9lzuaawkX5+ZXTH1FmA6VEEREFmdscprDnf3s3NSQ6VCuW31FidoQZmNm95jZCTNrM7MnkuwvNbOvBPv3m9nGYPv7zexQ3C1iZtuCfT8Irhnbt3IpX5iIZMbr5/uZnHbuyuWEUBmms+8akYhnOpS0mjchmFkIeBp4L7AVeNjMtiYc9iGgz91vAp4CPgng7l9y923uvg34PaDd3Q/Fnff+2H53v7IEr0dEMuxAey9msH1DDieEijATUxG6C2wsQiolhF1Am7ufcfcJ4HngvoRj7gO+ENz/GvBuM0vsfPww8OXFBCsi2e/Vs73cuqqG2vKSTIdy3epnehoVVrVRKgmhGeiIe9wZbEt6jLtPAQPAioRj3sebE8Lnguqiv0iSQEQkx0xNR3jtfB+7NtZnOpRFqa+MJrOO3sJqWE4lIST7ok6sWJvzGDO7Cxh196Nx+9/v7ncA7whuv5f0yc0eM7MWM2vp7u5OIVwRyZTWrkFGJ6bZtSnx92BuiZUQCq3raSqTlHcC6+IerwW6Zjmm08yKgVqgN27/QySUDtz9QvB3yMx2E62aei7xyd39GeAZgB07dhRWC49Ijti9/zwAPzwV/dHW2Tc6sy0XlYSKaKouLbjBaamUEA4AW8xsk5mFiX6570k4Zg/waHD/AeB77u4AZlYEPEi07YFgW7GZNQb3S4DfAI4iIjmt/eooKyrDMxPE5bJ19eV0FFgbwrwlBHefMrPHgX1ACHjW3VvN7Emgxd33AJ8FvmhmbURLBg/FXeJuoNPdz8RtKwX2BckgBHwX+NsleUUikhERd9p7Rti6pibToSyJdQ0VvHa+L9NhpFVK69q5+15gb8K2j8bdHyNaCkh27g+AtydsGwG2LzBWEcli3UPjXJuczsn5i5JZW1/Otw5fZGo6QnGoMMbwFsarFJFl1351BIBNOTjDaTLr6iuYjjiXBscyHUraKCGIyJI40z1CTVkx9RW5334A0SojKKyup0oIIrJoEXfargxz08pq8mVI0dr66EpvhdSwrIQgIot2oe8a1yan2XJDVaZDWTJr6sopssJaF0EJQUQW7eSVIQzY0pQ/CaEkVMTq2nLOB20jhUAJQUQW7dTlYZrry6koTanjYs7Y1FjJ2auqMhIRScnA6CQdvaNsWVmd6VCW3OamSs52DxOMs817Sggisij/eroHB27Oo/aDmE2NlQyOTdE7MpHpUNJCCUFEFuWlE92UlRSxNgfXT55PbEzFmZ7CaEdQQhCR6+buvHyqmxubqggV5Ud303ibG6OlnrPdSggiInNq7Rrk4sAYt9yQf+0HAM315ZSErGBKCPnVJUBE0uo7rZcoMrh1dX5MaBcvNn13XUWYl092sz4YufzIXeszGdayUglBRK7bt1svsXNjA1V51t00XmNVKT0FsrayEoKIXJezPSOcvDzMr962KtOhLKvGqjC9IxNECqDrqRKCiFyXfa2XAPjV2/M7ITRVlTIVcQZGJzMdyrJTQhCR6/Lto5e4o7mW5rryTIeyrFZUlQIURLWREoKILNilgTEOdfRzT56XDiBaZQTQrYQgIvJm3zkWVBfddkOGI1l+VaXFlBYX0TOc/6OVU0oIZnaPmZ0wszYzeyLJ/lIz+0qwf7+ZbQy2bzSza2Z2KLh9Ou6c7WZ2JDjnbyxfJlEXKQD7Wi9xY1MlN+Xh/EWJzIzGqlKuqoQAZhYCngbeC2wFHjazrQmHfQjoc/ebgKeAT8btO+3u24LbH8Zt/xTwGLAluN1z/S/j+o2MT9F2ZSgTTy2Sk/7u5TP8+PRV1tZXsHv/+Zn++vmssSqsNoTALqDN3c+4+wTwPHBfwjH3AV8I7n8NePdcv/jNbDVQ4+4/9ug0gs8B9y84+iXw9PfbuP/pHxXMbIYii/XGpSEiDretyb/BaLNprCqlf3SSyelIpkNZVqmMJmkGOuIedwJ3zXaMu0+Z2QCwIti3ycxeBwaBP3f3HwbHdyZcs3nh4S/et49eYnh8is/9aztlJaGZ7fk8GlFkMVq7BqgtL8n73kXxGqtKccj7WU9TSQjJfukn/pye7ZiLwHp3v2pm24FvmtltKV4zemGzx4hWLbF+/dJ+Sbs7XQPR5fGuTU7/TEIQkTcbnZji1JVhdm5qyJu1k1PRWCBdT1OpMuoE1sU9Xgt0zXaMmRUDtUCvu4+7+1UAdz8InAZuDo5fO881Cc57xt13uPuOpqamFMJNXUfvNcYmo0XAaxPTS3ptkXz00olupiLObXk4d9FcYl1P872nUSoJ4QCwxcw2mVkYeAjYk3DMHuDR4P4DwPfc3c2sKWiUxsw2E208PuPuF4EhM3t70NbwAeAfl+D1LMjRroGZ+9cmlRBE5vPt1ktUhENsWFGZ6VDSqrQkRHVZcd6XEOatMgraBB4H9gEh4Fl3bzWzJ4EWd98DfBb4opm1Ab1EkwbA3cCTZjYFTAN/6O69wb4/Aj4PlAP/HNzS6uiFuISgEoLInPpHJ9jXeok7muvycu2D+TRWldIzVOAJAcDd9wJ7E7Z9NO7+GPBgkvO+Dnx9lmu2ALcvJNildrRrkIpwiNGJaZUQRObxDy2djE1GePvmhkyHkhGNVWGOdQ1mOoxlVbAjld2d1gsDbG6KroikEoLI7KYjzhdfOceujQ2sri2c3kXxGqtKGZmYzutJ7go2IVwaHOPqyASbVlRQZGpDEJnLSyevcL53lA/82w2ZDiVjYj2Nzl7N39XTCjYhHL0QLfo115VTXhJSCUFkDl/40TlWVpfm/doHc1kR9DQ62zOc4UiWTwEnhAGKDFbVllMeDqmEIDKLsz0jvHSym/fftYGSUMF+ZdBQGabI4Gy3Sgh5p7VrgBubqggXF0VLCEoIIkl98cfnKAkZD9+1bv6D81hxURH1FWHO9ORvQsjfhVDncaxrkF2bor0lysMhRsaVEETi7d5/nvGpaXa/eo63rK7hu8euZDqkjGusKuVsHieEgiwhuDtXhsZZHczFohKCSHKHOvoZm4zwbzavmP/gAtBYFeZsz0jeToZZkAlheHyKqYhTX1ECREsIalQW+VnuzitnrrKmtoz1DRWZDicrrKgqZXRimsuD+TlArSATQn/Qj7i+ItproLwkxNjkNJE8zfoi1+Ps1REuD47z9s0rCmoiu7nEup6eydOeRgWZEGJT2MYnBAfGJ/N7rnORhXjpRDflJSHeurYu06FkjabqaEI4nac9jQoyIfSNBgmhMlZlFG1bVzuCSNT3T1zh1JVh3nnrSsLFBfk1kVRNWTG15SV5O4VFQf5Lx6qM6uJKCKCEIAIwOR3hY986xorKcMHOWzQbM+O2NTUcu6iEkDdiJYSGWEIIBwlBDcsifOmVc5zuHuHX7lhNcVFBfkXMaevqGt64OMhUHi6nWZD/2n0jE5hBTXlQZaQSgggAY5PT/PWLp/iFmxq5dVV1psPJSlvX1DA+FcnL8QiFmRBGJ6ktL5mZ010lBJGoF49foX90kj/6pRvVs2gWt62pBaA1D9sRCjQhTMxUF4FKCCIx33j9AjfUlPJ2DUSb1eamSsLFRXnZjlCwCaEuGJQGUBIyQkWmEoIUtL6RCV46eYV771xTkCuipaokVMStq6rzsqdRYSaEkcmZMQgQ7TkQnb5iKoNRiWTWPx25yOS0c//bmjMdStbburqG1q6BvJvCoiATQv/oBPWV4Z/ZpjURpNB98/UL3HxDFVtX12Q6lKy3dU0NfaOTXBocy3QoSyqlhGBm95jZCTNrM7MnkuwvNbOvBPv3m9nGYPuvmNlBMzsS/H1X3Dk/CK55KLitXKoXNZ/e0YmZeYxitCaCFLLT3cO0nOvjvm3NakxOwW1rokmz9UJ+VRvNO/21mYWAp4FfATqBA2a2x92PxR32IaDP3W8ys4eATwLvA3qA33T3LjO7HdgHxJdH3+/uLUv0WlIyNjnN2GRkZlBaTHlJiKHx/F0rVSSZ81dH+czLp/nawU5Ki4u4b9uaTIeUE25dVYMZHLs4yC9vvSHT4SyZVNZD2AW0ufsZADN7HrgPiE8I9wH/M7j/NeD/mpm5++txx7QCZWZW6u4ZmypwZlBaYpVROMSVofwq/onMJhJxnvtxO5/49htEIvDbP9fMf3jHZtbWa1bT+ezefx6AFZVhvn300syEd4/ctT6TYS2JVBJCM9AR97gTuGu2Y9x9yswGgBVESwgxvwO8npAMPmdm08DXgY95khYaM3sMeAxg/frFv+E/ndguocpIayJIgRibnOYPnmvhh6d6eOctTezatILa8hJePdvLq2d7Mx1ezlhTVz6zNkK+VLOl0oaQ7JUmfnHPeYyZ3Ua0Guk/xu1/v7vfAbwjuP1esid392fcfYe772hqakoh3LklzmPtF7YBAAAMxklEQVQUUx4OMTYZ0RTYkve+98YVfniqhz//9bfw7Ad3UlteMv9J8iabG6sYGpuiZ3gi06EsmVRKCJ1A/GKqa4GuWY7pNLNioBboBTCztcA3gA+4++nYCe5+Ifg7ZGa7iVZNPXedryNlMzOdJmlDgOivp4pwwa4sKnksVtXx9YOdlJUUUVoc4suvdsxzlsxmc1MlEF0bITYtdq5LpYRwANhiZpvMLAw8BOxJOGYP8Ghw/wHge+7uZlYH/BPwYXf/19jBZlZsZo3B/RLgN4Cji3spqekb+dmpr2M0fYUUgog7Jy8PsWVltQafLdKKyjA1ZcWcyaO1EeZNCO4+BTxOtIfQceCr7t5qZk+a2b3BYZ8FVphZG/BfgVjX1MeBm4C/SOheWgrsM7PDwCHgAvC3S/nCZtMXqzIqT15CUDuC5LOLA2MMjU9xiyauWzQzY3NTFWfyaI3llOpG3H0vsDdh20fj7o8BDyY572PAx2a57PbUw1w6faMTVJUWv2nRDyUEKQQnLw8BsGVlVYYjyQ+bGys51NHPlaH8WGO54EYq949Ovqm6CFRlJIXhxKUhmuvKqS5TQ/JS2NwUTaxnuvNjjeWCSwi9IxNvalAGqCqNFpaGxjSfkeSn0fEpOnpHVV20hBoqw9RVlHAmT9ZGKLiE0D868aYupwAV4RDhUNFMLySRfHPqyjAO3HKDEsJS2txYxZnuESKR3G9HKLiE0Dc6SUPFm4vLZkZ9ZclMo7NIPnF39p/tpbK0mOb68kyHk1c2N1VybXI6L9ZHKLyEMJK8hADRsQmxbqki+WTPT7povzrCL79lJUV5Mqo2W9x8QzUGvHDscqZDWbSCSgiT0xGGxqeStiFAkBBGJ/KmC5kIwNDYJB//p+M015Wzc2NDpsPJO1WlxaxfUcF3lBByS2zaioYkvYwA6ivDjE9F1PVU8sr/+e4puofHuffONSodLJOtq2s4fnGQjt7RTIeyKAWVEGINxrNXGUUTRd+I2hEkP3QPjfP5H7Xzu9vXsa5BM5kul9iiQrleSiishDCSfB6jmNj2XvU0kjzx9dc6mYo4f3D3pkyHktdWVJVy66pqvtN6KdOhLEpBJYTLwWjCFVVzJwQ1LEs+cHe+cqCDnRvruWmlupout/dsvYED7b0zU+znooJKCIc7+gkXF3FjU/Jh++XhEGUlGosg+WH/2V7O9ozwvp25v3BLLnjPbauIOHz3eO5WGxXUPM8/6ezn9jU1b5rHKF5D0NNIJFfFprn+aksHZSVFDI9NzWyT5XPbmhrWN1Swe/95Hty+NicXzSmYEsLkdIQjFwbYtq5+zuPqK8NqVJacd21imqMXBrhzbd2cP4Bk6ZgZj929mUMd/fxr29VMh3NdCuaTcuLSEGOTEe5cVzvncRqLIPng9Y4+piKucQdptHv/eSIRp6asmD//5tGcLJUVTEI41NEPwNvmKyFUlDAVcbqH82M6Wyk87k5Lex/NdeWsqdM0FelUHCri7pubaL86wtkcnPCuYBLCTzr6aagMs65h7v8g9ZXRnkYdvdfSEZbIkuvsu8alwTF2bJz7x48sj50bG6gqLebF45dzrqahYBLCoY5+tq2rm7ehJ9b1tLMvt0ccSuE60N5LSci4c21dpkMpSCWhIt55SxNnekZ46oWTmQ5nQQoiIQyNTdLWPZzSf5CfJgSVECT3DI9PcbhzgLc211EWrAIo6ff2zSvYvqGev/leG8+/mjttCSklBDO7x8xOmFmbmT2RZH+pmX0l2L/fzDbG7ftwsP2Emf1qqtdcSoc7B3CHbevnTwjh4iIqS4tzfk4SKUzf+kkXE9MRdqq6KKPMjPu3NXP3zU185JtHefr7bYzlwBxp8yYEMwsBTwPvBbYCD5vZ1oTDPgT0uftNwFPAJ4NztwIPAbcB9wD/z8xCKV5zycQalO9cO3cPo5j6ihIOnuujX+MRJIccvzjI/3nxFCurSzVvURYIFRn/7/0/x7tuXcn/2neCd//vl9i9/zwD17K3W3sqJYRdQJu7n3H3CeB54L6EY+4DvhDc/xrwbotW1t8HPO/u4+5+FmgLrpfKNZfMoY5+NjVWzjqpXaKfv6mR9qsj/Prf/AsH2nuZnI4sV2giixKJOAOjk3zrcBe/86kfEXHnwR3rcnJQVD7ac6iLd96ykg/9wiYc58++cYTtf/kCjz3XwmdeOs2/nOqh7coQnX2j9I5MMDY5ndGG6FRGKjcDHXGPO4G7ZjvG3afMbABYEWx/JeHc5uD+fNdcMo/sWs/gWOpZ+c61dTyyaz2Pf/k1Hvz0j4FoVVJJkf6Tyfyu57/z9X4HTExHmA6WbrxzXR3P/N52Xjx+5fouJsvmxqYq/viXbuJC/zVe7+intWtw1plRzSD2TRP/sXjhv/wiN61MPu3OUkklIST7Fkz8+M52zGzbk5VMkv6XMLPHgMeCh8NmdmKWOBuBnln2ZTPFnV55G/c5YM/j6QlmAfL2/U63LZ9I6bDZ4t6QysmpJIROYF3c47VA1yzHdJpZMVAL9M5z7nzXBMDdnwGemS9IM2tx9x3zHZdtFHd6Ke70Utzptdi4U2lDOABsMbNNZhYm2ki8J+GYPcCjwf0HgO95tCJsD/BQ0AtpE7AFeDXFa4qISBrNW0II2gQeB/YBIeBZd281syeBFnffA3wW+KKZtREtGTwUnNtqZl8FjgFTwB+7+zRAsmsu/csTEZFUpTT9tbvvBfYmbPto3P0x4MFZzv048PFUrrlI81YrZSnFnV6KO70Ud3otKm7Ltbk2RERkeRTE1BUiIjK/nE4IZva/zOwNMztsZt8ws7q4fUmnzMgGZvagmbWaWcTMdsRt32hm18zsUHD7dCbjTDRb3MG+rH2/E5nZ/zSzC3Hv869lOqbZpHOKl6VkZu1mdiR4f1syHc9czOxZM7tiZkfjtjWY2Qtmdir4m1VzgcwS86I/1zmdEIAXgNvd/a3ASeDDMPuUGRmL8s2OAr8NvJxk32l33xbc/jDNcc0nadw58H4n81Tc+7yUbVlLJt1TvCyDdwbvb7Z33/w80c9tvCeAF919C/Bi8DibfJ43xwyL/FzndEJw9++4+1Tw8BWi4xlg9ikzsoK7H3f32QbYZa054s7q9zuHpXWKl0Ll7i8T7R0ZL346ni8A96c1qHnMEvOi5XRCSPD7wD8H95NNt9H8pjOy0yYze93MXjKzd2Q6mBTl4vv9eFDV+Gy2VQfEycX3NcaB75jZwWC2gVxzg7tfBAj+rsxwPKla1Oc6pW6nmWRm3wVWJdn1EXf/x+CYjxAd5/Cl2GlJjk9rd6pU4k7iIrDe3a+a2Xbgm2Z2m7sPLlugCa4z7oy/34nmeh3Ap4C/JBrjXwL/m+gPimyTde/rAvy8u3eZ2UrgBTN7I/hVK8tn0Z/rrE8I7v7Lc+03s0eB3wDe7T/tQ5vKdBvLar64ZzlnHBgP7h80s9PAzUDaGuWuJ26y4P1OlOrrMLO/Bb61zOFcr6x7X1Pl7l3B3ytm9g2i1V+5lBAum9lqd79oZquBrJ8x0N1nZsu73s91TlcZmdk9wJ8C97p7/Io2s02ZkdXMrCnWGGtmm4nGfSazUaUkp97v4D94zG8RbSzPRjk5xYuZVZpZdew+8B6y9z2eTfx0PI8Cs5WOs8aSfK7dPWdvRBsvO4BDwe3Tcfs+ApwGTgDvzXSsCXH/FtFff+PAZWBfsP13gFbgJ8BrwG9mOtZU4s729zvJ6/gicAQ4TPQ//upMxzRHrL9GtAfdaaLVdhmPKYWYNwef4Z8En+esjhv4MtHq2sng8/0hotP3vwicCv42ZDrOFGJe9OdaI5VFRATI8SojERFZOkoIIiICKCGIiEhACUFERAAlBBERCSghiMzDzFaZ2fNmdtrMjpnZXjO7eYHX+LPlik9kqajbqcgczMyAHwFfcPdPB9u2AdXu/sMFXGfY3auWKUyRJaESgsjc3glMxpIBgLsfAv4lWI/jaDDv//sgOlrUzF4O5qM/ambvMLNPAOXBti/N8jwiGZf1cxmJZNjtwMEk238b2AbcCTQCB8zsZeARoiO4Px5MQ1Lh7j80s8fdfVvaoha5DkoIItfnF4Avu/s00YnQXgJ2Ep1/6FkzKwG+GZQmRHKCqoxE5tYKbE+yPdnU1Hh0iue7gQvAF83sA8sYm8iSUkIQmdv3gFIz+4PYBjPbCfQB7zOzkJk1EU0Cr5rZBuCKu/8t8Fng54LTJoNSg0jWUpWRyBzc3c3st4C/Dha5HwPagf8MVBGd0dOB/+7ul4L1Of7EzCaBYSBWQngGOGxmr7n7+9P9OkRSoW6nIiICqMpIREQCSggiIgIoIYiISEAJQUREACUEEREJKCGIiAighCAiIgElBBERAeD/A6VRmlMgnePWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(np.log(df_train_Y['Cost'] + 0.00000001))\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(x):\n",
    "    return np.log(x + 0.00000001)\n",
    "\n",
    "#for c in ['Sales', 'Impressions', 'Clicks', 'Cost']:\n",
    "for c in ['Cost']:\n",
    "    df_train_Y['Cost_log'] = df_train_Y['Cost'].apply(log)\n",
    "    df_val_Y['Cost_log'] = df_val_Y['Cost'].apply(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ構造転換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dushu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\dushu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "d_train_sales = xgb.DMatrix(df_train_X, label=df_train_Y['Cost_log'])\n",
    "d_val_sales = xgb.DMatrix(df_val_X, label=df_val_Y['Cost_log'])\n",
    "\n",
    "d_val = xgb.DMatrix(df_val_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータのベイズ最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.0844124152930095e-05, 'colsample_bytree': 0.8, 'gamma': 6.488802219533368e-08, 'lambda': 8.030383949490836e-05, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 0.137828558537393, 'n_estimators': 273.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.55702\teval-rmse:5.40314                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.277\teval-rmse:4.02465                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:3.55814\teval-rmse:3.25585                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.17517\teval-rmse:2.88277                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.95755\teval-rmse:2.70882                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.82915\teval-rmse:2.64227                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.74634\teval-rmse:2.61567                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.69177\teval-rmse:2.58981                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.63301\teval-rmse:2.59408                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.59256\teval-rmse:2.58873                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.56101\teval-rmse:2.6034                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.52818\teval-rmse:2.60866                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.49407\teval-rmse:2.61278                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.46353\teval-rmse:2.6164                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.43034\teval-rmse:2.61354                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.40191\teval-rmse:2.61989                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.34697\teval-rmse:2.63145                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.32581\teval-rmse:2.64427                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.30486\teval-rmse:2.64564                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.2927\teval-rmse:2.64453                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.26874\teval-rmse:2.64908                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.24818\teval-rmse:2.65351                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.24084\teval-rmse:2.66346                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.22107\teval-rmse:2.68129                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.19532\teval-rmse:2.69316                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.18356\teval-rmse:2.69338                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.16924\teval-rmse:2.69812                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.14322\teval-rmse:2.6994                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.12545\teval-rmse:2.69489                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.10886\teval-rmse:2.70399                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.59256\teval-rmse:2.58873\n",
      "\n",
      "\n",
      "loss: 67105832.45423814                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.7555840539196823e-06, 'colsample_bytree': 0.65, 'gamma': 1.271243416943148e-06, 'lambda': 7.687575660612738e-05, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 0.30025321037356395, 'n_estimators': 270.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:5.58196\teval-rmse:5.39989                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.32289\teval-rmse:4.02141                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.61936\teval-rmse:3.25775                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.2443\teval-rmse:2.88477                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.04799\teval-rmse:2.71837                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.92511\teval-rmse:2.66813                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.8591\teval-rmse:2.62486                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.80867\teval-rmse:2.61246                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.77834\teval-rmse:2.59611                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.75961\teval-rmse:2.59613                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.73429\teval-rmse:2.59082                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.69664\teval-rmse:2.61911                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.67811\teval-rmse:2.63151                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.66323\teval-rmse:2.63374                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.64033\teval-rmse:2.64532                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.60905\teval-rmse:2.66218                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.58573\teval-rmse:2.69557                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.55487\teval-rmse:2.67896                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.53586\teval-rmse:2.68002                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.50524\teval-rmse:2.6998                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.48307\teval-rmse:2.72063                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.46148\teval-rmse:2.76226                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.4484\teval-rmse:2.76979                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.43036\teval-rmse:2.77992                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24]\ttrain-rmse:2.41443\teval-rmse:2.79243                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.40077\teval-rmse:2.78562                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.36854\teval-rmse:2.79458                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.3457\teval-rmse:2.84682                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.32065\teval-rmse:2.84975                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.30736\teval-rmse:2.84881                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.29445\teval-rmse:2.86028                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.73429\teval-rmse:2.59082\n",
      "\n",
      "\n",
      "loss: 106967788.10213758                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.005851013301756004, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.0005556331252177203, 'lambda': 2.4881856950012997e-05, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 0.2945912182421276, 'n_estimators': 984.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:7.43464\teval-rmse:7.38668                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:7.13927\teval-rmse:7.06674                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:6.8606\teval-rmse:6.76251                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:6.59888\teval-rmse:6.47726                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:6.35261\teval-rmse:6.20674                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:6.12192\teval-rmse:5.95248                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:5.90563\teval-rmse:5.71224                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:5.70329\teval-rmse:5.48527                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:5.51388\teval-rmse:5.2722                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:5.33753\teval-rmse:5.07185                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:5.1715\teval-rmse:4.88411                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:5.01658\teval-rmse:4.70814                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:4.87287\teval-rmse:4.54181                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:4.73861\teval-rmse:4.38638                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:4.61426\teval-rmse:4.24197                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:4.49892\teval-rmse:4.10684                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:4.39119\teval-rmse:3.98115                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:4.29191\teval-rmse:3.86402                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:4.19936\teval-rmse:3.75496                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:4.11347\teval-rmse:3.65182                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:4.03452\teval-rmse:3.557                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:3.96177\teval-rmse:3.46889                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.89428\teval-rmse:3.38629                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.83211\teval-rmse:3.30992                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.77515\teval-rmse:3.24106                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.72204\teval-rmse:3.17542                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.67327\teval-rmse:3.11499                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.62877\teval-rmse:3.06071                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.58712\teval-rmse:3.01075                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.54942\teval-rmse:2.96453                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.5127\teval-rmse:2.92282                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:3.48086\teval-rmse:2.88349                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.45113\teval-rmse:2.84579                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.42346\teval-rmse:2.81311                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.39847\teval-rmse:2.78214                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.37486\teval-rmse:2.75554                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.35361\teval-rmse:2.72988                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.33411\teval-rmse:2.70508                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.31568\teval-rmse:2.68329                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.29851\teval-rmse:2.66526                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.28304\teval-rmse:2.64854                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.26928\teval-rmse:2.63157                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.25577\teval-rmse:2.61648                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.2432\teval-rmse:2.60407                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:3.23127\teval-rmse:2.59126                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.2208\teval-rmse:2.58113                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:3.21018\teval-rmse:2.5721                                                                               \n",
      "\n",
      "[47]\ttrain-rmse:3.20165\teval-rmse:2.56243                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.19327\teval-rmse:2.55392                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.18502\teval-rmse:2.54568                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.17727\teval-rmse:2.53949                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.1697\teval-rmse:2.53314                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52]\ttrain-rmse:3.16283\teval-rmse:2.52616                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.15599\teval-rmse:2.52062                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.15045\teval-rmse:2.51527                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:3.14558\teval-rmse:2.51007                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.14042\teval-rmse:2.50571                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:3.13562\teval-rmse:2.5019                                                                               \n",
      "\n",
      "[58]\ttrain-rmse:3.13065\teval-rmse:2.49883                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.12593\teval-rmse:2.49572                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:3.12094\teval-rmse:2.4934                                                                               \n",
      "\n",
      "[61]\ttrain-rmse:3.11683\teval-rmse:2.48979                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:3.11169\teval-rmse:2.48829                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:3.1078\teval-rmse:2.4853                                                                                \n",
      "\n",
      "[64]\ttrain-rmse:3.1033\teval-rmse:2.48299                                                                               \n",
      "\n",
      "[65]\ttrain-rmse:3.09913\teval-rmse:2.48224                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:3.09586\teval-rmse:2.48087                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:3.09307\teval-rmse:2.47921                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:3.08879\teval-rmse:2.47865                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:3.08522\teval-rmse:2.47747                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:3.08237\teval-rmse:2.47587                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:3.07916\teval-rmse:2.475                                                                                \n",
      "\n",
      "[72]\ttrain-rmse:3.07559\teval-rmse:2.47436                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:3.07135\teval-rmse:2.47533                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:3.06897\teval-rmse:2.47439                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:3.06587\teval-rmse:2.47402                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:3.06343\teval-rmse:2.47295                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:3.06021\teval-rmse:2.4717                                                                               \n",
      "\n",
      "[78]\ttrain-rmse:3.0578\teval-rmse:2.47094                                                                               \n",
      "\n",
      "[79]\ttrain-rmse:3.0546\teval-rmse:2.46982                                                                               \n",
      "\n",
      "[80]\ttrain-rmse:3.05105\teval-rmse:2.46808                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:3.04896\teval-rmse:2.46683                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:3.04693\teval-rmse:2.46742                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:3.04337\teval-rmse:2.46918                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:3.04044\teval-rmse:2.46826                                                                              \n",
      "\n",
      "[85]\ttrain-rmse:3.03849\teval-rmse:2.46893                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:3.0364\teval-rmse:2.468                                                                                 \n",
      "\n",
      "[87]\ttrain-rmse:3.03376\teval-rmse:2.46722                                                                              \n",
      "\n",
      "[88]\ttrain-rmse:3.03083\teval-rmse:2.46697                                                                              \n",
      "\n",
      "[89]\ttrain-rmse:3.02819\teval-rmse:2.46634                                                                              \n",
      "\n",
      "[90]\ttrain-rmse:3.02591\teval-rmse:2.46436                                                                              \n",
      "\n",
      "[91]\ttrain-rmse:3.02396\teval-rmse:2.46452                                                                              \n",
      "\n",
      "[92]\ttrain-rmse:3.02216\teval-rmse:2.46386                                                                              \n",
      "\n",
      "[93]\ttrain-rmse:3.02052\teval-rmse:2.4624                                                                               \n",
      "\n",
      "[94]\ttrain-rmse:3.01969\teval-rmse:2.46157                                                                              \n",
      "\n",
      "[95]\ttrain-rmse:3.01626\teval-rmse:2.46371                                                                              \n",
      "\n",
      "[96]\ttrain-rmse:3.0152\teval-rmse:2.46355                                                                               \n",
      "\n",
      "[97]\ttrain-rmse:3.01234\teval-rmse:2.46387                                                                              \n",
      "\n",
      "[98]\ttrain-rmse:3.01049\teval-rmse:2.4651                                                                               \n",
      "\n",
      "[99]\ttrain-rmse:3.00892\teval-rmse:2.46411                                                                              \n",
      "\n",
      "loss: 88161497.49864201                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0006789593520338962, 'colsample_bytree': 0.8, 'gamma': 0.005429453327551454, 'lambda': 0.16684469165016214, 'learning_rate': 0.25, 'max_depth': 4, 'min_child_weight': 0.3503674930149482, 'n_estimators': 636.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:6.23102\teval-rmse:6.05927                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.17755\teval-rmse:4.86205                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.46326\teval-rmse:4.01931                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.99965\teval-rmse:3.45875                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.70623\teval-rmse:3.08687                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.52122\teval-rmse:2.85162                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.40786\teval-rmse:2.70828                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.33806\teval-rmse:2.61742                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.29296\teval-rmse:2.55807                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.26326\teval-rmse:2.52386                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.24092\teval-rmse:2.50561                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.21907\teval-rmse:2.49084                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.20599\teval-rmse:2.48862                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\ttrain-rmse:3.19477\teval-rmse:2.48122                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.18265\teval-rmse:2.4828                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:3.17137\teval-rmse:2.47947                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.16257\teval-rmse:2.48242                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.15698\teval-rmse:2.48331                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.15097\teval-rmse:2.48962                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.14603\teval-rmse:2.48918                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.13617\teval-rmse:2.48513                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.12693\teval-rmse:2.481                                                                                \n",
      "\n",
      "[22]\ttrain-rmse:3.11971\teval-rmse:2.47711                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.1109\teval-rmse:2.48233                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:3.10622\teval-rmse:2.4827                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.1008\teval-rmse:2.48328                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:3.09704\teval-rmse:2.48091                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.09076\teval-rmse:2.48071                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.08715\teval-rmse:2.47979                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.08244\teval-rmse:2.47975                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.07688\teval-rmse:2.4818                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:3.07253\teval-rmse:2.48816                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.06994\teval-rmse:2.48593                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.06526\teval-rmse:2.49214                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.05939\teval-rmse:2.49309                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.05527\teval-rmse:2.49686                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.0503\teval-rmse:2.49536                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:3.04714\teval-rmse:2.4956                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:3.04471\teval-rmse:2.49366                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.03901\teval-rmse:2.49769                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.03552\teval-rmse:2.49593                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.03376\teval-rmse:2.49564                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.03057\teval-rmse:2.49596                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[22]\ttrain-rmse:3.11971\teval-rmse:2.47711\n",
      "\n",
      "\n",
      "loss: 88905504.10907248                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.2610954919137062e-06, 'colsample_bytree': 0.65, 'gamma': 0.035830858910217624, 'lambda': 0.0005363196813551141, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 3.677265913444196, 'n_estimators': 503.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:6.16843\teval-rmse:6.0385                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.04805\teval-rmse:4.82967                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.27876\teval-rmse:3.98109                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.7532\teval-rmse:3.41646                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.40481\teval-rmse:3.058                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:3.16569\teval-rmse:2.83869                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.01926\teval-rmse:2.71101                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.91327\teval-rmse:2.63154                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.83519\teval-rmse:2.5841                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.78897\teval-rmse:2.55287                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.75723\teval-rmse:2.53349                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.72211\teval-rmse:2.52497                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.69251\teval-rmse:2.51037                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.66337\teval-rmse:2.51664                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.63598\teval-rmse:2.52069                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.61385\teval-rmse:2.5075                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.58893\teval-rmse:2.50285                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.57592\teval-rmse:2.49452                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.54951\teval-rmse:2.50131                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.53555\teval-rmse:2.49945                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.50984\teval-rmse:2.50378                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.49378\teval-rmse:2.50723                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.47872\teval-rmse:2.50456                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.45739\teval-rmse:2.50909                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.445\teval-rmse:2.51798                                                                                \n",
      "\n",
      "[25]\ttrain-rmse:2.43567\teval-rmse:2.51914                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.41166\teval-rmse:2.53774                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.40656\teval-rmse:2.53879                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.39377\teval-rmse:2.54055                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.36647\teval-rmse:2.54313                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttrain-rmse:2.35505\teval-rmse:2.54358                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.33479\teval-rmse:2.55191                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.32233\teval-rmse:2.56163                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.31665\teval-rmse:2.56155                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.30459\teval-rmse:2.56458                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.28952\teval-rmse:2.57245                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.25784\teval-rmse:2.5704                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.24995\teval-rmse:2.57557                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:2.57592\teval-rmse:2.49452\n",
      "\n",
      "\n",
      "loss: 67351509.98319286                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.4893170001188832e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.23022121820616964, 'lambda': 0.007322273030591957, 'learning_rate': 0.15000000000000002, 'max_depth': 5, 'min_child_weight': 2.6160686969367206, 'n_estimators': 857.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.81604\teval-rmse:6.7212                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.05047\teval-rmse:5.88172                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.42763\teval-rmse:5.18643                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.9247\teval-rmse:4.60956                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:4.52291\teval-rmse:4.14748                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.20547\teval-rmse:3.77516                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.95791\teval-rmse:3.47139                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.76474\teval-rmse:3.23856                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.61706\teval-rmse:3.05247                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.50205\teval-rmse:2.9106                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.41317\teval-rmse:2.79801                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.34462\teval-rmse:2.71248                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.29136\teval-rmse:2.64661                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.25171\teval-rmse:2.60316                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.22049\teval-rmse:2.57436                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.19453\teval-rmse:2.54886                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.17349\teval-rmse:2.53122                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.15756\teval-rmse:2.51643                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.14083\teval-rmse:2.50012                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.12878\teval-rmse:2.49287                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.11679\teval-rmse:2.48512                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.10745\teval-rmse:2.47749                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.09682\teval-rmse:2.47623                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.08765\teval-rmse:2.47337                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.07935\teval-rmse:2.47032                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.06984\teval-rmse:2.46823                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.05892\teval-rmse:2.4761                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:3.05481\teval-rmse:2.47725                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.04806\teval-rmse:2.47679                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.03923\teval-rmse:2.4789                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:3.03157\teval-rmse:2.48643                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.02724\teval-rmse:2.48683                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.02246\teval-rmse:2.48426                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.01688\teval-rmse:2.48578                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.01335\teval-rmse:2.4817                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:3.00419\teval-rmse:2.477                                                                                \n",
      "\n",
      "[36]\ttrain-rmse:3.00058\teval-rmse:2.47616                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.99434\teval-rmse:2.47526                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.98985\teval-rmse:2.48136                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.98509\teval-rmse:2.48147                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.98147\teval-rmse:2.48275                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.97712\teval-rmse:2.48213                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.96907\teval-rmse:2.47568                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.96661\teval-rmse:2.47478                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.96364\teval-rmse:2.47371                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.95983\teval-rmse:2.4766                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[25]\ttrain-rmse:3.06984\teval-rmse:2.46823\n",
      "\n",
      "\n",
      "loss: 78166701.12430207                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.17047019433857732, 'colsample_bytree': 0.75, 'gamma': 0.10494236541614207, 'lambda': 0.014278466366709206, 'learning_rate': 0.30000000000000004, 'max_depth': 5, 'min_child_weight': 1.8584193201792474, 'n_estimators': 795.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.92151\teval-rmse:5.7338                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.7661\teval-rmse:4.42164                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.0665\teval-rmse:3.5984                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:3.66119\teval-rmse:3.10751                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.43759\teval-rmse:2.82046                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.30904\teval-rmse:2.66566                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.23966\teval-rmse:2.57759                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.19323\teval-rmse:2.536                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:3.16434\teval-rmse:2.50326                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.14316\teval-rmse:2.49535                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.12304\teval-rmse:2.49194                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.10145\teval-rmse:2.49544                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.08794\teval-rmse:2.49468                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.0815\teval-rmse:2.49768                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.06392\teval-rmse:2.49279                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.05094\teval-rmse:2.49194                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.0425\teval-rmse:2.49701                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:3.03712\teval-rmse:2.49863                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.03132\teval-rmse:2.49919                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.02189\teval-rmse:2.49744                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.01169\teval-rmse:2.49398                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.99949\teval-rmse:2.51193                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.98614\teval-rmse:2.51403                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.97583\teval-rmse:2.52262                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.96483\teval-rmse:2.5268                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.95843\teval-rmse:2.52465                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.95198\teval-rmse:2.51707                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.94344\teval-rmse:2.51886                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.93144\teval-rmse:2.51088                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.92298\teval-rmse:2.51374                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.91312\teval-rmse:2.5095                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.90524\teval-rmse:2.51185                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.89913\teval-rmse:2.51116                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.8963\teval-rmse:2.51638                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:2.88847\teval-rmse:2.51599                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.88291\teval-rmse:2.52374                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:3.05094\teval-rmse:2.49194\n",
      "\n",
      "\n",
      "loss: 74983728.16658808                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.015489544013970073, 'colsample_bytree': 0.65, 'gamma': 0.0007283934950891877, 'lambda': 0.5660004394220454, 'learning_rate': 0.2, 'max_depth': 5, 'min_child_weight': 0.6127785992313385, 'n_estimators': 275.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:6.51692\teval-rmse:6.38351                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.58221\teval-rmse:5.34082                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.87965\teval-rmse:4.5445                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:4.36474\teval-rmse:3.93772                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.99637\teval-rmse:3.49769                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.73552\teval-rmse:3.18335                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.55401\teval-rmse:2.95776                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.42685\teval-rmse:2.80511                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.34032\teval-rmse:2.69404                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.27914\teval-rmse:2.61434                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.23425\teval-rmse:2.56461                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.20535\teval-rmse:2.53178                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.17989\teval-rmse:2.51653                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.16154\teval-rmse:2.50184                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.14758\teval-rmse:2.49182                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.13273\teval-rmse:2.48852                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.11968\teval-rmse:2.48887                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.10749\teval-rmse:2.47973                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.09639\teval-rmse:2.48152                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.08645\teval-rmse:2.48232                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.07504\teval-rmse:2.47467                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.06782\teval-rmse:2.4794                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-rmse:3.05915\teval-rmse:2.48715                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.05064\teval-rmse:2.49795                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.04418\teval-rmse:2.49379                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.03663\teval-rmse:2.4945                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:3.02778\teval-rmse:2.49607                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.02421\teval-rmse:2.49445                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.01392\teval-rmse:2.50105                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.00598\teval-rmse:2.50481                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.99925\teval-rmse:2.51016                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.99396\teval-rmse:2.50756                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.99112\teval-rmse:2.50687                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.988\teval-rmse:2.50615                                                                                \n",
      "\n",
      "[34]\ttrain-rmse:2.98338\teval-rmse:2.51217                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.97373\teval-rmse:2.51722                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.96983\teval-rmse:2.51603                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.96561\teval-rmse:2.52328                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.95948\teval-rmse:2.52289                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.955\teval-rmse:2.51841                                                                                \n",
      "\n",
      "[40]\ttrain-rmse:2.94885\teval-rmse:2.51456                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[20]\ttrain-rmse:3.07504\teval-rmse:2.47467\n",
      "\n",
      "\n",
      "loss: 89606649.42480072                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.057222216463598714, 'colsample_bytree': 0.9, 'gamma': 0.007054157820564589, 'lambda': 0.009058743555981462, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 2.666448097959661, 'n_estimators': 135.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:7.11871\teval-rmse:7.0447                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.56269\teval-rmse:6.44261                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:6.07353\teval-rmse:5.90533                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:5.64386\teval-rmse:5.43092                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:5.26737\teval-rmse:5.00876                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.94067\teval-rmse:4.64202                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.65608\teval-rmse:4.3247                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:4.41277\teval-rmse:4.04923                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:4.20047\teval-rmse:3.80538                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:4.02118\teval-rmse:3.59515                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.86821\teval-rmse:3.41678                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.73487\teval-rmse:3.26359                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.62153\teval-rmse:3.13373                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.5273\teval-rmse:3.0229                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:3.44892\teval-rmse:2.93152                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.3816\teval-rmse:2.85156                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.3228\teval-rmse:2.78682                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:3.27358\teval-rmse:2.73363                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.23023\teval-rmse:2.69028                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.19527\teval-rmse:2.65069                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.16298\teval-rmse:2.61898                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.13659\teval-rmse:2.59647                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.11134\teval-rmse:2.57246                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.09325\teval-rmse:2.55272                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.07352\teval-rmse:2.54145                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.05737\teval-rmse:2.5302                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:3.04308\teval-rmse:2.5202                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:3.02986\teval-rmse:2.517                                                                                \n",
      "\n",
      "[28]\ttrain-rmse:3.01911\teval-rmse:2.51387                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.00555\teval-rmse:2.50907                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.9981\teval-rmse:2.50376                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.98479\teval-rmse:2.50026                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.97706\teval-rmse:2.49421                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.97027\teval-rmse:2.49005                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.96107\teval-rmse:2.49709                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.9565\teval-rmse:2.49563                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.95096\teval-rmse:2.49471                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.94552\teval-rmse:2.49107                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.93751\teval-rmse:2.48845                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.93208\teval-rmse:2.48548                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.92453\teval-rmse:2.48224                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41]\ttrain-rmse:2.9202\teval-rmse:2.47768                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:2.9145\teval-rmse:2.47739                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:2.90911\teval-rmse:2.47791                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.90306\teval-rmse:2.47619                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.89316\teval-rmse:2.4778                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.88776\teval-rmse:2.47634                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.88272\teval-rmse:2.47631                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.87643\teval-rmse:2.4758                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:2.86951\teval-rmse:2.47217                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.86448\teval-rmse:2.46996                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.86186\teval-rmse:2.46953                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.85511\teval-rmse:2.46995                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.84673\teval-rmse:2.4724                                                                               \n",
      "\n",
      "[54]\ttrain-rmse:2.83993\teval-rmse:2.47513                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.83613\teval-rmse:2.47388                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.83018\teval-rmse:2.4765                                                                               \n",
      "\n",
      "[57]\ttrain-rmse:2.82461\teval-rmse:2.47713                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.82071\teval-rmse:2.47875                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.81669\teval-rmse:2.48065                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.81511\teval-rmse:2.48036                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.80952\teval-rmse:2.48026                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.80477\teval-rmse:2.48252                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.80174\teval-rmse:2.48193                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.79551\teval-rmse:2.4798                                                                               \n",
      "\n",
      "[65]\ttrain-rmse:2.79107\teval-rmse:2.48131                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.78435\teval-rmse:2.48237                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.77906\teval-rmse:2.4817                                                                               \n",
      "\n",
      "[68]\ttrain-rmse:2.77343\teval-rmse:2.48312                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.76958\teval-rmse:2.48527                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:2.76496\teval-rmse:2.48212                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:2.76048\teval-rmse:2.48711                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[51]\ttrain-rmse:2.86186\teval-rmse:2.46953\n",
      "\n",
      "\n",
      "loss: 73050734.46002823                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.02978334511443684, 'colsample_bytree': 0.75, 'gamma': 2.8470083134004705e-08, 'lambda': 3.4692360268261777, 'learning_rate': 0.30000000000000004, 'max_depth': 8, 'min_child_weight': 5.635528595361697, 'n_estimators': 378.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:5.88481\teval-rmse:5.71713                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.68511\teval-rmse:4.4033                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.93313\teval-rmse:3.57975                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.48315\teval-rmse:3.08577                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.21752\teval-rmse:2.81872                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.05412\teval-rmse:2.66512                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.96179\teval-rmse:2.59423                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.89843\teval-rmse:2.56054                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.85274\teval-rmse:2.53598                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.82048\teval-rmse:2.52175                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.78634\teval-rmse:2.527                                                                                \n",
      "\n",
      "[11]\ttrain-rmse:2.744\teval-rmse:2.55347                                                                                \n",
      "\n",
      "[12]\ttrain-rmse:2.72016\teval-rmse:2.56261                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.68559\teval-rmse:2.56458                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.66556\teval-rmse:2.5625                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.65372\teval-rmse:2.56816                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.63918\teval-rmse:2.5706                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.62296\teval-rmse:2.57077                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.60039\teval-rmse:2.57108                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.57954\teval-rmse:2.56924                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.56855\teval-rmse:2.57726                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.55937\teval-rmse:2.57817                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.54655\teval-rmse:2.58684                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.52605\teval-rmse:2.59216                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.51201\teval-rmse:2.59721                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.48317\teval-rmse:2.60461                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.46294\teval-rmse:2.60941                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.44723\teval-rmse:2.61617                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.42421\teval-rmse:2.64447                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29]\ttrain-rmse:2.40724\teval-rmse:2.64564                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.82048\teval-rmse:2.52175\n",
      "\n",
      "\n",
      "loss: 72180501.45958517                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.461068748850531e-08, 'colsample_bytree': 0.9500000000000001, 'gamma': 6.535778327693953e-05, 'lambda': 2.774032170492528, 'learning_rate': 0.17500000000000002, 'max_depth': 9, 'min_child_weight': 0.34367946858167586, 'n_estimators': 524.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:6.6267\teval-rmse:6.54285                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.72173\teval-rmse:5.59769                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.00524\teval-rmse:4.84639                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.43789\teval-rmse:4.24786                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.99278\teval-rmse:3.78917                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.65253\teval-rmse:3.44388                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.38863\teval-rmse:3.18216                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.17915\teval-rmse:2.98749                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.02023\teval-rmse:2.8539                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.89709\teval-rmse:2.75226                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.80486\teval-rmse:2.68321                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.72655\teval-rmse:2.62817                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.65826\teval-rmse:2.60607                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.60664\teval-rmse:2.58621                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.56408\teval-rmse:2.57572                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.53017\teval-rmse:2.55677                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.50024\teval-rmse:2.551                                                                                \n",
      "\n",
      "[17]\ttrain-rmse:2.46826\teval-rmse:2.54736                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.43557\teval-rmse:2.5469                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.41162\teval-rmse:2.55049                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.38492\teval-rmse:2.55031                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.37205\teval-rmse:2.54829                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.35576\teval-rmse:2.54727                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.33384\teval-rmse:2.54717                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.31995\teval-rmse:2.53929                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.28272\teval-rmse:2.53707                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.26968\teval-rmse:2.53982                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.25133\teval-rmse:2.54473                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.22056\teval-rmse:2.55072                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.20576\teval-rmse:2.55285                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.17838\teval-rmse:2.55883                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.16679\teval-rmse:2.55582                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.15247\teval-rmse:2.5606                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.13822\teval-rmse:2.56396                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.1161\teval-rmse:2.57151                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:2.09035\teval-rmse:2.57124                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.07668\teval-rmse:2.57158                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.05406\teval-rmse:2.57358                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.03597\teval-rmse:2.58176                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.02684\teval-rmse:2.58237                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.00823\teval-rmse:2.5866                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.00231\teval-rmse:2.58722                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:1.98751\teval-rmse:2.5831                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:1.97682\teval-rmse:2.57847                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:1.96918\teval-rmse:2.57548                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:1.95275\teval-rmse:2.57688                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[25]\ttrain-rmse:2.28272\teval-rmse:2.53707\n",
      "\n",
      "\n",
      "loss: 67368438.8938029                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.016841515818269e-06, 'colsample_bytree': 0.8, 'gamma': 2.4214542035394003e-06, 'lambda': 0.08003619711742263, 'learning_rate': 0.35000000000000003, 'max_depth': 4, 'min_child_weight': 8.518117470212935, 'n_estimators': 193.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:5.65958\teval-rmse:5.4161                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.47204\teval-rmse:4.03729                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.83845\teval-rmse:3.25169                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.52564\teval-rmse:2.85109                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.3704\teval-rmse:2.66379                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-rmse:3.2942\teval-rmse:2.55519                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.25195\teval-rmse:2.51524                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.2279\teval-rmse:2.49378                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.20826\teval-rmse:2.49556                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.19654\teval-rmse:2.48771                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.18264\teval-rmse:2.4821                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.17155\teval-rmse:2.48079                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.15933\teval-rmse:2.48999                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.15631\teval-rmse:2.48547                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.14998\teval-rmse:2.48238                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.13752\teval-rmse:2.48145                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.13017\teval-rmse:2.49194                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.12406\teval-rmse:2.49762                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.11845\teval-rmse:2.49362                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.11046\teval-rmse:2.49454                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.10584\teval-rmse:2.49462                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.09945\teval-rmse:2.50743                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.08982\teval-rmse:2.50474                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.08425\teval-rmse:2.5266                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:3.07688\teval-rmse:2.51602                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.06945\teval-rmse:2.52047                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.06143\teval-rmse:2.51826                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.05745\teval-rmse:2.51668                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.05091\teval-rmse:2.5197                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:3.04608\teval-rmse:2.52372                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.03843\teval-rmse:2.51963                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.03056\teval-rmse:2.51849                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:3.17155\teval-rmse:2.48079\n",
      "\n",
      "\n",
      "loss: 94862157.02678417                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.008177572007879122, 'colsample_bytree': 0.75, 'gamma': 0.42710311505432663, 'lambda': 5.025389208979118e-06, 'learning_rate': 0.17500000000000002, 'max_depth': 4, 'min_child_weight': 6.9524929812576906, 'n_estimators': 200.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:6.67512\teval-rmse:6.55229                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.82942\teval-rmse:5.61067                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.1707\teval-rmse:4.86216                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:4.66211\teval-rmse:4.27203                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.27933\teval-rmse:3.81537                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.99104\teval-rmse:3.46814                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.77933\teval-rmse:3.19775                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.62508\teval-rmse:2.99523                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.51214\teval-rmse:2.85104                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.4308\teval-rmse:2.74561                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.37054\teval-rmse:2.6696                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.32754\teval-rmse:2.61851                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.29564\teval-rmse:2.57695                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.27193\teval-rmse:2.55112                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.25197\teval-rmse:2.52896                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.23692\teval-rmse:2.51687                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.22265\teval-rmse:2.50722                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.20806\teval-rmse:2.50583                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.19663\teval-rmse:2.50053                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.18896\teval-rmse:2.49763                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.18117\teval-rmse:2.49387                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.17454\teval-rmse:2.49043                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.16905\teval-rmse:2.49008                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.16185\teval-rmse:2.48969                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.15448\teval-rmse:2.48776                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.14607\teval-rmse:2.48076                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.14164\teval-rmse:2.47685                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.13801\teval-rmse:2.47367                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.13304\teval-rmse:2.47432                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.12755\teval-rmse:2.47045                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.12119\teval-rmse:2.47253                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.11642\teval-rmse:2.47783                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.11302\teval-rmse:2.47829                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\ttrain-rmse:3.10738\teval-rmse:2.48016                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.10549\teval-rmse:2.47924                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.10084\teval-rmse:2.47669                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.09818\teval-rmse:2.47351                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.0942\teval-rmse:2.47482                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:3.0896\teval-rmse:2.47947                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:3.08624\teval-rmse:2.48411                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.0835\teval-rmse:2.48321                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:3.0789\teval-rmse:2.48197                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:3.07693\teval-rmse:2.48118                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.07124\teval-rmse:2.47876                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.06758\teval-rmse:2.4713                                                                               \n",
      "\n",
      "[45]\ttrain-rmse:3.06336\teval-rmse:2.47377                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.05979\teval-rmse:2.47227                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.05484\teval-rmse:2.47252                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.05086\teval-rmse:2.47309                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.04935\teval-rmse:2.47359                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[29]\ttrain-rmse:3.12755\teval-rmse:2.47045\n",
      "\n",
      "\n",
      "loss: 89737391.50626312                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.065512224579755e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.15460734455236558, 'lambda': 2.675321595346888e-06, 'learning_rate': 0.25, 'max_depth': 4, 'min_child_weight': 0.3120334123804587, 'n_estimators': 659.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.23079\teval-rmse:6.06354                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.17759\teval-rmse:4.87471                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.4657\teval-rmse:4.04828                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:4.0022\teval-rmse:3.47931                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.70494\teval-rmse:3.10962                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.5201\teval-rmse:2.87499                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.40663\teval-rmse:2.72503                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.33092\teval-rmse:2.63935                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.28621\teval-rmse:2.57707                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.25694\teval-rmse:2.53996                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.23411\teval-rmse:2.5204                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.2178\teval-rmse:2.50926                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.20293\teval-rmse:2.49929                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.19271\teval-rmse:2.49328                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.18554\teval-rmse:2.48708                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.17277\teval-rmse:2.48027                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.16577\teval-rmse:2.47544                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.15557\teval-rmse:2.47312                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.14866\teval-rmse:2.46825                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.14351\teval-rmse:2.47356                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.13711\teval-rmse:2.47126                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.1286\teval-rmse:2.47833                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:3.12007\teval-rmse:2.47532                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.1159\teval-rmse:2.47523                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:3.10881\teval-rmse:2.47764                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.10448\teval-rmse:2.4732                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:3.09493\teval-rmse:2.4668                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:3.08899\teval-rmse:2.47452                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.08524\teval-rmse:2.47933                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.07922\teval-rmse:2.48185                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.07641\teval-rmse:2.48044                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.07228\teval-rmse:2.48193                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.06679\teval-rmse:2.48438                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.06259\teval-rmse:2.48449                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.05618\teval-rmse:2.48629                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.05003\teval-rmse:2.48402                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.04517\teval-rmse:2.47587                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.04275\teval-rmse:2.47918                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.03617\teval-rmse:2.48077                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.03138\teval-rmse:2.47574                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.02716\teval-rmse:2.47838                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.0245\teval-rmse:2.47836                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:3.02001\teval-rmse:2.48961                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43]\ttrain-rmse:3.01407\teval-rmse:2.49424                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.011\teval-rmse:2.49347                                                                                \n",
      "\n",
      "[45]\ttrain-rmse:3.00583\teval-rmse:2.49531                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.00541\teval-rmse:2.49544                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[26]\ttrain-rmse:3.09493\teval-rmse:2.4668\n",
      "\n",
      "\n",
      "loss: 80024971.11686586                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.9890632364655563e-08, 'colsample_bytree': 0.8500000000000001, 'gamma': 7.646410354847015e-05, 'lambda': 0.00020359952493890314, 'learning_rate': 0.15000000000000002, 'max_depth': 7, 'min_child_weight': 0.15816573116480986, 'n_estimators': 494.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:6.79996\teval-rmse:6.70947                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.01734\teval-rmse:5.86524                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.3754\teval-rmse:5.16373                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:4.85427\teval-rmse:4.58954                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.43546\teval-rmse:4.12808                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.09821\teval-rmse:3.75792                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.83367\teval-rmse:3.46429                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.62782\teval-rmse:3.23331                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.46519\teval-rmse:3.05372                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.33646\teval-rmse:2.9162                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.23663\teval-rmse:2.81458                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.1595\teval-rmse:2.73134                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.09809\teval-rmse:2.67033                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.04735\teval-rmse:2.62457                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.00316\teval-rmse:2.59618                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.9707\teval-rmse:2.57028                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.9417\teval-rmse:2.55913                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.91603\teval-rmse:2.54733                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.89112\teval-rmse:2.54533                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.87146\teval-rmse:2.53592                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.85319\teval-rmse:2.52737                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.83591\teval-rmse:2.52337                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.82604\teval-rmse:2.52551                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.80963\teval-rmse:2.52535                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.79603\teval-rmse:2.52501                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.78347\teval-rmse:2.52044                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.77272\teval-rmse:2.52038                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.76141\teval-rmse:2.51816                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.74784\teval-rmse:2.5347                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.73548\teval-rmse:2.53058                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.72934\teval-rmse:2.53081                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.72231\teval-rmse:2.53505                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.71878\teval-rmse:2.53097                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.70791\teval-rmse:2.5323                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:2.69305\teval-rmse:2.52339                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.67842\teval-rmse:2.52084                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.67252\teval-rmse:2.52424                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.66657\teval-rmse:2.52458                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.65693\teval-rmse:2.52714                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.65048\teval-rmse:2.52725                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.64311\teval-rmse:2.52831                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.63839\teval-rmse:2.52849                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.62695\teval-rmse:2.5265                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:2.61821\teval-rmse:2.52405                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.61168\teval-rmse:2.52886                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.60131\teval-rmse:2.53197                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.58901\teval-rmse:2.53638                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.58031\teval-rmse:2.54065                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[27]\ttrain-rmse:2.76141\teval-rmse:2.51816\n",
      "\n",
      "\n",
      "loss: 74866396.84593259                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.246834545736269e-05, 'colsample_bytree': 0.75, 'gamma': 1.7417076859836084e-07, 'lambda': 8.75975584632451e-06, 'learning_rate': 0.375, 'max_depth': 7, 'min_child_weight': 0.7650573817697599, 'n_estimators': 582.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:5.45208\teval-rmse:5.24336                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.18892\teval-rmse:3.82535                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.54805\teval-rmse:3.09177                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.23051\teval-rmse:2.73675                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.07034\teval-rmse:2.59785                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.97841\teval-rmse:2.55249                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.92173\teval-rmse:2.52688                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.89058\teval-rmse:2.51013                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.86686\teval-rmse:2.5063                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.82524\teval-rmse:2.52432                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.79743\teval-rmse:2.52641                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.7821\teval-rmse:2.53046                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.7562\teval-rmse:2.52169                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.73891\teval-rmse:2.5213                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.71361\teval-rmse:2.51915                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.69469\teval-rmse:2.52645                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.67688\teval-rmse:2.53848                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.66197\teval-rmse:2.53173                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.637\teval-rmse:2.5553                                                                                 \n",
      "\n",
      "[19]\ttrain-rmse:2.62236\teval-rmse:2.55729                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.60443\teval-rmse:2.56536                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.59105\teval-rmse:2.57137                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.55865\teval-rmse:2.57903                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.52978\teval-rmse:2.58574                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.51364\teval-rmse:2.59582                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.49845\teval-rmse:2.6057                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.48171\teval-rmse:2.61169                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.47675\teval-rmse:2.6093                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.45884\teval-rmse:2.60537                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.86686\teval-rmse:2.5063\n",
      "\n",
      "\n",
      "loss: 77656187.40221108                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.516563957097081e-06, 'colsample_bytree': 0.8, 'gamma': 0.006808665832658476, 'lambda': 3.871169301569916e-05, 'learning_rate': 0.125, 'max_depth': 6, 'min_child_weight': 0.20918704517774042, 'n_estimators': 748.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:6.96376\teval-rmse:6.88249                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.29378\teval-rmse:6.1521                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:5.72401\teval-rmse:5.52442                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:5.24456\teval-rmse:4.98798                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.84102\teval-rmse:4.54202                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.50346\teval-rmse:4.16084                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.22715\teval-rmse:3.83879                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.9998\teval-rmse:3.57404                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.81308\teval-rmse:3.35383                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.66066\teval-rmse:3.17175                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.53832\teval-rmse:3.02726                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.44065\teval-rmse:2.9094                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.35758\teval-rmse:2.8179                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.28923\teval-rmse:2.74305                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.23756\teval-rmse:2.68456                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.19651\teval-rmse:2.63547                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.15834\teval-rmse:2.5957                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:3.12702\teval-rmse:2.56652                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.1013\teval-rmse:2.54835                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.07832\teval-rmse:2.53005                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.05925\teval-rmse:2.51572                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.04301\teval-rmse:2.51069                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.02659\teval-rmse:2.50223                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.0157\teval-rmse:2.4964                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:3.00673\teval-rmse:2.49195                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.99608\teval-rmse:2.48771                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.98604\teval-rmse:2.48244                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.9787\teval-rmse:2.48485                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.96853\teval-rmse:2.48558                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.96193\teval-rmse:2.47969                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.95536\teval-rmse:2.48007                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\ttrain-rmse:2.94484\teval-rmse:2.48348                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.93868\teval-rmse:2.48153                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.92658\teval-rmse:2.48397                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.92165\teval-rmse:2.48154                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.91412\teval-rmse:2.48273                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.90982\teval-rmse:2.4818                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.90268\teval-rmse:2.47807                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.89631\teval-rmse:2.48089                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.89046\teval-rmse:2.48067                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.87852\teval-rmse:2.48265                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.87431\teval-rmse:2.48252                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.87134\teval-rmse:2.4844                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:2.86477\teval-rmse:2.48852                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.86013\teval-rmse:2.48441                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.85144\teval-rmse:2.48301                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.83955\teval-rmse:2.48274                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.83422\teval-rmse:2.48277                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.82757\teval-rmse:2.48084                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.82191\teval-rmse:2.48221                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.81608\teval-rmse:2.48004                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.81081\teval-rmse:2.48206                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.80743\teval-rmse:2.48411                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.80198\teval-rmse:2.48628                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.79602\teval-rmse:2.48887                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.78992\teval-rmse:2.49176                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.78219\teval-rmse:2.49665                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.77483\teval-rmse:2.49533                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[37]\ttrain-rmse:2.90268\teval-rmse:2.47807\n",
      "\n",
      "\n",
      "loss: 73310778.39112031                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.561128876732497e-08, 'colsample_bytree': 0.8, 'gamma': 1.2892116911964424e-06, 'lambda': 2.059344463301302, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 0.2574478355653845, 'n_estimators': 770.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:7.12978\teval-rmse:7.05195                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.58552\teval-rmse:6.45396                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:6.10581\teval-rmse:5.92009                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:5.68602\teval-rmse:5.44964                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:5.32108\teval-rmse:5.03754                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:5.00476\teval-rmse:4.67858                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.72927\teval-rmse:4.356                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:4.4938\teval-rmse:4.07418                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:4.29207\teval-rmse:3.831                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:4.12035\teval-rmse:3.62097                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.97456\teval-rmse:3.44272                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.8503\teval-rmse:3.28635                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.74625\teval-rmse:3.1543                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.65787\teval-rmse:3.04559                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.58469\teval-rmse:2.95165                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.52353\teval-rmse:2.87331                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.47113\teval-rmse:2.80464                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.42819\teval-rmse:2.74913                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.39057\teval-rmse:2.70368                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.35937\teval-rmse:2.66139                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.33374\teval-rmse:2.6286                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:3.31179\teval-rmse:2.60085                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.29274\teval-rmse:2.58075                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.27641\teval-rmse:2.56161                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.26247\teval-rmse:2.54344                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.2498\teval-rmse:2.52648                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:3.23913\teval-rmse:2.51518                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.23031\teval-rmse:2.50813                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.22189\teval-rmse:2.50262                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.21262\teval-rmse:2.49744                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.20653\teval-rmse:2.49201                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.19876\teval-rmse:2.48842                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.19289\teval-rmse:2.48443                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\ttrain-rmse:3.18807\teval-rmse:2.48256                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.18344\teval-rmse:2.47939                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.17879\teval-rmse:2.47631                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.17435\teval-rmse:2.47537                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.16925\teval-rmse:2.47128                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.16521\teval-rmse:2.46739                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.1616\teval-rmse:2.46761                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:3.15667\teval-rmse:2.46739                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.15206\teval-rmse:2.46456                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.14895\teval-rmse:2.46437                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.14611\teval-rmse:2.46257                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.14331\teval-rmse:2.4612                                                                               \n",
      "\n",
      "[45]\ttrain-rmse:3.13987\teval-rmse:2.46379                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.13495\teval-rmse:2.46391                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.13272\teval-rmse:2.46347                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.12941\teval-rmse:2.46223                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.12552\teval-rmse:2.45876                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.12206\teval-rmse:2.45883                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.11997\teval-rmse:2.45916                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.11732\teval-rmse:2.45608                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.11534\teval-rmse:2.45617                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.11276\teval-rmse:2.45604                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:3.11035\teval-rmse:2.45514                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.10723\teval-rmse:2.4585                                                                               \n",
      "\n",
      "[57]\ttrain-rmse:3.1043\teval-rmse:2.45827                                                                               \n",
      "\n",
      "[58]\ttrain-rmse:3.10295\teval-rmse:2.45807                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.10238\teval-rmse:2.45715                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:3.10107\teval-rmse:2.45867                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:3.09784\teval-rmse:2.45869                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:3.09477\teval-rmse:2.45594                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:3.09368\teval-rmse:2.45694                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:3.09146\teval-rmse:2.45752                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:3.0896\teval-rmse:2.45746                                                                               \n",
      "\n",
      "[66]\ttrain-rmse:3.08666\teval-rmse:2.4555                                                                               \n",
      "\n",
      "[67]\ttrain-rmse:3.08411\teval-rmse:2.45693                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:3.08173\teval-rmse:2.45407                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:3.07911\teval-rmse:2.45434                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:3.0773\teval-rmse:2.45314                                                                               \n",
      "\n",
      "[71]\ttrain-rmse:3.07468\teval-rmse:2.45307                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:3.07409\teval-rmse:2.45284                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:3.07108\teval-rmse:2.45142                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:3.06937\teval-rmse:2.44781                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:3.06719\teval-rmse:2.44701                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:3.06528\teval-rmse:2.44733                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:3.06316\teval-rmse:2.44752                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:3.06041\teval-rmse:2.44711                                                                              \n",
      "\n",
      "[79]\ttrain-rmse:3.05898\teval-rmse:2.44674                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:3.05675\teval-rmse:2.44594                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:3.0552\teval-rmse:2.44557                                                                               \n",
      "\n",
      "[82]\ttrain-rmse:3.05297\teval-rmse:2.44545                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:3.05107\teval-rmse:2.44489                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:3.0502\teval-rmse:2.4443                                                                                \n",
      "\n",
      "[85]\ttrain-rmse:3.04849\teval-rmse:2.44506                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:3.04668\teval-rmse:2.44652                                                                              \n",
      "\n",
      "[87]\ttrain-rmse:3.04431\teval-rmse:2.44958                                                                              \n",
      "\n",
      "[88]\ttrain-rmse:3.04202\teval-rmse:2.44927                                                                              \n",
      "\n",
      "[89]\ttrain-rmse:3.03972\teval-rmse:2.45037                                                                              \n",
      "\n",
      "[90]\ttrain-rmse:3.03701\teval-rmse:2.45201                                                                              \n",
      "\n",
      "[91]\ttrain-rmse:3.03431\teval-rmse:2.45225                                                                              \n",
      "\n",
      "[92]\ttrain-rmse:3.0338\teval-rmse:2.4516                                                                                \n",
      "\n",
      "[93]\ttrain-rmse:3.03122\teval-rmse:2.44822                                                                              \n",
      "\n",
      "[94]\ttrain-rmse:3.02963\teval-rmse:2.44551                                                                              \n",
      "\n",
      "[95]\ttrain-rmse:3.02751\teval-rmse:2.44933                                                                              \n",
      "\n",
      "[96]\ttrain-rmse:3.02535\teval-rmse:2.44677                                                                              \n",
      "\n",
      "[97]\ttrain-rmse:3.0234\teval-rmse:2.44554                                                                               \n",
      "\n",
      "[98]\ttrain-rmse:3.02181\teval-rmse:2.44518                                                                              \n",
      "\n",
      "[99]\ttrain-rmse:3.02028\teval-rmse:2.44533                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 85390269.96450128                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.911734268026068e-07, 'colsample_bytree': 0.7000000000000001, 'gamma': 2.1962451036883316e-05, 'lambda': 1.4578662640679396, 'learning_rate': 0.4, 'max_depth': 3, 'min_child_weight': 5.4016600586199255, 'n_estimators': 677.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.41673\teval-rmse:5.11682                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.24618\teval-rmse:3.73294                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.70843\teval-rmse:3.04731                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.47593\teval-rmse:2.74335                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.37506\teval-rmse:2.6095                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.3314\teval-rmse:2.54887                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.3038\teval-rmse:2.51546                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.28949\teval-rmse:2.50606                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.28039\teval-rmse:2.49637                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.25786\teval-rmse:2.50075                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.24429\teval-rmse:2.48624                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.23366\teval-rmse:2.4848                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.22915\teval-rmse:2.48863                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.2243\teval-rmse:2.48858                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.21749\teval-rmse:2.48745                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.20717\teval-rmse:2.47203                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.2051\teval-rmse:2.47168                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:3.19973\teval-rmse:2.48488                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.19327\teval-rmse:2.48407                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.18991\teval-rmse:2.48426                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.18621\teval-rmse:2.48676                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.17911\teval-rmse:2.47992                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.17663\teval-rmse:2.47721                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.17196\teval-rmse:2.48027                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.16981\teval-rmse:2.4823                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.16549\teval-rmse:2.47579                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.15955\teval-rmse:2.48004                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.15419\teval-rmse:2.47861                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.14894\teval-rmse:2.47903                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.14305\teval-rmse:2.48072                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.13712\teval-rmse:2.47742                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.13287\teval-rmse:2.48025                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.12824\teval-rmse:2.47761                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.12273\teval-rmse:2.478                                                                                \n",
      "\n",
      "[34]\ttrain-rmse:3.11955\teval-rmse:2.47399                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.11597\teval-rmse:2.4739                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:3.11104\teval-rmse:2.47433                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[16]\ttrain-rmse:3.2051\teval-rmse:2.47168\n",
      "\n",
      "\n",
      "loss: 80253208.57645582                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.10889055933174645, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.017737006408737342, 'lambda': 8.231549334236799e-05, 'learning_rate': 0.025, 'max_depth': 7, 'min_child_weight': 0.14626837346692098, 'n_estimators': 591.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:7.5892\teval-rmse:7.55656                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:7.43347\teval-rmse:7.39033                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:7.28229\teval-rmse:7.22823                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:7.13537\teval-rmse:7.0712                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:6.99272\teval-rmse:6.91879                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:6.85396\teval-rmse:6.77067                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:6.71955\teval-rmse:6.62567                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:6.58954\teval-rmse:6.48486                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:6.46282\teval-rmse:6.34835                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:6.34029\teval-rmse:6.21556                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:6.22089\teval-rmse:6.08656                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:6.10535\teval-rmse:5.96082                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:5.99328\teval-rmse:5.83899                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:5.88457\teval-rmse:5.72115                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:5.7794\teval-rmse:5.60637                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:5.67766\teval-rmse:5.49475                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\ttrain-rmse:5.5788\teval-rmse:5.38709                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:5.48306\teval-rmse:5.28285                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:5.39007\teval-rmse:5.18135                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:5.30046\teval-rmse:5.08327                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:5.21378\teval-rmse:4.98797                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:5.13018\teval-rmse:4.89572                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:5.04854\teval-rmse:4.80627                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:4.96979\teval-rmse:4.71941                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:4.89345\teval-rmse:4.6351                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:4.81969\teval-rmse:4.55376                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:4.74809\teval-rmse:4.47458                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:4.67962\teval-rmse:4.39766                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:4.61289\teval-rmse:4.32473                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:4.54863\teval-rmse:4.25356                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:4.48592\teval-rmse:4.18429                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:4.42554\teval-rmse:4.11786                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:4.36669\teval-rmse:4.05376                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:4.31012\teval-rmse:3.99102                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:4.25607\teval-rmse:3.93137                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:4.20386\teval-rmse:3.87317                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:4.15322\teval-rmse:3.81726                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:4.1047\teval-rmse:3.76324                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:4.05798\teval-rmse:3.71021                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:4.01282\teval-rmse:3.66024                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.96953\teval-rmse:3.61135                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.92749\teval-rmse:3.56477                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.88667\teval-rmse:3.51936                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.84747\teval-rmse:3.47539                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.80916\teval-rmse:3.43395                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.77247\teval-rmse:3.39323                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.73759\teval-rmse:3.35539                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.70387\teval-rmse:3.31859                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.67117\teval-rmse:3.28278                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.63948\teval-rmse:3.24842                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.60916\teval-rmse:3.21495                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.58011\teval-rmse:3.18341                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.55161\teval-rmse:3.15258                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.52445\teval-rmse:3.12266                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.49789\teval-rmse:3.09493                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:3.47263\teval-rmse:3.06734                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.44812\teval-rmse:3.04139                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:3.42493\teval-rmse:3.01548                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:3.40231\teval-rmse:2.99109                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.38041\teval-rmse:2.96771                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:3.35957\teval-rmse:2.94517                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:3.3389\teval-rmse:2.92399                                                                               \n",
      "\n",
      "[62]\ttrain-rmse:3.31988\teval-rmse:2.90268                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:3.30149\teval-rmse:2.88321                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:3.28234\teval-rmse:2.86491                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:3.26533\teval-rmse:2.84715                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:3.24791\teval-rmse:2.83015                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:3.23125\teval-rmse:2.81327                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:3.21575\teval-rmse:2.79869                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:3.20029\teval-rmse:2.78355                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:3.18656\teval-rmse:2.76851                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:3.17188\teval-rmse:2.75468                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:3.15894\teval-rmse:2.74179                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:3.14682\teval-rmse:2.72864                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:3.13334\teval-rmse:2.71583                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:3.1212\teval-rmse:2.70464                                                                               \n",
      "\n",
      "[76]\ttrain-rmse:3.10871\teval-rmse:2.69349                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:3.09699\teval-rmse:2.68249                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:3.08614\teval-rmse:2.67266                                                                              \n",
      "\n",
      "[79]\ttrain-rmse:3.07533\teval-rmse:2.66277                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:3.06496\teval-rmse:2.65295                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:3.05521\teval-rmse:2.64385                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:3.04541\teval-rmse:2.63595                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83]\ttrain-rmse:3.03594\teval-rmse:2.62866                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:3.02634\teval-rmse:2.621                                                                                \n",
      "\n",
      "[85]\ttrain-rmse:3.01738\teval-rmse:2.6138                                                                               \n",
      "\n",
      "[86]\ttrain-rmse:3.00921\teval-rmse:2.60703                                                                              \n",
      "\n",
      "[87]\ttrain-rmse:3.00172\teval-rmse:2.59991                                                                              \n",
      "\n",
      "[88]\ttrain-rmse:2.99346\teval-rmse:2.59359                                                                              \n",
      "\n",
      "[89]\ttrain-rmse:2.98634\teval-rmse:2.58786                                                                              \n",
      "\n",
      "[90]\ttrain-rmse:2.97812\teval-rmse:2.58147                                                                              \n",
      "\n",
      "[91]\ttrain-rmse:2.97122\teval-rmse:2.57595                                                                              \n",
      "\n",
      "[92]\ttrain-rmse:2.9642\teval-rmse:2.57158                                                                               \n",
      "\n",
      "[93]\ttrain-rmse:2.95718\teval-rmse:2.56631                                                                              \n",
      "\n",
      "[94]\ttrain-rmse:2.95047\teval-rmse:2.56097                                                                              \n",
      "\n",
      "[95]\ttrain-rmse:2.94434\teval-rmse:2.55723                                                                              \n",
      "\n",
      "[96]\ttrain-rmse:2.93762\teval-rmse:2.55145                                                                              \n",
      "\n",
      "[97]\ttrain-rmse:2.93142\teval-rmse:2.54779                                                                              \n",
      "\n",
      "[98]\ttrain-rmse:2.92536\teval-rmse:2.54379                                                                              \n",
      "\n",
      "[99]\ttrain-rmse:2.92033\teval-rmse:2.53966                                                                              \n",
      "\n",
      "loss: 140337336.29437658                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.678612398504269e-07, 'colsample_bytree': 0.9, 'gamma': 1.2701041610945207e-08, 'lambda': 0.0007989805339672234, 'learning_rate': 0.5, 'max_depth': 8, 'min_child_weight': 1.4722129343089894, 'n_estimators': 361.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.71749\teval-rmse:4.48163                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.48527\teval-rmse:3.18746                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.03595\teval-rmse:2.77546                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.86521\teval-rmse:2.68723                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.78823\teval-rmse:2.66881                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.71286\teval-rmse:2.69236                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.66439\teval-rmse:2.69768                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.62947\teval-rmse:2.7443                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.58028\teval-rmse:2.74905                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.55209\teval-rmse:2.74939                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.48106\teval-rmse:2.79637                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.43925\teval-rmse:2.78903                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.40735\teval-rmse:2.79702                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.36846\teval-rmse:2.7926                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.35456\teval-rmse:2.78962                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.32473\teval-rmse:2.80373                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.30583\teval-rmse:2.81259                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.28954\teval-rmse:2.83442                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.25642\teval-rmse:2.82462                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.2348\teval-rmse:2.82424                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.21401\teval-rmse:2.8292                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.1722\teval-rmse:2.84555                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.16281\teval-rmse:2.86493                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.1342\teval-rmse:2.87626                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.09937\teval-rmse:2.87857                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.78823\teval-rmse:2.66881\n",
      "\n",
      "\n",
      "loss: 66756494.461788826                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.812744168096657e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 2.2761964813613756e-08, 'lambda': 0.0009320554281497574, 'learning_rate': 0.5, 'max_depth': 8, 'min_child_weight': 1.4382864900478776, 'n_estimators': 402.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.7165\teval-rmse:4.47438                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.48648\teval-rmse:3.1814                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.03202\teval-rmse:2.76504                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.86005\teval-rmse:2.66499                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.75331\teval-rmse:2.65766                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.71658\teval-rmse:2.63985                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.66611\teval-rmse:2.63209                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.62767\teval-rmse:2.64731                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.58935\teval-rmse:2.65368                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.54821\teval-rmse:2.64693                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.4804\teval-rmse:2.65937                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\ttrain-rmse:2.45604\teval-rmse:2.67309                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.41962\teval-rmse:2.69156                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.3852\teval-rmse:2.7154                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:2.3635\teval-rmse:2.71398                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.32914\teval-rmse:2.73363                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.29265\teval-rmse:2.76192                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.25731\teval-rmse:2.77132                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.21077\teval-rmse:2.79224                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.1797\teval-rmse:2.78763                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.15966\teval-rmse:2.7951                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.12248\teval-rmse:2.79824                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.10097\teval-rmse:2.78865                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.0896\teval-rmse:2.81109                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.06441\teval-rmse:2.8081                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.05032\teval-rmse:2.80792                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.0357\teval-rmse:2.80777                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.66611\teval-rmse:2.63209\n",
      "\n",
      "\n",
      "loss: 73522692.49372917                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0001480293104610703, 'colsample_bytree': 0.9, 'gamma': 1.9509344812138667e-07, 'lambda': 1.0107397635811187e-06, 'learning_rate': 0.5, 'max_depth': 8, 'min_child_weight': 0.10297494943093448, 'n_estimators': 375.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.71701\teval-rmse:4.47382                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.4858\teval-rmse:3.20505                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.03503\teval-rmse:2.81372                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.86394\teval-rmse:2.71385                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.79876\teval-rmse:2.70315                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.72018\teval-rmse:2.78103                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.66761\teval-rmse:2.80263                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.64607\teval-rmse:2.80243                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.60317\teval-rmse:2.79756                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.58265\teval-rmse:2.79271                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.5101\teval-rmse:2.81315                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.47097\teval-rmse:2.81418                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.43379\teval-rmse:2.823                                                                                \n",
      "\n",
      "[13]\ttrain-rmse:2.40996\teval-rmse:2.82117                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.37958\teval-rmse:2.82075                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.3703\teval-rmse:2.81595                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.33878\teval-rmse:2.8255                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.32082\teval-rmse:2.82798                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.27397\teval-rmse:2.85051                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.23097\teval-rmse:2.84891                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.21477\teval-rmse:2.85383                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.16059\teval-rmse:2.84779                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.12121\teval-rmse:2.85619                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.11364\teval-rmse:2.8524                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.0991\teval-rmse:2.85276                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.79876\teval-rmse:2.70315\n",
      "\n",
      "\n",
      "loss: 108052613.63230784                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.000585635203404875, 'colsample_bytree': 0.9, 'gamma': 1.2624182649149177e-07, 'lambda': 0.0015843107658348732, 'learning_rate': 0.45, 'max_depth': 8, 'min_child_weight': 1.1008207459966022, 'n_estimators': 108.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.99207\teval-rmse:4.77323                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.71546\teval-rmse:3.3809                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.17759\teval-rmse:2.84609                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.95789\teval-rmse:2.66961                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.84116\teval-rmse:2.59992                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.76327\teval-rmse:2.59868                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.72228\teval-rmse:2.61027                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.67269\teval-rmse:2.63879                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.64355\teval-rmse:2.64109                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.60775\teval-rmse:2.65895                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.57549\teval-rmse:2.65842                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\ttrain-rmse:2.54929\teval-rmse:2.66154                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.50732\teval-rmse:2.68762                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.48308\teval-rmse:2.69288                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.46988\teval-rmse:2.69249                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.4306\teval-rmse:2.69231                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.4025\teval-rmse:2.69447                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.38573\teval-rmse:2.71023                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.36275\teval-rmse:2.71849                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.32252\teval-rmse:2.71859                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.3117\teval-rmse:2.71861                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.28686\teval-rmse:2.72105                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.26195\teval-rmse:2.72366                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.23436\teval-rmse:2.72606                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.18687\teval-rmse:2.75537                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.16197\teval-rmse:2.76467                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.76327\teval-rmse:2.59868\n",
      "\n",
      "\n",
      "loss: 6878935615.344924                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.4609107974402284e-07, 'colsample_bytree': 0.9, 'gamma': 1.834330879445765e-08, 'lambda': 0.0002836260585540156, 'learning_rate': 0.45, 'max_depth': 9, 'min_child_weight': 0.6633007511810483, 'n_estimators': 298.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.93682\teval-rmse:4.78235                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.59582\teval-rmse:3.45004                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.98097\teval-rmse:2.9228                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.7052\teval-rmse:2.77206                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.60293\teval-rmse:2.71517                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.52064\teval-rmse:2.71905                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.4604\teval-rmse:2.72687                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.4063\teval-rmse:2.7285                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.37471\teval-rmse:2.73192                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.30532\teval-rmse:2.75835                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.27441\teval-rmse:2.79369                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.22649\teval-rmse:2.80701                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.16646\teval-rmse:2.80814                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.15061\teval-rmse:2.80207                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.11066\teval-rmse:2.81486                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.08022\teval-rmse:2.82334                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.04273\teval-rmse:2.91194                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.02835\teval-rmse:2.91187                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.0073\teval-rmse:2.92425                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.98106\teval-rmse:2.92468                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.9337\teval-rmse:2.9262                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:1.90367\teval-rmse:2.92688                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.87199\teval-rmse:2.94541                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.8531\teval-rmse:2.9393                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:1.8271\teval-rmse:2.93992                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.60293\teval-rmse:2.71517\n",
      "\n",
      "\n",
      "loss: 70470472.53349787                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.212993832082956e-07, 'colsample_bytree': 0.8500000000000001, 'gamma': 6.159236324883316e-06, 'lambda': 0.002233321257243866, 'learning_rate': 0.42500000000000004, 'max_depth': 3, 'min_child_weight': 1.0267398845660545, 'n_estimators': 418.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.2756\teval-rmse:4.95734                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.12169\teval-rmse:3.56202                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.62645\teval-rmse:2.94395                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.42956\teval-rmse:2.6778                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.34937\teval-rmse:2.57852                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.31572\teval-rmse:2.52852                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.29166\teval-rmse:2.51553                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.26635\teval-rmse:2.51036                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.25221\teval-rmse:2.49391                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.23859\teval-rmse:2.49589                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.23408\teval-rmse:2.49445                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.22149\teval-rmse:2.48627                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\ttrain-rmse:3.21335\teval-rmse:2.48886                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.20763\teval-rmse:2.48322                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.20451\teval-rmse:2.48805                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.19863\teval-rmse:2.49223                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.1908\teval-rmse:2.48645                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:3.18458\teval-rmse:2.48508                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.17916\teval-rmse:2.4826                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.17381\teval-rmse:2.47978                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.16894\teval-rmse:2.47607                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.16541\teval-rmse:2.47603                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.15863\teval-rmse:2.47717                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.1528\teval-rmse:2.47428                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:3.15121\teval-rmse:2.4731                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.14582\teval-rmse:2.47385                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.1387\teval-rmse:2.47297                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:3.13458\teval-rmse:2.46788                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.12862\teval-rmse:2.46523                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.12647\teval-rmse:2.46578                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.12205\teval-rmse:2.46254                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.1161\teval-rmse:2.46422                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:3.1118\teval-rmse:2.46571                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:3.1092\teval-rmse:2.46338                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:3.10772\teval-rmse:2.46138                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.1031\teval-rmse:2.46517                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:3.10007\teval-rmse:2.46917                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.09483\teval-rmse:2.48261                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.09106\teval-rmse:2.48193                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.08767\teval-rmse:2.48296                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.08605\teval-rmse:2.48906                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.08429\teval-rmse:2.48919                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.08181\teval-rmse:2.48726                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.07807\teval-rmse:2.48548                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.0747\teval-rmse:2.48693                                                                               \n",
      "\n",
      "[45]\ttrain-rmse:3.07013\teval-rmse:2.49756                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.06583\teval-rmse:2.49809                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.06374\teval-rmse:2.49519                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.06162\teval-rmse:2.5001                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:3.05981\teval-rmse:2.4947                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:3.05465\teval-rmse:2.48735                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.05246\teval-rmse:2.48781                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.04934\teval-rmse:2.48232                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.04528\teval-rmse:2.48933                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.04192\teval-rmse:2.49799                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[34]\ttrain-rmse:3.10772\teval-rmse:2.46138\n",
      "\n",
      "\n",
      "loss: 85385416.78642814                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00039544819461175825, 'colsample_bytree': 0.9500000000000001, 'gamma': 8.270849566410441e-08, 'lambda': 0.05603022635506795, 'learning_rate': 0.47500000000000003, 'max_depth': 8, 'min_child_weight': 0.458020154637372, 'n_estimators': 326.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.85019\teval-rmse:4.62806                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.58035\teval-rmse:3.28734                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.08255\teval-rmse:2.87903                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.87659\teval-rmse:2.72798                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.77756\teval-rmse:2.66647                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.72345\teval-rmse:2.66328                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.68708\teval-rmse:2.66018                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.65061\teval-rmse:2.68375                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.60333\teval-rmse:2.71228                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.57239\teval-rmse:2.71242                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.53459\teval-rmse:2.70994                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.48163\teval-rmse:2.71503                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.45423\teval-rmse:2.72109                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.42977\teval-rmse:2.71576                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.36967\teval-rmse:2.7126                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.35483\teval-rmse:2.71133                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\ttrain-rmse:2.32169\teval-rmse:2.71438                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.28014\teval-rmse:2.72049                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.26668\teval-rmse:2.71606                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.25472\teval-rmse:2.71348                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.21002\teval-rmse:2.73791                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.18738\teval-rmse:2.75241                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.16646\teval-rmse:2.75108                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.13836\teval-rmse:2.76356                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.10791\teval-rmse:2.76245                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.08657\teval-rmse:2.77484                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.0531\teval-rmse:2.77094                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.68708\teval-rmse:2.66018\n",
      "\n",
      "\n",
      "loss: 64929996.79066122                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0015272000332139431, 'colsample_bytree': 0.9, 'gamma': 4.787862259814547e-07, 'lambda': 0.038908841125728115, 'learning_rate': 0.47500000000000003, 'max_depth': 8, 'min_child_weight': 0.43228798332090934, 'n_estimators': 452.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.85933\teval-rmse:4.61422                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.59742\teval-rmse:3.26993                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.09858\teval-rmse:2.75343                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.90853\teval-rmse:2.64698                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.80173\teval-rmse:2.60526                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.73187\teval-rmse:2.60171                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.67583\teval-rmse:2.61201                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.65419\teval-rmse:2.61021                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.60969\teval-rmse:2.6573                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.58009\teval-rmse:2.67254                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.55649\teval-rmse:2.67706                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.50991\teval-rmse:2.69444                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.47561\teval-rmse:2.6989                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.43623\teval-rmse:2.70349                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.41121\teval-rmse:2.71767                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.39817\teval-rmse:2.71892                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.37097\teval-rmse:2.71585                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.34513\teval-rmse:2.71946                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.32665\teval-rmse:2.71723                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.29472\teval-rmse:2.72122                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.28137\teval-rmse:2.73612                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.25834\teval-rmse:2.73425                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.23802\teval-rmse:2.73587                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.21414\teval-rmse:2.73582                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.17127\teval-rmse:2.7361                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.13251\teval-rmse:2.74743                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.73187\teval-rmse:2.60171\n",
      "\n",
      "\n",
      "loss: 8354647386.8252125                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.8618332991101165e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 4.477236571473217e-08, 'lambda': 0.38601327957515474, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 0.4862795054620191, 'n_estimators': 203.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.27194\teval-rmse:5.08078                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.9646\teval-rmse:3.67089                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.32745\teval-rmse:3.01775                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.01877\teval-rmse:2.74409                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.86998\teval-rmse:2.6446                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.77916\teval-rmse:2.62635                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.72355\teval-rmse:2.62322                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.66926\teval-rmse:2.62248                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.62419\teval-rmse:2.61448                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.60119\teval-rmse:2.61747                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.5667\teval-rmse:2.61832                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.54219\teval-rmse:2.61529                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.49723\teval-rmse:2.62332                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.46754\teval-rmse:2.64938                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.4518\teval-rmse:2.64767                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\ttrain-rmse:2.42976\teval-rmse:2.65151                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.41011\teval-rmse:2.65458                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.39266\teval-rmse:2.6616                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.35819\teval-rmse:2.65537                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.3151\teval-rmse:2.64503                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.26902\teval-rmse:2.65058                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.23648\teval-rmse:2.65367                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.21633\teval-rmse:2.65087                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.19983\teval-rmse:2.65804                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.17574\teval-rmse:2.65423                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.1477\teval-rmse:2.65182                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.11958\teval-rmse:2.66032                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.08942\teval-rmse:2.66174                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.05752\teval-rmse:2.66442                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.62419\teval-rmse:2.61448\n",
      "\n",
      "\n",
      "loss: 60408342.12115701                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.61963316702392e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 8.464196590833562e-06, 'lambda': 0.4937705100795507, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 0.42491737935740787, 'n_estimators': 187.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.83098\teval-rmse:5.72295                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.5726\teval-rmse:4.40971                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.76879\teval-rmse:3.58508                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.2705\teval-rmse:3.11778                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.96758\teval-rmse:2.84648                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.78177\teval-rmse:2.71566                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.66843\teval-rmse:2.6395                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.56237\teval-rmse:2.60332                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.49391\teval-rmse:2.59412                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.45887\teval-rmse:2.59803                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.40697\teval-rmse:2.58888                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.36346\teval-rmse:2.58023                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.32766\teval-rmse:2.57614                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.29093\teval-rmse:2.58118                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.25993\teval-rmse:2.5793                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.21511\teval-rmse:2.59384                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.17812\teval-rmse:2.58869                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.16724\teval-rmse:2.59032                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.12937\teval-rmse:2.59158                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.11405\teval-rmse:2.59258                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.09653\teval-rmse:2.5973                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.06667\teval-rmse:2.6057                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.03386\teval-rmse:2.61884                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.00601\teval-rmse:2.6233                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.99943\teval-rmse:2.62314                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.97816\teval-rmse:2.62118                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.95503\teval-rmse:2.62291                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.92767\teval-rmse:2.62787                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.8998\teval-rmse:2.61767                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:1.88481\teval-rmse:2.62068                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.87656\teval-rmse:2.62081                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.868\teval-rmse:2.6203                                                                                 \n",
      "\n",
      "[32]\ttrain-rmse:1.84845\teval-rmse:2.61583                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.32766\teval-rmse:2.57614\n",
      "\n",
      "\n",
      "loss: 60089106.37688475                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.647896054963412e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.3336838329074634e-05, 'lambda': 0.340355280672007, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 0.20938382337940473, 'n_estimators': 207.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.82925\teval-rmse:5.72051                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.56933\teval-rmse:4.4011                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.76436\teval-rmse:3.59224                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.27361\teval-rmse:3.11547                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.96426\teval-rmse:2.83923                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-rmse:2.75729\teval-rmse:2.70666                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.63595\teval-rmse:2.63329                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.55445\teval-rmse:2.61281                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.49955\teval-rmse:2.60017                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.4503\teval-rmse:2.60689                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.42307\teval-rmse:2.60413                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.39743\teval-rmse:2.6002                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.37271\teval-rmse:2.596                                                                                \n",
      "\n",
      "[13]\ttrain-rmse:2.33188\teval-rmse:2.58923                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.27147\teval-rmse:2.57441                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.23206\teval-rmse:2.5843                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.19997\teval-rmse:2.59183                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.18568\teval-rmse:2.59635                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.14974\teval-rmse:2.6056                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.13762\teval-rmse:2.60778                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.08708\teval-rmse:2.62172                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.06656\teval-rmse:2.62163                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.05114\teval-rmse:2.62638                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.02148\teval-rmse:2.63047                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.00415\teval-rmse:2.63269                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.9711\teval-rmse:2.63885                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.94\teval-rmse:2.63821                                                                                 \n",
      "\n",
      "[27]\ttrain-rmse:1.9131\teval-rmse:2.64752                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.89439\teval-rmse:2.65134                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.88851\teval-rmse:2.64626                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.8729\teval-rmse:2.64127                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:1.866\teval-rmse:2.64103                                                                                \n",
      "\n",
      "[32]\ttrain-rmse:1.84265\teval-rmse:2.65005                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.81584\teval-rmse:2.65166                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.80403\teval-rmse:2.66336                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[14]\ttrain-rmse:2.27147\teval-rmse:2.57441\n",
      "\n",
      "\n",
      "loss: 63997347.45908827                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.8025584408389819, 'colsample_bytree': 0.6000000000000001, 'gamma': 0.0005182180595290622, 'lambda': 7.596846247776608, 'learning_rate': 0.375, 'max_depth': 9, 'min_child_weight': 0.5236224364092389, 'n_estimators': 121.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.43674\teval-rmse:5.23196                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.17063\teval-rmse:3.83224                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.47923\teval-rmse:3.09755                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.13316\teval-rmse:2.73075                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.94752\teval-rmse:2.60487                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.83547\teval-rmse:2.57999                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.76748\teval-rmse:2.56255                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.71636\teval-rmse:2.56949                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.68413\teval-rmse:2.56278                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.64277\teval-rmse:2.57118                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.59915\teval-rmse:2.59144                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.55909\teval-rmse:2.58901                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.5112\teval-rmse:2.60983                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.47261\teval-rmse:2.61488                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.45422\teval-rmse:2.61564                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.42561\teval-rmse:2.60137                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.37469\teval-rmse:2.62427                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.35581\teval-rmse:2.62764                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.34144\teval-rmse:2.62791                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.31005\teval-rmse:2.62482                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.28657\teval-rmse:2.63222                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.25658\teval-rmse:2.64863                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.21998\teval-rmse:2.65253                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.18004\teval-rmse:2.66052                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.1555\teval-rmse:2.66308                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.13551\teval-rmse:2.66192                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.10539\teval-rmse:2.6573                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.76748\teval-rmse:2.56255\n",
      "\n",
      "\n",
      "loss: 74470802.41057645                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0022805241211867762, 'colsample_bytree': 0.9500000000000001, 'gamma': 7.104323176035062e-07, 'lambda': 9.45474342816598, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.10865837785351642, 'n_estimators': 246.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.72693\teval-rmse:5.56025                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.47114\teval-rmse:4.20844                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.70977\teval-rmse:3.39737                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.27227\teval-rmse:2.94749                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.01768\teval-rmse:2.72307                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.86129\teval-rmse:2.62004                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.75829\teval-rmse:2.56487                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.67629\teval-rmse:2.55252                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.62299\teval-rmse:2.53532                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.58097\teval-rmse:2.52266                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.53931\teval-rmse:2.53517                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.50108\teval-rmse:2.54556                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.47053\teval-rmse:2.55119                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.43316\teval-rmse:2.55267                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.41933\teval-rmse:2.55468                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.37282\teval-rmse:2.56844                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.33098\teval-rmse:2.56941                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.31453\teval-rmse:2.57166                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.28652\teval-rmse:2.57413                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.26617\teval-rmse:2.57193                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.2461\teval-rmse:2.57501                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.22522\teval-rmse:2.57596                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.21465\teval-rmse:2.58053                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.18108\teval-rmse:2.59127                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.15665\teval-rmse:2.5949                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.13206\teval-rmse:2.59482                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.11673\teval-rmse:2.5998                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.07907\teval-rmse:2.6034                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.05824\teval-rmse:2.61653                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.03323\teval-rmse:2.60861                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.58097\teval-rmse:2.52266\n",
      "\n",
      "\n",
      "loss: 63704971.177134074                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.5512047771140982e-06, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.001174729155480617, 'lambda': 0.6906646668438817, 'learning_rate': 0.225, 'max_depth': 9, 'min_child_weight': 0.8816667445996965, 'n_estimators': 940.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.29866\teval-rmse:6.20773                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.21405\teval-rmse:5.08002                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.41686\teval-rmse:4.25532                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.83557\teval-rmse:3.67213                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.42143\teval-rmse:3.26375                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.12073\teval-rmse:3.00344                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.91161\teval-rmse:2.81955                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.76823\teval-rmse:2.70364                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.65687\teval-rmse:2.63745                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.57768\teval-rmse:2.6106                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.5061\teval-rmse:2.59254                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.44916\teval-rmse:2.57441                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.40262\teval-rmse:2.57069                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.35624\teval-rmse:2.56633                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.3338\teval-rmse:2.56111                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.30719\teval-rmse:2.5657                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.2818\teval-rmse:2.56248                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.25347\teval-rmse:2.56616                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.21248\teval-rmse:2.5657                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.19552\teval-rmse:2.56254                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.18212\teval-rmse:2.56681                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.16229\teval-rmse:2.56806                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.14228\teval-rmse:2.56754                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.12351\teval-rmse:2.56734                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24]\ttrain-rmse:2.09369\teval-rmse:2.56088                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.07341\teval-rmse:2.56502                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.06028\teval-rmse:2.56949                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.04846\teval-rmse:2.56848                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.03826\teval-rmse:2.56649                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.01056\teval-rmse:2.56751                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.00013\teval-rmse:2.56773                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.97453\teval-rmse:2.56633                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.9467\teval-rmse:2.56471                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:1.93822\teval-rmse:2.5639                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:1.92854\teval-rmse:2.56457                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.91948\teval-rmse:2.56176                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.89341\teval-rmse:2.56403                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.88436\teval-rmse:2.56287                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.87468\teval-rmse:2.56159                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:1.86556\teval-rmse:2.56161                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:1.84669\teval-rmse:2.56668                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:1.83487\teval-rmse:2.56852                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:1.8248\teval-rmse:2.56911                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:1.81389\teval-rmse:2.57164                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:1.80182\teval-rmse:2.57526                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[24]\ttrain-rmse:2.09369\teval-rmse:2.56088\n",
      "\n",
      "\n",
      "loss: 61139210.04122939                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00024689915438209583, 'colsample_bytree': 0.9500000000000001, 'gamma': 3.855860663313724e-06, 'lambda': 0.20919597691672825, 'learning_rate': 0.4, 'max_depth': 3, 'min_child_weight': 0.19730416030238265, 'n_estimators': 165.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.40915\teval-rmse:5.10338                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.23642\teval-rmse:3.6832                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.70165\teval-rmse:3.01927                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.46553\teval-rmse:2.72056                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.36359\teval-rmse:2.5852                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.32013\teval-rmse:2.53202                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.29223\teval-rmse:2.51043                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.27205\teval-rmse:2.50581                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.25587\teval-rmse:2.50068                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.2464\teval-rmse:2.50444                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.23791\teval-rmse:2.50762                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.23343\teval-rmse:2.50111                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.22298\teval-rmse:2.49696                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.21831\teval-rmse:2.49802                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.20603\teval-rmse:2.49464                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.19692\teval-rmse:2.49561                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.18963\teval-rmse:2.51001                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.18735\teval-rmse:2.51                                                                                 \n",
      "\n",
      "[18]\ttrain-rmse:3.18248\teval-rmse:2.50892                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.17722\teval-rmse:2.50866                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.17241\teval-rmse:2.50895                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.16793\teval-rmse:2.50215                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.16323\teval-rmse:2.50242                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.16117\teval-rmse:2.50127                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.15681\teval-rmse:2.50239                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.1532\teval-rmse:2.50403                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:3.14703\teval-rmse:2.49989                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.1439\teval-rmse:2.51053                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:3.14097\teval-rmse:2.50873                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.13655\teval-rmse:2.51337                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.1311\teval-rmse:2.51883                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:3.12598\teval-rmse:2.5127                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:3.12512\teval-rmse:2.51179                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.1218\teval-rmse:2.51535                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:3.11629\teval-rmse:2.51405                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[14]\ttrain-rmse:3.20603\teval-rmse:2.49464\n",
      "\n",
      "\n",
      "loss: 87138186.95657441                                                                                                \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 3.9083128213313784e-05, 'colsample_bytree': 0.6000000000000001, 'gamma': 0.00016492935341849542, 'lambda': 0.02270286704237618, 'learning_rate': 0.275, 'max_depth': 6, 'min_child_weight': 0.40252097234386763, 'n_estimators': 245.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.05257\teval-rmse:5.8912                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.92859\teval-rmse:4.6221                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.19423\teval-rmse:3.77505                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.73592\teval-rmse:3.2348                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.45907\teval-rmse:2.9214                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.29071\teval-rmse:2.73279                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.19133\teval-rmse:2.62457                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.12844\teval-rmse:2.57144                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.08291\teval-rmse:2.52843                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.05027\teval-rmse:2.56305                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.02483\teval-rmse:2.54909                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.00386\teval-rmse:2.55468                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.98014\teval-rmse:2.55015                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.9682\teval-rmse:2.54957                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.95503\teval-rmse:2.54969                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.93579\teval-rmse:2.54628                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.91992\teval-rmse:2.54006                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.90518\teval-rmse:2.54368                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.89011\teval-rmse:2.54191                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.87391\teval-rmse:2.54385                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.86296\teval-rmse:2.54599                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.8489\teval-rmse:2.55668                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.83282\teval-rmse:2.55261                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.82347\teval-rmse:2.55215                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.81033\teval-rmse:2.56613                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.7959\teval-rmse:2.56338                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.78237\teval-rmse:2.56535                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.77468\teval-rmse:2.57129                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.76914\teval-rmse:2.57105                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:3.08291\teval-rmse:2.52843\n",
      "\n",
      "\n",
      "loss: 74573151.70960926                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.083380090706147e-06, 'colsample_bytree': 0.8500000000000001, 'gamma': 2.5086541681884755e-05, 'lambda': 0.16501649953374997, 'learning_rate': 0.35000000000000003, 'max_depth': 9, 'min_child_weight': 0.5933887795590724, 'n_estimators': 326.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:5.5502\teval-rmse:5.39725                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.24222\teval-rmse:4.01304                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.50578\teval-rmse:3.27784                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.11157\teval-rmse:2.87659                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.89453\teval-rmse:2.70875                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.75675\teval-rmse:2.6204                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.67187\teval-rmse:2.6034                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.62185\teval-rmse:2.58999                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.5772\teval-rmse:2.60899                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.54061\teval-rmse:2.59278                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.49475\teval-rmse:2.59763                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.46496\teval-rmse:2.59906                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.42678\teval-rmse:2.63199                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.41666\teval-rmse:2.63419                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.3972\teval-rmse:2.63429                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.37404\teval-rmse:2.64325                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.35202\teval-rmse:2.64309                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.32394\teval-rmse:2.65963                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.29543\teval-rmse:2.68664                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.27927\teval-rmse:2.69797                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.23706\teval-rmse:2.7093                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.21791\teval-rmse:2.71685                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.19088\teval-rmse:2.71049                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.166\teval-rmse:2.71398                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:2.14366\teval-rmse:2.71533                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.11539\teval-rmse:2.7691                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\ttrain-rmse:2.09323\teval-rmse:2.76638                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.06385\teval-rmse:2.81067                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.62185\teval-rmse:2.58999\n",
      "\n",
      "\n",
      "loss: 202568517.1165005                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.1951827670572636e-05, 'colsample_bytree': 0.9, 'gamma': 4.737807057278399e-07, 'lambda': 0.003893882433140298, 'learning_rate': 0.325, 'max_depth': 5, 'min_child_weight': 2.20860080157048, 'n_estimators': 464.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.78178\teval-rmse:5.55988                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.59769\teval-rmse:4.20467                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.91878\teval-rmse:3.39803                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.55466\teval-rmse:2.94234                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.36303\teval-rmse:2.71135                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.25565\teval-rmse:2.59259                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.19838\teval-rmse:2.52818                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.16305\teval-rmse:2.48983                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.13964\teval-rmse:2.47587                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.1204\teval-rmse:2.47812                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.10263\teval-rmse:2.47071                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.08494\teval-rmse:2.48102                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.06723\teval-rmse:2.47453                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.0599\teval-rmse:2.46579                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.04761\teval-rmse:2.46346                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.04241\teval-rmse:2.465                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:3.03216\teval-rmse:2.47023                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.0261\teval-rmse:2.47224                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:3.0194\teval-rmse:2.46936                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.01232\teval-rmse:2.4685                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:3.00371\teval-rmse:2.46396                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.99391\teval-rmse:2.46772                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.98936\teval-rmse:2.47619                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.98076\teval-rmse:2.48125                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.96897\teval-rmse:2.47701                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.96127\teval-rmse:2.48146                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.94533\teval-rmse:2.48715                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.93533\teval-rmse:2.48947                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.92335\teval-rmse:2.48144                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.91685\teval-rmse:2.4865                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.90667\teval-rmse:2.48637                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.8966\teval-rmse:2.48573                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.8895\teval-rmse:2.4882                                                                                \n",
      "\n",
      "[33]\ttrain-rmse:2.88197\teval-rmse:2.49138                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.87787\teval-rmse:2.49642                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[14]\ttrain-rmse:3.04761\teval-rmse:2.46346\n",
      "\n",
      "\n",
      "loss: 77982672.98361199                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.043369746231817e-08, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.0002020530716216246, 'lambda': 0.9847796566224318, 'learning_rate': 0.225, 'max_depth': 6, 'min_child_weight': 1.2648726429076813, 'n_estimators': 151.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:6.35194\teval-rmse:6.20647                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.33298\teval-rmse:5.07748                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.60417\teval-rmse:4.24596                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.09263\teval-rmse:3.65357                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.74296\teval-rmse:3.23461                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.50271\teval-rmse:2.95488                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.34674\teval-rmse:2.77123                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.23944\teval-rmse:2.65212                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.16459\teval-rmse:2.57348                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.11661\teval-rmse:2.52406                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.0779\teval-rmse:2.49497                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.04584\teval-rmse:2.47383                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.01942\teval-rmse:2.46107                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.00052\teval-rmse:2.45938                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.98158\teval-rmse:2.45793                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\ttrain-rmse:2.96711\teval-rmse:2.45818                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.95257\teval-rmse:2.45724                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.94355\teval-rmse:2.45549                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.9281\teval-rmse:2.45079                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.91331\teval-rmse:2.44549                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.90499\teval-rmse:2.44774                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.89363\teval-rmse:2.45008                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.87798\teval-rmse:2.45734                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.86899\teval-rmse:2.45754                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.86143\teval-rmse:2.46448                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.85206\teval-rmse:2.46346                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.83872\teval-rmse:2.46691                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.82576\teval-rmse:2.48663                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.81528\teval-rmse:2.49474                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.80857\teval-rmse:2.49061                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.79933\teval-rmse:2.49007                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.79018\teval-rmse:2.48864                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.77671\teval-rmse:2.48379                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.76491\teval-rmse:2.49417                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.75516\teval-rmse:2.49703                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.74834\teval-rmse:2.50174                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.74372\teval-rmse:2.50168                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.73407\teval-rmse:2.49869                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.72151\teval-rmse:2.5055                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:2.71166\teval-rmse:2.50358                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[19]\ttrain-rmse:2.91331\teval-rmse:2.44549\n",
      "\n",
      "\n",
      "loss: 70883103.9886789                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.0949664091258654e-06, 'colsample_bytree': 0.8500000000000001, 'gamma': 5.216092875497198e-08, 'lambda': 4.7221944088434595, 'learning_rate': 0.42500000000000004, 'max_depth': 5, 'min_child_weight': 0.2661459297147418, 'n_estimators': 110.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.22353\teval-rmse:4.92379                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.02321\teval-rmse:3.52209                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.5108\teval-rmse:2.88088                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.29965\teval-rmse:2.62781                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.20759\teval-rmse:2.53908                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.16068\teval-rmse:2.50123                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.12645\teval-rmse:2.49636                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.10494\teval-rmse:2.49553                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.08405\teval-rmse:2.47959                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.06646\teval-rmse:2.48839                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.04982\teval-rmse:2.50235                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.02745\teval-rmse:2.50008                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.01444\teval-rmse:2.50464                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.99593\teval-rmse:2.53195                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.98113\teval-rmse:2.54496                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.97161\teval-rmse:2.54055                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.96557\teval-rmse:2.53827                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.95972\teval-rmse:2.53125                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.94876\teval-rmse:2.53483                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.94036\teval-rmse:2.53694                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.93367\teval-rmse:2.53674                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.92142\teval-rmse:2.54401                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.90886\teval-rmse:2.54061                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.9013\teval-rmse:2.55759                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.89787\teval-rmse:2.56473                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.8862\teval-rmse:2.56913                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.87353\teval-rmse:2.57171                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.86733\teval-rmse:2.57788                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.85345\teval-rmse:2.5826                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:3.08405\teval-rmse:2.47959\n",
      "\n",
      "\n",
      "loss: 77055450.84753138                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00010962241943475009, 'colsample_bytree': 0.9, 'gamma': 0.0019772285723918676, 'lambda': 0.09913365372040825, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 1.750453379914555, 'n_estimators': 243.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.99182\teval-rmse:5.8752                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.78533\teval-rmse:4.60403                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.98325\teval-rmse:3.7582                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.45814\teval-rmse:3.22637                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.12473\teval-rmse:2.90819                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.89844\teval-rmse:2.72917                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.74141\teval-rmse:2.6207                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.65863\teval-rmse:2.57113                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.58997\teval-rmse:2.53932                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.54574\teval-rmse:2.52374                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.49257\teval-rmse:2.51545                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.45919\teval-rmse:2.52157                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.4059\teval-rmse:2.52076                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.38601\teval-rmse:2.51123                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.36317\teval-rmse:2.50631                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.34468\teval-rmse:2.50585                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.31757\teval-rmse:2.50393                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.30775\teval-rmse:2.50256                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.27429\teval-rmse:2.51145                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.25379\teval-rmse:2.51281                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.23452\teval-rmse:2.51608                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.20909\teval-rmse:2.51767                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.17909\teval-rmse:2.52406                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.15805\teval-rmse:2.52852                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.14435\teval-rmse:2.53223                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.11015\teval-rmse:2.53865                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.08533\teval-rmse:2.53766                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.05837\teval-rmse:2.54096                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.04118\teval-rmse:2.53785                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.02873\teval-rmse:2.53632                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.00802\teval-rmse:2.54174                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.96215\teval-rmse:2.5293                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:1.93522\teval-rmse:2.53911                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.91895\teval-rmse:2.53726                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.90636\teval-rmse:2.54293                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.87835\teval-rmse:2.53965                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.85656\teval-rmse:2.54439                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.83079\teval-rmse:2.54825                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:2.30775\teval-rmse:2.50256\n",
      "\n",
      "\n",
      "loss: 67570979.49833137                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0027636394224987274, 'colsample_bytree': 0.65, 'gamma': 1.0879341350043885e-05, 'lambda': 0.006298267434341664, 'learning_rate': 0.325, 'max_depth': 3, 'min_child_weight': 0.7682986691090015, 'n_estimators': 909.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.82463\teval-rmse:5.58886                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.67715\teval-rmse:4.24214                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.02507\teval-rmse:3.45468                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.67646\teval-rmse:2.99691                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.49215\teval-rmse:2.75986                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.39882\teval-rmse:2.63925                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.34918\teval-rmse:2.57139                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.3212\teval-rmse:2.53332                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.29983\teval-rmse:2.50965                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.28192\teval-rmse:2.50321                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.2686\teval-rmse:2.48837                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.26009\teval-rmse:2.47869                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.25015\teval-rmse:2.48265                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.23869\teval-rmse:2.4784                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.23448\teval-rmse:2.48478                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.22432\teval-rmse:2.47783                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.22194\teval-rmse:2.47464                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.21617\teval-rmse:2.46344                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.2094\teval-rmse:2.46501                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\ttrain-rmse:3.20661\teval-rmse:2.46345                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.20088\teval-rmse:2.46291                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.19841\teval-rmse:2.46288                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.19567\teval-rmse:2.46286                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.19207\teval-rmse:2.46362                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.18946\teval-rmse:2.46353                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.18448\teval-rmse:2.45757                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.17847\teval-rmse:2.45589                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.17373\teval-rmse:2.46436                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.166\teval-rmse:2.46483                                                                                \n",
      "\n",
      "[29]\ttrain-rmse:3.16179\teval-rmse:2.46911                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.15833\teval-rmse:2.47154                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.15455\teval-rmse:2.46984                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.15272\teval-rmse:2.47012                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.1484\teval-rmse:2.4703                                                                                \n",
      "\n",
      "[34]\ttrain-rmse:3.14461\teval-rmse:2.46616                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.1411\teval-rmse:2.46162                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:3.13875\teval-rmse:2.46105                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.13587\teval-rmse:2.45823                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.1327\teval-rmse:2.4546                                                                                \n",
      "\n",
      "[39]\ttrain-rmse:3.13117\teval-rmse:2.45398                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.12742\teval-rmse:2.4533                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:3.12337\teval-rmse:2.45635                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.12204\teval-rmse:2.45345                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.11819\teval-rmse:2.45579                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.11501\teval-rmse:2.45804                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.1119\teval-rmse:2.45784                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:3.10924\teval-rmse:2.45879                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.10377\teval-rmse:2.45681                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.10171\teval-rmse:2.45494                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.09942\teval-rmse:2.453                                                                                \n",
      "\n",
      "[50]\ttrain-rmse:3.09726\teval-rmse:2.45448                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.09489\teval-rmse:2.4532                                                                               \n",
      "\n",
      "[52]\ttrain-rmse:3.08924\teval-rmse:2.45066                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.08608\teval-rmse:2.45467                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.0846\teval-rmse:2.45426                                                                               \n",
      "\n",
      "[55]\ttrain-rmse:3.08188\teval-rmse:2.45286                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.07912\teval-rmse:2.45275                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:3.07647\teval-rmse:2.4534                                                                               \n",
      "\n",
      "[58]\ttrain-rmse:3.07301\teval-rmse:2.45793                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.06933\teval-rmse:2.46544                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:3.0684\teval-rmse:2.46633                                                                               \n",
      "\n",
      "[61]\ttrain-rmse:3.06715\teval-rmse:2.4674                                                                               \n",
      "\n",
      "[62]\ttrain-rmse:3.06469\teval-rmse:2.47043                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:3.06039\teval-rmse:2.47052                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:3.0585\teval-rmse:2.4707                                                                                \n",
      "\n",
      "[65]\ttrain-rmse:3.05541\teval-rmse:2.47501                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:3.05396\teval-rmse:2.47352                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:3.05281\teval-rmse:2.47355                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:3.04887\teval-rmse:2.47057                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:3.04468\teval-rmse:2.47404                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:3.04348\teval-rmse:2.47253                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:3.041\teval-rmse:2.47333                                                                                \n",
      "\n",
      "[72]\ttrain-rmse:3.03863\teval-rmse:2.47387                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[52]\ttrain-rmse:3.08924\teval-rmse:2.45066\n",
      "\n",
      "\n",
      "loss: 81121198.56306277                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.575012269276786e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.024480259200071e-08, 'lambda': 0.018813376374287007, 'learning_rate': 0.375, 'max_depth': 7, 'min_child_weight': 0.12836780889525853, 'n_estimators': 296.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.4537\teval-rmse:5.24306                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.19397\teval-rmse:3.86418                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.55308\teval-rmse:3.13818                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.2424\teval-rmse:2.78734                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.08614\teval-rmse:2.65956                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-rmse:2.99257\teval-rmse:2.62633                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.94449\teval-rmse:2.60767                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.91347\teval-rmse:2.59936                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.88644\teval-rmse:2.60042                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.86105\teval-rmse:2.61654                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.83411\teval-rmse:2.61925                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.80005\teval-rmse:2.62176                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.77495\teval-rmse:2.64741                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.75493\teval-rmse:2.67129                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.74698\teval-rmse:2.66943                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.72523\teval-rmse:2.66295                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.69849\teval-rmse:2.7414                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.67475\teval-rmse:2.74611                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.65487\teval-rmse:2.7547                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.63168\teval-rmse:2.73365                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.61918\teval-rmse:2.73807                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.60023\teval-rmse:2.73129                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.58612\teval-rmse:2.73214                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.55098\teval-rmse:2.74474                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.53263\teval-rmse:2.74607                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.51331\teval-rmse:2.8028                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.48693\teval-rmse:2.80729                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.47824\teval-rmse:2.80683                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.91347\teval-rmse:2.59936\n",
      "\n",
      "\n",
      "loss: 69490793.74601121                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.7584625314564297, 'colsample_bytree': 0.8, 'gamma': 1.207741098822334e-06, 'lambda': 0.3936582801519973, 'learning_rate': 0.225, 'max_depth': 8, 'min_child_weight': 3.7448684745709953, 'n_estimators': 715.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:6.31913\teval-rmse:6.20599                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.26584\teval-rmse:5.083                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:4.50304\teval-rmse:4.25123                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.95704\teval-rmse:3.66394                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.57638\teval-rmse:3.25448                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.30902\teval-rmse:2.98374                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.12657\teval-rmse:2.80519                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.0049\teval-rmse:2.69101                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.9024\teval-rmse:2.62782                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.84407\teval-rmse:2.57557                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.78881\teval-rmse:2.55308                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.75106\teval-rmse:2.53557                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.71716\teval-rmse:2.53411                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.69403\teval-rmse:2.52507                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.67299\teval-rmse:2.52199                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.64424\teval-rmse:2.52129                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.62454\teval-rmse:2.52983                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.6003\teval-rmse:2.52553                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.57752\teval-rmse:2.52487                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.55394\teval-rmse:2.52228                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.532\teval-rmse:2.5267                                                                                 \n",
      "\n",
      "[21]\ttrain-rmse:2.51806\teval-rmse:2.5263                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.50487\teval-rmse:2.52732                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.47887\teval-rmse:2.52233                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.45584\teval-rmse:2.52419                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.44456\teval-rmse:2.53023                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.4308\teval-rmse:2.53595                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.41583\teval-rmse:2.5361                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.40093\teval-rmse:2.54038                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.38256\teval-rmse:2.55015                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.36981\teval-rmse:2.55161                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.35501\teval-rmse:2.55232                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.34642\teval-rmse:2.54917                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.33821\teval-rmse:2.54904                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.32306\teval-rmse:2.55487                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.30876\teval-rmse:2.5495                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.64424\teval-rmse:2.52129\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 70028962.51772986                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.013862458077003e-06, 'colsample_bytree': 0.9, 'gamma': 4.101201524713412e-05, 'lambda': 0.03548593098304714, 'learning_rate': 0.30000000000000004, 'max_depth': 5, 'min_child_weight': 0.1730799259029148, 'n_estimators': 572.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:5.92145\teval-rmse:5.71954                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.76627\teval-rmse:4.40141                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.06355\teval-rmse:3.57364                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.65631\teval-rmse:3.08514                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.42963\teval-rmse:2.80935                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.30302\teval-rmse:2.64011                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.22878\teval-rmse:2.5494                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.18525\teval-rmse:2.49616                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.14848\teval-rmse:2.47276                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.12754\teval-rmse:2.45634                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.10789\teval-rmse:2.45466                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.08982\teval-rmse:2.44645                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.0732\teval-rmse:2.46696                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.0565\teval-rmse:2.46384                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.04889\teval-rmse:2.45704                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.03372\teval-rmse:2.46462                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.02754\teval-rmse:2.46283                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.01539\teval-rmse:2.46554                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.01094\teval-rmse:2.46909                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.00389\teval-rmse:2.47271                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.9953\teval-rmse:2.47512                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.99379\teval-rmse:2.47648                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.98308\teval-rmse:2.47768                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.97227\teval-rmse:2.47569                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.96325\teval-rmse:2.46914                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.95557\teval-rmse:2.46656                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.94492\teval-rmse:2.46837                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.93493\teval-rmse:2.46659                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.92557\teval-rmse:2.4691                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.91794\teval-rmse:2.47104                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.91095\teval-rmse:2.47817                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.90244\teval-rmse:2.47923                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:3.08982\teval-rmse:2.44645\n",
      "\n",
      "\n",
      "loss: 77897350.50514257                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.2732197753134777e-06, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.8650003178199049, 'lambda': 5.24737548272349, 'learning_rate': 0.2, 'max_depth': 9, 'min_child_weight': 3.1236908775959003, 'n_estimators': 195.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.47492\teval-rmse:6.37694                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.49139\teval-rmse:5.32119                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.74614\teval-rmse:4.51888                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.17503\teval-rmse:3.91715                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.75531\teval-rmse:3.48418                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.43945\teval-rmse:3.16172                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.20437\teval-rmse:2.9295                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.03657\teval-rmse:2.77541                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.91353\teval-rmse:2.66106                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.82393\teval-rmse:2.59582                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.75509\teval-rmse:2.54977                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.6946\teval-rmse:2.51695                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.65111\teval-rmse:2.49455                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.61763\teval-rmse:2.479                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:2.5915\teval-rmse:2.46373                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.56399\teval-rmse:2.45661                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.54128\teval-rmse:2.45451                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.52329\teval-rmse:2.45129                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.50489\teval-rmse:2.44886                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.48567\teval-rmse:2.44401                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.46462\teval-rmse:2.44032                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]\ttrain-rmse:2.43908\teval-rmse:2.43708                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.41724\teval-rmse:2.43803                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.39856\teval-rmse:2.43274                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.386\teval-rmse:2.43376                                                                                \n",
      "\n",
      "[25]\ttrain-rmse:2.37785\teval-rmse:2.43607                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.35009\teval-rmse:2.44451                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.32931\teval-rmse:2.44864                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.30177\teval-rmse:2.43654                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.28088\teval-rmse:2.43646                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.26802\teval-rmse:2.43505                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.26136\teval-rmse:2.43669                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.2529\teval-rmse:2.44489                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.23963\teval-rmse:2.45072                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.22657\teval-rmse:2.44586                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.22013\teval-rmse:2.44728                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.1969\teval-rmse:2.44972                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.18688\teval-rmse:2.44847                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.17459\teval-rmse:2.45053                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.15938\teval-rmse:2.45045                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.15188\teval-rmse:2.45118                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.13382\teval-rmse:2.44928                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.12637\teval-rmse:2.45428                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.10912\teval-rmse:2.45425                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[23]\ttrain-rmse:2.39856\teval-rmse:2.43274\n",
      "\n",
      "\n",
      "loss: 69989735.88460101                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0012456197994751112, 'colsample_bytree': 0.9500000000000001, 'gamma': 2.083460848315536e-06, 'lambda': 0.011396666027573938, 'learning_rate': 0.4, 'max_depth': 4, 'min_child_weight': 0.36947075176913646, 'n_estimators': 817.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.37987\teval-rmse:5.09225                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.1876\teval-rmse:3.67235                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.63983\teval-rmse:2.99715                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.4082\teval-rmse:2.69254                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.30178\teval-rmse:2.55805                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.25377\teval-rmse:2.50929                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.22563\teval-rmse:2.48468                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.20586\teval-rmse:2.47923                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.18117\teval-rmse:2.4722                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.1679\teval-rmse:2.47274                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.15376\teval-rmse:2.4764                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.14099\teval-rmse:2.48287                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.13436\teval-rmse:2.4773                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.12086\teval-rmse:2.45614                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.11179\teval-rmse:2.45818                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.10033\teval-rmse:2.46177                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.08805\teval-rmse:2.45674                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.07824\teval-rmse:2.46894                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.07201\teval-rmse:2.46793                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.06427\teval-rmse:2.47295                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.05663\teval-rmse:2.4824                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:3.04518\teval-rmse:2.4926                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:3.03424\teval-rmse:2.48737                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.03012\teval-rmse:2.48735                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.0231\teval-rmse:2.48977                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.01988\teval-rmse:2.48784                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.0141\teval-rmse:2.48917                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:3.00952\teval-rmse:2.48625                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.00422\teval-rmse:2.48531                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.99442\teval-rmse:2.48242                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.98747\teval-rmse:2.49369                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.98509\teval-rmse:2.49373                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.97536\teval-rmse:2.49551                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.9648\teval-rmse:2.49289                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:3.12086\teval-rmse:2.45614\n",
      "\n",
      "\n",
      "loss: 81647039.72347037                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.442036976977299e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.038092199797426396, 'lambda': 1.136416194557436, 'learning_rate': 0.07500000000000001, 'max_depth': 6, 'min_child_weight': 0.4997612978958308, 'n_estimators': 442.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:7.27585\teval-rmse:7.21692                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.84306\teval-rmse:6.74938                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:6.44925\teval-rmse:6.32024                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:6.09054\teval-rmse:5.92866                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:5.76603\teval-rmse:5.56851                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:5.47138\teval-rmse:5.24434                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:5.20447\teval-rmse:4.94593                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:4.96512\teval-rmse:4.67486                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:4.74945\teval-rmse:4.43156                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:4.55539\teval-rmse:4.21151                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:4.38065\teval-rmse:4.01244                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:4.22485\teval-rmse:3.83323                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:4.0859\teval-rmse:3.66991                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.96112\teval-rmse:3.52483                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.85133\teval-rmse:3.39637                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.75465\teval-rmse:3.28103                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.66743\teval-rmse:3.17843                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.59152\teval-rmse:3.08874                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.5233\teval-rmse:3.00577                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.46186\teval-rmse:2.93788                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.40874\teval-rmse:2.87606                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.36094\teval-rmse:2.82165                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.31897\teval-rmse:2.77556                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.28204\teval-rmse:2.73338                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.24795\teval-rmse:2.69822                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.21772\teval-rmse:2.66637                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.19171\teval-rmse:2.64024                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.16876\teval-rmse:2.61672                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.14852\teval-rmse:2.59836                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.13\teval-rmse:2.5811                                                                                  \n",
      "\n",
      "[30]\ttrain-rmse:3.10959\teval-rmse:2.5649                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:3.09417\teval-rmse:2.55072                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.08017\teval-rmse:2.53943                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.06711\teval-rmse:2.52659                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.05591\teval-rmse:2.51663                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.04349\teval-rmse:2.51018                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.03376\teval-rmse:2.5067                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:3.02446\teval-rmse:2.50052                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.01448\teval-rmse:2.4955                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:3.00587\teval-rmse:2.49157                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.99694\teval-rmse:2.48577                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.98893\teval-rmse:2.48432                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.9823\teval-rmse:2.48116                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:2.97661\teval-rmse:2.4791                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:2.96951\teval-rmse:2.47748                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.96396\teval-rmse:2.47651                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.95859\teval-rmse:2.4753                                                                               \n",
      "\n",
      "[47]\ttrain-rmse:2.95323\teval-rmse:2.47485                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.94861\teval-rmse:2.47472                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.94222\teval-rmse:2.47588                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.93572\teval-rmse:2.47651                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.93034\teval-rmse:2.47727                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.92645\teval-rmse:2.47761                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.92097\teval-rmse:2.47949                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.91829\teval-rmse:2.47833                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.91339\teval-rmse:2.47813                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.90819\teval-rmse:2.47744                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.90506\teval-rmse:2.47707                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.90055\teval-rmse:2.47708                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.89563\teval-rmse:2.47673                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.89094\teval-rmse:2.47776                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.88703\teval-rmse:2.47743                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62]\ttrain-rmse:2.88241\teval-rmse:2.4792                                                                               \n",
      "\n",
      "[63]\ttrain-rmse:2.87798\teval-rmse:2.48076                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.87501\teval-rmse:2.48223                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.87112\teval-rmse:2.48408                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.86769\teval-rmse:2.48626                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.86153\teval-rmse:2.48387                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:2.85853\teval-rmse:2.48443                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[48]\ttrain-rmse:2.94861\teval-rmse:2.47472\n",
      "\n",
      "\n",
      "loss: 79655131.669573                                                                                                  \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.010501955713212208, 'colsample_bytree': 0.75, 'gamma': 4.9961730969644316e-08, 'lambda': 0.22840736951393859, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 0.29125537185011713, 'n_estimators': 628.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:5.58261\teval-rmse:5.40147                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.30948\teval-rmse:4.01508                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.60143\teval-rmse:3.2508                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.23645\teval-rmse:2.85623                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.03569\teval-rmse:2.67759                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.91373\teval-rmse:2.59586                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.84239\teval-rmse:2.57001                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.79874\teval-rmse:2.55404                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.7679\teval-rmse:2.56404                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.74321\teval-rmse:2.57738                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.71556\teval-rmse:2.59497                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.68002\teval-rmse:2.5773                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.64918\teval-rmse:2.58663                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.63674\teval-rmse:2.60955                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.61074\teval-rmse:2.61618                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.58564\teval-rmse:2.61448                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.56614\teval-rmse:2.61637                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.55347\teval-rmse:2.61                                                                                 \n",
      "\n",
      "[18]\ttrain-rmse:2.52996\teval-rmse:2.61274                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.50393\teval-rmse:2.62871                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.48521\teval-rmse:2.6438                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.46977\teval-rmse:2.64598                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.45561\teval-rmse:2.64112                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.42494\teval-rmse:2.64966                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.38621\teval-rmse:2.65006                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.36602\teval-rmse:2.65322                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.35336\teval-rmse:2.65198                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.3383\teval-rmse:2.64005                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.79874\teval-rmse:2.55404\n",
      "\n",
      "\n",
      "loss: 78793767.72112548                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.994875669106208e-05, 'colsample_bytree': 0.8, 'gamma': 2.3086119620332466e-07, 'lambda': 2.4215058287593982, 'learning_rate': 0.275, 'max_depth': 7, 'min_child_weight': 0.23403789710885275, 'n_estimators': 504.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:6.04113\teval-rmse:5.89285                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.8899\teval-rmse:4.62054                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.13949\teval-rmse:3.78998                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.67138\teval-rmse:3.26454                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.38638\teval-rmse:2.95496                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.20986\teval-rmse:2.76913                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.09956\teval-rmse:2.65232                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.03171\teval-rmse:2.59819                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.97911\teval-rmse:2.54412                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.94481\teval-rmse:2.52651                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.91149\teval-rmse:2.50814                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.88798\teval-rmse:2.50058                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.86981\teval-rmse:2.50532                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.84573\teval-rmse:2.50735                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.82866\teval-rmse:2.50403                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.80815\teval-rmse:2.50714                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.78375\teval-rmse:2.52212                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\ttrain-rmse:2.77347\teval-rmse:2.52344                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.74595\teval-rmse:2.52827                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.72562\teval-rmse:2.54089                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.71403\teval-rmse:2.54341                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.68706\teval-rmse:2.5453                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.66507\teval-rmse:2.54255                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.64736\teval-rmse:2.54031                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.64308\teval-rmse:2.54041                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.62841\teval-rmse:2.54832                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.6101\teval-rmse:2.55222                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.598\teval-rmse:2.55068                                                                                \n",
      "\n",
      "[28]\ttrain-rmse:2.57969\teval-rmse:2.54593                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.56412\teval-rmse:2.54449                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.5485\teval-rmse:2.54852                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.53231\teval-rmse:2.54967                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.88798\teval-rmse:2.50058\n",
      "\n",
      "\n",
      "loss: 72842122.75442778                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.023439452004207106, 'colsample_bytree': 0.65, 'gamma': 0.003720098201430748, 'lambda': 0.13981163137690042, 'learning_rate': 0.25, 'max_depth': 4, 'min_child_weight': 0.8344577682366237, 'n_estimators': 541.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.23161\teval-rmse:6.06355                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.17982\teval-rmse:4.86882                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.46636\teval-rmse:4.04406                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.99927\teval-rmse:3.4699                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.70607\teval-rmse:3.10896                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.51907\teval-rmse:2.88293                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.40626\teval-rmse:2.74915                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.33653\teval-rmse:2.65766                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.2903\teval-rmse:2.59413                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.25822\teval-rmse:2.55632                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.23598\teval-rmse:2.53084                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.22238\teval-rmse:2.52284                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.20898\teval-rmse:2.51697                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.19479\teval-rmse:2.51354                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.18485\teval-rmse:2.51013                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.17368\teval-rmse:2.50841                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.16708\teval-rmse:2.50655                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.16154\teval-rmse:2.50618                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.14954\teval-rmse:2.51789                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.1439\teval-rmse:2.52261                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:3.13901\teval-rmse:2.5257                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:3.13389\teval-rmse:2.52234                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.1265\teval-rmse:2.52478                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:3.11867\teval-rmse:2.52397                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.11155\teval-rmse:2.52353                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.10469\teval-rmse:2.52078                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.10195\teval-rmse:2.5205                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:3.09698\teval-rmse:2.52411                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.09401\teval-rmse:2.5245                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:3.08954\teval-rmse:2.52312                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.08475\teval-rmse:2.52067                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.08246\teval-rmse:2.52141                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.0767\teval-rmse:2.52798                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:3.07078\teval-rmse:2.53027                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.0667\teval-rmse:2.5289                                                                                \n",
      "\n",
      "[35]\ttrain-rmse:3.06347\teval-rmse:2.52743                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.05892\teval-rmse:2.52283                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.05497\teval-rmse:2.51961                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:3.16154\teval-rmse:2.50618\n",
      "\n",
      "\n",
      "loss: 86763661.77464262                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.5062203269729117e-08, 'colsample_bytree': 0.8, 'gamma': 0.00029113954850151845, 'lambda': 0.005095646852161141, 'learning_rate': 0.42500000000000004, 'max_depth': 8, 'min_child_weight': 0.6428759335678077, 'n_estimators': 158.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.13227\teval-rmse:4.9383                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.83746\teval-rmse:3.5458                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.25228\teval-rmse:2.93068                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.99051\teval-rmse:2.70473                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.84238\teval-rmse:2.64996                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.77809\teval-rmse:2.63026                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.74508\teval-rmse:2.62629                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.66864\teval-rmse:2.63603                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.63989\teval-rmse:2.63953                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.62275\teval-rmse:2.63768                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.59377\teval-rmse:2.63574                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.5779\teval-rmse:2.64465                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.55144\teval-rmse:2.64657                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.50522\teval-rmse:2.64584                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.47798\teval-rmse:2.65677                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.44949\teval-rmse:2.65162                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.43388\teval-rmse:2.66559                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.42082\teval-rmse:2.6613                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.40301\teval-rmse:2.67767                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.35772\teval-rmse:2.69698                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.32865\teval-rmse:2.69453                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.29124\teval-rmse:2.70814                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.2612\teval-rmse:2.71396                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.23205\teval-rmse:2.72623                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.20239\teval-rmse:2.73206                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.18159\teval-rmse:2.73191                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.15696\teval-rmse:2.73703                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.74508\teval-rmse:2.62629\n",
      "\n",
      "\n",
      "loss: 67902706.53058559                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00020522520553914288, 'colsample_bytree': 0.9500000000000001, 'gamma': 5.075083741028977e-06, 'lambda': 0.5847294950857331, 'learning_rate': 0.17500000000000002, 'max_depth': 9, 'min_child_weight': 0.3124836323100621, 'n_estimators': 332.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.61412\teval-rmse:6.54378                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.70816\teval-rmse:5.59753                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.9764\teval-rmse:4.837                                                                                  \n",
      "\n",
      "[3]\ttrain-rmse:4.39322\teval-rmse:4.2452                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.93542\teval-rmse:3.79067                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.58422\teval-rmse:3.44002                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.31184\teval-rmse:3.18063                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.10006\teval-rmse:2.98666                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.94614\teval-rmse:2.84945                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.8152\teval-rmse:2.74281                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.70782\teval-rmse:2.67846                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.61931\teval-rmse:2.63212                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.55029\teval-rmse:2.60389                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.50286\teval-rmse:2.57798                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.45975\teval-rmse:2.56236                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.42605\teval-rmse:2.5615                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.39004\teval-rmse:2.55513                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.36229\teval-rmse:2.55162                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.33538\teval-rmse:2.54772                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.31207\teval-rmse:2.54482                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.29361\teval-rmse:2.54552                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.27022\teval-rmse:2.54591                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.24333\teval-rmse:2.54448                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.23366\teval-rmse:2.54304                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.21621\teval-rmse:2.54211                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.19823\teval-rmse:2.54713                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.19185\teval-rmse:2.54582                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.18021\teval-rmse:2.54899                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.15854\teval-rmse:2.5535                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.14538\teval-rmse:2.5531                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.13228\teval-rmse:2.5524                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\ttrain-rmse:2.09842\teval-rmse:2.55381                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.07659\teval-rmse:2.56742                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.06538\teval-rmse:2.56344                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.05414\teval-rmse:2.55943                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.03916\teval-rmse:2.56479                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.0266\teval-rmse:2.56558                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.00563\teval-rmse:2.5585                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:1.99087\teval-rmse:2.55659                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:1.98068\teval-rmse:2.55898                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:1.95739\teval-rmse:2.56013                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:1.9422\teval-rmse:2.55851                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:1.93466\teval-rmse:2.55273                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:1.92669\teval-rmse:2.55569                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:1.92111\teval-rmse:2.55589                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[24]\ttrain-rmse:2.21621\teval-rmse:2.54211\n",
      "\n",
      "\n",
      "loss: 65915519.31561859                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.5700914981912016e-05, 'colsample_bytree': 0.75, 'gamma': 6.879245546581619e-05, 'lambda': 0.06370000431032419, 'learning_rate': 0.375, 'max_depth': 3, 'min_child_weight': 1.9366103202099336, 'n_estimators': 281.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:5.55201\teval-rmse:5.28447                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.37802\teval-rmse:3.8822                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.80044\teval-rmse:3.17822                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.52843\teval-rmse:2.83374                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.39706\teval-rmse:2.66274                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.33901\teval-rmse:2.57346                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.30675\teval-rmse:2.54378                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.2872\teval-rmse:2.51575                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.269\teval-rmse:2.50488                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:3.26024\teval-rmse:2.49618                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.24719\teval-rmse:2.49139                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.23765\teval-rmse:2.48929                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.2284\teval-rmse:2.48592                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.2226\teval-rmse:2.48425                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.21359\teval-rmse:2.47157                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.20932\teval-rmse:2.47226                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.20375\teval-rmse:2.47239                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.19825\teval-rmse:2.4687                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:3.19291\teval-rmse:2.46987                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.18782\teval-rmse:2.4734                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:3.18217\teval-rmse:2.47008                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.17849\teval-rmse:2.47572                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.17402\teval-rmse:2.4776                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:3.17017\teval-rmse:2.47774                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.16473\teval-rmse:2.47166                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.16013\teval-rmse:2.48027                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.15698\teval-rmse:2.47992                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.1499\teval-rmse:2.47038                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:3.14844\teval-rmse:2.47136                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.1459\teval-rmse:2.47043                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:3.14067\teval-rmse:2.4622                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:3.13599\teval-rmse:2.45572                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.13421\teval-rmse:2.46028                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.13091\teval-rmse:2.46724                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.12635\teval-rmse:2.4652                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:3.12276\teval-rmse:2.46423                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.11907\teval-rmse:2.46203                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.11636\teval-rmse:2.4694                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:3.11179\teval-rmse:2.46964                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.10504\teval-rmse:2.47039                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.10356\teval-rmse:2.471                                                                                \n",
      "\n",
      "[41]\ttrain-rmse:3.10004\teval-rmse:2.47278                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.09594\teval-rmse:2.46774                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.09325\teval-rmse:2.46989                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.09129\teval-rmse:2.47009                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.08667\teval-rmse:2.4737                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46]\ttrain-rmse:3.08308\teval-rmse:2.48022                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.08051\teval-rmse:2.48108                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.07836\teval-rmse:2.4805                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:3.0752\teval-rmse:2.47919                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:3.07299\teval-rmse:2.48291                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.07044\teval-rmse:2.48114                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[31]\ttrain-rmse:3.13599\teval-rmse:2.45572\n",
      "\n",
      "\n",
      "loss: 85971986.36077732                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.791758591155097e-08, 'colsample_bytree': 0.9, 'gamma': 3.1019618624112814e-07, 'lambda': 0.00024589357937914314, 'learning_rate': 0.45, 'max_depth': 5, 'min_child_weight': 1.1452454821750322, 'n_estimators': 225.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:5.0886\teval-rmse:4.7743                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.91115\teval-rmse:3.38978                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.45027\teval-rmse:2.81259                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.27712\teval-rmse:2.59824                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.20001\teval-rmse:2.52469                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.16773\teval-rmse:2.50915                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.13959\teval-rmse:2.51422                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.12555\teval-rmse:2.53281                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.10869\teval-rmse:2.53186                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.09071\teval-rmse:2.54007                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.07898\teval-rmse:2.55721                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.06863\teval-rmse:2.55219                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.06355\teval-rmse:2.55281                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.0511\teval-rmse:2.55666                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.03271\teval-rmse:2.54965                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.01685\teval-rmse:2.54505                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.00723\teval-rmse:2.5627                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.99681\teval-rmse:2.55513                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.98393\teval-rmse:2.56327                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.9713\teval-rmse:2.56159                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.9604\teval-rmse:2.56654                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.95234\teval-rmse:2.56686                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.94503\teval-rmse:2.5699                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.93088\teval-rmse:2.58018                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.9154\teval-rmse:2.59961                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.90693\teval-rmse:2.59517                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:3.16773\teval-rmse:2.50915\n",
      "\n",
      "\n",
      "loss: 95417947.2735495                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.005008081645822912, 'colsample_bytree': 0.8500000000000001, 'gamma': 3.013946979388165e-08, 'lambda': 1.7455032476914079, 'learning_rate': 0.15000000000000002, 'max_depth': 7, 'min_child_weight': 0.13126621031162322, 'n_estimators': 396.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.801\teval-rmse:6.70896                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.01902\teval-rmse:5.86764                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.37823\teval-rmse:5.16669                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.85577\teval-rmse:4.58931                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.43613\teval-rmse:4.12076                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.10037\teval-rmse:3.74342                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.82924\teval-rmse:3.44567                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.62051\teval-rmse:3.20622                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.45689\teval-rmse:3.02406                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.33071\teval-rmse:2.88161                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.22577\teval-rmse:2.77111                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.14653\teval-rmse:2.69629                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.08506\teval-rmse:2.63639                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.03567\teval-rmse:2.5933                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.99158\teval-rmse:2.55841                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.95617\teval-rmse:2.52883                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.92818\teval-rmse:2.50893                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.90708\teval-rmse:2.4949                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.88521\teval-rmse:2.48424                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.86219\teval-rmse:2.47462                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttrain-rmse:2.84205\teval-rmse:2.46887                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.82674\teval-rmse:2.4665                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.80809\teval-rmse:2.46646                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.79375\teval-rmse:2.47161                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.78107\teval-rmse:2.4722                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.76836\teval-rmse:2.47                                                                                 \n",
      "\n",
      "[26]\ttrain-rmse:2.75971\teval-rmse:2.4684                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.74991\teval-rmse:2.47027                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.73146\teval-rmse:2.46859                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.71984\teval-rmse:2.47481                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.70594\teval-rmse:2.48219                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.69632\teval-rmse:2.48274                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.67923\teval-rmse:2.48318                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.66559\teval-rmse:2.48603                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.65797\teval-rmse:2.4844                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:2.64882\teval-rmse:2.48516                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.64022\teval-rmse:2.48369                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.63063\teval-rmse:2.48094                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.62112\teval-rmse:2.48159                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.61048\teval-rmse:2.48154                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.6018\teval-rmse:2.48006                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.59292\teval-rmse:2.48188                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.58701\teval-rmse:2.48134                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[22]\ttrain-rmse:2.80809\teval-rmse:2.46646\n",
      "\n",
      "\n",
      "loss: 69492505.30172233                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.719774275872119e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 9.39918394495133e-08, 'lambda': 9.779941727313109e-05, 'learning_rate': 0.47500000000000003, 'max_depth': 8, 'min_child_weight': 0.9386689540542804, 'n_estimators': 354.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.85696\teval-rmse:4.61953                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.6025\teval-rmse:3.27426                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.09505\teval-rmse:2.80094                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.91131\teval-rmse:2.64505                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.79588\teval-rmse:2.64005                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.74082\teval-rmse:2.62021                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.69018\teval-rmse:2.65114                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.64013\teval-rmse:2.66129                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.61029\teval-rmse:2.65537                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.56877\teval-rmse:2.66297                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.54679\teval-rmse:2.66584                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.53142\teval-rmse:2.66161                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.51171\teval-rmse:2.66871                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.48535\teval-rmse:2.67234                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.43553\teval-rmse:2.68301                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.4109\teval-rmse:2.67935                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.36886\teval-rmse:2.75024                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.33353\teval-rmse:2.75751                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.31161\teval-rmse:2.75556                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.27334\teval-rmse:2.756                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:2.24538\teval-rmse:2.75129                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.22069\teval-rmse:2.7508                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.18922\teval-rmse:2.75778                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.14877\teval-rmse:2.76492                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.11311\teval-rmse:2.77522                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.07924\teval-rmse:2.7745                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.74082\teval-rmse:2.62021\n",
      "\n",
      "\n",
      "loss: 14228762685.3887                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.915293901631937e-06, 'colsample_bytree': 0.9, 'gamma': 0.01697879794979091, 'lambda': 9.698333419846051, 'learning_rate': 0.30000000000000004, 'max_depth': 6, 'min_child_weight': 4.312403576566212, 'n_estimators': 487.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.91563\teval-rmse:5.72206                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.74312\teval-rmse:4.40975                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.03123\teval-rmse:3.57757                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\ttrain-rmse:3.61525\teval-rmse:3.08312                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.3752\teval-rmse:2.79889                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.24085\teval-rmse:2.64885                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.15829\teval-rmse:2.57814                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.11078\teval-rmse:2.53551                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.07422\teval-rmse:2.51138                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.05205\teval-rmse:2.50008                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.02432\teval-rmse:2.50618                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.00714\teval-rmse:2.51115                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.98907\teval-rmse:2.50378                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.97241\teval-rmse:2.51646                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.95439\teval-rmse:2.50754                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.94595\teval-rmse:2.51131                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.93087\teval-rmse:2.51394                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.92075\teval-rmse:2.51039                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.9086\teval-rmse:2.50556                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.89244\teval-rmse:2.50466                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.88088\teval-rmse:2.50648                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.86339\teval-rmse:2.50929                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.85616\teval-rmse:2.50887                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.84188\teval-rmse:2.51064                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.83787\teval-rmse:2.50339                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.83327\teval-rmse:2.50531                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.82129\teval-rmse:2.50744                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.80857\teval-rmse:2.50416                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.79256\teval-rmse:2.50491                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.78416\teval-rmse:2.50375                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:3.05205\teval-rmse:2.50008\n",
      "\n",
      "\n",
      "loss: 76297875.181496                                                                                                  \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0007569635010849846, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.0581637557184235e-06, 'lambda': 3.7248467922083655, 'learning_rate': 0.2, 'max_depth': 4, 'min_child_weight': 9.584089996368423, 'n_estimators': 178.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:6.52603\teval-rmse:6.38633                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.60028\teval-rmse:5.35177                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.9117\teval-rmse:4.56323                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:4.40669\teval-rmse:3.96418                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.04199\teval-rmse:3.52271                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.7882\teval-rmse:3.21498                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.6106\teval-rmse:2.98782                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.486\teval-rmse:2.82375                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:3.40106\teval-rmse:2.70542                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.34427\teval-rmse:2.62809                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.30081\teval-rmse:2.57762                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.27197\teval-rmse:2.5466                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.25056\teval-rmse:2.5234                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.23401\teval-rmse:2.5099                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.22261\teval-rmse:2.49947                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.21113\teval-rmse:2.4869                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.20291\teval-rmse:2.48139                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.19118\teval-rmse:2.48922                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.18352\teval-rmse:2.48191                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.17669\teval-rmse:2.47852                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.1707\teval-rmse:2.47505                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:3.16566\teval-rmse:2.47407                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.16026\teval-rmse:2.47248                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.15342\teval-rmse:2.46621                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.14454\teval-rmse:2.46418                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.14092\teval-rmse:2.46301                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.13641\teval-rmse:2.45657                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.13167\teval-rmse:2.4597                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:3.1261\teval-rmse:2.45906                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:3.12129\teval-rmse:2.45678                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.11796\teval-rmse:2.45798                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.1133\teval-rmse:2.4659                                                                                \n",
      "\n",
      "[32]\ttrain-rmse:3.11071\teval-rmse:2.46951                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\ttrain-rmse:3.10562\teval-rmse:2.46665                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.09947\teval-rmse:2.46413                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.09746\teval-rmse:2.46666                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.09395\teval-rmse:2.47068                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.08971\teval-rmse:2.47619                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.0852\teval-rmse:2.47137                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:3.08009\teval-rmse:2.46928                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.07729\teval-rmse:2.46937                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.07653\teval-rmse:2.46772                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.07112\teval-rmse:2.46573                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.06852\teval-rmse:2.46529                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.06534\teval-rmse:2.46394                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.06082\teval-rmse:2.46171                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.05703\teval-rmse:2.4625                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[26]\ttrain-rmse:3.13641\teval-rmse:2.45657\n",
      "\n",
      "\n",
      "loss: 78921239.539021                                                                                                  \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.0433577143729441e-05, 'colsample_bytree': 0.9, 'gamma': 3.327314557908736e-06, 'lambda': 2.438310788490393e-05, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.5304641695719542, 'n_estimators': 131.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:5.68849\teval-rmse:5.56194                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.39709\teval-rmse:4.20667                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.62284\teval-rmse:3.40348                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.16758\teval-rmse:2.97933                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.88716\teval-rmse:2.79835                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.72704\teval-rmse:2.7044                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.62495\teval-rmse:2.66165                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.55421\teval-rmse:2.64709                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.49626\teval-rmse:2.65053                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.45545\teval-rmse:2.66244                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.42994\teval-rmse:2.66334                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.40265\teval-rmse:2.66562                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.36889\teval-rmse:2.66304                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.33768\teval-rmse:2.66937                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.30527\teval-rmse:2.66464                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.28236\teval-rmse:2.68886                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.25662\teval-rmse:2.6981                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.22155\teval-rmse:2.69532                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.20038\teval-rmse:2.68632                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.17515\teval-rmse:2.67799                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.15267\teval-rmse:2.67918                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.12776\teval-rmse:2.67293                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.10675\teval-rmse:2.66775                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.07228\teval-rmse:2.66521                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.0424\teval-rmse:2.67656                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.0328\teval-rmse:2.67867                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.9982\teval-rmse:2.67936                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.96253\teval-rmse:2.69629                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.55421\teval-rmse:2.64709\n",
      "\n",
      "\n",
      "loss: 70404759.26846273                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.2242083800853145e-06, 'colsample_bytree': 0.6000000000000001, 'gamma': 9.373347568211343e-06, 'lambda': 0.0013897799960714073, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 0.167308004598143, 'n_estimators': 424.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.16445\teval-rmse:6.04025                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.04737\teval-rmse:4.85165                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.26145\teval-rmse:4.00451                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.73227\teval-rmse:3.42633                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.38646\teval-rmse:3.0684                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.1489\teval-rmse:2.84707                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.99226\teval-rmse:2.72647                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.87735\teval-rmse:2.66423                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.80815\teval-rmse:2.616                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:2.75998\teval-rmse:2.58767                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:2.72145\teval-rmse:2.57213                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.70071\teval-rmse:2.56696                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.66875\teval-rmse:2.5656                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.63894\teval-rmse:2.56816                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.60735\teval-rmse:2.56442                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.58242\teval-rmse:2.56777                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.56831\teval-rmse:2.56726                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.55425\teval-rmse:2.5666                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.53439\teval-rmse:2.5822                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.51026\teval-rmse:2.59861                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.48319\teval-rmse:2.6052                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.4711\teval-rmse:2.60589                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.45204\teval-rmse:2.60263                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.4377\teval-rmse:2.60817                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.41957\teval-rmse:2.61361                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.41255\teval-rmse:2.61404                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.40377\teval-rmse:2.62204                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.38295\teval-rmse:2.62502                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.3632\teval-rmse:2.62912                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.35072\teval-rmse:2.63367                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.33149\teval-rmse:2.64215                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.31054\teval-rmse:2.64088                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.29883\teval-rmse:2.64054                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.28299\teval-rmse:2.64563                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.27173\teval-rmse:2.64866                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[14]\ttrain-rmse:2.60735\teval-rmse:2.56442\n",
      "\n",
      "\n",
      "loss: 70405329.83749458                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.2042189207867114, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.0001234017271819339, 'lambda': 0.3447862015270172, 'learning_rate': 0.35000000000000003, 'max_depth': 3, 'min_child_weight': 1.4882347961399625, 'n_estimators': 610.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.67989\teval-rmse:5.42196                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.51783\teval-rmse:4.05417                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.8962\teval-rmse:3.30509                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.58835\teval-rmse:2.90795                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.44014\teval-rmse:2.70946                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.36125\teval-rmse:2.61348                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.3211\teval-rmse:2.56816                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.29697\teval-rmse:2.54121                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.27818\teval-rmse:2.52062                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.26361\teval-rmse:2.51574                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.25449\teval-rmse:2.51012                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.24356\teval-rmse:2.51084                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.23463\teval-rmse:2.50352                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.22398\teval-rmse:2.49469                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.21376\teval-rmse:2.48804                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.20564\teval-rmse:2.48786                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.19959\teval-rmse:2.49217                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.19663\teval-rmse:2.49107                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.19247\teval-rmse:2.48409                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.18762\teval-rmse:2.49032                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.18299\teval-rmse:2.49496                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.17839\teval-rmse:2.49686                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.17248\teval-rmse:2.50286                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.16853\teval-rmse:2.49764                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.16469\teval-rmse:2.49748                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.16007\teval-rmse:2.49757                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.15659\teval-rmse:2.49949                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.15029\teval-rmse:2.48432                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.1471\teval-rmse:2.48328                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:3.14215\teval-rmse:2.48664                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.13883\teval-rmse:2.48033                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.13479\teval-rmse:2.48027                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.13047\teval-rmse:2.47695                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.12607\teval-rmse:2.47775                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34]\ttrain-rmse:3.12104\teval-rmse:2.48072                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.11978\teval-rmse:2.47929                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.11725\teval-rmse:2.47961                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.11252\teval-rmse:2.47901                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.11056\teval-rmse:2.48003                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.10615\teval-rmse:2.47364                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.10321\teval-rmse:2.47375                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.1006\teval-rmse:2.4761                                                                                \n",
      "\n",
      "[42]\ttrain-rmse:3.09844\teval-rmse:2.47275                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.09492\teval-rmse:2.47619                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.09279\teval-rmse:2.47828                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.08962\teval-rmse:2.47886                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.08702\teval-rmse:2.47789                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.08394\teval-rmse:2.47137                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.07999\teval-rmse:2.4711                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:3.07775\teval-rmse:2.47084                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.07721\teval-rmse:2.47013                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.07342\teval-rmse:2.48001                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.07067\teval-rmse:2.47801                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.06754\teval-rmse:2.47848                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.06416\teval-rmse:2.47904                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:3.06166\teval-rmse:2.48048                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.05885\teval-rmse:2.49196                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:3.0571\teval-rmse:2.49043                                                                               \n",
      "\n",
      "[58]\ttrain-rmse:3.05498\teval-rmse:2.4892                                                                               \n",
      "\n",
      "[59]\ttrain-rmse:3.05202\teval-rmse:2.48932                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:3.04944\teval-rmse:2.49543                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:3.04699\teval-rmse:2.49188                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:3.04431\teval-rmse:2.49613                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:3.04068\teval-rmse:2.48515                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:3.03758\teval-rmse:2.48624                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:3.03558\teval-rmse:2.48622                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:3.03302\teval-rmse:2.49456                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:3.03247\teval-rmse:2.4943                                                                               \n",
      "\n",
      "[68]\ttrain-rmse:3.0304\teval-rmse:2.495                                                                                 \n",
      "\n",
      "[69]\ttrain-rmse:3.02724\teval-rmse:2.49715                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:3.02514\teval-rmse:2.50162                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[50]\ttrain-rmse:3.07721\teval-rmse:2.47013\n",
      "\n",
      "\n",
      "loss: 79962001.34039856                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00041510347857984996, 'colsample_bytree': 0.8, 'gamma': 2.784166544624897e-05, 'lambda': 0.029220805128856327, 'learning_rate': 0.4, 'max_depth': 9, 'min_child_weight': 0.35635793177375585, 'n_estimators': 680.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.24452\teval-rmse:5.08538                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.91766\teval-rmse:3.69447                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.2626\teval-rmse:3.02531                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.9489\teval-rmse:2.75716                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.78961\teval-rmse:2.64865                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.70236\teval-rmse:2.63779                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.65961\teval-rmse:2.62548                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.5938\teval-rmse:2.63288                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.54578\teval-rmse:2.62621                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.50644\teval-rmse:2.62167                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.47261\teval-rmse:2.61987                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.42966\teval-rmse:2.63129                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.36429\teval-rmse:2.63798                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.34328\teval-rmse:2.65367                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.30986\teval-rmse:2.65926                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.2808\teval-rmse:2.6847                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:2.25178\teval-rmse:2.70315                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.21298\teval-rmse:2.71078                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.17864\teval-rmse:2.71851                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.14696\teval-rmse:2.7205                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.12248\teval-rmse:2.71444                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.08623\teval-rmse:2.73311                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.07282\teval-rmse:2.73963                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\ttrain-rmse:2.05132\teval-rmse:2.74476                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.0289\teval-rmse:2.75481                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.99879\teval-rmse:2.7563                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.96229\teval-rmse:2.76587                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.909\teval-rmse:2.76847                                                                                \n",
      "\n",
      "[28]\ttrain-rmse:1.88057\teval-rmse:2.79256                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.85394\teval-rmse:2.79318                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.84121\teval-rmse:2.79607                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.47261\teval-rmse:2.61987\n",
      "\n",
      "\n",
      "loss: 1215320040.6598003                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.786169395078215e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.915268208491225e-06, 'lambda': 0.01075675003862191, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 0.11853097902311939, 'n_estimators': 274.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:7.42545\teval-rmse:7.38509                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:7.11972\teval-rmse:7.06122                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:6.83152\teval-rmse:6.75526                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:6.55894\teval-rmse:6.46693                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:6.30328\teval-rmse:6.19469                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:6.06232\teval-rmse:5.93782                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:5.83526\teval-rmse:5.69555                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:5.62147\teval-rmse:5.46708                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:5.42105\teval-rmse:5.25427                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:5.23192\teval-rmse:5.05472                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:5.05559\teval-rmse:4.86724                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:4.88945\teval-rmse:4.68981                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:4.73406\teval-rmse:4.52355                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:4.58945\teval-rmse:4.36706                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:4.45186\teval-rmse:4.22234                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:4.32507\teval-rmse:4.08743                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:4.20606\teval-rmse:3.96173                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:4.09564\teval-rmse:3.84457                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.99177\teval-rmse:3.73531                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.89583\teval-rmse:3.63396                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.80411\teval-rmse:3.53862                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.71994\teval-rmse:3.45157                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.64104\teval-rmse:3.36959                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.56658\teval-rmse:3.29325                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.49777\teval-rmse:3.22513                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.43394\teval-rmse:3.16307                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.37454\teval-rmse:3.10598                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.32037\teval-rmse:3.05183                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.26998\teval-rmse:3.00267                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.22111\teval-rmse:2.95735                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.17508\teval-rmse:2.91373                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.13397\teval-rmse:2.87591                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.09592\teval-rmse:2.84124                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.05825\teval-rmse:2.80851                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.02376\teval-rmse:2.77908                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.99061\teval-rmse:2.75381                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.9623\teval-rmse:2.73127                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.9358\teval-rmse:2.70913                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:2.91125\teval-rmse:2.68993                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.8851\teval-rmse:2.67092                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:2.86188\teval-rmse:2.65176                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.84324\teval-rmse:2.63528                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.82108\teval-rmse:2.6213                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:2.80201\teval-rmse:2.60588                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.78651\teval-rmse:2.59334                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.77054\teval-rmse:2.58356                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.7561\teval-rmse:2.57429                                                                               \n",
      "\n",
      "[47]\ttrain-rmse:2.74197\teval-rmse:2.56859                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.72989\teval-rmse:2.56259                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.71776\teval-rmse:2.55612                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.70667\teval-rmse:2.55187                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51]\ttrain-rmse:2.69487\teval-rmse:2.54638                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.68078\teval-rmse:2.54033                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.67134\teval-rmse:2.53688                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.6594\teval-rmse:2.53315                                                                               \n",
      "\n",
      "[55]\ttrain-rmse:2.6503\teval-rmse:2.52949                                                                               \n",
      "\n",
      "[56]\ttrain-rmse:2.64048\teval-rmse:2.52492                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.63029\teval-rmse:2.52209                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.62226\teval-rmse:2.51801                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.61362\teval-rmse:2.51585                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.60518\teval-rmse:2.50957                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.59611\teval-rmse:2.50623                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.58743\teval-rmse:2.50525                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.58267\teval-rmse:2.50324                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.57334\teval-rmse:2.50195                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.56635\teval-rmse:2.49946                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.55911\teval-rmse:2.49952                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.55241\teval-rmse:2.4983                                                                               \n",
      "\n",
      "[68]\ttrain-rmse:2.54649\teval-rmse:2.49678                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.54183\teval-rmse:2.49604                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:2.53476\teval-rmse:2.49608                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:2.52925\teval-rmse:2.49608                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:2.52332\teval-rmse:2.49475                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:2.51693\teval-rmse:2.49547                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:2.5095\teval-rmse:2.49813                                                                               \n",
      "\n",
      "[75]\ttrain-rmse:2.50165\teval-rmse:2.49951                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:2.49663\teval-rmse:2.49929                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:2.49228\teval-rmse:2.49709                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:2.48671\teval-rmse:2.49704                                                                              \n",
      "\n",
      "[79]\ttrain-rmse:2.48146\teval-rmse:2.4979                                                                               \n",
      "\n",
      "[80]\ttrain-rmse:2.47509\teval-rmse:2.50074                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:2.46865\teval-rmse:2.50088                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:2.46523\teval-rmse:2.49951                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:2.45978\teval-rmse:2.49921                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:2.45127\teval-rmse:2.49916                                                                              \n",
      "\n",
      "[85]\ttrain-rmse:2.44632\teval-rmse:2.49854                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:2.44162\teval-rmse:2.49918                                                                              \n",
      "\n",
      "[87]\ttrain-rmse:2.43744\teval-rmse:2.4972                                                                               \n",
      "\n",
      "[88]\ttrain-rmse:2.43328\teval-rmse:2.49687                                                                              \n",
      "\n",
      "[89]\ttrain-rmse:2.42806\teval-rmse:2.49661                                                                              \n",
      "\n",
      "[90]\ttrain-rmse:2.42531\teval-rmse:2.4963                                                                               \n",
      "\n",
      "[91]\ttrain-rmse:2.42198\teval-rmse:2.49617                                                                              \n",
      "\n",
      "[92]\ttrain-rmse:2.41515\teval-rmse:2.49728                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[72]\ttrain-rmse:2.52332\teval-rmse:2.49475\n",
      "\n",
      "\n",
      "loss: 73378737.34885955                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.632377798697111e-05, 'colsample_bytree': 0.9, 'gamma': 0.00037895811065692236, 'lambda': 0.10456324568612735, 'learning_rate': 0.42500000000000004, 'max_depth': 7, 'min_child_weight': 0.6999498072378058, 'n_estimators': 996.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.17009\teval-rmse:4.91449                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.92258\teval-rmse:3.49443                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.36108\teval-rmse:2.88915                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.12874\teval-rmse:2.68112                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.01511\teval-rmse:2.59585                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.95444\teval-rmse:2.55545                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.9141\teval-rmse:2.55251                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.86342\teval-rmse:2.56413                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.83045\teval-rmse:2.56269                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.80909\teval-rmse:2.57581                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.78178\teval-rmse:2.57281                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.74758\teval-rmse:2.60256                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.72604\teval-rmse:2.62188                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.69096\teval-rmse:2.62039                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.65827\teval-rmse:2.63473                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.6401\teval-rmse:2.6389                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:2.63029\teval-rmse:2.64217                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\ttrain-rmse:2.61187\teval-rmse:2.63274                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.59815\teval-rmse:2.63435                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.57791\teval-rmse:2.64002                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.55314\teval-rmse:2.6643                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.53078\teval-rmse:2.6629                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.50258\teval-rmse:2.66414                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.48126\teval-rmse:2.68164                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.45869\teval-rmse:2.6888                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.43615\teval-rmse:2.68984                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.42938\teval-rmse:2.695                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.9141\teval-rmse:2.55251\n",
      "\n",
      "\n",
      "loss: 113421862.2073543                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.0288922279523315e-06, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.0010859266727267047, 'lambda': 0.6019711530215065, 'learning_rate': 0.125, 'max_depth': 9, 'min_child_weight': 0.9581731886523925, 'n_estimators': 936.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.93463\teval-rmse:6.87596                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.23508\teval-rmse:6.14527                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.63521\teval-rmse:5.51718                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:5.12054\teval-rmse:4.98073                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.68164\teval-rmse:4.52587                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.31327\teval-rmse:4.14487                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.99453\teval-rmse:3.82615                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.7339\teval-rmse:3.56374                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.51239\teval-rmse:3.34728                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.31964\teval-rmse:3.17075                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.16368\teval-rmse:3.02656                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.04046\teval-rmse:2.91039                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.93225\teval-rmse:2.81669                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.84006\teval-rmse:2.74158                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.76355\teval-rmse:2.68646                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.70626\teval-rmse:2.64383                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.65139\teval-rmse:2.61086                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.60735\teval-rmse:2.58317                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.56433\teval-rmse:2.56476                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.53008\teval-rmse:2.54275                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.49478\teval-rmse:2.52805                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.46796\teval-rmse:2.5185                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.43668\teval-rmse:2.51777                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.40625\teval-rmse:2.51931                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.38602\teval-rmse:2.51025                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.36564\teval-rmse:2.51293                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.34778\teval-rmse:2.5103                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.32578\teval-rmse:2.50697                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.31098\teval-rmse:2.50522                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.29378\teval-rmse:2.50337                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.28292\teval-rmse:2.5007                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.27101\teval-rmse:2.50015                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.25523\teval-rmse:2.5016                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.24071\teval-rmse:2.50758                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.2237\teval-rmse:2.51147                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:2.20967\teval-rmse:2.51113                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.1947\teval-rmse:2.51158                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.17648\teval-rmse:2.51132                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.16767\teval-rmse:2.51066                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.15708\teval-rmse:2.51167                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.14985\teval-rmse:2.51351                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.14068\teval-rmse:2.5122                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:2.12708\teval-rmse:2.51476                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.11804\teval-rmse:2.50987                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.10892\teval-rmse:2.50866                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.09757\teval-rmse:2.50764                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.085\teval-rmse:2.51232                                                                                \n",
      "\n",
      "[47]\ttrain-rmse:2.07362\teval-rmse:2.5148                                                                               \n",
      "\n",
      "[48]\ttrain-rmse:2.06899\teval-rmse:2.51389                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49]\ttrain-rmse:2.05556\teval-rmse:2.51151                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.03723\teval-rmse:2.51344                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.02759\teval-rmse:2.512                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[31]\ttrain-rmse:2.27101\teval-rmse:2.50015\n",
      "\n",
      "\n",
      "loss: 65399528.677567765                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.166939833351998e-05, 'colsample_bytree': 0.9, 'gamma': 0.0012977055137883288, 'lambda': 0.04606678174568414, 'learning_rate': 0.17500000000000002, 'max_depth': 9, 'min_child_weight': 2.426942898092422, 'n_estimators': 856.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.61428\teval-rmse:6.54088                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.70154\teval-rmse:5.58528                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.97285\teval-rmse:4.82047                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.39986\teval-rmse:4.22628                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.94069\teval-rmse:3.76626                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.59021\teval-rmse:3.42244                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.31783\teval-rmse:3.16372                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.10791\teval-rmse:2.97678                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.94589\teval-rmse:2.84377                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.82236\teval-rmse:2.74817                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.71351\teval-rmse:2.68966                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.63993\teval-rmse:2.63783                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.58306\teval-rmse:2.61096                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.54136\teval-rmse:2.58618                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.50126\teval-rmse:2.57397                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.46482\teval-rmse:2.57023                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.44254\teval-rmse:2.56161                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.41908\teval-rmse:2.55659                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.39475\teval-rmse:2.54976                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.36685\teval-rmse:2.53847                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.34138\teval-rmse:2.53528                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.3264\teval-rmse:2.53173                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.30651\teval-rmse:2.53711                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.29188\teval-rmse:2.53738                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.26464\teval-rmse:2.53574                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.23875\teval-rmse:2.53657                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.21831\teval-rmse:2.54185                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.2093\teval-rmse:2.54289                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.19564\teval-rmse:2.5433                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.18389\teval-rmse:2.54327                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.16784\teval-rmse:2.54139                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.1505\teval-rmse:2.54708                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.12787\teval-rmse:2.54508                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.10129\teval-rmse:2.54119                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.08795\teval-rmse:2.54398                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.08105\teval-rmse:2.54471                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.06559\teval-rmse:2.54569                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.05472\teval-rmse:2.54782                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.02102\teval-rmse:2.5585                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:2.00291\teval-rmse:2.55852                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:1.97839\teval-rmse:2.56174                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:1.96966\teval-rmse:2.56065                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[21]\ttrain-rmse:2.3264\teval-rmse:2.53173\n",
      "\n",
      "\n",
      "loss: 61387997.25791788                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.122473091452384e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.007913922797984356, 'lambda': 0.9461515566717617, 'learning_rate': 0.225, 'max_depth': 9, 'min_child_weight': 1.254775418806197, 'n_estimators': 910.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.30096\teval-rmse:6.21277                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.2233\teval-rmse:5.08184                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.43413\teval-rmse:4.25408                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.85046\teval-rmse:3.67219                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.4419\teval-rmse:3.26732                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.15347\teval-rmse:2.99985                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.95802\teval-rmse:2.83075                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\ttrain-rmse:2.81561\teval-rmse:2.71327                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.71415\teval-rmse:2.64593                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.64092\teval-rmse:2.60403                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.56972\teval-rmse:2.58471                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.51302\teval-rmse:2.57688                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.47502\teval-rmse:2.57711                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.43262\teval-rmse:2.57158                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.40836\teval-rmse:2.57515                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.37299\teval-rmse:2.59356                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.34394\teval-rmse:2.59583                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.32111\teval-rmse:2.59317                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.29786\teval-rmse:2.58949                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.27817\teval-rmse:2.59276                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.24203\teval-rmse:2.59992                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.22658\teval-rmse:2.59967                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.20447\teval-rmse:2.6124                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.18452\teval-rmse:2.61197                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.16116\teval-rmse:2.61706                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.15521\teval-rmse:2.61537                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.13971\teval-rmse:2.61049                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.12506\teval-rmse:2.61741                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.09703\teval-rmse:2.61275                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.08773\teval-rmse:2.61113                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.07309\teval-rmse:2.60737                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.05712\teval-rmse:2.60864                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.03025\teval-rmse:2.61005                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.00772\teval-rmse:2.61178                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.43262\teval-rmse:2.57158\n",
      "\n",
      "\n",
      "loss: 65064110.354115084                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.887241994060084e-08, 'colsample_bytree': 0.75, 'gamma': 0.0031990675614660836, 'lambda': 0.6628617880039241, 'learning_rate': 0.225, 'max_depth': 9, 'min_child_weight': 0.5672135628909699, 'n_estimators': 967.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.30253\teval-rmse:6.21744                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.22552\teval-rmse:5.08853                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.42917\teval-rmse:4.25933                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.85305\teval-rmse:3.67418                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.44349\teval-rmse:3.27404                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.14074\teval-rmse:3.00288                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.93083\teval-rmse:2.82513                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.78688\teval-rmse:2.71398                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.68927\teval-rmse:2.65169                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.60191\teval-rmse:2.60893                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.53248\teval-rmse:2.58525                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.48889\teval-rmse:2.5667                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.44224\teval-rmse:2.5469                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.40225\teval-rmse:2.53643                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.37177\teval-rmse:2.53606                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.34131\teval-rmse:2.52824                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.31353\teval-rmse:2.52489                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.28959\teval-rmse:2.52145                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.2741\teval-rmse:2.51905                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.26212\teval-rmse:2.51847                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.24382\teval-rmse:2.52724                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.20429\teval-rmse:2.52337                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.18246\teval-rmse:2.52123                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.15928\teval-rmse:2.51924                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.14495\teval-rmse:2.51884                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.12859\teval-rmse:2.52449                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.09679\teval-rmse:2.52551                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.09009\teval-rmse:2.52762                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.07044\teval-rmse:2.52745                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.04269\teval-rmse:2.52887                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.01952\teval-rmse:2.52961                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.00777\teval-rmse:2.53193                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.0025\teval-rmse:2.53182                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\ttrain-rmse:1.97902\teval-rmse:2.52945                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:1.9524\teval-rmse:2.53383                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:1.93194\teval-rmse:2.53698                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.91268\teval-rmse:2.53257                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:1.89667\teval-rmse:2.52785                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.89139\teval-rmse:2.5297                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:1.88167\teval-rmse:2.52756                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[19]\ttrain-rmse:2.26212\teval-rmse:2.51847\n",
      "\n",
      "\n",
      "loss: 69549422.90708554                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0001261774803909964, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.08005742688163894, 'lambda': 5.789299118790892, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 0.438817150934864, 'n_estimators': 759.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.0134\teval-rmse:5.87991                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.82404\teval-rmse:4.63049                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.02878\teval-rmse:3.78494                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.51625\teval-rmse:3.23616                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.1916\teval-rmse:2.91803                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.96678\teval-rmse:2.72329                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.82082\teval-rmse:2.6308                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.73201\teval-rmse:2.57152                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.65579\teval-rmse:2.54549                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.60372\teval-rmse:2.53845                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.55463\teval-rmse:2.53674                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.52246\teval-rmse:2.52795                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.48601\teval-rmse:2.52623                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.46729\teval-rmse:2.52781                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.43849\teval-rmse:2.53239                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.41288\teval-rmse:2.54193                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.38239\teval-rmse:2.53706                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.35759\teval-rmse:2.5381                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.31319\teval-rmse:2.53933                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.27839\teval-rmse:2.53322                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.2598\teval-rmse:2.53523                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.23399\teval-rmse:2.53848                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.22378\teval-rmse:2.54327                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.19649\teval-rmse:2.54461                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.17364\teval-rmse:2.55416                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.1619\teval-rmse:2.55377                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.13796\teval-rmse:2.54805                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.12127\teval-rmse:2.54884                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.08426\teval-rmse:2.55009                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.05803\teval-rmse:2.54654                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.03792\teval-rmse:2.54686                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.00823\teval-rmse:2.54567                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:1.98848\teval-rmse:2.54603                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.48601\teval-rmse:2.52623\n",
      "\n",
      "\n",
      "loss: 68383304.83162835                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.529218944584015e-06, 'colsample_bytree': 0.9, 'gamma': 0.0007558374593256351, 'lambda': 2.799542725234813, 'learning_rate': 0.125, 'max_depth': 9, 'min_child_weight': 0.8558006792895364, 'n_estimators': 802.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.94132\teval-rmse:6.88057                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.24395\teval-rmse:6.15128                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.6484\teval-rmse:5.52226                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:5.13844\teval-rmse:4.98889                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.70649\teval-rmse:4.53388                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.33923\teval-rmse:4.15092                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:4.02401\teval-rmse:3.83209                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.7659\teval-rmse:3.56914                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.54909\teval-rmse:3.35021                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.36339\teval-rmse:3.17788                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.21108\teval-rmse:3.03555                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.08569\teval-rmse:2.91743                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\ttrain-rmse:2.98028\teval-rmse:2.8288                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.89271\teval-rmse:2.7538                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.81696\teval-rmse:2.69592                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.75417\teval-rmse:2.65188                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.69819\teval-rmse:2.61711                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.65005\teval-rmse:2.58607                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.60704\teval-rmse:2.5672                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.56789\teval-rmse:2.55401                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.53526\teval-rmse:2.54023                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.49954\teval-rmse:2.52993                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.47478\teval-rmse:2.5223                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.44906\teval-rmse:2.51649                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.42134\teval-rmse:2.51808                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.39956\teval-rmse:2.52241                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.37477\teval-rmse:2.52139                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.35316\teval-rmse:2.52171                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.34184\teval-rmse:2.52242                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.32287\teval-rmse:2.52063                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.3108\teval-rmse:2.52048                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.30425\teval-rmse:2.5204                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.2952\teval-rmse:2.5187                                                                                \n",
      "\n",
      "[33]\ttrain-rmse:2.28252\teval-rmse:2.52087                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.2691\teval-rmse:2.5191                                                                                \n",
      "\n",
      "[35]\ttrain-rmse:2.2616\teval-rmse:2.51812                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.24997\teval-rmse:2.51815                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.23742\teval-rmse:2.51581                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.22906\teval-rmse:2.5181                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:2.21479\teval-rmse:2.51643                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.21062\teval-rmse:2.51609                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.19664\teval-rmse:2.51752                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.17921\teval-rmse:2.517                                                                                \n",
      "\n",
      "[43]\ttrain-rmse:2.1667\teval-rmse:2.51857                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:2.15234\teval-rmse:2.51903                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.13414\teval-rmse:2.52346                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.12963\teval-rmse:2.52451                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.12027\teval-rmse:2.52378                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.10614\teval-rmse:2.52625                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.09189\teval-rmse:2.5257                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:2.07915\teval-rmse:2.52592                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.06982\teval-rmse:2.52736                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.06573\teval-rmse:2.5245                                                                               \n",
      "\n",
      "[53]\ttrain-rmse:2.05935\teval-rmse:2.52248                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.04622\teval-rmse:2.52612                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.03801\teval-rmse:2.52647                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.03442\teval-rmse:2.52621                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.02613\teval-rmse:2.52558                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[37]\ttrain-rmse:2.23742\teval-rmse:2.51581\n",
      "\n",
      "\n",
      "loss: 65559635.39161901                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.2617182576089637e-07, 'colsample_bytree': 0.8, 'gamma': 0.4366903243019775, 'lambda': 0.26389700842241, 'learning_rate': 0.30000000000000004, 'max_depth': 5, 'min_child_weight': 1.6695791017595711, 'n_estimators': 102.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.92063\teval-rmse:5.73888                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.76529\teval-rmse:4.42909                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.06275\teval-rmse:3.59507                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.66274\teval-rmse:3.10584                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.43548\teval-rmse:2.82408                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.3085\teval-rmse:2.66795                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.23543\teval-rmse:2.58776                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.18873\teval-rmse:2.55084                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.15649\teval-rmse:2.52859                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.13112\teval-rmse:2.52299                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.11518\teval-rmse:2.5173                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.09355\teval-rmse:2.51027                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.07895\teval-rmse:2.51045                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\ttrain-rmse:3.06757\teval-rmse:2.50643                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.05931\teval-rmse:2.50855                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.04565\teval-rmse:2.50632                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.03594\teval-rmse:2.50644                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.02347\teval-rmse:2.5078                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:3.01026\teval-rmse:2.50999                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.99845\teval-rmse:2.50382                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.98771\teval-rmse:2.49394                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.97348\teval-rmse:2.48692                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.96142\teval-rmse:2.48323                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.95196\teval-rmse:2.48355                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.94373\teval-rmse:2.48617                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.93806\teval-rmse:2.48587                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.92955\teval-rmse:2.48774                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.91865\teval-rmse:2.48986                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.90679\teval-rmse:2.49311                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.89476\teval-rmse:2.49842                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.88994\teval-rmse:2.49887                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.88061\teval-rmse:2.49491                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.87526\teval-rmse:2.4948                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.87149\teval-rmse:2.49744                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.86238\teval-rmse:2.49815                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.85336\teval-rmse:2.4927                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.84569\teval-rmse:2.4939                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.83732\teval-rmse:2.49082                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.82637\teval-rmse:2.49356                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.81722\teval-rmse:2.49141                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.81001\teval-rmse:2.49175                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.80323\teval-rmse:2.49234                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.79908\teval-rmse:2.48952                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[22]\ttrain-rmse:2.96142\teval-rmse:2.48323\n",
      "\n",
      "\n",
      "loss: 74396747.50402157                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.773846638369798e-08, 'colsample_bytree': 0.9500000000000001, 'gamma': 4.393802385236299e-05, 'lambda': 0.0030931172300223088, 'learning_rate': 0.17500000000000002, 'max_depth': 6, 'min_child_weight': 0.3966870945544276, 'n_estimators': 215.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.65516\teval-rmse:6.54153                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.78711\teval-rmse:5.59086                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.10745\teval-rmse:4.83101                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.57933\teval-rmse:4.23671                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.17898\teval-rmse:3.77276                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.87451\teval-rmse:3.41979                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.64928\teval-rmse:3.15708                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.48218\teval-rmse:2.9566                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.3561\teval-rmse:2.81247                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.26266\teval-rmse:2.71144                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.19461\teval-rmse:2.64153                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.14214\teval-rmse:2.59919                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.10138\teval-rmse:2.55978                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.06622\teval-rmse:2.53762                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.03834\teval-rmse:2.51785                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.01568\teval-rmse:2.5172                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.00018\teval-rmse:2.50975                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.98029\teval-rmse:2.51401                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.96788\teval-rmse:2.50342                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.95512\teval-rmse:2.50658                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.93838\teval-rmse:2.50704                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.92733\teval-rmse:2.50698                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.91397\teval-rmse:2.50885                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.90247\teval-rmse:2.50772                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.89219\teval-rmse:2.50828                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.87841\teval-rmse:2.51453                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.87182\teval-rmse:2.51339                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.86087\teval-rmse:2.52033                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.85449\teval-rmse:2.51734                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29]\ttrain-rmse:2.846\teval-rmse:2.51518                                                                                \n",
      "\n",
      "[30]\ttrain-rmse:2.83725\teval-rmse:2.51758                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.83129\teval-rmse:2.51897                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.82516\teval-rmse:2.52075                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.81455\teval-rmse:2.51845                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.80103\teval-rmse:2.51782                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.79166\teval-rmse:2.51989                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.78452\teval-rmse:2.51977                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.77517\teval-rmse:2.52748                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.76797\teval-rmse:2.53509                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[18]\ttrain-rmse:2.96788\teval-rmse:2.50342\n",
      "\n",
      "\n",
      "loss: 73068405.66550532                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.4361956599466228e-06, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.012340203781788206, 'lambda': 1.5641146674314903, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 0.24353686720484397, 'n_estimators': 712.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.1504\teval-rmse:6.05296                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.99754\teval-rmse:4.84091                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.19085\teval-rmse:4.00009                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.63303\teval-rmse:3.43378                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.25977\teval-rmse:3.06603                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.00237\teval-rmse:2.83583                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.82753\teval-rmse:2.71211                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.70145\teval-rmse:2.64482                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.61995\teval-rmse:2.59049                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.54656\teval-rmse:2.56413                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.48398\teval-rmse:2.55579                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.43761\teval-rmse:2.55644                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.41651\teval-rmse:2.54585                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.39321\teval-rmse:2.54636                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.36671\teval-rmse:2.5562                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.31702\teval-rmse:2.56235                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.2757\teval-rmse:2.56807                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.24471\teval-rmse:2.56749                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.22275\teval-rmse:2.56859                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.20984\teval-rmse:2.56905                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.18591\teval-rmse:2.57478                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.17238\teval-rmse:2.57742                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.15146\teval-rmse:2.57882                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.13056\teval-rmse:2.58099                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.10779\teval-rmse:2.57946                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.08284\teval-rmse:2.58127                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.06373\teval-rmse:2.58724                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.04084\teval-rmse:2.59122                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.02811\teval-rmse:2.58473                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.00167\teval-rmse:2.58995                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.99236\teval-rmse:2.58867                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.9674\teval-rmse:2.59273                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:1.94781\teval-rmse:2.59327                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.41651\teval-rmse:2.54585\n",
      "\n",
      "\n",
      "loss: 66944865.31595728                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.8559919716750184e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.04832496060378702, 'lambda': 0.14275533942617544, 'learning_rate': 0.2, 'max_depth': 8, 'min_child_weight': 0.18768652944632017, 'n_estimators': 315.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:6.47524\teval-rmse:6.37331                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.4965\teval-rmse:5.33079                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.75104\teval-rmse:4.52711                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.19286\teval-rmse:3.92919                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.78007\teval-rmse:3.49349                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.47873\teval-rmse:3.1734                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.2542\teval-rmse:2.96222                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.09449\teval-rmse:2.82425                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.97168\teval-rmse:2.7205                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\ttrain-rmse:2.88401\teval-rmse:2.65191                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.81438\teval-rmse:2.60961                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.75614\teval-rmse:2.57312                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.713\teval-rmse:2.55591                                                                                \n",
      "\n",
      "[13]\ttrain-rmse:2.67618\teval-rmse:2.54162                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.64716\teval-rmse:2.53093                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.61649\teval-rmse:2.5233                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.5876\teval-rmse:2.52909                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.56387\teval-rmse:2.53345                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.55273\teval-rmse:2.53323                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.54066\teval-rmse:2.53312                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.51174\teval-rmse:2.5322                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.49053\teval-rmse:2.5394                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.47816\teval-rmse:2.53729                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.45232\teval-rmse:2.5456                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.44221\teval-rmse:2.54416                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.43315\teval-rmse:2.54877                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.42049\teval-rmse:2.5484                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.40689\teval-rmse:2.55369                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.3886\teval-rmse:2.55806                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.37121\teval-rmse:2.56192                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.36064\teval-rmse:2.56045                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.34611\teval-rmse:2.55644                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.33235\teval-rmse:2.56045                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.31933\teval-rmse:2.55889                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.29149\teval-rmse:2.5634                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:2.27724\teval-rmse:2.5671                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.61649\teval-rmse:2.5233\n",
      "\n",
      "\n",
      "loss: 62450791.94865507                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.258964866786003e-06, 'colsample_bytree': 0.9, 'gamma': 0.00010188470364580304, 'lambda': 0.015743780764046367, 'learning_rate': 0.1, 'max_depth': 4, 'min_child_weight': 0.3299609401139481, 'n_estimators': 860.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:7.12869\teval-rmse:7.04995                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.58271\teval-rmse:6.45166                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:6.10258\teval-rmse:5.9166                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:5.68404\teval-rmse:5.4446                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:5.31866\teval-rmse:5.02784                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:5.00091\teval-rmse:4.6622                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:4.72653\teval-rmse:4.34161                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:4.49145\teval-rmse:4.06281                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:4.29032\teval-rmse:3.82346                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:4.1186\teval-rmse:3.61522                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.97299\teval-rmse:3.43559                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.84819\teval-rmse:3.28513                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.74349\teval-rmse:3.15604                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.65676\teval-rmse:3.04588                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.58289\teval-rmse:2.95316                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.52057\teval-rmse:2.87305                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.46879\teval-rmse:2.80515                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.42588\teval-rmse:2.75168                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.38793\teval-rmse:2.70414                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.35733\teval-rmse:2.66502                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.3318\teval-rmse:2.62967                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:3.30917\teval-rmse:2.6022                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:3.29002\teval-rmse:2.58047                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.27397\teval-rmse:2.56059                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.25944\teval-rmse:2.5464                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.24746\teval-rmse:2.53185                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.23573\teval-rmse:2.51966                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.22488\teval-rmse:2.514                                                                                \n",
      "\n",
      "[28]\ttrain-rmse:3.21591\teval-rmse:2.50581                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.20891\teval-rmse:2.4979                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:3.20272\teval-rmse:2.49288                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.19802\teval-rmse:2.49009                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.19297\teval-rmse:2.48666                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\ttrain-rmse:3.18642\teval-rmse:2.48657                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.18165\teval-rmse:2.48377                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.17783\teval-rmse:2.48199                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.17347\teval-rmse:2.4812                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:3.1675\teval-rmse:2.4805                                                                                \n",
      "\n",
      "[38]\ttrain-rmse:3.16186\teval-rmse:2.48668                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.15792\teval-rmse:2.48576                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.15391\teval-rmse:2.4837                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:3.15031\teval-rmse:2.48513                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.14656\teval-rmse:2.48428                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.14321\teval-rmse:2.48434                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.14047\teval-rmse:2.48434                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.13736\teval-rmse:2.48368                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.13444\teval-rmse:2.48233                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.12927\teval-rmse:2.4818                                                                               \n",
      "\n",
      "[48]\ttrain-rmse:3.12752\teval-rmse:2.48253                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.12484\teval-rmse:2.48077                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.12093\teval-rmse:2.47723                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.11871\teval-rmse:2.47715                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.11621\teval-rmse:2.47501                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.11407\teval-rmse:2.47555                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.11151\teval-rmse:2.47413                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:3.10856\teval-rmse:2.47492                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.10492\teval-rmse:2.46978                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:3.10171\teval-rmse:2.47                                                                                 \n",
      "\n",
      "[58]\ttrain-rmse:3.10047\teval-rmse:2.47064                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.09741\teval-rmse:2.4717                                                                               \n",
      "\n",
      "[60]\ttrain-rmse:3.09506\teval-rmse:2.47298                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:3.09197\teval-rmse:2.47198                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:3.08829\teval-rmse:2.47488                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:3.086\teval-rmse:2.47618                                                                                \n",
      "\n",
      "[64]\ttrain-rmse:3.08492\teval-rmse:2.47603                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:3.08225\teval-rmse:2.47556                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:3.08069\teval-rmse:2.47681                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:3.07922\teval-rmse:2.47682                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:3.07569\teval-rmse:2.47736                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:3.07281\teval-rmse:2.47648                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:3.07078\teval-rmse:2.47472                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:3.06833\teval-rmse:2.47522                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:3.06409\teval-rmse:2.474                                                                                \n",
      "\n",
      "[73]\ttrain-rmse:3.06153\teval-rmse:2.47486                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:3.06003\teval-rmse:2.4723                                                                               \n",
      "\n",
      "[75]\ttrain-rmse:3.05714\teval-rmse:2.47349                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:3.05396\teval-rmse:2.47419                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[56]\ttrain-rmse:3.10492\teval-rmse:2.46978\n",
      "\n",
      "\n",
      "loss: 88063851.18975623                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.1050092137459474e-08, 'colsample_bytree': 0.75, 'gamma': 0.0018287767196533099, 'lambda': 0.0634627239189973, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.7137310888167613, 'n_estimators': 248.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.67113\teval-rmse:5.58061                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.37178\teval-rmse:4.23227                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.59044\teval-rmse:3.43795                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.13791\teval-rmse:3.00521                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.86304\teval-rmse:2.8                                                                                   \n",
      "\n",
      "[5]\ttrain-rmse:2.68674\teval-rmse:2.67904                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.58202\teval-rmse:2.64268                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.4968\teval-rmse:2.62593                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.4445\teval-rmse:2.62359                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.40558\teval-rmse:2.60938                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.36814\teval-rmse:2.60275                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.33289\teval-rmse:2.60215                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.31144\teval-rmse:2.61332                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.29233\teval-rmse:2.61749                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.25992\teval-rmse:2.61791                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.22476\teval-rmse:2.64097                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\ttrain-rmse:2.19676\teval-rmse:2.66059                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.16719\teval-rmse:2.66547                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.12372\teval-rmse:2.65255                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.09667\teval-rmse:2.65754                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.05437\teval-rmse:2.66787                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.02542\teval-rmse:2.67571                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.00393\teval-rmse:2.68257                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.9534\teval-rmse:2.67957                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.92204\teval-rmse:2.67843                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.906\teval-rmse:2.68315                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:1.87328\teval-rmse:2.68518                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.84946\teval-rmse:2.67686                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.83462\teval-rmse:2.67196                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.81941\teval-rmse:2.67185                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.79119\teval-rmse:2.67303                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.76415\teval-rmse:2.67704                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.33289\teval-rmse:2.60215\n",
      "\n",
      "\n",
      "loss: 69779789.96547382                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.269835773204796e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.16566901499100106, 'lambda': 0.3771246240568817, 'learning_rate': 0.35000000000000003, 'max_depth': 3, 'min_child_weight': 0.47120441994157514, 'n_estimators': 144.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.67989\teval-rmse:5.42227                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.50973\teval-rmse:4.03009                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.88932\teval-rmse:3.27692                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.57924\teval-rmse:2.86847                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.42938\teval-rmse:2.67958                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.35383\teval-rmse:2.58897                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.31569\teval-rmse:2.54606                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.29044\teval-rmse:2.51894                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.26912\teval-rmse:2.50684                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.26063\teval-rmse:2.50006                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.2476\teval-rmse:2.50565                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.24\teval-rmse:2.50317                                                                                 \n",
      "\n",
      "[12]\ttrain-rmse:3.23044\teval-rmse:2.4963                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.22306\teval-rmse:2.50484                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.21732\teval-rmse:2.50176                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.2111\teval-rmse:2.50171                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.20204\teval-rmse:2.49496                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.1936\teval-rmse:2.50635                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:3.18682\teval-rmse:2.50343                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.18205\teval-rmse:2.50532                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.17942\teval-rmse:2.50417                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.17122\teval-rmse:2.49738                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.16593\teval-rmse:2.49685                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.15957\teval-rmse:2.49646                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.1559\teval-rmse:2.48884                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.15185\teval-rmse:2.49025                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.14954\teval-rmse:2.48913                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.14726\teval-rmse:2.49177                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.143\teval-rmse:2.48999                                                                                \n",
      "\n",
      "[29]\ttrain-rmse:3.1381\teval-rmse:2.49559                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:3.13485\teval-rmse:2.49832                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.13393\teval-rmse:2.49819                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.13003\teval-rmse:2.49633                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.12616\teval-rmse:2.49538                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.12302\teval-rmse:2.49017                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.11986\teval-rmse:2.49023                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.11727\teval-rmse:2.49428                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.11203\teval-rmse:2.48544                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.10825\teval-rmse:2.48444                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.10419\teval-rmse:2.48263                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.10154\teval-rmse:2.48231                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.10002\teval-rmse:2.47945                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.09699\teval-rmse:2.48073                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43]\ttrain-rmse:3.09644\teval-rmse:2.4803                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:3.09329\teval-rmse:2.48188                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.0893\teval-rmse:2.4794                                                                                \n",
      "\n",
      "[46]\ttrain-rmse:3.08695\teval-rmse:2.48031                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.08421\teval-rmse:2.48183                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.08079\teval-rmse:2.4865                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:3.07924\teval-rmse:2.48602                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.07647\teval-rmse:2.4856                                                                               \n",
      "\n",
      "[51]\ttrain-rmse:3.07163\teval-rmse:2.48364                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.06876\teval-rmse:2.48221                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.06618\teval-rmse:2.48978                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.06552\teval-rmse:2.48974                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:3.06278\teval-rmse:2.48933                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.05919\teval-rmse:2.48316                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:3.0559\teval-rmse:2.48446                                                                               \n",
      "\n",
      "[58]\ttrain-rmse:3.05261\teval-rmse:2.48076                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.05\teval-rmse:2.48012                                                                                 \n",
      "\n",
      "[60]\ttrain-rmse:3.04773\teval-rmse:2.48474                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:3.04442\teval-rmse:2.49121                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:3.04208\teval-rmse:2.49524                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:3.03966\teval-rmse:2.4995                                                                               \n",
      "\n",
      "[64]\ttrain-rmse:3.03722\teval-rmse:2.4968                                                                               \n",
      "\n",
      "[65]\ttrain-rmse:3.0347\teval-rmse:2.49867                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[45]\ttrain-rmse:3.0893\teval-rmse:2.4794\n",
      "\n",
      "\n",
      "loss: 82067884.21755938                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.8578608885510106e-05, 'colsample_bytree': 0.9, 'gamma': 1.626902660420816e-05, 'lambda': 0.9604127545221981, 'learning_rate': 0.375, 'max_depth': 8, 'min_child_weight': 2.029792498237964, 'n_estimators': 374.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.41931\teval-rmse:5.24306                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.1196\teval-rmse:3.83662                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.44014\teval-rmse:3.11541                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.0881\teval-rmse:2.77816                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.91984\teval-rmse:2.62369                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.81238\teval-rmse:2.57868                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.73709\teval-rmse:2.55585                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.69234\teval-rmse:2.54663                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.64698\teval-rmse:2.54059                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.61316\teval-rmse:2.53635                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.58543\teval-rmse:2.53582                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.56539\teval-rmse:2.54385                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.54914\teval-rmse:2.54276                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.52784\teval-rmse:2.54216                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.51174\teval-rmse:2.55566                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.47119\teval-rmse:2.5637                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.44863\teval-rmse:2.57424                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.42623\teval-rmse:2.56948                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.37275\teval-rmse:2.57093                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.3493\teval-rmse:2.57587                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.32714\teval-rmse:2.57783                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.29469\teval-rmse:2.5937                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.27811\teval-rmse:2.59246                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.27172\teval-rmse:2.59204                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.23396\teval-rmse:2.59271                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.2214\teval-rmse:2.59314                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.20487\teval-rmse:2.59866                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.17864\teval-rmse:2.60472                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.14931\teval-rmse:2.60118                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.12104\teval-rmse:2.61066                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.10379\teval-rmse:2.61601                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.58543\teval-rmse:2.53582\n",
      "\n",
      "\n",
      "loss: 57440721.44144043                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00018489755177770206, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.3494642788564748e-05, 'lambda': 0.09763918518840624, 'learning_rate': 0.45, 'max_depth': 8, 'min_child_weight': 6.24451710645325, 'n_estimators': 348.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.0002\teval-rmse:4.75704                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.73545\teval-rmse:3.3732                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.19946\teval-rmse:2.82342                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.97523\teval-rmse:2.61904                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.85798\teval-rmse:2.5567                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.79065\teval-rmse:2.53187                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.74966\teval-rmse:2.53251                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.72352\teval-rmse:2.54186                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.6905\teval-rmse:2.55617                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.6755\teval-rmse:2.5653                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.63624\teval-rmse:2.60051                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.59958\teval-rmse:2.62483                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.57926\teval-rmse:2.63419                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.54779\teval-rmse:2.6771                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.53327\teval-rmse:2.68682                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.4945\teval-rmse:2.70693                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.481\teval-rmse:2.73476                                                                                \n",
      "\n",
      "[17]\ttrain-rmse:2.45823\teval-rmse:2.73319                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.41792\teval-rmse:2.76452                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.38318\teval-rmse:2.76592                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.36555\teval-rmse:2.76306                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.34124\teval-rmse:2.77316                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.28651\teval-rmse:2.75885                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.27161\teval-rmse:2.75467                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.25829\teval-rmse:2.76597                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.24699\teval-rmse:2.76871                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.79065\teval-rmse:2.53187\n",
      "\n",
      "\n",
      "loss: 122109387.91654482                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.864874576036506e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 6.7437190066540145e-06, 'lambda': 0.0006296374651015486, 'learning_rate': 0.375, 'max_depth': 8, 'min_child_weight': 4.741245954099182, 'n_estimators': 373.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.41934\teval-rmse:5.2314                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.11714\teval-rmse:3.8267                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.44014\teval-rmse:3.10814                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.10277\teval-rmse:2.77755                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.93112\teval-rmse:2.64056                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.83786\teval-rmse:2.59165                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.77365\teval-rmse:2.57529                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.72046\teval-rmse:2.57706                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.69207\teval-rmse:2.57135                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.64516\teval-rmse:2.56569                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.60447\teval-rmse:2.55764                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.59245\teval-rmse:2.55976                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.56834\teval-rmse:2.56078                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.53588\teval-rmse:2.56555                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.49209\teval-rmse:2.55663                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.45915\teval-rmse:2.57677                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.43095\teval-rmse:2.5834                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.41151\teval-rmse:2.58803                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.39059\teval-rmse:2.59679                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.38234\teval-rmse:2.59855                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.35144\teval-rmse:2.60548                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.31692\teval-rmse:2.62105                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.28717\teval-rmse:2.62098                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.27053\teval-rmse:2.61555                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.24219\teval-rmse:2.6173                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.22847\teval-rmse:2.6226                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.20815\teval-rmse:2.62641                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.19564\teval-rmse:2.62648                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.18635\teval-rmse:2.62802                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.17315\teval-rmse:2.62887                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.1639\teval-rmse:2.6292                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\ttrain-rmse:2.1397\teval-rmse:2.6341                                                                                \n",
      "\n",
      "[32]\ttrain-rmse:2.13039\teval-rmse:2.637                                                                                \n",
      "\n",
      "[33]\ttrain-rmse:2.11359\teval-rmse:2.63347                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.10755\teval-rmse:2.63376                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[14]\ttrain-rmse:2.49209\teval-rmse:2.55663\n",
      "\n",
      "\n",
      "loss: 69536528.2769285                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0002938013791422319, 'colsample_bytree': 0.9, 'gamma': 5.358666455954731e-07, 'lambda': 1.9961212576843465e-06, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 3.2098137700139615, 'n_estimators': 181.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.27696\teval-rmse:5.07151                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.97228\teval-rmse:3.65967                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.3326\teval-rmse:2.99726                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.04636\teval-rmse:2.72768                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.8981\teval-rmse:2.62805                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.81574\teval-rmse:2.60048                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.74164\teval-rmse:2.60799                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.7074\teval-rmse:2.60535                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.65449\teval-rmse:2.60039                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.63812\teval-rmse:2.59511                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.61007\teval-rmse:2.59578                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.57391\teval-rmse:2.59485                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.54104\teval-rmse:2.59725                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.50718\teval-rmse:2.61642                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.48628\teval-rmse:2.61516                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.46785\teval-rmse:2.60455                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.45339\teval-rmse:2.6118                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.40638\teval-rmse:2.62858                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.36443\teval-rmse:2.63615                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.34846\teval-rmse:2.6263                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.33889\teval-rmse:2.62733                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.32168\teval-rmse:2.62961                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.29891\teval-rmse:2.62889                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.25646\teval-rmse:2.64533                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.23341\teval-rmse:2.64137                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.20627\teval-rmse:2.66755                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.16823\teval-rmse:2.67773                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.14591\teval-rmse:2.69664                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.1245\teval-rmse:2.72109                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.10993\teval-rmse:2.71205                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.08888\teval-rmse:2.71494                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.07161\teval-rmse:2.71894                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.57391\teval-rmse:2.59485\n",
      "\n",
      "\n",
      "loss: 63540432.32857251                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0008710756436020113, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.5071600444644761e-07, 'lambda': 8.629818170712776, 'learning_rate': 0.47500000000000003, 'max_depth': 8, 'min_child_weight': 2.7800951752715917, 'n_estimators': 398.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.90089\teval-rmse:4.62343                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.67382\teval-rmse:3.25016                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.18401\teval-rmse:2.74849                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.99753\teval-rmse:2.58236                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.89794\teval-rmse:2.53028                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.83737\teval-rmse:2.53627                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.79276\teval-rmse:2.53843                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.7749\teval-rmse:2.541                                                                                  \n",
      "\n",
      "[8]\ttrain-rmse:2.721\teval-rmse:2.56076                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:2.70381\teval-rmse:2.56707                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.65524\teval-rmse:2.56602                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.61137\teval-rmse:2.56016                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.56623\teval-rmse:2.59042                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.52539\teval-rmse:2.61233                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.50492\teval-rmse:2.61149                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.47888\teval-rmse:2.60882                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\ttrain-rmse:2.46559\teval-rmse:2.61543                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.43085\teval-rmse:2.62432                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.39709\teval-rmse:2.63744                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.36936\teval-rmse:2.62779                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.34927\teval-rmse:2.63987                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.32613\teval-rmse:2.64244                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.30258\teval-rmse:2.64896                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.27982\teval-rmse:2.65416                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.26259\teval-rmse:2.65735                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.89794\teval-rmse:2.53028\n",
      "\n",
      "\n",
      "loss: 79225733.31348772                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.2923803826188555e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.3203524444786038e-08, 'lambda': 1.0686249977467224, 'learning_rate': 0.45, 'max_depth': 8, 'min_child_weight': 2.2127994930449844, 'n_estimators': 473.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:5.01286\teval-rmse:4.76845                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.75927\teval-rmse:3.38557                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.21858\teval-rmse:2.82747                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.00013\teval-rmse:2.64283                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.88947\teval-rmse:2.58741                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.82453\teval-rmse:2.61106                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.77246\teval-rmse:2.62088                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.73458\teval-rmse:2.66065                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.68714\teval-rmse:2.67544                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.66259\teval-rmse:2.66462                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.63636\teval-rmse:2.67889                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.59983\teval-rmse:2.71109                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.55202\teval-rmse:2.75533                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.52081\teval-rmse:2.75897                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.49727\teval-rmse:2.76615                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.46003\teval-rmse:2.76753                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.42945\teval-rmse:2.77731                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.39257\teval-rmse:2.78192                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.36493\teval-rmse:2.80348                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.34569\teval-rmse:2.80338                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.32326\teval-rmse:2.80177                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.30118\teval-rmse:2.79679                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.27517\teval-rmse:2.79497                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.2436\teval-rmse:2.79535                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.22681\teval-rmse:2.82038                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.88947\teval-rmse:2.58741\n",
      "\n",
      "\n",
      "loss: 5946824102.869896                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.005117197672916612, 'colsample_bytree': 0.9, 'gamma': 1.888554918870945e-05, 'lambda': 0.025677232695160337, 'learning_rate': 0.5, 'max_depth': 8, 'min_child_weight': 0.28785946408759866, 'n_estimators': 302.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.71536\teval-rmse:4.47684                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.47751\teval-rmse:3.19663                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.02296\teval-rmse:2.78003                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.85267\teval-rmse:2.65915                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.75962\teval-rmse:2.65164                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.70779\teval-rmse:2.64323                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.6702\teval-rmse:2.64243                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.6106\teval-rmse:2.66432                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.5473\teval-rmse:2.68684                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.50883\teval-rmse:2.69882                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.49324\teval-rmse:2.7039                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.47236\teval-rmse:2.71117                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.4363\teval-rmse:2.71868                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.422\teval-rmse:2.72887                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:2.36571\teval-rmse:2.73103                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.34481\teval-rmse:2.73611                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.32244\teval-rmse:2.73736                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.30243\teval-rmse:2.73946                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18]\ttrain-rmse:2.27029\teval-rmse:2.74246                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.24005\teval-rmse:2.74276                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.22303\teval-rmse:2.74667                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.1917\teval-rmse:2.74782                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.17363\teval-rmse:2.76237                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.13901\teval-rmse:2.78244                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.08465\teval-rmse:2.78298                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.07512\teval-rmse:2.78122                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.03455\teval-rmse:2.79273                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.6702\teval-rmse:2.64243\n",
      "\n",
      "\n",
      "loss: 85371349.46136494                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.002634364618402598, 'colsample_bytree': 0.9, 'gamma': 7.249771732080934e-07, 'lambda': 3.8248897074642736, 'learning_rate': 0.375, 'max_depth': 5, 'min_child_weight': 1.0957221381993756, 'n_estimators': 531.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.49732\teval-rmse:5.24035                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.28352\teval-rmse:3.84084                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.67833\teval-rmse:3.10349                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.39604\teval-rmse:2.74882                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.26772\teval-rmse:2.59177                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.19928\teval-rmse:2.52071                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.16163\teval-rmse:2.47616                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.13132\teval-rmse:2.48621                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.11048\teval-rmse:2.48832                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.09547\teval-rmse:2.48097                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.07536\teval-rmse:2.48669                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.06252\teval-rmse:2.47987                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.04809\teval-rmse:2.49019                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.03586\teval-rmse:2.4945                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.03137\teval-rmse:2.49159                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.01956\teval-rmse:2.49523                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.01371\teval-rmse:2.51012                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.00289\teval-rmse:2.50874                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.99509\teval-rmse:2.51029                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.97722\teval-rmse:2.51331                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.96177\teval-rmse:2.51309                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.95367\teval-rmse:2.51773                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.9405\teval-rmse:2.51706                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.92696\teval-rmse:2.51855                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.91649\teval-rmse:2.51771                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.90323\teval-rmse:2.52255                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.89397\teval-rmse:2.52122                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:3.16163\teval-rmse:2.47616\n",
      "\n",
      "\n",
      "loss: 75659098.94221255                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.2371977148364244e-05, 'colsample_bytree': 0.7000000000000001, 'gamma': 3.612631534522762e-08, 'lambda': 0.008200964480306702, 'learning_rate': 0.42500000000000004, 'max_depth': 7, 'min_child_weight': 0.15044209439968617, 'n_estimators': 231.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.16753\teval-rmse:4.92092                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.90717\teval-rmse:3.49774                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.35103\teval-rmse:2.89                                                                                  \n",
      "\n",
      "[3]\ttrain-rmse:3.11022\teval-rmse:2.6398                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.998\teval-rmse:2.55578                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.9328\teval-rmse:2.53726                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.89276\teval-rmse:2.51321                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.84259\teval-rmse:2.50397                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.82274\teval-rmse:2.50171                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.78202\teval-rmse:2.50374                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.74517\teval-rmse:2.50711                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.72094\teval-rmse:2.50317                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.70043\teval-rmse:2.5105                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.67857\teval-rmse:2.51026                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.66357\teval-rmse:2.52232                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.64905\teval-rmse:2.53074                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\ttrain-rmse:2.60938\teval-rmse:2.51559                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.59351\teval-rmse:2.51881                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.5877\teval-rmse:2.51576                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.5596\teval-rmse:2.51728                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.54008\teval-rmse:2.51645                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.52877\teval-rmse:2.52272                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.49864\teval-rmse:2.54713                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.48434\teval-rmse:2.54352                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.46957\teval-rmse:2.54442                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.45031\teval-rmse:2.54432                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.42639\teval-rmse:2.55273                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.4072\teval-rmse:2.54362                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.40081\teval-rmse:2.5424                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.82274\teval-rmse:2.50171\n",
      "\n",
      "\n",
      "loss: 74943901.73402756                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.934767392543247e-06, 'colsample_bytree': 0.8500000000000001, 'gamma': 4.057208146369232e-05, 'lambda': 2.5463050962270057, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 8.281561501423818, 'n_estimators': 265.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:5.30337\teval-rmse:5.08216                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.02144\teval-rmse:3.66207                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.40101\teval-rmse:2.99272                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.11845\teval-rmse:2.69224                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.96871\teval-rmse:2.57131                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.89913\teval-rmse:2.53633                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.85697\teval-rmse:2.52217                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.82676\teval-rmse:2.5151                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.7759\teval-rmse:2.50796                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.757\teval-rmse:2.51122                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.73708\teval-rmse:2.52719                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.71954\teval-rmse:2.52474                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.68142\teval-rmse:2.54702                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.65898\teval-rmse:2.55901                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.63732\teval-rmse:2.57987                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.60735\teval-rmse:2.58284                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.58421\teval-rmse:2.58825                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.57525\teval-rmse:2.58625                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.55385\teval-rmse:2.60651                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.52617\teval-rmse:2.58856                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.51716\teval-rmse:2.59275                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.49808\teval-rmse:2.60398                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.46432\teval-rmse:2.613                                                                                \n",
      "\n",
      "[23]\ttrain-rmse:2.43412\teval-rmse:2.61912                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.41581\teval-rmse:2.62337                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.40245\teval-rmse:2.62722                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.39418\teval-rmse:2.63354                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.36694\teval-rmse:2.65773                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.34726\teval-rmse:2.66246                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.7759\teval-rmse:2.50796\n",
      "\n",
      "\n",
      "loss: 67083229.00703128                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.5457720199741515e-06, 'colsample_bytree': 0.65, 'gamma': 3.1118575242965695e-07, 'lambda': 6.804860147788983, 'learning_rate': 0.35000000000000003, 'max_depth': 6, 'min_child_weight': 0.58825991786068, 'n_estimators': 558.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.62582\teval-rmse:5.41288                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.41241\teval-rmse:4.02358                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.75513\teval-rmse:3.25332                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.41843\teval-rmse:2.84263                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.24609\teval-rmse:2.65855                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.15281\teval-rmse:2.57809                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.10524\teval-rmse:2.52911                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.06824\teval-rmse:2.51119                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.04396\teval-rmse:2.50855                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.02472\teval-rmse:2.50207                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:3.00579\teval-rmse:2.50927                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.98885\teval-rmse:2.50774                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.97069\teval-rmse:2.51561                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.95697\teval-rmse:2.51731                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.94192\teval-rmse:2.52183                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.92092\teval-rmse:2.52261                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.90855\teval-rmse:2.52071                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.89775\teval-rmse:2.51008                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.88303\teval-rmse:2.52123                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.87025\teval-rmse:2.52736                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.85573\teval-rmse:2.52294                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.84481\teval-rmse:2.52992                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.83462\teval-rmse:2.53313                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.81908\teval-rmse:2.53031                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.79939\teval-rmse:2.53042                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.78619\teval-rmse:2.52909                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.78072\teval-rmse:2.52757                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.76995\teval-rmse:2.54146                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.75423\teval-rmse:2.53325                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.738\teval-rmse:2.53578                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:3.02472\teval-rmse:2.50207\n",
      "\n",
      "\n",
      "loss: 72347379.65581585                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 9.271842757541149e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.00022049425267712806, 'lambda': 0.47061969786292385, 'learning_rate': 0.30000000000000004, 'max_depth': 4, 'min_child_weight': 1.3945826637928762, 'n_estimators': 445.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.93865\teval-rmse:5.72357                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.7973\teval-rmse:4.40492                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.10941\teval-rmse:3.58577                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.71342\teval-rmse:3.07781                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.48951\teval-rmse:2.80182                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.36944\teval-rmse:2.6464                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.29921\teval-rmse:2.55967                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.25906\teval-rmse:2.52285                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.23241\teval-rmse:2.48926                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.21637\teval-rmse:2.48018                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.19653\teval-rmse:2.47801                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.17738\teval-rmse:2.47661                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.1631\teval-rmse:2.47748                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.15516\teval-rmse:2.47468                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.14478\teval-rmse:2.4831                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:3.13561\teval-rmse:2.48579                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.13234\teval-rmse:2.48549                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.12452\teval-rmse:2.48924                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.11369\teval-rmse:2.49471                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.10619\teval-rmse:2.49364                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.09797\teval-rmse:2.48997                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.09039\teval-rmse:2.49952                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.08178\teval-rmse:2.50156                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.0777\teval-rmse:2.49623                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:3.06948\teval-rmse:2.4958                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.06309\teval-rmse:2.49323                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.05509\teval-rmse:2.49321                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.05112\teval-rmse:2.49383                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.04613\teval-rmse:2.49308                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.03709\teval-rmse:2.48779                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.03159\teval-rmse:2.48189                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.02609\teval-rmse:2.48522                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.01992\teval-rmse:2.48644                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.01528\teval-rmse:2.48336                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:3.15516\teval-rmse:2.47468\n",
      "\n",
      "\n",
      "loss: 83514999.68848304                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.03989535029113257, 'colsample_bytree': 0.9, 'gamma': 3.2541513204605883e-06, 'lambda': 0.2261073714482834, 'learning_rate': 0.325, 'max_depth': 8, 'min_child_weight': 1.8556272468314856, 'n_estimators': 517.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.71709\teval-rmse:5.55656                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.45941\teval-rmse:4.19097                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.72812\teval-rmse:3.38169                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.30784\teval-rmse:2.92289                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.06353\teval-rmse:2.7015                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.92596\teval-rmse:2.6048                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.82587\teval-rmse:2.55178                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.76681\teval-rmse:2.53287                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.73232\teval-rmse:2.51347                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.70536\teval-rmse:2.5101                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.67032\teval-rmse:2.51915                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.63588\teval-rmse:2.54342                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.60336\teval-rmse:2.54449                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.59066\teval-rmse:2.53512                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.56675\teval-rmse:2.53674                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.53048\teval-rmse:2.53634                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.50071\teval-rmse:2.53016                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.4712\teval-rmse:2.54253                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.45816\teval-rmse:2.55351                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.43225\teval-rmse:2.5479                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.41136\teval-rmse:2.54822                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.39405\teval-rmse:2.55502                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.37414\teval-rmse:2.56131                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.34372\teval-rmse:2.55989                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.31799\teval-rmse:2.56499                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.30334\teval-rmse:2.57021                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.27337\teval-rmse:2.56755                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.25327\teval-rmse:2.56865                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.22635\teval-rmse:2.57447                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.20772\teval-rmse:2.59614                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.70536\teval-rmse:2.5101\n",
      "\n",
      "\n",
      "loss: 74861810.58834524                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00036197298198659264, 'colsample_bytree': 0.9500000000000001, 'gamma': 8.775942087198732e-08, 'lambda': 0.7999888871233389, 'learning_rate': 0.5, 'max_depth': 8, 'min_child_weight': 3.562278446184794, 'n_estimators': 170.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.72262\teval-rmse:4.47506                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.49658\teval-rmse:3.17695                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.05653\teval-rmse:2.75034                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.88795\teval-rmse:2.65179                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.80295\teval-rmse:2.62728                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.74373\teval-rmse:2.63984                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.68362\teval-rmse:2.6747                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.65546\teval-rmse:2.67386                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.61571\teval-rmse:2.74665                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.59153\teval-rmse:2.75625                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.54255\teval-rmse:2.75544                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.51073\teval-rmse:2.77128                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.48846\teval-rmse:2.77689                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.46461\teval-rmse:2.78671                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.43281\teval-rmse:2.79445                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.41479\teval-rmse:2.79219                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.35504\teval-rmse:2.77404                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.33487\teval-rmse:2.78166                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.29214\teval-rmse:2.77958                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.25184\teval-rmse:2.78856                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.20174\teval-rmse:2.78533                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.18628\teval-rmse:2.78268                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.16641\teval-rmse:2.78038                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.1412\teval-rmse:2.78471                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.13105\teval-rmse:2.78396                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.80295\teval-rmse:2.62728\n",
      "\n",
      "\n",
      "loss: 210066238.766039                                                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.0008178253504736e-05, 'colsample_bytree': 0.9, 'gamma': 8.052002351521948e-06, 'lambda': 0.00014389497101408635, 'learning_rate': 0.42500000000000004, 'max_depth': 3, 'min_child_weight': 0.7504428161814689, 'n_estimators': 412.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.27717\teval-rmse:4.95947                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.12097\teval-rmse:3.56092                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.629\teval-rmse:2.93819                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:3.43369\teval-rmse:2.69671                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.35024\teval-rmse:2.58447                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.31043\teval-rmse:2.54023                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.28834\teval-rmse:2.51466                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.27476\teval-rmse:2.51423                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.26603\teval-rmse:2.50536                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.25131\teval-rmse:2.49728                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.24602\teval-rmse:2.4958                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.23634\teval-rmse:2.50572                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.23022\teval-rmse:2.52075                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.2234\teval-rmse:2.51393                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.21856\teval-rmse:2.51822                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.20803\teval-rmse:2.51095                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.20644\teval-rmse:2.51101                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.20114\teval-rmse:2.53097                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.19784\teval-rmse:2.53961                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.19483\teval-rmse:2.53727                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.18494\teval-rmse:2.53239                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.17606\teval-rmse:2.52621                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.17206\teval-rmse:2.52427                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.16909\teval-rmse:2.52162                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.16164\teval-rmse:2.52149                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.15672\teval-rmse:2.51735                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.15153\teval-rmse:2.51551                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.14956\teval-rmse:2.52045                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.14406\teval-rmse:2.53323                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.14076\teval-rmse:2.52761                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.1372\teval-rmse:2.52961                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:3.24602\teval-rmse:2.4958\n",
      "\n",
      "\n",
      "loss: 87303191.37860869                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0005541007437128318, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.6202321431888864e-06, 'lambda': 0.0016086926914955248, 'learning_rate': 0.375, 'max_depth': 7, 'min_child_weight': 1.6207790248120044, 'n_estimators': 120.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.44842\teval-rmse:5.23021                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.18584\teval-rmse:3.84233                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.5354\teval-rmse:3.13225                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.21976\teval-rmse:2.80276                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.05116\teval-rmse:2.6791                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.96753\teval-rmse:2.61898                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.91174\teval-rmse:2.57193                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.87126\teval-rmse:2.57389                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.82728\teval-rmse:2.62077                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.8045\teval-rmse:2.62898                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.77052\teval-rmse:2.64421                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.74551\teval-rmse:2.65277                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.72369\teval-rmse:2.65605                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.71241\teval-rmse:2.65355                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.69014\teval-rmse:2.64577                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.66135\teval-rmse:2.65591                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.63866\teval-rmse:2.67833                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.61937\teval-rmse:2.68039                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.59736\teval-rmse:2.66984                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.5707\teval-rmse:2.67327                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.54865\teval-rmse:2.67836                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.52286\teval-rmse:2.68232                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.49951\teval-rmse:2.69002                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\ttrain-rmse:2.47673\teval-rmse:2.69622                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.45752\teval-rmse:2.73413                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.44027\teval-rmse:2.73359                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.43297\teval-rmse:2.73606                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.91174\teval-rmse:2.57193\n",
      "\n",
      "\n",
      "loss: 65364100.95400972                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0017118639676647186, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.4750646835799086e-05, 'lambda': 1.4841712828567661, 'learning_rate': 0.47500000000000003, 'max_depth': 5, 'min_child_weight': 0.22610672619744288, 'n_estimators': 198.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.95634\teval-rmse:4.61893                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.80997\teval-rmse:3.23639                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.38314\teval-rmse:2.72093                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.23379\teval-rmse:2.55979                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.17617\teval-rmse:2.50637                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.14008\teval-rmse:2.49152                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.10744\teval-rmse:2.498                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:3.08971\teval-rmse:2.49483                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.07003\teval-rmse:2.49354                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.05103\teval-rmse:2.50629                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.04406\teval-rmse:2.50654                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.02735\teval-rmse:2.5173                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.00813\teval-rmse:2.50857                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.98175\teval-rmse:2.49989                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.97168\teval-rmse:2.49787                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.96696\teval-rmse:2.49128                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.95412\teval-rmse:2.49225                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.94555\teval-rmse:2.49832                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.93856\teval-rmse:2.49197                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.92525\teval-rmse:2.49105                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.91528\teval-rmse:2.49297                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.89823\teval-rmse:2.49163                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.89057\teval-rmse:2.49212                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.87823\teval-rmse:2.50402                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.86947\teval-rmse:2.51567                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.8572\teval-rmse:2.52029                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.84508\teval-rmse:2.52893                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.83546\teval-rmse:2.52891                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.8232\teval-rmse:2.53188                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.81075\teval-rmse:2.54476                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.79777\teval-rmse:2.54641                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.7846\teval-rmse:2.54788                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.7762\teval-rmse:2.55124                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.76664\teval-rmse:2.55858                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.75761\teval-rmse:2.55806                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.75096\teval-rmse:2.56048                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.74611\teval-rmse:2.55955                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.73522\teval-rmse:2.55803                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.72477\teval-rmse:2.55736                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.71633\teval-rmse:2.55878                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[19]\ttrain-rmse:2.92525\teval-rmse:2.49105\n",
      "\n",
      "\n",
      "loss: 73478727.20818794                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.014480889869914094, 'colsample_bytree': 0.8, 'gamma': 5.257978184805538e-06, 'lambda': 0.005399160727535331, 'learning_rate': 0.275, 'max_depth': 6, 'min_child_weight': 0.2651275377923363, 'n_estimators': 384.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.05068\teval-rmse:5.89233                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.91598\teval-rmse:4.62387                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.18527\teval-rmse:3.77766                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.73203\teval-rmse:3.24899                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.45567\teval-rmse:2.93403                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.28651\teval-rmse:2.75609                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.18487\teval-rmse:2.6528                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.12479\teval-rmse:2.59616                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain-rmse:3.0816\teval-rmse:2.56246                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.05121\teval-rmse:2.54049                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.01754\teval-rmse:2.53689                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.99984\teval-rmse:2.52851                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.9853\teval-rmse:2.52535                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.96281\teval-rmse:2.54502                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.94736\teval-rmse:2.54118                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.92611\teval-rmse:2.55004                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.91454\teval-rmse:2.54821                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.90534\teval-rmse:2.54825                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.89527\teval-rmse:2.55335                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.88149\teval-rmse:2.56232                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.87233\teval-rmse:2.56075                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.85981\teval-rmse:2.56333                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.84505\teval-rmse:2.56459                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.83083\teval-rmse:2.5671                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.81619\teval-rmse:2.57347                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.80053\teval-rmse:2.57979                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.7907\teval-rmse:2.57947                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.78039\teval-rmse:2.5838                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.77327\teval-rmse:2.58401                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.76635\teval-rmse:2.58435                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.75088\teval-rmse:2.58464                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.74261\teval-rmse:2.59344                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.73133\teval-rmse:2.58941                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.9853\teval-rmse:2.52535\n",
      "\n",
      "\n",
      "loss: 73638360.64890738                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0009879664627737215, 'colsample_bytree': 0.9500000000000001, 'gamma': 8.806159388887534e-07, 'lambda': 0.043957807790933084, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 2.089074276085753, 'n_estimators': 336.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:5.56691\teval-rmse:5.38918                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.29295\teval-rmse:4.00959                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.57301\teval-rmse:3.24654                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.19223\teval-rmse:2.85169                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.98678\teval-rmse:2.6592                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.86739\teval-rmse:2.58249                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.80949\teval-rmse:2.53405                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.75496\teval-rmse:2.50279                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.71794\teval-rmse:2.49747                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.67798\teval-rmse:2.51721                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.63787\teval-rmse:2.52063                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.59469\teval-rmse:2.51853                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.57146\teval-rmse:2.54288                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.55911\teval-rmse:2.53749                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.52297\teval-rmse:2.54598                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.50056\teval-rmse:2.55365                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.48716\teval-rmse:2.56626                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.47218\teval-rmse:2.56906                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.45356\teval-rmse:2.5685                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.42505\teval-rmse:2.56482                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.40231\teval-rmse:2.55612                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.38687\teval-rmse:2.56611                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.36805\teval-rmse:2.57381                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.34339\teval-rmse:2.57998                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.30003\teval-rmse:2.57136                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.258\teval-rmse:2.57193                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:2.2318\teval-rmse:2.57615                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.22151\teval-rmse:2.57714                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.19585\teval-rmse:2.58555                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.71794\teval-rmse:2.49747\n",
      "\n",
      "\n",
      "loss: 75215475.58830895                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00011307590602032005, 'colsample_bytree': 0.9, 'gamma': 5.690295053692382e-05, 'lambda': 0.12409165253885397, 'learning_rate': 0.325, 'max_depth': 4, 'min_child_weight': 0.41048469066256493, 'n_estimators': 293.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.79615\teval-rmse:5.56212                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.62887\teval-rmse:4.21916                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.96591\teval-rmse:3.41464                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.61048\teval-rmse:2.96203                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.42436\teval-rmse:2.72302                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.32717\teval-rmse:2.60247                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.27178\teval-rmse:2.53847                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.23957\teval-rmse:2.50841                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.21712\teval-rmse:2.4983                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.19496\teval-rmse:2.4944                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.17725\teval-rmse:2.51312                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.15727\teval-rmse:2.51256                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.1472\teval-rmse:2.51067                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.14039\teval-rmse:2.50604                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.13133\teval-rmse:2.50524                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.12113\teval-rmse:2.501                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:3.11126\teval-rmse:2.51499                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.10582\teval-rmse:2.50832                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.09917\teval-rmse:2.50231                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.09462\teval-rmse:2.50659                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.08985\teval-rmse:2.51668                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.08243\teval-rmse:2.51804                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.0744\teval-rmse:2.51459                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:3.06828\teval-rmse:2.51033                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.05989\teval-rmse:2.51562                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.05544\teval-rmse:2.52044                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.04779\teval-rmse:2.51615                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.04534\teval-rmse:2.51573                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.03615\teval-rmse:2.51475                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.03221\teval-rmse:2.51319                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:3.19496\teval-rmse:2.4944\n",
      "\n",
      "\n",
      "loss: 87056294.41265588                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.365510169040839e-06, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.0006721034362714088, 'lambda': 2.0315444521340267e-05, 'learning_rate': 0.45, 'max_depth': 8, 'min_child_weight': 1.275503591065445, 'n_estimators': 262.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.991\teval-rmse:4.77801                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.70428\teval-rmse:3.41854                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.14288\teval-rmse:2.88223                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.91228\teval-rmse:2.71293                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.80213\teval-rmse:2.67246                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.7193\teval-rmse:2.6672                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:2.66761\teval-rmse:2.68309                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.63469\teval-rmse:2.66971                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.58229\teval-rmse:2.69239                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.55777\teval-rmse:2.72126                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.5024\teval-rmse:2.73636                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.45388\teval-rmse:2.73449                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.43955\teval-rmse:2.739                                                                                \n",
      "\n",
      "[13]\ttrain-rmse:2.38692\teval-rmse:2.75303                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.37121\teval-rmse:2.75685                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.34916\teval-rmse:2.78825                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.32567\teval-rmse:2.77641                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.3068\teval-rmse:2.77313                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.28693\teval-rmse:2.77995                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.26489\teval-rmse:2.78735                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.22376\teval-rmse:2.79043                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.20016\teval-rmse:2.79441                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.14949\teval-rmse:2.79836                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.10945\teval-rmse:2.79425                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.09694\teval-rmse:2.81826                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.08757\teval-rmse:2.81797                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.7193\teval-rmse:2.6672\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 125490903.99720395                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.6455733907879215e-05, 'colsample_bytree': 0.9, 'gamma': 0.0001320022675154527, 'lambda': 0.08009148786654625, 'learning_rate': 0.30000000000000004, 'max_depth': 3, 'min_child_weight': 0.5384309590685804, 'n_estimators': 361.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:5.96238\teval-rmse:5.73572                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.84061\teval-rmse:4.42921                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.16023\teval-rmse:3.61288                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.7706\teval-rmse:3.13336                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.55147\teval-rmse:2.83728                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.43345\teval-rmse:2.67488                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.36881\teval-rmse:2.57809                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.33129\teval-rmse:2.52874                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.30876\teval-rmse:2.50154                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.29128\teval-rmse:2.49443                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.27603\teval-rmse:2.48176                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.26467\teval-rmse:2.47835                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.25664\teval-rmse:2.48075                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.25088\teval-rmse:2.47946                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.23934\teval-rmse:2.47566                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.23263\teval-rmse:2.47416                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.2282\teval-rmse:2.4798                                                                                \n",
      "\n",
      "[17]\ttrain-rmse:3.21997\teval-rmse:2.48911                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.2115\teval-rmse:2.48365                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.20468\teval-rmse:2.4854                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:3.20007\teval-rmse:2.48364                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.19484\teval-rmse:2.4853                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:3.19287\teval-rmse:2.48352                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.18967\teval-rmse:2.49036                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.18413\teval-rmse:2.48534                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.18065\teval-rmse:2.48537                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.17834\teval-rmse:2.48069                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.17377\teval-rmse:2.48057                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.16927\teval-rmse:2.48815                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.1666\teval-rmse:2.48724                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:3.16341\teval-rmse:2.4838                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:3.16188\teval-rmse:2.48368                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.16102\teval-rmse:2.48304                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.15844\teval-rmse:2.48713                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.15562\teval-rmse:2.48708                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.15223\teval-rmse:2.49138                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:3.23263\teval-rmse:2.47416\n",
      "\n",
      "\n",
      "loss: 89700976.99514568                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.939827281202914e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 2.9842955297704607e-07, 'lambda': 0.2727735409377913, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 1.039588196858259, 'n_estimators': 430.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.2695\teval-rmse:5.07893                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.96462\teval-rmse:3.68792                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.32189\teval-rmse:3.01667                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.01409\teval-rmse:2.75727                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.85427\teval-rmse:2.64613                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.77889\teval-rmse:2.60664                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.71193\teval-rmse:2.59712                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.66056\teval-rmse:2.59463                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.63109\teval-rmse:2.58853                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.59854\teval-rmse:2.59737                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.5571\teval-rmse:2.60816                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.52393\teval-rmse:2.60608                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.48101\teval-rmse:2.6123                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.46489\teval-rmse:2.60957                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.43041\teval-rmse:2.62667                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.39794\teval-rmse:2.63578                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.35536\teval-rmse:2.63859                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\ttrain-rmse:2.33835\teval-rmse:2.64735                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.31063\teval-rmse:2.67502                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.29203\teval-rmse:2.681                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:2.26111\teval-rmse:2.68347                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.23089\teval-rmse:2.6926                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.19713\teval-rmse:2.677                                                                                \n",
      "\n",
      "[23]\ttrain-rmse:2.16439\teval-rmse:2.67609                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.14367\teval-rmse:2.67347                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.13166\teval-rmse:2.67354                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.11147\teval-rmse:2.67432                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.095\teval-rmse:2.6748                                                                                 \n",
      "\n",
      "[28]\ttrain-rmse:2.06449\teval-rmse:2.6794                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.63109\teval-rmse:2.58853\n",
      "\n",
      "\n",
      "loss: 65359135.154622145                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.940558431341587e-05, 'colsample_bytree': 0.8, 'gamma': 5.670595465369452e-08, 'lambda': 0.17245044504248092, 'learning_rate': 0.375, 'max_depth': 7, 'min_child_weight': 0.6324874690929116, 'n_estimators': 215.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.44648\teval-rmse:5.22792                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.18469\teval-rmse:3.82505                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.53942\teval-rmse:3.11143                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.22337\teval-rmse:2.76505                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.05484\teval-rmse:2.62404                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.96124\teval-rmse:2.56241                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.91061\teval-rmse:2.53195                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.86559\teval-rmse:2.52874                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.82618\teval-rmse:2.55205                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.78889\teval-rmse:2.55956                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.761\teval-rmse:2.58289                                                                                \n",
      "\n",
      "[11]\ttrain-rmse:2.74289\teval-rmse:2.58634                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.71778\teval-rmse:2.58921                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.69674\teval-rmse:2.58464                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.68351\teval-rmse:2.58995                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.66904\teval-rmse:2.58261                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.66\teval-rmse:2.58174                                                                                 \n",
      "\n",
      "[17]\ttrain-rmse:2.63689\teval-rmse:2.58934                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.6288\teval-rmse:2.58284                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.62069\teval-rmse:2.58885                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.6022\teval-rmse:2.58704                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.58496\teval-rmse:2.59058                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.56372\teval-rmse:2.59748                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.54338\teval-rmse:2.59489                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.50794\teval-rmse:2.61807                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.48431\teval-rmse:2.61287                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.4654\teval-rmse:2.62432                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.4457\teval-rmse:2.626                                                                                 \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.86559\teval-rmse:2.52874\n",
      "\n",
      "\n",
      "loss: 79534133.62237026                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.000153931904538849, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.1831757024795909e-07, 'lambda': 0.0003995955319512007, 'learning_rate': 0.25, 'max_depth': 5, 'min_child_weight': 2.7719610554306637, 'n_estimators': 311.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.21387\teval-rmse:6.04723                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.14753\teval-rmse:4.84829                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.4237\teval-rmse:4.00899                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.9507\teval-rmse:3.4485                                                                                 \n",
      "\n",
      "[4]\ttrain-rmse:3.64857\teval-rmse:3.0795                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.45373\teval-rmse:2.85215                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.3346\teval-rmse:2.71129                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.26268\teval-rmse:2.63172                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.2113\teval-rmse:2.57984                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.17618\teval-rmse:2.54572                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.14488\teval-rmse:2.52963                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.12382\teval-rmse:2.52157                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\ttrain-rmse:3.10287\teval-rmse:2.52782                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.08816\teval-rmse:2.52239                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.0723\teval-rmse:2.52106                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:3.06097\teval-rmse:2.51783                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.0447\teval-rmse:2.51206                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:3.03534\teval-rmse:2.50597                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.02543\teval-rmse:2.5057                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.02009\teval-rmse:2.50911                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.00676\teval-rmse:2.51088                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.99961\teval-rmse:2.50762                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.9882\teval-rmse:2.50644                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.98319\teval-rmse:2.51057                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.97368\teval-rmse:2.5159                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.96804\teval-rmse:2.51496                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.96196\teval-rmse:2.52068                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.95592\teval-rmse:2.52799                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.94509\teval-rmse:2.52515                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.93554\teval-rmse:2.52723                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.92956\teval-rmse:2.5292                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.92449\teval-rmse:2.53767                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.91508\teval-rmse:2.53493                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.90529\teval-rmse:2.53197                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.89954\teval-rmse:2.53654                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.89553\teval-rmse:2.53835                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.88876\teval-rmse:2.54128                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.88286\teval-rmse:2.53992                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.8735\teval-rmse:2.54122                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[18]\ttrain-rmse:3.02543\teval-rmse:2.5057\n",
      "\n",
      "\n",
      "loss: 82151744.4072918                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.245358634771858e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.00040122335835360827, 'lambda': 0.020459122418030124, 'learning_rate': 0.47500000000000003, 'max_depth': 6, 'min_child_weight': 0.4760499613357646, 'n_estimators': 132.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:4.93546\teval-rmse:4.60589                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.7608\teval-rmse:3.23928                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.32502\teval-rmse:2.72603                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.16511\teval-rmse:2.57003                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.09871\teval-rmse:2.54125                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.05835\teval-rmse:2.53094                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.02458\teval-rmse:2.52703                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.99728\teval-rmse:2.53351                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.97045\teval-rmse:2.55342                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.94811\teval-rmse:2.5584                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.925\teval-rmse:2.56734                                                                                \n",
      "\n",
      "[11]\ttrain-rmse:2.90821\teval-rmse:2.56902                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.89161\teval-rmse:2.59039                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.87503\teval-rmse:2.56736                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.85844\teval-rmse:2.57332                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.84746\teval-rmse:2.58463                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.83197\teval-rmse:2.59267                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.81864\teval-rmse:2.59623                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.79787\teval-rmse:2.61913                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.78611\teval-rmse:2.63496                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.77564\teval-rmse:2.63047                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.76157\teval-rmse:2.65536                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.74298\teval-rmse:2.65494                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.72627\teval-rmse:2.65325                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.71832\teval-rmse:2.65104                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.7004\teval-rmse:2.69194                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.68258\teval-rmse:2.69305                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:3.02458\teval-rmse:2.52703\n",
      "\n",
      "\n",
      "loss: 78505857.41425252                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.09892563125816028, 'colsample_bytree': 0.9, 'gamma': 2.191145614952809e-08, 'lambda': 4.365124561418576, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 0.7843165205042831, 'n_estimators': 465.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.58648\teval-rmse:5.39921                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.31335\teval-rmse:4.01497                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.60822\teval-rmse:3.24389                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.23076\teval-rmse:2.86631                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.00961\teval-rmse:2.66441                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.87549\teval-rmse:2.57534                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.80052\teval-rmse:2.53462                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.73912\teval-rmse:2.52759                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.69183\teval-rmse:2.51385                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.66051\teval-rmse:2.51155                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.63099\teval-rmse:2.52614                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.59151\teval-rmse:2.54812                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.57016\teval-rmse:2.54782                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.53505\teval-rmse:2.54661                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.51549\teval-rmse:2.54758                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.47734\teval-rmse:2.55091                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.45708\teval-rmse:2.56031                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.44663\teval-rmse:2.56327                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.42722\teval-rmse:2.55624                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.39645\teval-rmse:2.55086                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.37933\teval-rmse:2.55295                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.3607\teval-rmse:2.55099                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.3375\teval-rmse:2.55466                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.31455\teval-rmse:2.55811                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.27746\teval-rmse:2.55886                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.24796\teval-rmse:2.57061                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.23233\teval-rmse:2.57913                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.2193\teval-rmse:2.57967                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.19154\teval-rmse:2.58233                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.17375\teval-rmse:2.5873                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.66051\teval-rmse:2.51155\n",
      "\n",
      "\n",
      "loss: 65293274.486860335                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.2259515189130707e-05, 'colsample_bytree': 0.75, 'gamma': 2.418447382558962e-06, 'lambda': 0.012685987536087092, 'learning_rate': 0.275, 'max_depth': 4, 'min_child_weight': 0.3703188161678485, 'n_estimators': 598.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.08383\teval-rmse:5.90323                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.98094\teval-rmse:4.65091                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.27619\teval-rmse:3.81907                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.8438\teval-rmse:3.28314                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.58395\teval-rmse:2.95306                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.4335\teval-rmse:2.7635                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:3.34341\teval-rmse:2.64339                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.28886\teval-rmse:2.5718                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.25344\teval-rmse:2.53078                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.22955\teval-rmse:2.50458                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.21513\teval-rmse:2.49324                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.19886\teval-rmse:2.48463                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.18799\teval-rmse:2.48321                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.18067\teval-rmse:2.48442                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.16617\teval-rmse:2.47845                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.15504\teval-rmse:2.4792                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.14868\teval-rmse:2.47437                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.13908\teval-rmse:2.47338                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.12887\teval-rmse:2.47387                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.12151\teval-rmse:2.46561                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.11296\teval-rmse:2.46718                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.10826\teval-rmse:2.46712                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.10482\teval-rmse:2.46325                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.09827\teval-rmse:2.45874                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.09467\teval-rmse:2.45898                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.08694\teval-rmse:2.45993                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.08084\teval-rmse:2.46214                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.07675\teval-rmse:2.46253                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28]\ttrain-rmse:3.06856\teval-rmse:2.45873                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.05979\teval-rmse:2.45894                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.05628\teval-rmse:2.45704                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.05084\teval-rmse:2.46437                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.04995\teval-rmse:2.46338                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.04478\teval-rmse:2.46287                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.04079\teval-rmse:2.46205                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.03404\teval-rmse:2.46101                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.02887\teval-rmse:2.46034                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.02513\teval-rmse:2.46394                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.02088\teval-rmse:2.46962                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.01567\teval-rmse:2.47004                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.01076\teval-rmse:2.4736                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:3.00544\teval-rmse:2.47211                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.99921\teval-rmse:2.47742                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.99181\teval-rmse:2.4707                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:2.99081\teval-rmse:2.47044                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.98538\teval-rmse:2.4709                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.97938\teval-rmse:2.47206                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.97867\teval-rmse:2.47191                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.97442\teval-rmse:2.47214                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.96718\teval-rmse:2.47558                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.96387\teval-rmse:2.47486                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[30]\ttrain-rmse:3.05628\teval-rmse:2.45704\n",
      "\n",
      "\n",
      "loss: 80927105.99473129                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.6200241661696564e-07, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.4043969079845392e-06, 'lambda': 1.923525489951131, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 0.17746597357336455, 'n_estimators': 160.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.84623\teval-rmse:5.72381                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.60021\teval-rmse:4.40963                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.80608\teval-rmse:3.58434                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.31107\teval-rmse:3.10752                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.01336\teval-rmse:2.83782                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.81813\teval-rmse:2.70625                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.70339\teval-rmse:2.62466                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.60055\teval-rmse:2.59285                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.53407\teval-rmse:2.57079                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.47101\teval-rmse:2.5676                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.43471\teval-rmse:2.5674                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.39982\teval-rmse:2.57041                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.38195\teval-rmse:2.57703                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.3563\teval-rmse:2.58373                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.3363\teval-rmse:2.57723                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.30522\teval-rmse:2.58042                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.26915\teval-rmse:2.59097                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.23642\teval-rmse:2.59541                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.21292\teval-rmse:2.60436                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.20095\teval-rmse:2.60844                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.17959\teval-rmse:2.60919                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.16207\teval-rmse:2.61101                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.13473\teval-rmse:2.61039                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.10383\teval-rmse:2.60644                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.06303\teval-rmse:2.61224                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.05326\teval-rmse:2.61187                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.01528\teval-rmse:2.6035                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.00753\teval-rmse:2.60485                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.97\teval-rmse:2.59859                                                                                 \n",
      "\n",
      "[29]\ttrain-rmse:1.94521\teval-rmse:2.59927                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.92626\teval-rmse:2.59938                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.43471\teval-rmse:2.5674\n",
      "\n",
      "\n",
      "loss: 69301264.2182529                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.20986482995685e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 2.595709349006362e-05, 'lambda': 0.03221331748497707, 'learning_rate': 0.42500000000000004, 'max_depth': 3, 'min_child_weight': 4.023303406985339, 'n_estimators': 283.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.27698\teval-rmse:4.95759                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.1192\teval-rmse:3.55258                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.62788\teval-rmse:2.93857                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.43635\teval-rmse:2.69607                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.35431\teval-rmse:2.58588                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.31464\teval-rmse:2.54949                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.29171\teval-rmse:2.53176                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.27552\teval-rmse:2.52535                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.26662\teval-rmse:2.51727                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.25412\teval-rmse:2.51396                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.24612\teval-rmse:2.52359                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.23835\teval-rmse:2.51824                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.22366\teval-rmse:2.51522                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.2186\teval-rmse:2.51525                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.2124\teval-rmse:2.49953                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:3.20928\teval-rmse:2.50331                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.20134\teval-rmse:2.50433                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.19754\teval-rmse:2.50761                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.19235\teval-rmse:2.50481                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.18761\teval-rmse:2.50728                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.18386\teval-rmse:2.51397                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.17355\teval-rmse:2.50865                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.1702\teval-rmse:2.51248                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:3.1618\teval-rmse:2.51258                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:3.1582\teval-rmse:2.50989                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.15521\teval-rmse:2.50955                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.14694\teval-rmse:2.49827                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.14214\teval-rmse:2.50521                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.13676\teval-rmse:2.54464                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.13359\teval-rmse:2.53729                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.13009\teval-rmse:2.53332                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.12758\teval-rmse:2.52637                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.12397\teval-rmse:2.52639                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.12057\teval-rmse:2.53538                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.11701\teval-rmse:2.53362                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.11289\teval-rmse:2.5295                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:3.11042\teval-rmse:2.53797                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.10766\teval-rmse:2.53563                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.10434\teval-rmse:2.53552                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.10383\teval-rmse:2.5347                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:3.10107\teval-rmse:2.53086                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.09958\teval-rmse:2.53098                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.09721\teval-rmse:2.52679                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.09497\teval-rmse:2.52542                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.09311\teval-rmse:2.5244                                                                               \n",
      "\n",
      "[45]\ttrain-rmse:3.08783\teval-rmse:2.5317                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:3.08647\teval-rmse:2.53362                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[26]\ttrain-rmse:3.14694\teval-rmse:2.49827\n",
      "\n",
      "\n",
      "loss: 95828798.10473108                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.6510641572447594e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 4.196592593318984e-06, 'lambda': 0.0029684785450987674, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 2.4943092046046633, 'n_estimators': 190.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.27468\teval-rmse:5.08369                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.96407\teval-rmse:3.69224                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.32529\teval-rmse:3.03257                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.02729\teval-rmse:2.73677                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.87169\teval-rmse:2.61365                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.7788\teval-rmse:2.58613                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.71548\teval-rmse:2.57943                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.68983\teval-rmse:2.57882                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.65564\teval-rmse:2.58349                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.62448\teval-rmse:2.59015                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:2.59175\teval-rmse:2.59112                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.55839\teval-rmse:2.60624                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.52394\teval-rmse:2.62164                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.5019\teval-rmse:2.63052                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.48896\teval-rmse:2.63363                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.45321\teval-rmse:2.6513                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.41968\teval-rmse:2.65871                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.41263\teval-rmse:2.66038                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.35608\teval-rmse:2.67486                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.32653\teval-rmse:2.67352                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.26957\teval-rmse:2.69041                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.25622\teval-rmse:2.68783                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.22739\teval-rmse:2.69322                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.20928\teval-rmse:2.69647                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.19823\teval-rmse:2.69586                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.17792\teval-rmse:2.69615                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.15585\teval-rmse:2.70038                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.13369\teval-rmse:2.69978                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.68983\teval-rmse:2.57882\n",
      "\n",
      "\n",
      "loss: 69069610.66520017                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0038486622899273656, 'colsample_bytree': 0.65, 'gamma': 1.0224445198578686e-08, 'lambda': 3.9472696123364245e-05, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.20342178822103607, 'n_estimators': 650.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.67464\teval-rmse:5.56007                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.37535\teval-rmse:4.20545                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.59108\teval-rmse:3.40905                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.12703\teval-rmse:2.9849                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.86196\teval-rmse:2.77435                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.67807\teval-rmse:2.67449                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.57601\teval-rmse:2.62976                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.50356\teval-rmse:2.62148                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.45396\teval-rmse:2.59923                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.40134\teval-rmse:2.60793                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.35611\teval-rmse:2.61262                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.30573\teval-rmse:2.63002                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.28266\teval-rmse:2.629                                                                                \n",
      "\n",
      "[13]\ttrain-rmse:2.2567\teval-rmse:2.63669                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.22911\teval-rmse:2.63864                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.1916\teval-rmse:2.65824                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.16258\teval-rmse:2.66084                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.12767\teval-rmse:2.69785                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.10033\teval-rmse:2.70903                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.07099\teval-rmse:2.70775                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.04799\teval-rmse:2.70771                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.0305\teval-rmse:2.70928                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.00214\teval-rmse:2.70738                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.98486\teval-rmse:2.70511                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.97189\teval-rmse:2.70727                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.95953\teval-rmse:2.70687                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.91322\teval-rmse:2.71189                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.885\teval-rmse:2.70423                                                                                \n",
      "\n",
      "[28]\ttrain-rmse:1.86151\teval-rmse:2.71121                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.45396\teval-rmse:2.59923\n",
      "\n",
      "\n",
      "loss: 69273971.50198047                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0005638085031115569, 'colsample_bytree': 0.9, 'gamma': 5.366609093787371e-07, 'lambda': 2.975308941999231, 'learning_rate': 0.275, 'max_depth': 7, 'min_child_weight': 0.8980141506290596, 'n_estimators': 237.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:6.04346\teval-rmse:5.88621                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.89579\teval-rmse:4.61551                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.14818\teval-rmse:3.76902                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.67858\teval-rmse:3.2299                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.38335\teval-rmse:2.90137                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-rmse:3.20158\teval-rmse:2.71789                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.08897\teval-rmse:2.61102                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.00987\teval-rmse:2.55122                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.95714\teval-rmse:2.52186                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.91716\teval-rmse:2.51117                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.89136\teval-rmse:2.50457                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.86842\teval-rmse:2.49809                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.84453\teval-rmse:2.50102                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.82421\teval-rmse:2.50139                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.80156\teval-rmse:2.5149                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.78533\teval-rmse:2.51251                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.75551\teval-rmse:2.51299                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.72508\teval-rmse:2.5089                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.69635\teval-rmse:2.52209                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.67951\teval-rmse:2.52045                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.66457\teval-rmse:2.51878                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.64707\teval-rmse:2.52095                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.63077\teval-rmse:2.51792                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.61728\teval-rmse:2.5173                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.58429\teval-rmse:2.5116                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.572\teval-rmse:2.52013                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:2.56039\teval-rmse:2.5211                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.54659\teval-rmse:2.5214                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.52987\teval-rmse:2.51918                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.51634\teval-rmse:2.51854                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.49788\teval-rmse:2.52494                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.49228\teval-rmse:2.52537                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.86842\teval-rmse:2.49809\n",
      "\n",
      "\n",
      "loss: 70256617.82634068                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0073787946302593865, 'colsample_bytree': 0.9, 'gamma': 8.493176577132433e-05, 'lambda': 0.5108314365500742, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 1.2058736647030905, 'n_estimators': 490.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.57162\teval-rmse:5.3995                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.295\teval-rmse:4.00854                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:3.58499\teval-rmse:3.24791                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.21534\teval-rmse:2.84905                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.00543\teval-rmse:2.67262                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.89768\teval-rmse:2.61672                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.80956\teval-rmse:2.5781                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.76054\teval-rmse:2.56083                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.70272\teval-rmse:2.56319                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.66426\teval-rmse:2.56804                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.63128\teval-rmse:2.56713                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.59414\teval-rmse:2.57221                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.57882\teval-rmse:2.58405                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.55623\teval-rmse:2.59051                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.52613\teval-rmse:2.59694                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.51434\teval-rmse:2.5929                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.49396\teval-rmse:2.59431                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.46834\teval-rmse:2.59867                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.44743\teval-rmse:2.61352                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.41711\teval-rmse:2.61481                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.39926\teval-rmse:2.62784                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.37886\teval-rmse:2.63437                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.34845\teval-rmse:2.63346                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.33363\teval-rmse:2.63707                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.31406\teval-rmse:2.63978                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.2887\teval-rmse:2.6557                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:2.27052\teval-rmse:2.66074                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.26006\teval-rmse:2.66965                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.76054\teval-rmse:2.56083\n",
      "\n",
      "\n",
      "loss: 69417812.688143                                                                                                  \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.00024966935259043444, 'colsample_bytree': 0.6000000000000001, 'gamma': 0.004386494645616856, 'lambda': 1.1638661443188698, 'learning_rate': 0.15000000000000002, 'max_depth': 5, 'min_child_weight': 1.360154633977799, 'n_estimators': 255.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.81694\teval-rmse:6.72077                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.05804\teval-rmse:5.88042                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.43309\teval-rmse:5.18036                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.92922\teval-rmse:4.60485                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.52718\teval-rmse:4.1418                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:4.20905\teval-rmse:3.7753                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.96047\teval-rmse:3.47476                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.76778\teval-rmse:3.24428                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.61995\teval-rmse:3.05948                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.50644\teval-rmse:2.91597                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.41819\teval-rmse:2.80569                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.35147\teval-rmse:2.72628                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.29774\teval-rmse:2.66568                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.25398\teval-rmse:2.61865                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.22448\teval-rmse:2.58437                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.19902\teval-rmse:2.55531                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.17801\teval-rmse:2.53315                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.15967\teval-rmse:2.51574                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.14342\teval-rmse:2.50433                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.13218\teval-rmse:2.49575                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.11815\teval-rmse:2.48718                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.10803\teval-rmse:2.48824                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.09847\teval-rmse:2.48502                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.09043\teval-rmse:2.48127                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.08067\teval-rmse:2.47862                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.07367\teval-rmse:2.47811                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.06685\teval-rmse:2.47502                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.05939\teval-rmse:2.47987                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.05236\teval-rmse:2.47987                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.04633\teval-rmse:2.4824                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:3.04055\teval-rmse:2.48376                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.03629\teval-rmse:2.48402                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.03127\teval-rmse:2.47916                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.02652\teval-rmse:2.47945                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.02431\teval-rmse:2.48044                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.01952\teval-rmse:2.47977                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.01465\teval-rmse:2.47589                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.01184\teval-rmse:2.47257                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.00638\teval-rmse:2.47172                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.99965\teval-rmse:2.46826                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.99548\teval-rmse:2.46866                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.99013\teval-rmse:2.47018                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.98485\teval-rmse:2.46798                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.97802\teval-rmse:2.46977                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.97398\teval-rmse:2.47072                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.97027\teval-rmse:2.46714                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.96685\teval-rmse:2.46716                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.96138\teval-rmse:2.46748                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.9583\teval-rmse:2.46565                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:2.95271\teval-rmse:2.46605                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.94857\teval-rmse:2.46203                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.9473\teval-rmse:2.4619                                                                                \n",
      "\n",
      "[52]\ttrain-rmse:2.94194\teval-rmse:2.4629                                                                               \n",
      "\n",
      "[53]\ttrain-rmse:2.93721\teval-rmse:2.46143                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.93456\teval-rmse:2.46102                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.9317\teval-rmse:2.4632                                                                                \n",
      "\n",
      "[56]\ttrain-rmse:2.92645\teval-rmse:2.46391                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.92279\teval-rmse:2.46395                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.91856\teval-rmse:2.4666                                                                               \n",
      "\n",
      "[59]\ttrain-rmse:2.91305\teval-rmse:2.47185                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.91199\teval-rmse:2.47079                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.90764\teval-rmse:2.47081                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.90445\teval-rmse:2.47466                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63]\ttrain-rmse:2.9029\teval-rmse:2.47447                                                                               \n",
      "\n",
      "[64]\ttrain-rmse:2.90094\teval-rmse:2.47478                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.89859\teval-rmse:2.47491                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.89468\teval-rmse:2.47525                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.89347\teval-rmse:2.47494                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:2.89001\teval-rmse:2.47646                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.88594\teval-rmse:2.47562                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:2.88209\teval-rmse:2.47839                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:2.87807\teval-rmse:2.47696                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:2.87355\teval-rmse:2.47769                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:2.87047\teval-rmse:2.47404                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:2.8676\teval-rmse:2.47592                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[54]\ttrain-rmse:2.93456\teval-rmse:2.46102\n",
      "\n",
      "\n",
      "loss: 74653140.29559839                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.446470666903637e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.0002614179569092543, 'lambda': 0.059705827256460675, 'learning_rate': 0.2, 'max_depth': 6, 'min_child_weight': 6.92139051008757, 'n_estimators': 344.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.50319\teval-rmse:6.37451                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.55505\teval-rmse:5.32924                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.8408\teval-rmse:4.52853                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:4.31581\teval-rmse:3.92489                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.93558\teval-rmse:3.48136                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.66294\teval-rmse:3.15846                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.47419\teval-rmse:2.93517                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.33751\teval-rmse:2.77493                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.24079\teval-rmse:2.66633                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.17206\teval-rmse:2.60141                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.12281\teval-rmse:2.56126                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.08772\teval-rmse:2.52808                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.0625\teval-rmse:2.50129                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.03943\teval-rmse:2.48064                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.02276\teval-rmse:2.47708                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.00522\teval-rmse:2.47416                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.99025\teval-rmse:2.47237                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.9754\teval-rmse:2.47424                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.95837\teval-rmse:2.47196                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.9445\teval-rmse:2.46724                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.93363\teval-rmse:2.47145                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.92\teval-rmse:2.4759                                                                                  \n",
      "\n",
      "[22]\ttrain-rmse:2.91342\teval-rmse:2.47595                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.90809\teval-rmse:2.47444                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.90244\teval-rmse:2.47979                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.8956\teval-rmse:2.48057                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.88456\teval-rmse:2.48587                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.86954\teval-rmse:2.4946                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.85896\teval-rmse:2.49653                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.85023\teval-rmse:2.49429                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.83919\teval-rmse:2.50353                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.8357\teval-rmse:2.50389                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.82436\teval-rmse:2.50292                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.8184\teval-rmse:2.50723                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:2.79824\teval-rmse:2.50436                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.7912\teval-rmse:2.50583                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.78543\teval-rmse:2.50509                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.7726\teval-rmse:2.50229                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:2.76126\teval-rmse:2.50719                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.75577\teval-rmse:2.50648                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[19]\ttrain-rmse:2.9445\teval-rmse:2.46724\n",
      "\n",
      "\n",
      "loss: 69928614.73432161                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.850819424416714e-05, 'colsample_bytree': 0.8, 'gamma': 1.6512630294475406e-08, 'lambda': 0.0011881347902151498, 'learning_rate': 0.375, 'max_depth': 9, 'min_child_weight': 1.5591034624230138, 'n_estimators': 322.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.38068\teval-rmse:5.2261                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.04573\teval-rmse:3.82161                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.32441\teval-rmse:3.11668                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.95154\teval-rmse:2.79291                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.74169\teval-rmse:2.66074                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.60229\teval-rmse:2.63175                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.49053\teval-rmse:2.65354                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.4415\teval-rmse:2.65084                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.37156\teval-rmse:2.64605                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.33686\teval-rmse:2.67698                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.29217\teval-rmse:2.68819                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.23628\teval-rmse:2.72523                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.19779\teval-rmse:2.72052                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.1727\teval-rmse:2.73003                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.15202\teval-rmse:2.72724                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.11032\teval-rmse:2.74597                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.09445\teval-rmse:2.76534                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.07486\teval-rmse:2.77108                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.04348\teval-rmse:2.78239                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.02671\teval-rmse:2.78159                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.99223\teval-rmse:2.79156                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.98071\teval-rmse:2.78998                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.9694\teval-rmse:2.78909                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.92409\teval-rmse:2.7918                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:1.90993\teval-rmse:2.7941                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.86811\teval-rmse:2.80104                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.60229\teval-rmse:2.63175\n",
      "\n",
      "\n",
      "loss: 76579895.13261448                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.430776361273153e-08, 'colsample_bytree': 0.9, 'gamma': 1.8907531503342677e-07, 'lambda': 0.3111926558040843, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 0.2926663885425122, 'n_estimators': 109.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:6.16829\teval-rmse:6.04326                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.04934\teval-rmse:4.83706                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.27043\teval-rmse:3.99849                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.74747\teval-rmse:3.43039                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.39857\teval-rmse:3.07351                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.16929\teval-rmse:2.84943                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.01386\teval-rmse:2.71114                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.90362\teval-rmse:2.63588                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.82079\teval-rmse:2.58451                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.76656\teval-rmse:2.5517                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.72936\teval-rmse:2.53767                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.69431\teval-rmse:2.53568                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.67192\teval-rmse:2.53247                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.63771\teval-rmse:2.53563                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.59811\teval-rmse:2.54799                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.58039\teval-rmse:2.55967                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.55287\teval-rmse:2.56893                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.52591\teval-rmse:2.5745                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.50894\teval-rmse:2.57368                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.48815\teval-rmse:2.57239                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.45663\teval-rmse:2.57587                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.4463\teval-rmse:2.5765                                                                                \n",
      "\n",
      "[22]\ttrain-rmse:2.42035\teval-rmse:2.57538                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.4\teval-rmse:2.58431                                                                                  \n",
      "\n",
      "[24]\ttrain-rmse:2.37053\teval-rmse:2.59656                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.35005\teval-rmse:2.60258                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.32985\teval-rmse:2.59368                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.30267\teval-rmse:2.60373                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.28534\teval-rmse:2.61247                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.26718\teval-rmse:2.61325                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.25918\teval-rmse:2.61372                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.24147\teval-rmse:2.61229                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.23282\teval-rmse:2.6136                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.67192\teval-rmse:2.53247\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 61688196.60372104                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.3138157355562787, 'colsample_bytree': 0.9500000000000001, 'gamma': 9.87562027435791e-06, 'lambda': 6.102932745858477e-06, 'learning_rate': 0.42500000000000004, 'max_depth': 4, 'min_child_weight': 0.9970038472321346, 'n_estimators': 379.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.24553\teval-rmse:4.93365                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.06909\teval-rmse:3.5223                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.56419\teval-rmse:2.89515                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.36158\teval-rmse:2.64734                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.27757\teval-rmse:2.53802                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.23092\teval-rmse:2.50008                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.20799\teval-rmse:2.48481                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.18828\teval-rmse:2.48375                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.17019\teval-rmse:2.46952                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.15479\teval-rmse:2.4695                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.14071\teval-rmse:2.49899                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.1299\teval-rmse:2.50022                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.12154\teval-rmse:2.49489                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.10786\teval-rmse:2.49947                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.10163\teval-rmse:2.49731                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.09362\teval-rmse:2.5162                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.09025\teval-rmse:2.51488                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.08157\teval-rmse:2.52657                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.07615\teval-rmse:2.52935                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.06922\teval-rmse:2.53155                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.06009\teval-rmse:2.53164                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.05341\teval-rmse:2.53022                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.04254\teval-rmse:2.52919                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.03555\teval-rmse:2.52885                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.028\teval-rmse:2.52669                                                                                \n",
      "\n",
      "[25]\ttrain-rmse:3.01709\teval-rmse:2.52126                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.00807\teval-rmse:2.51529                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.00157\teval-rmse:2.52081                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.9989\teval-rmse:2.51908                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.99026\teval-rmse:2.5154                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:3.15479\teval-rmse:2.4695\n",
      "\n",
      "\n",
      "loss: 83221145.50482576                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.297938371315963e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 4.345921729124825e-05, 'lambda': 9.550764489963296, 'learning_rate': 0.225, 'max_depth': 3, 'min_child_weight': 5.152851327888419, 'n_estimators': 102.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:6.39314\teval-rmse:6.22412                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.41405\teval-rmse:5.10593                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.71358\teval-rmse:4.29764                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.2335\teval-rmse:3.72335                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.90672\teval-rmse:3.31186                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.69359\teval-rmse:3.04209                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.55372\teval-rmse:2.85241                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.45811\teval-rmse:2.72538                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.39713\teval-rmse:2.64383                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.35801\teval-rmse:2.58439                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.33022\teval-rmse:2.54559                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.30637\teval-rmse:2.52196                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.29221\teval-rmse:2.50891                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.27928\teval-rmse:2.50141                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.26912\teval-rmse:2.4941                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:3.26012\teval-rmse:2.49145                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.25318\teval-rmse:2.49551                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.24773\teval-rmse:2.49335                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.24173\teval-rmse:2.49768                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.2389\teval-rmse:2.49653                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:3.23044\teval-rmse:2.49281                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.2255\teval-rmse:2.49532                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:3.22049\teval-rmse:2.50308                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\ttrain-rmse:3.21582\teval-rmse:2.50454                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.21248\teval-rmse:2.50146                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.20986\teval-rmse:2.50172                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.20076\teval-rmse:2.49648                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.19668\teval-rmse:2.49361                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.19276\teval-rmse:2.48968                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.18951\teval-rmse:2.48481                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.18477\teval-rmse:2.48794                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.18188\teval-rmse:2.48704                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.1802\teval-rmse:2.48754                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:3.17557\teval-rmse:2.48501                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.17298\teval-rmse:2.48882                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.16956\teval-rmse:2.48788                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.16544\teval-rmse:2.48261                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.1625\teval-rmse:2.48231                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:3.15998\teval-rmse:2.48262                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.15922\teval-rmse:2.48399                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.15636\teval-rmse:2.48156                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.15401\teval-rmse:2.48164                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.15243\teval-rmse:2.48069                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.15034\teval-rmse:2.48202                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.14815\teval-rmse:2.48212                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.14563\teval-rmse:2.48137                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.14264\teval-rmse:2.48039                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.13985\teval-rmse:2.48012                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.13831\teval-rmse:2.48279                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.13663\teval-rmse:2.48224                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.13453\teval-rmse:2.48228                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.13268\teval-rmse:2.47679                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.12997\teval-rmse:2.47769                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.12677\teval-rmse:2.47652                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.124\teval-rmse:2.48027                                                                                \n",
      "\n",
      "[55]\ttrain-rmse:3.12282\teval-rmse:2.48017                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.1201\teval-rmse:2.4814                                                                                \n",
      "\n",
      "[57]\ttrain-rmse:3.11729\teval-rmse:2.47997                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:3.11539\teval-rmse:2.48121                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.11307\teval-rmse:2.47956                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:3.11247\teval-rmse:2.47864                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:3.10972\teval-rmse:2.47762                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:3.10779\teval-rmse:2.47821                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:3.10492\teval-rmse:2.47882                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:3.1034\teval-rmse:2.4789                                                                                \n",
      "\n",
      "[65]\ttrain-rmse:3.10121\teval-rmse:2.47942                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:3.09894\teval-rmse:2.47694                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:3.0983\teval-rmse:2.477                                                                                 \n",
      "\n",
      "[68]\ttrain-rmse:3.09628\teval-rmse:2.47208                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:3.09377\teval-rmse:2.47335                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:3.09076\teval-rmse:2.47155                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:3.08936\teval-rmse:2.47089                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:3.0879\teval-rmse:2.47022                                                                               \n",
      "\n",
      "[73]\ttrain-rmse:3.08463\teval-rmse:2.47151                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:3.08267\teval-rmse:2.47395                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:3.08074\teval-rmse:2.47439                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:3.07827\teval-rmse:2.47342                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:3.07597\teval-rmse:2.47478                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:3.07457\teval-rmse:2.4771                                                                               \n",
      "\n",
      "[79]\ttrain-rmse:3.07359\teval-rmse:2.47744                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:3.07139\teval-rmse:2.47737                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:3.07037\teval-rmse:2.47605                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:3.06922\teval-rmse:2.47473                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:3.06703\teval-rmse:2.47216                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:3.06487\teval-rmse:2.47254                                                                              \n",
      "\n",
      "[85]\ttrain-rmse:3.06252\teval-rmse:2.47411                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:3.0604\teval-rmse:2.47511                                                                               \n",
      "\n",
      "[87]\ttrain-rmse:3.05877\teval-rmse:2.4752                                                                               \n",
      "\n",
      "[88]\ttrain-rmse:3.05763\teval-rmse:2.47377                                                                              \n",
      "\n",
      "[89]\ttrain-rmse:3.05586\teval-rmse:2.47553                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90]\ttrain-rmse:3.05389\teval-rmse:2.47455                                                                              \n",
      "\n",
      "[91]\ttrain-rmse:3.0524\teval-rmse:2.47506                                                                               \n",
      "\n",
      "[92]\ttrain-rmse:3.05109\teval-rmse:2.47505                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[72]\ttrain-rmse:3.0879\teval-rmse:2.47022\n",
      "\n",
      "\n",
      "loss: 82598673.73732479                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.9827572336750697e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.9184212142976157e-05, 'lambda': 5.963393348191345, 'learning_rate': 0.47500000000000003, 'max_depth': 8, 'min_child_weight': 0.6818452342012203, 'n_estimators': 145.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.88075\teval-rmse:4.61522                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.62841\teval-rmse:3.26104                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.1334\teval-rmse:2.74869                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.92527\teval-rmse:2.56902                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.83985\teval-rmse:2.53444                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.74911\teval-rmse:2.5651                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.69218\teval-rmse:2.57354                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.65324\teval-rmse:2.597                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.61876\teval-rmse:2.59378                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.59272\teval-rmse:2.59875                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.55187\teval-rmse:2.61675                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.52363\teval-rmse:2.61986                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.50127\teval-rmse:2.62137                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.47644\teval-rmse:2.62                                                                                 \n",
      "\n",
      "[14]\ttrain-rmse:2.40543\teval-rmse:2.62647                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.3852\teval-rmse:2.62036                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.32925\teval-rmse:2.61875                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.31286\teval-rmse:2.61768                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.27339\teval-rmse:2.61694                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.25448\teval-rmse:2.61077                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.22943\teval-rmse:2.6083                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.18998\teval-rmse:2.61515                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.17544\teval-rmse:2.61547                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.1682\teval-rmse:2.61955                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.13378\teval-rmse:2.62131                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.83985\teval-rmse:2.53444\n",
      "\n",
      "\n",
      "loss: 82951548.68562725                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.5974880843187134e-05, 'colsample_bytree': 0.9, 'gamma': 0.002454575461131991, 'lambda': 0.19337402764119396, 'learning_rate': 0.45, 'max_depth': 9, 'min_child_weight': 0.3254865220017384, 'n_estimators': 212.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.93894\teval-rmse:4.77627                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.59529\teval-rmse:3.42476                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.97616\teval-rmse:2.90719                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.69021\teval-rmse:2.76481                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.56535\teval-rmse:2.73915                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.48863\teval-rmse:2.71833                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.42091\teval-rmse:2.72094                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.39006\teval-rmse:2.71592                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.35328\teval-rmse:2.727                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:2.32887\teval-rmse:2.7305                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.28285\teval-rmse:2.74949                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.25233\teval-rmse:2.75773                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.20529\teval-rmse:2.79414                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.17897\teval-rmse:2.80613                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.14642\teval-rmse:2.80306                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.11806\teval-rmse:2.81195                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.07668\teval-rmse:2.81217                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.05483\teval-rmse:2.82086                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.9877\teval-rmse:2.83477                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.94775\teval-rmse:2.82219                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.93116\teval-rmse:2.83583                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.9042\teval-rmse:2.84987                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.88408\teval-rmse:2.84828                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.8644\teval-rmse:2.84678                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24]\ttrain-rmse:1.83396\teval-rmse:2.84025                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.78811\teval-rmse:2.87047                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.76352\teval-rmse:2.86989                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.73104\teval-rmse:2.87121                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.39006\teval-rmse:2.71592\n",
      "\n",
      "\n",
      "loss: 797147604.0148519                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.3467051063167578e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.000903786041701846, 'lambda': 0.0834904359561871, 'learning_rate': 0.30000000000000004, 'max_depth': 8, 'min_child_weight': 0.11423077728282041, 'n_estimators': 434.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:5.87188\teval-rmse:5.72319                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.65797\teval-rmse:4.41341                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.89507\teval-rmse:3.5996                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.42814\teval-rmse:3.11588                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.1607\teval-rmse:2.86237                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.98793\teval-rmse:2.72624                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.88807\teval-rmse:2.66035                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.81642\teval-rmse:2.63945                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.77889\teval-rmse:2.62223                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.74149\teval-rmse:2.61526                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.70911\teval-rmse:2.63365                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.69236\teval-rmse:2.63592                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.65712\teval-rmse:2.64018                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.63574\teval-rmse:2.63829                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.61658\teval-rmse:2.63781                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.59951\teval-rmse:2.64852                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.56496\teval-rmse:2.67412                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.54359\teval-rmse:2.66697                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.53023\teval-rmse:2.67247                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.50886\teval-rmse:2.67553                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.49498\teval-rmse:2.67619                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.47407\teval-rmse:2.68444                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.4654\teval-rmse:2.68407                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.43341\teval-rmse:2.6894                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.42341\teval-rmse:2.6992                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.39022\teval-rmse:2.71509                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.37646\teval-rmse:2.7153                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.35485\teval-rmse:2.71096                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.33301\teval-rmse:2.71841                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.31178\teval-rmse:2.71003                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.74149\teval-rmse:2.61526\n",
      "\n",
      "\n",
      "loss: 94353381.12321177                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.053824217555642e-07, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.00047726740148098916, 'lambda': 0.002212220228625394, 'learning_rate': 0.025, 'max_depth': 7, 'min_child_weight': 0.8240426103048873, 'n_estimators': 557.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:7.58922\teval-rmse:7.55618                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:7.43361\teval-rmse:7.38986                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:7.28223\teval-rmse:7.22777                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:7.13528\teval-rmse:7.07032                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:6.99266\teval-rmse:6.91795                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:6.85389\teval-rmse:6.76964                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:6.71943\teval-rmse:6.62428                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:6.58921\teval-rmse:6.48384                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:6.46233\teval-rmse:6.34755                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:6.33958\teval-rmse:6.21509                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:6.22053\teval-rmse:6.08678                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:6.105\teval-rmse:5.96156                                                                                \n",
      "\n",
      "[12]\ttrain-rmse:5.99316\teval-rmse:5.84093                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:5.88469\teval-rmse:5.72269                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:5.77963\teval-rmse:5.60792                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:5.67758\teval-rmse:5.49705                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:5.57873\teval-rmse:5.38953                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\ttrain-rmse:5.483\teval-rmse:5.28507                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:5.38964\teval-rmse:5.18403                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:5.3002\teval-rmse:5.08501                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:5.2131\teval-rmse:4.98941                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:5.12955\teval-rmse:4.89792                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:5.04813\teval-rmse:4.80858                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:4.96963\teval-rmse:4.72219                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:4.89286\teval-rmse:4.63759                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:4.81945\teval-rmse:4.55641                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:4.748\teval-rmse:4.47764                                                                                \n",
      "\n",
      "[27]\ttrain-rmse:4.67969\teval-rmse:4.40118                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:4.61278\teval-rmse:4.32792                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:4.54887\teval-rmse:4.2566                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:4.48588\teval-rmse:4.1868                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:4.42503\teval-rmse:4.11986                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:4.36664\teval-rmse:4.05547                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:4.31066\teval-rmse:3.99349                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:4.25696\teval-rmse:3.93296                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:4.20505\teval-rmse:3.87466                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:4.15462\teval-rmse:3.81879                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:4.10605\teval-rmse:3.76492                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:4.05924\teval-rmse:3.71218                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:4.01388\teval-rmse:3.66199                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.96978\teval-rmse:3.61403                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.92756\teval-rmse:3.56698                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.88648\teval-rmse:3.52177                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.84665\teval-rmse:3.47831                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.80808\teval-rmse:3.4366                                                                               \n",
      "\n",
      "[45]\ttrain-rmse:3.77168\teval-rmse:3.3963                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:3.73663\teval-rmse:3.35717                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.7031\teval-rmse:3.31977                                                                               \n",
      "\n",
      "[48]\ttrain-rmse:3.6706\teval-rmse:3.28349                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:3.6391\teval-rmse:3.24952                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:3.6085\teval-rmse:3.21589                                                                               \n",
      "\n",
      "[51]\ttrain-rmse:3.57936\teval-rmse:3.18392                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.55139\teval-rmse:3.15324                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.52425\teval-rmse:3.12359                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.49759\teval-rmse:3.09591                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:3.47188\teval-rmse:3.06901                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.44753\teval-rmse:3.043                                                                                \n",
      "\n",
      "[57]\ttrain-rmse:3.42437\teval-rmse:3.0173                                                                               \n",
      "\n",
      "[58]\ttrain-rmse:3.40243\teval-rmse:2.99311                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.38131\teval-rmse:2.9699                                                                               \n",
      "\n",
      "[60]\ttrain-rmse:3.36005\teval-rmse:2.94758                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:3.33958\teval-rmse:2.92658                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:3.32009\teval-rmse:2.90614                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:3.3022\teval-rmse:2.8874                                                                                \n",
      "\n",
      "[64]\ttrain-rmse:3.28345\teval-rmse:2.86933                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:3.26618\teval-rmse:2.85203                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:3.2494\teval-rmse:2.83402                                                                               \n",
      "\n",
      "[67]\ttrain-rmse:3.23303\teval-rmse:2.81548                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:3.21778\teval-rmse:2.80041                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:3.20275\teval-rmse:2.78513                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:3.18829\teval-rmse:2.77121                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:3.17489\teval-rmse:2.75788                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:3.1612\teval-rmse:2.74522                                                                               \n",
      "\n",
      "[73]\ttrain-rmse:3.14779\teval-rmse:2.73242                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:3.13528\teval-rmse:2.72039                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:3.12306\teval-rmse:2.70931                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:3.1108\teval-rmse:2.69829                                                                               \n",
      "\n",
      "[77]\ttrain-rmse:3.09955\teval-rmse:2.68818                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:3.08873\teval-rmse:2.67811                                                                              \n",
      "\n",
      "[79]\ttrain-rmse:3.07832\teval-rmse:2.66868                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:3.06734\teval-rmse:2.65938                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:3.05726\teval-rmse:2.65015                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:3.04742\teval-rmse:2.64223                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:3.03833\teval-rmse:2.63497                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84]\ttrain-rmse:3.0292\teval-rmse:2.62745                                                                               \n",
      "\n",
      "[85]\ttrain-rmse:3.02117\teval-rmse:2.62068                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:3.01315\teval-rmse:2.61407                                                                              \n",
      "\n",
      "[87]\ttrain-rmse:3.00526\teval-rmse:2.60761                                                                              \n",
      "\n",
      "[88]\ttrain-rmse:2.99661\teval-rmse:2.60107                                                                              \n",
      "\n",
      "[89]\ttrain-rmse:2.98866\teval-rmse:2.59555                                                                              \n",
      "\n",
      "[90]\ttrain-rmse:2.98085\teval-rmse:2.58959                                                                              \n",
      "\n",
      "[91]\ttrain-rmse:2.9741\teval-rmse:2.58401                                                                               \n",
      "\n",
      "[92]\ttrain-rmse:2.96724\teval-rmse:2.57907                                                                              \n",
      "\n",
      "[93]\ttrain-rmse:2.96051\teval-rmse:2.57397                                                                              \n",
      "\n",
      "[94]\ttrain-rmse:2.95458\teval-rmse:2.56908                                                                              \n",
      "\n",
      "[95]\ttrain-rmse:2.94821\teval-rmse:2.56482                                                                              \n",
      "\n",
      "[96]\ttrain-rmse:2.94168\teval-rmse:2.56078                                                                              \n",
      "\n",
      "[97]\ttrain-rmse:2.93545\teval-rmse:2.55613                                                                              \n",
      "\n",
      "[98]\ttrain-rmse:2.92989\teval-rmse:2.55182                                                                              \n",
      "\n",
      "[99]\ttrain-rmse:2.92424\teval-rmse:2.54822                                                                              \n",
      "\n",
      "loss: 140330436.85457948                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 9.461143799087494e-06, 'colsample_bytree': 0.75, 'gamma': 0.027025178650449025, 'lambda': 0.7772521802697128, 'learning_rate': 0.5, 'max_depth': 5, 'min_child_weight': 0.13999196734000927, 'n_estimators': 412.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:4.8281\teval-rmse:4.49046                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.72442\teval-rmse:3.15855                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.35398\teval-rmse:2.7393                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.2282\teval-rmse:2.57738                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.18\teval-rmse:2.54407                                                                                  \n",
      "\n",
      "[5]\ttrain-rmse:3.15494\teval-rmse:2.53604                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.12762\teval-rmse:2.53746                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.11043\teval-rmse:2.53842                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.09409\teval-rmse:2.53633                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.07357\teval-rmse:2.55177                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.05497\teval-rmse:2.57743                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.03884\teval-rmse:2.57636                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.03199\teval-rmse:2.58161                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.01984\teval-rmse:2.58015                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.99653\teval-rmse:2.58294                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.98457\teval-rmse:2.58331                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.97429\teval-rmse:2.58411                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.95648\teval-rmse:2.58207                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.94043\teval-rmse:2.60325                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.93385\teval-rmse:2.60286                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.92239\teval-rmse:2.62673                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.90868\teval-rmse:2.63237                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.89384\teval-rmse:2.64167                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.87954\teval-rmse:2.64478                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.86872\teval-rmse:2.65048                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.86161\teval-rmse:2.65114                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:3.15494\teval-rmse:2.53604\n",
      "\n",
      "\n",
      "loss: 74462004.60999718                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0016969138617213, 'colsample_bytree': 0.7000000000000001, 'gamma': 4.251240978221342e-08, 'lambda': 0.007980351013317273, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.22594140867476137, 'n_estimators': 273.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.67798\teval-rmse:5.56571                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.37727\teval-rmse:4.21865                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.59595\teval-rmse:3.41362                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.14733\teval-rmse:2.99268                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.8712\teval-rmse:2.78514                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.68883\teval-rmse:2.6731                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.58429\teval-rmse:2.63335                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.51803\teval-rmse:2.59691                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.45627\teval-rmse:2.57902                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.40495\teval-rmse:2.59435                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.36824\teval-rmse:2.60134                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\ttrain-rmse:2.34211\teval-rmse:2.60062                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.29925\teval-rmse:2.60582                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.28147\teval-rmse:2.60607                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.26185\teval-rmse:2.60316                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.21505\teval-rmse:2.61144                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.1815\teval-rmse:2.61612                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.16487\teval-rmse:2.62316                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.15042\teval-rmse:2.62468                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.11676\teval-rmse:2.64687                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.09478\teval-rmse:2.64275                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.06528\teval-rmse:2.64464                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.02453\teval-rmse:2.65317                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.00656\teval-rmse:2.65701                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.9908\teval-rmse:2.66361                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.97917\teval-rmse:2.67305                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.93983\teval-rmse:2.67229                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.92186\teval-rmse:2.67331                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.89037\teval-rmse:2.67484                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.45627\teval-rmse:2.57902\n",
      "\n",
      "\n",
      "loss: 71064798.22353962                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.810681170124129e-08, 'colsample_bytree': 0.9, 'gamma': 0.006179555395732087, 'lambda': 1.8973884552144054, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 1.9775002433672808, 'n_estimators': 358.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.28007\teval-rmse:5.0978                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.97645\teval-rmse:3.68559                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.34066\teval-rmse:3.01528                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.04346\teval-rmse:2.72181                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.87325\teval-rmse:2.59631                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.77689\teval-rmse:2.57476                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.71349\teval-rmse:2.5697                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.67455\teval-rmse:2.57532                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.63248\teval-rmse:2.56933                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.59787\teval-rmse:2.57061                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.5665\teval-rmse:2.58527                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.53405\teval-rmse:2.59666                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.50412\teval-rmse:2.59966                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.467\teval-rmse:2.60601                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:2.43386\teval-rmse:2.60216                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.40729\teval-rmse:2.60606                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.37869\teval-rmse:2.6031                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.37036\teval-rmse:2.60392                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.3402\teval-rmse:2.61309                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.31617\teval-rmse:2.61194                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.29889\teval-rmse:2.61743                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.27596\teval-rmse:2.62099                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.2494\teval-rmse:2.62353                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.22054\teval-rmse:2.62265                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.20233\teval-rmse:2.62144                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.19663\teval-rmse:2.63208                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.16917\teval-rmse:2.65282                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.12992\teval-rmse:2.6481                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.09944\teval-rmse:2.65602                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.63248\teval-rmse:2.56933\n",
      "\n",
      "\n",
      "loss: 62555034.72609836                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.2244952759536253e-08, 'colsample_bytree': 0.8, 'gamma': 0.00016571895088980985, 'lambda': 0.43674920804421385, 'learning_rate': 0.375, 'max_depth': 6, 'min_child_weight': 3.269913832475719, 'n_estimators': 507.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.47193\teval-rmse:5.24934                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.23786\teval-rmse:3.83596                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.61952\teval-rmse:3.09518                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.33102\teval-rmse:2.75128                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.18914\teval-rmse:2.6176                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-rmse:3.10674\teval-rmse:2.55235                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.067\teval-rmse:2.52092                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:3.02801\teval-rmse:2.5427                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.00006\teval-rmse:2.5346                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.97305\teval-rmse:2.54481                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.95839\teval-rmse:2.54777                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.93565\teval-rmse:2.55081                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.91407\teval-rmse:2.55847                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.8956\teval-rmse:2.54948                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.88441\teval-rmse:2.55631                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.87039\teval-rmse:2.56132                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.8521\teval-rmse:2.57662                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.83845\teval-rmse:2.58056                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.82897\teval-rmse:2.58054                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.81544\teval-rmse:2.57673                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.8004\teval-rmse:2.57452                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.77574\teval-rmse:2.58496                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.76425\teval-rmse:2.58544                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.74809\teval-rmse:2.59432                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.73831\teval-rmse:2.59573                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.72964\teval-rmse:2.59094                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.71364\teval-rmse:2.59281                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:3.067\teval-rmse:2.52092\n",
      "\n",
      "\n",
      "loss: 64781025.2250439                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.9696487222842776e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 3.198137374141119e-05, 'lambda': 0.015853349867310233, 'learning_rate': 0.45, 'max_depth': 4, 'min_child_weight': 0.37881142873176243, 'n_estimators': 173.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.11354\teval-rmse:4.77994                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.95901\teval-rmse:3.38257                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.50612\teval-rmse:2.80991                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.33979\teval-rmse:2.61039                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.26677\teval-rmse:2.53662                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.22897\teval-rmse:2.5114                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.19993\teval-rmse:2.49347                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.18179\teval-rmse:2.49466                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.16542\teval-rmse:2.50179                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.1558\teval-rmse:2.49933                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.13847\teval-rmse:2.52811                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.13148\teval-rmse:2.52527                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.11953\teval-rmse:2.51599                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.10966\teval-rmse:2.52206                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.10421\teval-rmse:2.52024                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.09086\teval-rmse:2.51297                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.07913\teval-rmse:2.52415                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.06967\teval-rmse:2.53213                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.061\teval-rmse:2.53163                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:3.05579\teval-rmse:2.52968                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.04721\teval-rmse:2.55512                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.04417\teval-rmse:2.55518                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.03624\teval-rmse:2.54947                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.02732\teval-rmse:2.56288                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.01877\teval-rmse:2.5855                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.00761\teval-rmse:2.58318                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.00205\teval-rmse:2.58399                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:3.19993\teval-rmse:2.49347\n",
      "\n",
      "\n",
      "loss: 83285456.16963701                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.617654364248083e-07, 'colsample_bytree': 0.8500000000000001, 'gamma': 3.973494953633576e-07, 'lambda': 0.004214503712912003, 'learning_rate': 0.325, 'max_depth': 8, 'min_child_weight': 1.7805813876211851, 'n_estimators': 451.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.71255\teval-rmse:5.55026                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.45232\teval-rmse:4.1884                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.70769\teval-rmse:3.40148                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\ttrain-rmse:3.29191\teval-rmse:2.96722                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.05291\teval-rmse:2.76801                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.90397\teval-rmse:2.68526                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.82545\teval-rmse:2.63669                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.75376\teval-rmse:2.62644                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.70296\teval-rmse:2.62135                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.6789\teval-rmse:2.60974                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.64251\teval-rmse:2.61172                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.62288\teval-rmse:2.60847                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.57553\teval-rmse:2.6415                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.53939\teval-rmse:2.66222                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.52623\teval-rmse:2.65058                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.51453\teval-rmse:2.64635                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.48163\teval-rmse:2.65877                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.45194\teval-rmse:2.67035                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.43269\teval-rmse:2.67517                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.40802\teval-rmse:2.66884                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.38852\teval-rmse:2.66256                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.36463\teval-rmse:2.65655                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.32267\teval-rmse:2.66725                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.29647\teval-rmse:2.66536                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.27485\teval-rmse:2.6636                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.26587\teval-rmse:2.66462                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.23695\teval-rmse:2.6672                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.21787\teval-rmse:2.66088                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.19793\teval-rmse:2.66481                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.18362\teval-rmse:2.66541                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.16935\teval-rmse:2.67237                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.15328\teval-rmse:2.68113                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.62288\teval-rmse:2.60847\n",
      "\n",
      "\n",
      "loss: 63045526.01758963                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.791019703900109e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 2.9744489898897907e-06, 'lambda': 0.11827271246726563, 'learning_rate': 0.275, 'max_depth': 3, 'min_child_weight': 0.4381015556853825, 'n_estimators': 299.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.10074\teval-rmse:5.90145                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.00931\teval-rmse:4.6386                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.31475\teval-rmse:3.82356                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.88948\teval-rmse:3.29847                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.63232\teval-rmse:2.965                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:3.4879\teval-rmse:2.77108                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.40078\teval-rmse:2.65699                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.34913\teval-rmse:2.58701                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.31794\teval-rmse:2.54571                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.29192\teval-rmse:2.5266                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.27393\teval-rmse:2.51533                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.26057\teval-rmse:2.50768                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.24863\teval-rmse:2.50964                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.24143\teval-rmse:2.50005                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.23575\teval-rmse:2.49828                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.22888\teval-rmse:2.49418                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.22187\teval-rmse:2.48944                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.21238\teval-rmse:2.49397                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.20812\teval-rmse:2.49083                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.20107\teval-rmse:2.50243                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.19769\teval-rmse:2.50091                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.19316\teval-rmse:2.50176                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.18717\teval-rmse:2.49724                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.18462\teval-rmse:2.49387                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.18326\teval-rmse:2.49352                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.17828\teval-rmse:2.49468                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.17366\teval-rmse:2.49396                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.17072\teval-rmse:2.49294                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.16744\teval-rmse:2.49281                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.16345\teval-rmse:2.49421                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttrain-rmse:3.15887\teval-rmse:2.48872                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.15487\teval-rmse:2.48845                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.15276\teval-rmse:2.48611                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.14895\teval-rmse:2.4901                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:3.1474\teval-rmse:2.48904                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:3.14627\teval-rmse:2.48962                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.14288\teval-rmse:2.49117                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.13999\teval-rmse:2.49088                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.13717\teval-rmse:2.49052                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.13289\teval-rmse:2.49057                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.12825\teval-rmse:2.48979                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.1257\teval-rmse:2.49041                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:3.12037\teval-rmse:2.48932                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.11714\teval-rmse:2.49327                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.11445\teval-rmse:2.49299                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.11227\teval-rmse:2.4997                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:3.10938\teval-rmse:2.49811                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.10678\teval-rmse:2.49994                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.10529\teval-rmse:2.50015                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.10187\teval-rmse:2.5059                                                                               \n",
      "\n",
      "[50]\ttrain-rmse:3.09946\teval-rmse:2.50751                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.0987\teval-rmse:2.50744                                                                               \n",
      "\n",
      "[52]\ttrain-rmse:3.09557\teval-rmse:2.50536                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[32]\ttrain-rmse:3.15276\teval-rmse:2.48611\n",
      "\n",
      "\n",
      "loss: 82403442.05046123                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00038277590365430077, 'colsample_bytree': 0.8, 'gamma': 8.705063807468917e-07, 'lambda': 1.2142817496532725, 'learning_rate': 0.35000000000000003, 'max_depth': 9, 'min_child_weight': 0.5060147095866218, 'n_estimators': 478.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:5.54769\teval-rmse:5.42053                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.22211\teval-rmse:4.03038                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.45968\teval-rmse:3.27817                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.05723\teval-rmse:2.88455                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.82838\teval-rmse:2.74278                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.67948\teval-rmse:2.64549                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.6071\teval-rmse:2.60907                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.55275\teval-rmse:2.5888                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.49836\teval-rmse:2.58478                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.44335\teval-rmse:2.59019                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.3977\teval-rmse:2.59792                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.34888\teval-rmse:2.59632                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.30274\teval-rmse:2.61217                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.28705\teval-rmse:2.61611                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.2646\teval-rmse:2.62331                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.2398\teval-rmse:2.62632                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.21202\teval-rmse:2.64332                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.18936\teval-rmse:2.65571                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.16082\teval-rmse:2.65562                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.13817\teval-rmse:2.65551                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.11489\teval-rmse:2.67178                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.09989\teval-rmse:2.67671                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.06643\teval-rmse:2.67749                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.03943\teval-rmse:2.69242                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.01955\teval-rmse:2.69872                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.9936\teval-rmse:2.69309                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:1.96872\teval-rmse:2.68989                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.9522\teval-rmse:2.6922                                                                                \n",
      "\n",
      "[28]\ttrain-rmse:1.91956\teval-rmse:2.68799                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.49836\teval-rmse:2.58478\n",
      "\n",
      "\n",
      "loss: 69758999.59802175                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00019363952091726118, 'colsample_bytree': 0.9, 'gamma': 5.716468805046373e-05, 'lambda': 0.04878460909081057, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 2.2764477142787376, 'n_estimators': 227.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.2784\teval-rmse:5.08323                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.98178\teval-rmse:3.67624                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.36851\teval-rmse:2.99856                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.07095\teval-rmse:2.71863                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.9288\teval-rmse:2.62408                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.86247\teval-rmse:2.60968                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.81176\teval-rmse:2.62062                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.7625\teval-rmse:2.61497                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.72018\teval-rmse:2.62258                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.68315\teval-rmse:2.66783                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.66457\teval-rmse:2.67884                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.62493\teval-rmse:2.68068                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.60538\teval-rmse:2.7012                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.58606\teval-rmse:2.70599                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.56787\teval-rmse:2.71273                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.54126\teval-rmse:2.7184                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.5242\teval-rmse:2.72761                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.50403\teval-rmse:2.73118                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.46965\teval-rmse:2.72989                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.43477\teval-rmse:2.72838                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.41374\teval-rmse:2.73412                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.38552\teval-rmse:2.73685                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.34709\teval-rmse:2.74196                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.31611\teval-rmse:2.74159                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.2732\teval-rmse:2.74419                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.23705\teval-rmse:2.75045                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.86247\teval-rmse:2.60968\n",
      "\n",
      "\n",
      "loss: 142314727.37979993                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.775690114350769e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 8.325455195327133e-08, 'lambda': 3.6265837473372806, 'learning_rate': 0.225, 'max_depth': 5, 'min_child_weight': 0.15692280242995485, 'n_estimators': 618.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:6.36422\teval-rmse:6.21191                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.35882\teval-rmse:5.08398                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.64055\teval-rmse:4.25345                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.14173\teval-rmse:3.66271                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.80404\teval-rmse:3.24379                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.57934\teval-rmse:2.97035                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.43094\teval-rmse:2.7869                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.331\teval-rmse:2.66349                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:3.26275\teval-rmse:2.58438                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.21831\teval-rmse:2.53577                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.18372\teval-rmse:2.50915                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.15915\teval-rmse:2.49238                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.14074\teval-rmse:2.47931                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.12244\teval-rmse:2.46867                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.10905\teval-rmse:2.46551                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.09667\teval-rmse:2.46508                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.08506\teval-rmse:2.47722                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.07128\teval-rmse:2.4711                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:3.06451\teval-rmse:2.46868                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.05427\teval-rmse:2.47059                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.04675\teval-rmse:2.47591                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.03783\teval-rmse:2.48079                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.02555\teval-rmse:2.4722                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:3.01451\teval-rmse:2.47296                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.0112\teval-rmse:2.47277                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.00528\teval-rmse:2.47129                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.99871\teval-rmse:2.47738                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.99039\teval-rmse:2.48005                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.98314\teval-rmse:2.47741                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.97805\teval-rmse:2.47863                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.97403\teval-rmse:2.47998                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.96607\teval-rmse:2.47523                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.95968\teval-rmse:2.47213                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33]\ttrain-rmse:2.95127\teval-rmse:2.47769                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.94429\teval-rmse:2.48334                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.93764\teval-rmse:2.48114                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:3.09667\teval-rmse:2.46508\n",
      "\n",
      "\n",
      "loss: 79794637.92106253                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.020159298668772155, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.938961885252672, 'lambda': 2.2666675912634107, 'learning_rate': 0.07500000000000001, 'max_depth': 7, 'min_child_weight': 1.146042962983846, 'n_estimators': 391.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:7.27193\teval-rmse:7.21701                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.83515\teval-rmse:6.74963                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:6.4377\teval-rmse:6.31899                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:6.07508\teval-rmse:5.92732                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:5.74596\teval-rmse:5.56719                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:5.44654\teval-rmse:5.24191                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:5.17479\teval-rmse:4.94491                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:4.93094\teval-rmse:4.67701                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:4.71005\teval-rmse:4.43272                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:4.51124\teval-rmse:4.21275                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:4.33131\teval-rmse:4.01044                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:4.17142\teval-rmse:3.82829                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:4.02783\teval-rmse:3.66773                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.90023\teval-rmse:3.52226                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.78561\teval-rmse:3.39405                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.6838\teval-rmse:3.28023                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.59134\teval-rmse:3.1787                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:3.50847\teval-rmse:3.08899                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.43658\teval-rmse:3.01144                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.37065\teval-rmse:2.94323                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.31271\teval-rmse:2.88215                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.26225\teval-rmse:2.83041                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.21502\teval-rmse:2.78342                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.17621\teval-rmse:2.74342                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.14091\teval-rmse:2.70842                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.10773\teval-rmse:2.67711                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.07845\teval-rmse:2.65155                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.05106\teval-rmse:2.62924                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.02717\teval-rmse:2.60909                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.0063\teval-rmse:2.59043                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.98779\teval-rmse:2.57391                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.96995\teval-rmse:2.5621                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.94995\teval-rmse:2.55049                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.9314\teval-rmse:2.54                                                                                  \n",
      "\n",
      "[34]\ttrain-rmse:2.91796\teval-rmse:2.53032                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.90517\teval-rmse:2.52388                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.89257\teval-rmse:2.51776                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.88147\teval-rmse:2.51379                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.86946\teval-rmse:2.51001                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.86059\teval-rmse:2.50585                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.85361\teval-rmse:2.50531                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.84447\teval-rmse:2.50183                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.83526\teval-rmse:2.49947                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.82801\teval-rmse:2.49584                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.81909\teval-rmse:2.49357                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.81118\teval-rmse:2.49271                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.80552\teval-rmse:2.48871                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.80034\teval-rmse:2.48727                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.79413\teval-rmse:2.48517                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.78565\teval-rmse:2.48509                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.77813\teval-rmse:2.48823                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.77028\teval-rmse:2.4899                                                                               \n",
      "\n",
      "[52]\ttrain-rmse:2.76725\teval-rmse:2.48944                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.75796\teval-rmse:2.49043                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.75435\teval-rmse:2.49332                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.7472\teval-rmse:2.49193                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56]\ttrain-rmse:2.73902\teval-rmse:2.49332                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.73463\teval-rmse:2.49247                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.73049\teval-rmse:2.4917                                                                               \n",
      "\n",
      "[59]\ttrain-rmse:2.72416\teval-rmse:2.49327                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:2.71815\teval-rmse:2.4922                                                                               \n",
      "\n",
      "[61]\ttrain-rmse:2.71097\teval-rmse:2.49113                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.70782\teval-rmse:2.49122                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.70238\teval-rmse:2.48964                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.69537\teval-rmse:2.49165                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.68547\teval-rmse:2.49244                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.68129\teval-rmse:2.49292                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:2.67422\teval-rmse:2.4939                                                                               \n",
      "\n",
      "[68]\ttrain-rmse:2.67044\teval-rmse:2.49367                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:2.66679\teval-rmse:2.49323                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[49]\ttrain-rmse:2.78565\teval-rmse:2.48509\n",
      "\n",
      "\n",
      "loss: 74840811.02735937                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.822322690386284e-05, 'colsample_bytree': 0.9, 'gamma': 1.2979708108159514e-06, 'lambda': 0.0003984295344468015, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 0.6023776218789774, 'n_estimators': 686.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.13671\teval-rmse:6.04128                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.97471\teval-rmse:4.85386                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.15548\teval-rmse:4.01618                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.59434\teval-rmse:3.44728                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.20132\teval-rmse:3.07578                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.94436\teval-rmse:2.85397                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.7735\teval-rmse:2.72574                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.64602\teval-rmse:2.64258                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.55982\teval-rmse:2.60481                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.4915\teval-rmse:2.5856                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.43425\teval-rmse:2.56861                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.3985\teval-rmse:2.56425                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.36267\teval-rmse:2.55824                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.31941\teval-rmse:2.55841                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.27929\teval-rmse:2.56565                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.26071\teval-rmse:2.56692                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.24015\teval-rmse:2.56455                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.22705\teval-rmse:2.56235                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.20694\teval-rmse:2.56487                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.17289\teval-rmse:2.57095                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.14832\teval-rmse:2.57314                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.13298\teval-rmse:2.57316                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.11284\teval-rmse:2.57184                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.07192\teval-rmse:2.57265                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.02531\teval-rmse:2.57589                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.01063\teval-rmse:2.57704                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.97994\teval-rmse:2.58003                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.95658\teval-rmse:2.58392                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.92461\teval-rmse:2.58898                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.9051\teval-rmse:2.5875                                                                                \n",
      "\n",
      "[30]\ttrain-rmse:1.89549\teval-rmse:2.58746                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.88541\teval-rmse:2.5843                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:1.86291\teval-rmse:2.58547                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.36267\teval-rmse:2.55824\n",
      "\n",
      "\n",
      "loss: 63359900.35434241                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.7053001185072244e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.0015012579002795711, 'lambda': 0.6333551585985528, 'learning_rate': 0.42500000000000004, 'max_depth': 6, 'min_child_weight': 4.406013110053495, 'n_estimators': 578.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.19985\teval-rmse:4.91977                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.9809\teval-rmse:3.50293                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.44771\teval-rmse:2.88027                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.23247\teval-rmse:2.62704                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.13389\teval-rmse:2.54347                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-rmse:3.08361\teval-rmse:2.51642                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.04355\teval-rmse:2.49979                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.02208\teval-rmse:2.49997                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.98656\teval-rmse:2.53589                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.96653\teval-rmse:2.54487                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.95007\teval-rmse:2.55073                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.93032\teval-rmse:2.54805                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.91562\teval-rmse:2.54768                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.89454\teval-rmse:2.54524                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.88396\teval-rmse:2.54392                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.86917\teval-rmse:2.5516                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.85385\teval-rmse:2.55289                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.84267\teval-rmse:2.55044                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.82806\teval-rmse:2.54651                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.81053\teval-rmse:2.54301                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.79122\teval-rmse:2.54305                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.78324\teval-rmse:2.54294                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.76153\teval-rmse:2.54548                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.74023\teval-rmse:2.55174                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.72537\teval-rmse:2.55777                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.7103\teval-rmse:2.56691                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.69925\teval-rmse:2.57366                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:3.04355\teval-rmse:2.49979\n",
      "\n",
      "\n",
      "loss: 63829714.05436919                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.759039796990839e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 2.988128338980991e-08, 'lambda': 0.025205141106347903, 'learning_rate': 0.30000000000000004, 'max_depth': 8, 'min_child_weight': 0.5686529642082552, 'n_estimators': 126.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:5.86764\teval-rmse:5.72377                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.64917\teval-rmse:4.42462                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.88225\teval-rmse:3.60716                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.42361\teval-rmse:3.11944                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.14286\teval-rmse:2.85303                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.97571\teval-rmse:2.7138                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.86781\teval-rmse:2.66613                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.80404\teval-rmse:2.65011                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.76681\teval-rmse:2.63324                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.73112\teval-rmse:2.61276                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.70176\teval-rmse:2.61147                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.68148\teval-rmse:2.61352                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.64433\teval-rmse:2.62481                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.6269\teval-rmse:2.62702                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.59872\teval-rmse:2.63128                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.57845\teval-rmse:2.63564                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.55701\teval-rmse:2.64388                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.52163\teval-rmse:2.64664                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.50659\teval-rmse:2.64024                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.47863\teval-rmse:2.6424                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.46745\teval-rmse:2.62835                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.45524\teval-rmse:2.62828                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.43843\teval-rmse:2.63308                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.41538\teval-rmse:2.64057                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.39721\teval-rmse:2.64047                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.39001\teval-rmse:2.63884                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.37465\teval-rmse:2.6478                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.36321\teval-rmse:2.65491                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.33287\teval-rmse:2.65291                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.32144\teval-rmse:2.64701                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.30549\teval-rmse:2.63933                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.70176\teval-rmse:2.61147\n",
      "\n",
      "\n",
      "loss: 92468904.52695166                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.001209213791134822, 'colsample_bytree': 0.9, 'gamma': 0.010660892926368019, 'lambda': 5.489961813623661, 'learning_rate': 0.375, 'max_depth': 4, 'min_child_weight': 0.34107662902944536, 'n_estimators': 193.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:5.52143\teval-rmse:5.24743                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.33176\teval-rmse:3.84856                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.74073\teval-rmse:3.11544                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.46413\teval-rmse:2.75916                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.34261\teval-rmse:2.59003                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.28313\teval-rmse:2.52733                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.25155\teval-rmse:2.49282                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.23011\teval-rmse:2.478                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:3.21499\teval-rmse:2.46824                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.19701\teval-rmse:2.4531                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.18723\teval-rmse:2.46397                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.17717\teval-rmse:2.46888                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.16047\teval-rmse:2.46228                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.15267\teval-rmse:2.45799                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.14302\teval-rmse:2.47514                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.13489\teval-rmse:2.48142                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.12623\teval-rmse:2.49118                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.11359\teval-rmse:2.48136                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.10438\teval-rmse:2.48225                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.09707\teval-rmse:2.49474                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.09365\teval-rmse:2.49252                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.08776\teval-rmse:2.50418                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.08109\teval-rmse:2.51625                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.07475\teval-rmse:2.5138                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:3.06909\teval-rmse:2.51561                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.06201\teval-rmse:2.52275                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.05172\teval-rmse:2.52512                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.04564\teval-rmse:2.52822                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.03776\teval-rmse:2.5318                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:3.03188\teval-rmse:2.5328                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:3.19701\teval-rmse:2.4531\n",
      "\n",
      "\n",
      "loss: 82507782.95115551                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00010373116163555898, 'colsample_bytree': 0.9, 'gamma': 5.1256519058054346e-06, 'lambda': 7.3682699270356204, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 6.11458148651327, 'n_estimators': 532.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.59168\teval-rmse:5.39616                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.32307\teval-rmse:4.00094                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.61405\teval-rmse:3.23572                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.23894\teval-rmse:2.84919                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.04637\teval-rmse:2.67013                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.93799\teval-rmse:2.58212                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.86593\teval-rmse:2.54478                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.81492\teval-rmse:2.52417                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.77593\teval-rmse:2.51557                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.73822\teval-rmse:2.52189                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.69875\teval-rmse:2.52269                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.66794\teval-rmse:2.52417                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.65126\teval-rmse:2.5296                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.63024\teval-rmse:2.527                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:2.61119\teval-rmse:2.53654                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.58123\teval-rmse:2.53462                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.55801\teval-rmse:2.56417                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.54238\teval-rmse:2.56564                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.51082\teval-rmse:2.56963                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.49975\teval-rmse:2.56494                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.45312\teval-rmse:2.55625                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.43908\teval-rmse:2.55189                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.41573\teval-rmse:2.54953                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.40033\teval-rmse:2.55466                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.38401\teval-rmse:2.55803                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.37342\teval-rmse:2.5569                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.34166\teval-rmse:2.57143                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.32402\teval-rmse:2.57243                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28]\ttrain-rmse:2.29922\teval-rmse:2.58161                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.77593\teval-rmse:2.51557\n",
      "\n",
      "\n",
      "loss: 59345869.62396799                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.011595922312277348, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.2004813785135072e-05, 'lambda': 1.5429844490190212, 'learning_rate': 0.275, 'max_depth': 9, 'min_child_weight': 9.406351730560496, 'n_estimators': 708.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.0034\teval-rmse:5.87794                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.80617\teval-rmse:4.61062                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.00919\teval-rmse:3.77631                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.48277\teval-rmse:3.24031                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.16427\teval-rmse:2.92396                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.95031\teval-rmse:2.74435                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.81294\teval-rmse:2.63449                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.72518\teval-rmse:2.58178                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.65864\teval-rmse:2.54215                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.61512\teval-rmse:2.51691                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.58009\teval-rmse:2.51766                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.55079\teval-rmse:2.51471                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.52525\teval-rmse:2.52355                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.49578\teval-rmse:2.52536                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.48307\teval-rmse:2.52334                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.4664\teval-rmse:2.53336                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.45351\teval-rmse:2.53727                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.43884\teval-rmse:2.53601                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.40297\teval-rmse:2.53754                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.38594\teval-rmse:2.53898                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.3609\teval-rmse:2.54298                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.34841\teval-rmse:2.54312                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.31182\teval-rmse:2.56271                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.29573\teval-rmse:2.55979                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.28624\teval-rmse:2.56334                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.2794\teval-rmse:2.56332                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.26909\teval-rmse:2.56405                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.25528\teval-rmse:2.56368                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.2196\teval-rmse:2.56856                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.20152\teval-rmse:2.57415                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.18884\teval-rmse:2.58326                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.17363\teval-rmse:2.58411                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.55079\teval-rmse:2.51471\n",
      "\n",
      "\n",
      "loss: 63464318.229553446                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00012060645885176639, 'colsample_bytree': 0.8, 'gamma': 5.672339232978612e-06, 'lambda': 1.0359081372278187e-06, 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 8.830405191995974, 'n_estimators': 659.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.54029\teval-rmse:6.39457                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.62751\teval-rmse:5.3769                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.94158\teval-rmse:4.58383                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.44544\teval-rmse:3.98262                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.08901\teval-rmse:3.55029                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.83627\teval-rmse:3.22631                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.66085\teval-rmse:2.99807                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.54149\teval-rmse:2.84074                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.45887\teval-rmse:2.73075                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.40198\teval-rmse:2.65717                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.36217\teval-rmse:2.60041                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.33499\teval-rmse:2.55914                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.31517\teval-rmse:2.53339                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.29808\teval-rmse:2.51998                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.28743\teval-rmse:2.50864                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.27642\teval-rmse:2.49414                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.26622\teval-rmse:2.48775                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.26058\teval-rmse:2.48336                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.25458\teval-rmse:2.47658                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\ttrain-rmse:3.24861\teval-rmse:2.4763                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:3.24075\teval-rmse:2.4774                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:3.23715\teval-rmse:2.47563                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.23269\teval-rmse:2.47582                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.22821\teval-rmse:2.47535                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.22208\teval-rmse:2.47236                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.21862\teval-rmse:2.47378                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.21607\teval-rmse:2.47105                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.21213\teval-rmse:2.47065                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.2082\teval-rmse:2.47148                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:3.20457\teval-rmse:2.47101                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.20209\teval-rmse:2.4699                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:3.19734\teval-rmse:2.47024                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.19237\teval-rmse:2.46632                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.18811\teval-rmse:2.46917                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.18431\teval-rmse:2.46789                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.18099\teval-rmse:2.46721                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.17758\teval-rmse:2.46581                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.17454\teval-rmse:2.46685                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.17219\teval-rmse:2.46655                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.16881\teval-rmse:2.46954                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.16817\teval-rmse:2.46939                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.16623\teval-rmse:2.46941                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.16339\teval-rmse:2.46854                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.1591\teval-rmse:2.46658                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:3.15727\teval-rmse:2.46371                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.15446\teval-rmse:2.46596                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.15316\teval-rmse:2.4659                                                                               \n",
      "\n",
      "[47]\ttrain-rmse:3.1507\teval-rmse:2.46673                                                                               \n",
      "\n",
      "[48]\ttrain-rmse:3.14858\teval-rmse:2.46438                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.14514\teval-rmse:2.46789                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.14247\teval-rmse:2.4685                                                                               \n",
      "\n",
      "[51]\ttrain-rmse:3.13961\teval-rmse:2.46891                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.13625\teval-rmse:2.47108                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.13434\teval-rmse:2.47145                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.1328\teval-rmse:2.47102                                                                               \n",
      "\n",
      "[55]\ttrain-rmse:3.13119\teval-rmse:2.46942                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.1304\teval-rmse:2.46869                                                                               \n",
      "\n",
      "[57]\ttrain-rmse:3.12711\teval-rmse:2.47402                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:3.12507\teval-rmse:2.47356                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.12268\teval-rmse:2.47866                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:3.12098\teval-rmse:2.47835                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:3.1192\teval-rmse:2.47904                                                                               \n",
      "\n",
      "[62]\ttrain-rmse:3.11737\teval-rmse:2.47912                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:3.11561\teval-rmse:2.47853                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:3.11392\teval-rmse:2.4782                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[44]\ttrain-rmse:3.15727\teval-rmse:2.46371\n",
      "\n",
      "\n",
      "loss: 82918808.49151248                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.002960945947111191, 'colsample_bytree': 0.8500000000000001, 'gamma': 9.816579655648244e-05, 'lambda': 9.56635576887504, 'learning_rate': 0.325, 'max_depth': 8, 'min_child_weight': 7.664879780080541, 'n_estimators': 738.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:5.74598\teval-rmse:5.55559                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.51246\teval-rmse:4.18896                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.78715\teval-rmse:3.38243                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.37478\teval-rmse:2.94017                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.14748\teval-rmse:2.71192                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.01566\teval-rmse:2.60476                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.93154\teval-rmse:2.55029                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.88141\teval-rmse:2.53211                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.84076\teval-rmse:2.52256                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.8077\teval-rmse:2.53904                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.76149\teval-rmse:2.53678                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.72382\teval-rmse:2.54913                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.70154\teval-rmse:2.5633                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.67488\teval-rmse:2.56752                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\ttrain-rmse:2.65345\teval-rmse:2.56952                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.63863\teval-rmse:2.5724                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.61904\teval-rmse:2.57414                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.60697\teval-rmse:2.57442                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.58396\teval-rmse:2.57661                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.56475\teval-rmse:2.57603                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.54534\teval-rmse:2.58504                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.52643\teval-rmse:2.59741                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.51738\teval-rmse:2.59734                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.49843\teval-rmse:2.60284                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.48348\teval-rmse:2.60558                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.47268\teval-rmse:2.60925                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.45045\teval-rmse:2.6159                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.4313\teval-rmse:2.62929                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.41318\teval-rmse:2.62925                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.84076\teval-rmse:2.52256\n",
      "\n",
      "\n",
      "loss: 69097223.89495501                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 9.071068252224616e-05, 'colsample_bytree': 0.8, 'gamma': 2.219727762137221e-06, 'lambda': 6.519256268491379, 'learning_rate': 0.17500000000000002, 'max_depth': 7, 'min_child_weight': 3.013593868245805, 'n_estimators': 517.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:6.65156\teval-rmse:6.54887                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.77794\teval-rmse:5.59895                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.09095\teval-rmse:4.84029                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.55828\teval-rmse:4.23745                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.14958\teval-rmse:3.78164                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.83764\teval-rmse:3.42738                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.60342\teval-rmse:3.16001                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.43029\teval-rmse:2.96504                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.29791\teval-rmse:2.82162                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.20011\teval-rmse:2.70835                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.12567\teval-rmse:2.63427                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.06702\teval-rmse:2.58347                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.02147\teval-rmse:2.54969                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.98619\teval-rmse:2.52343                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.95488\teval-rmse:2.5023                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.93058\teval-rmse:2.4915                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.91076\teval-rmse:2.48544                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.8902\teval-rmse:2.47876                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.87287\teval-rmse:2.47292                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.85907\teval-rmse:2.46859                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.84704\teval-rmse:2.47022                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.83584\teval-rmse:2.47049                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.82054\teval-rmse:2.47051                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.80526\teval-rmse:2.48458                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.79425\teval-rmse:2.48877                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.78274\teval-rmse:2.47973                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.77474\teval-rmse:2.48028                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.76191\teval-rmse:2.4857                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.74805\teval-rmse:2.49117                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.7376\teval-rmse:2.49375                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.72113\teval-rmse:2.50143                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.70971\teval-rmse:2.50239                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.7044\teval-rmse:2.50233                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.69339\teval-rmse:2.50474                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.68973\teval-rmse:2.5049                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:2.68242\teval-rmse:2.50392                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.67086\teval-rmse:2.50276                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.66148\teval-rmse:2.49928                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.65167\teval-rmse:2.49742                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.64164\teval-rmse:2.49694                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[19]\ttrain-rmse:2.85907\teval-rmse:2.46859\n",
      "\n",
      "\n",
      "loss: 75968744.53371657                                                                                                \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.05258943424072634, 'colsample_bytree': 0.75, 'gamma': 1.791104607688656e-05, 'lambda': 0.8879400851036684, 'learning_rate': 0.15000000000000002, 'max_depth': 8, 'min_child_weight': 6.169828067977701, 'n_estimators': 538.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.79009\teval-rmse:6.70479                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.99871\teval-rmse:5.85721                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.34821\teval-rmse:5.15377                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.81683\teval-rmse:4.58002                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.38914\teval-rmse:4.12447                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.04353\teval-rmse:3.74951                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.76563\teval-rmse:3.45581                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.54555\teval-rmse:3.22441                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.37572\teval-rmse:3.04219                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.2369\teval-rmse:2.90495                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.12841\teval-rmse:2.7974                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.0372\teval-rmse:2.72106                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.97014\teval-rmse:2.65718                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.91657\teval-rmse:2.6098                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.87279\teval-rmse:2.57685                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.83559\teval-rmse:2.54786                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.8006\teval-rmse:2.53248                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.77412\teval-rmse:2.52226                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.74441\teval-rmse:2.51894                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.72666\teval-rmse:2.50906                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.70546\teval-rmse:2.50651                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.68838\teval-rmse:2.50287                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.6726\teval-rmse:2.50314                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.66402\teval-rmse:2.50244                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.65502\teval-rmse:2.49925                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.64324\teval-rmse:2.50305                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.62757\teval-rmse:2.50367                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.60989\teval-rmse:2.50919                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.59761\teval-rmse:2.50906                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.58037\teval-rmse:2.50933                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.57317\teval-rmse:2.51202                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.55681\teval-rmse:2.51454                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.5421\teval-rmse:2.52029                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.53251\teval-rmse:2.51969                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.52029\teval-rmse:2.51474                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.50959\teval-rmse:2.51803                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.4962\teval-rmse:2.51729                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.48592\teval-rmse:2.51415                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.471\teval-rmse:2.51548                                                                                \n",
      "\n",
      "[39]\ttrain-rmse:2.4641\teval-rmse:2.51348                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:2.4578\teval-rmse:2.51347                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.44382\teval-rmse:2.51531                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.43396\teval-rmse:2.517                                                                                \n",
      "\n",
      "[43]\ttrain-rmse:2.42807\teval-rmse:2.52095                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.42489\teval-rmse:2.52096                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[24]\ttrain-rmse:2.65502\teval-rmse:2.49925\n",
      "\n",
      "\n",
      "loss: 68073973.76094143                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0007201692052457529, 'colsample_bytree': 0.65, 'gamma': 6.3615698872772965e-06, 'lambda': 3.309787203103238, 'learning_rate': 0.35000000000000003, 'max_depth': 5, 'min_child_weight': 5.758044150722605, 'n_estimators': 597.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.63939\teval-rmse:5.41892                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.44163\teval-rmse:4.02932                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.80214\teval-rmse:3.25474                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.47622\teval-rmse:2.84374                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.31651\teval-rmse:2.6596                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.23905\teval-rmse:2.57487                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.19622\teval-rmse:2.54305                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.16745\teval-rmse:2.53118                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.14243\teval-rmse:2.50656                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.12444\teval-rmse:2.50876                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:3.10593\teval-rmse:2.50774                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.08937\teval-rmse:2.50169                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.0733\teval-rmse:2.51534                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.0579\teval-rmse:2.52943                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.05073\teval-rmse:2.52929                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.0413\teval-rmse:2.52514                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.03478\teval-rmse:2.52329                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.02644\teval-rmse:2.51366                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.01724\teval-rmse:2.51255                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.00764\teval-rmse:2.52413                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.00168\teval-rmse:2.52343                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.99185\teval-rmse:2.52992                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.98135\teval-rmse:2.5361                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.9742\teval-rmse:2.5468                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:2.96334\teval-rmse:2.5483                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.95664\teval-rmse:2.55602                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.94887\teval-rmse:2.57348                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.93927\teval-rmse:2.57891                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.92722\teval-rmse:2.58265                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.9183\teval-rmse:2.5832                                                                                \n",
      "\n",
      "[30]\ttrain-rmse:2.91004\teval-rmse:2.58588                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.89582\teval-rmse:2.58066                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:3.08937\teval-rmse:2.50169\n",
      "\n",
      "\n",
      "loss: 85814622.92559795                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0002904682751854413, 'colsample_bytree': 0.9, 'gamma': 3.2643875523115384e-05, 'lambda': 1.5498392981349373e-05, 'learning_rate': 0.25, 'max_depth': 9, 'min_child_weight': 3.7677968139516618, 'n_estimators': 788.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:6.14634\teval-rmse:6.03952                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.00213\teval-rmse:4.83805                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.19996\teval-rmse:3.99247                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.65482\teval-rmse:3.44458                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.2798\teval-rmse:3.09917                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.02062\teval-rmse:2.87727                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.8494\teval-rmse:2.74229                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.72138\teval-rmse:2.66621                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.62956\teval-rmse:2.62253                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.57406\teval-rmse:2.59167                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.51278\teval-rmse:2.58553                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.48098\teval-rmse:2.57668                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.45253\teval-rmse:2.5712                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.41333\teval-rmse:2.56396                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.38347\teval-rmse:2.57753                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.36388\teval-rmse:2.58509                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.33019\teval-rmse:2.58681                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.3072\teval-rmse:2.58648                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.28178\teval-rmse:2.58478                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.26268\teval-rmse:2.57744                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.24606\teval-rmse:2.56745                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.2267\teval-rmse:2.56747                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.19707\teval-rmse:2.57473                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.16286\teval-rmse:2.58066                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.15546\teval-rmse:2.57937                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.12914\teval-rmse:2.57942                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.11352\teval-rmse:2.59745                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.09604\teval-rmse:2.59997                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.07575\teval-rmse:2.5906                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.06499\teval-rmse:2.59264                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.05741\teval-rmse:2.59412                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.02751\teval-rmse:2.59682                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.00195\teval-rmse:2.59448                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:1.99136\teval-rmse:2.59414                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.41333\teval-rmse:2.56396\n",
      "\n",
      "\n",
      "loss: 66187038.08365136                                                                                                \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 8.890373034709694e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 4.079296628595994e-06, 'lambda': 0.3367320618040987, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 4.925300868473654, 'n_estimators': 567.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.27593\teval-rmse:5.08271                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.97153\teval-rmse:3.67117                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.33551\teval-rmse:2.99392                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.02701\teval-rmse:2.72586                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.8694\teval-rmse:2.62266                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.7755\teval-rmse:2.61396                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.71185\teval-rmse:2.5907                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.67893\teval-rmse:2.59655                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.63494\teval-rmse:2.60196                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.60656\teval-rmse:2.6059                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.56014\teval-rmse:2.59402                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.5314\teval-rmse:2.59883                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.49843\teval-rmse:2.59708                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.47369\teval-rmse:2.5904                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.46116\teval-rmse:2.59598                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.45088\teval-rmse:2.59314                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.42917\teval-rmse:2.59742                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.41197\teval-rmse:2.60268                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.36664\teval-rmse:2.6094                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.33788\teval-rmse:2.60809                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.31782\teval-rmse:2.60538                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.30041\teval-rmse:2.60162                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.29508\teval-rmse:2.6021                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.27486\teval-rmse:2.60532                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.22644\teval-rmse:2.61552                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.20569\teval-rmse:2.62378                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.18953\teval-rmse:2.62897                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.1649\teval-rmse:2.62799                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.1476\teval-rmse:2.60926                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.13597\teval-rmse:2.60485                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.12358\teval-rmse:2.60567                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.10964\teval-rmse:2.60693                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.07568\teval-rmse:2.61027                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.05839\teval-rmse:2.61681                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.47369\teval-rmse:2.5904\n",
      "\n",
      "\n",
      "loss: 63847070.02164279                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.5220855928813837e-05, 'colsample_bytree': 0.9, 'gamma': 5.456087772847897e-07, 'lambda': 0.1729174486979199, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 0.25889084622189557, 'n_estimators': 321.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.56316\teval-rmse:5.38715                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.26898\teval-rmse:3.99839                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.54463\teval-rmse:3.23462                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.1555\teval-rmse:2.831                                                                                  \n",
      "\n",
      "[4]\ttrain-rmse:2.95038\teval-rmse:2.63588                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.83593\teval-rmse:2.55188                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.75722\teval-rmse:2.52453                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.70249\teval-rmse:2.51227                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.66499\teval-rmse:2.51035                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.62419\teval-rmse:2.5209                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.59646\teval-rmse:2.52733                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.55955\teval-rmse:2.52528                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.54287\teval-rmse:2.52535                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.51469\teval-rmse:2.52135                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.50056\teval-rmse:2.52998                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.46559\teval-rmse:2.54465                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.44171\teval-rmse:2.56276                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.41962\teval-rmse:2.56051                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.40829\teval-rmse:2.55864                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.37568\teval-rmse:2.55501                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.32962\teval-rmse:2.55782                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]\ttrain-rmse:2.29697\teval-rmse:2.56233                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.25867\teval-rmse:2.5663                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.24215\teval-rmse:2.58005                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.23394\teval-rmse:2.5799                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.2114\teval-rmse:2.58406                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.17517\teval-rmse:2.58142                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.16346\teval-rmse:2.58177                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.12933\teval-rmse:2.5846                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.66499\teval-rmse:2.51035\n",
      "\n",
      "\n",
      "loss: 66374378.74030921                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.2086280659060371e-05, 'colsample_bytree': 0.9, 'gamma': 0.0003235250485096303, 'lambda': 4.690427629624792, 'learning_rate': 0.375, 'max_depth': 8, 'min_child_weight': 7.2620864253084045, 'n_estimators': 459.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.44011\teval-rmse:5.23511                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.15459\teval-rmse:3.82608                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.48646\teval-rmse:3.09786                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.15931\teval-rmse:2.75705                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.99067\teval-rmse:2.59413                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.89363\teval-rmse:2.53025                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.82054\teval-rmse:2.51362                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.78381\teval-rmse:2.50069                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.7408\teval-rmse:2.50696                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.70264\teval-rmse:2.52455                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.66915\teval-rmse:2.52723                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.64909\teval-rmse:2.53718                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.62121\teval-rmse:2.53447                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.57782\teval-rmse:2.54315                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.56619\teval-rmse:2.54117                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.55246\teval-rmse:2.53887                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.51949\teval-rmse:2.53696                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.506\teval-rmse:2.54147                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:2.48463\teval-rmse:2.54855                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.4693\teval-rmse:2.55177                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.42668\teval-rmse:2.55855                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.40707\teval-rmse:2.56866                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.40026\teval-rmse:2.57194                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.3831\teval-rmse:2.57231                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.36889\teval-rmse:2.57134                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.3406\teval-rmse:2.58837                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.32841\teval-rmse:2.5905                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.30317\teval-rmse:2.60886                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.78381\teval-rmse:2.50069\n",
      "\n",
      "\n",
      "loss: 72992711.81914066                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00015735921846568538, 'colsample_bytree': 0.9500000000000001, 'gamma': 2.501168169719089e-07, 'lambda': 0.2576741054096525, 'learning_rate': 0.30000000000000004, 'max_depth': 8, 'min_child_weight': 0.41703618029012346, 'n_estimators': 643.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.86028\teval-rmse:5.71945                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.63763\teval-rmse:4.39668                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.86052\teval-rmse:3.57978                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.3917\teval-rmse:3.09774                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.11258\teval-rmse:2.84769                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.93627\teval-rmse:2.70821                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.83656\teval-rmse:2.63338                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.75797\teval-rmse:2.60148                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.70318\teval-rmse:2.58095                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.64199\teval-rmse:2.60407                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.61745\teval-rmse:2.59725                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.5911\teval-rmse:2.59557                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.57326\teval-rmse:2.60005                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.53925\teval-rmse:2.60142                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.51758\teval-rmse:2.59236                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.48522\teval-rmse:2.6048                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\ttrain-rmse:2.46356\teval-rmse:2.60299                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.44584\teval-rmse:2.60058                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.43396\teval-rmse:2.59406                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.39608\teval-rmse:2.59204                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.37657\teval-rmse:2.59381                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.36235\teval-rmse:2.59751                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.34053\teval-rmse:2.5999                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.32564\teval-rmse:2.59692                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.30706\teval-rmse:2.60069                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.29202\teval-rmse:2.60107                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.27839\teval-rmse:2.60235                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.25316\teval-rmse:2.59707                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.21564\teval-rmse:2.60223                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.70318\teval-rmse:2.58095\n",
      "\n",
      "\n",
      "loss: 61863632.19628075                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.005225980026022e-06, 'colsample_bytree': 0.9, 'gamma': 1.9382087410806267e-06, 'lambda': 0.5020195196347027, 'learning_rate': 0.42500000000000004, 'max_depth': 8, 'min_child_weight': 0.10166058751410073, 'n_estimators': 365.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.12969\teval-rmse:4.91572                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.82364\teval-rmse:3.51376                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.2238\teval-rmse:2.89478                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.94482\teval-rmse:2.65232                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.81307\teval-rmse:2.55866                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.72576\teval-rmse:2.53369                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.67995\teval-rmse:2.52552                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.63339\teval-rmse:2.55574                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.58877\teval-rmse:2.56916                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.5522\teval-rmse:2.5793                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.52294\teval-rmse:2.57993                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.49605\teval-rmse:2.58726                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.46016\teval-rmse:2.60816                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.4502\teval-rmse:2.61647                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.42925\teval-rmse:2.61874                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.38814\teval-rmse:2.6196                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.34905\teval-rmse:2.62308                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.32368\teval-rmse:2.63118                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.27706\teval-rmse:2.64095                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.2499\teval-rmse:2.63741                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.23199\teval-rmse:2.6344                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.20558\teval-rmse:2.63483                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.14205\teval-rmse:2.63562                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.11388\teval-rmse:2.64524                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.09715\teval-rmse:2.64874                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.09034\teval-rmse:2.64945                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.0841\teval-rmse:2.65646                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.67995\teval-rmse:2.52552\n",
      "\n",
      "\n",
      "loss: 70138574.82156183                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.921579938182089e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.3384413113384477e-07, 'lambda': 2.2686309143473373, 'learning_rate': 0.45, 'max_depth': 8, 'min_child_weight': 0.4847886410978567, 'n_estimators': 409.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.99947\teval-rmse:4.79029                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.71586\teval-rmse:3.41375                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.17052\teval-rmse:2.86481                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.93635\teval-rmse:2.67434                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.81546\teval-rmse:2.62827                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.74359\teval-rmse:2.6438                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.6813\teval-rmse:2.67815                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.64659\teval-rmse:2.67526                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.60531\teval-rmse:2.71087                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.56422\teval-rmse:2.72974                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.51392\teval-rmse:2.74567                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.49274\teval-rmse:2.74046                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\ttrain-rmse:2.44929\teval-rmse:2.74347                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.43524\teval-rmse:2.74082                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.39097\teval-rmse:2.7592                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.36522\teval-rmse:2.7548                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.33884\teval-rmse:2.75884                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.32247\teval-rmse:2.75782                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.30172\teval-rmse:2.77318                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.28677\teval-rmse:2.77304                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.23008\teval-rmse:2.76674                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.20317\teval-rmse:2.77027                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.17136\teval-rmse:2.78909                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.15191\teval-rmse:2.79143                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.12209\teval-rmse:2.7935                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.81546\teval-rmse:2.62827\n",
      "\n",
      "\n",
      "loss: 61285499.2933094                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00048053201540873385, 'colsample_bytree': 0.9500000000000001, 'gamma': 6.959175050712528e-05, 'lambda': 9.775656204754473, 'learning_rate': 0.375, 'max_depth': 8, 'min_child_weight': 0.670898219479714, 'n_estimators': 493.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.45022\teval-rmse:5.23423                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.16672\teval-rmse:3.82229                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.50282\teval-rmse:3.07072                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.16411\teval-rmse:2.73772                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.99791\teval-rmse:2.59115                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.89362\teval-rmse:2.53325                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.82911\teval-rmse:2.50083                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.77238\teval-rmse:2.49077                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.7247\teval-rmse:2.50033                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.69677\teval-rmse:2.50487                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.66244\teval-rmse:2.48894                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.64457\teval-rmse:2.48996                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.62998\teval-rmse:2.49143                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.60648\teval-rmse:2.4812                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.58611\teval-rmse:2.48224                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.56453\teval-rmse:2.48472                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.52699\teval-rmse:2.48379                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.49389\teval-rmse:2.49226                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.4669\teval-rmse:2.50364                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.42055\teval-rmse:2.50403                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.4002\teval-rmse:2.50924                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.38687\teval-rmse:2.51044                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.38107\teval-rmse:2.50599                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.34512\teval-rmse:2.51386                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.3328\teval-rmse:2.51675                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.31456\teval-rmse:2.51971                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.28288\teval-rmse:2.52051                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.25972\teval-rmse:2.53166                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.24488\teval-rmse:2.53582                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.22417\teval-rmse:2.54122                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.21687\teval-rmse:2.54295                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.21029\teval-rmse:2.54147                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.19596\teval-rmse:2.54174                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.15999\teval-rmse:2.5315                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.60648\teval-rmse:2.4812\n",
      "\n",
      "\n",
      "loss: 66029800.408285394                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.1619732994287592e-06, 'colsample_bytree': 0.9, 'gamma': 8.98116104905069e-06, 'lambda': 1.1787026726204812, 'learning_rate': 0.325, 'max_depth': 8, 'min_child_weight': 0.9233834946142793, 'n_estimators': 340.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.71375\teval-rmse:5.55706                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.44767\teval-rmse:4.19044                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.70657\teval-rmse:3.39316                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.28347\teval-rmse:2.95963                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.01932\teval-rmse:2.74862                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-rmse:2.87217\teval-rmse:2.64754                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.7895\teval-rmse:2.5863                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:2.73147\teval-rmse:2.56641                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.69616\teval-rmse:2.55067                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.6545\teval-rmse:2.55338                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.61459\teval-rmse:2.56604                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.59048\teval-rmse:2.57111                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.5581\teval-rmse:2.57358                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.52674\teval-rmse:2.56988                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.50098\teval-rmse:2.57421                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.47384\teval-rmse:2.58495                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.42009\teval-rmse:2.58828                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.40929\teval-rmse:2.58489                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.38998\teval-rmse:2.58341                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.36745\teval-rmse:2.58707                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.33367\teval-rmse:2.59228                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.31131\teval-rmse:2.58675                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.29087\teval-rmse:2.58546                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.25763\teval-rmse:2.57902                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.23674\teval-rmse:2.60653                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.22206\teval-rmse:2.6146                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.20752\teval-rmse:2.61401                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.18532\teval-rmse:2.62244                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.17606\teval-rmse:2.61702                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.69616\teval-rmse:2.55067\n",
      "\n",
      "\n",
      "loss: 68374216.99398059                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.8456271150243806e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 6.839313755981329e-07, 'lambda': 0.7995394364885133, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 3.4887982516577787, 'n_estimators': 832.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.56715\teval-rmse:5.39359                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.28561\teval-rmse:4.00274                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.57383\teval-rmse:3.22715                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.19344\teval-rmse:2.83563                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.99327\teval-rmse:2.66299                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.86429\teval-rmse:2.59273                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.79931\teval-rmse:2.5638                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.73394\teval-rmse:2.55519                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.69046\teval-rmse:2.55979                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.65549\teval-rmse:2.55819                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.62854\teval-rmse:2.55771                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.60609\teval-rmse:2.56277                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.58216\teval-rmse:2.55859                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.56865\teval-rmse:2.56011                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.54812\teval-rmse:2.57975                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.52693\teval-rmse:2.57993                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.50019\teval-rmse:2.57856                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.48572\teval-rmse:2.57468                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.46216\teval-rmse:2.5817                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.4511\teval-rmse:2.5781                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:2.41744\teval-rmse:2.57136                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.407\teval-rmse:2.57084                                                                                \n",
      "\n",
      "[22]\ttrain-rmse:2.38953\teval-rmse:2.5723                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.3544\teval-rmse:2.581                                                                                 \n",
      "\n",
      "[24]\ttrain-rmse:2.34559\teval-rmse:2.58349                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.31897\teval-rmse:2.60408                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.28706\teval-rmse:2.60461                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.27268\teval-rmse:2.60403                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.73394\teval-rmse:2.55519\n",
      "\n",
      "\n",
      "loss: 62354408.97692715                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.305332552260152e-06, 'colsample_bytree': 0.9, 'gamma': 0.00014758299077650142, 'lambda': 0.06809191817207742, 'learning_rate': 0.4, 'max_depth': 6, 'min_child_weight': 0.7503511431623008, 'n_estimators': 249.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.33559\teval-rmse:5.07617                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.1014\teval-rmse:3.66997                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.51635\teval-rmse:3.00094                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.25285\teval-rmse:2.71012                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.13749\teval-rmse:2.59082                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.07576\teval-rmse:2.54273                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.03097\teval-rmse:2.51716                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.99759\teval-rmse:2.5052                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.97398\teval-rmse:2.54119                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.95328\teval-rmse:2.55201                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.93013\teval-rmse:2.55531                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.91111\teval-rmse:2.5624                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.89975\teval-rmse:2.57869                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.88247\teval-rmse:2.60019                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.87214\teval-rmse:2.59897                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.847\teval-rmse:2.59976                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:2.83327\teval-rmse:2.59828                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.8137\teval-rmse:2.59455                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.80807\teval-rmse:2.59516                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.79869\teval-rmse:2.5999                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.77282\teval-rmse:2.61223                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.75119\teval-rmse:2.61286                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.73545\teval-rmse:2.60873                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.72481\teval-rmse:2.60612                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.6977\teval-rmse:2.61306                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.68636\teval-rmse:2.60907                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.68075\teval-rmse:2.60805                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.66382\teval-rmse:2.608                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.99759\teval-rmse:2.5052\n",
      "\n",
      "\n",
      "loss: 77125324.37856385                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.163738491593052e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.4461616411538655e-05, 'lambda': 0.13365113764744374, 'learning_rate': 0.275, 'max_depth': 4, 'min_child_weight': 4.393652175484073, 'n_estimators': 630.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.08236\teval-rmse:5.88823                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.97914\teval-rmse:4.62168                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.27207\teval-rmse:3.78837                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.83749\teval-rmse:3.25382                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.57688\teval-rmse:2.93817                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.42571\teval-rmse:2.75422                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.33721\teval-rmse:2.64418                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.27945\teval-rmse:2.57487                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.24799\teval-rmse:2.53468                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.22411\teval-rmse:2.51765                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.20662\teval-rmse:2.50732                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.19288\teval-rmse:2.49789                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.17757\teval-rmse:2.48832                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.16853\teval-rmse:2.4838                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.15782\teval-rmse:2.49866                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.14513\teval-rmse:2.49719                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.13662\teval-rmse:2.5078                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:3.12955\teval-rmse:2.50452                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.12232\teval-rmse:2.49956                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.11557\teval-rmse:2.50022                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.11076\teval-rmse:2.50051                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.10536\teval-rmse:2.49924                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.09661\teval-rmse:2.50632                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.09235\teval-rmse:2.50533                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.08832\teval-rmse:2.50655                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.08388\teval-rmse:2.50554                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.07913\teval-rmse:2.5043                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:3.07548\teval-rmse:2.50099                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.07253\teval-rmse:2.5012                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:3.06526\teval-rmse:2.51451                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.06057\teval-rmse:2.51742                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.05485\teval-rmse:2.51803                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32]\ttrain-rmse:3.04962\teval-rmse:2.51376                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.04452\teval-rmse:2.51489                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:3.16853\teval-rmse:2.4838\n",
      "\n",
      "\n",
      "loss: 85390339.8266262                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.456298492221489e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 2.3118137089418672e-05, 'lambda': 7.326599289752496, 'learning_rate': 0.325, 'max_depth': 8, 'min_child_weight': 9.954652977569303, 'n_estimators': 545.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.7389\teval-rmse:5.55611                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.49484\teval-rmse:4.1854                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.76143\teval-rmse:3.3861                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.34606\teval-rmse:2.95207                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.11638\teval-rmse:2.71776                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.97823\teval-rmse:2.60816                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.89599\teval-rmse:2.56879                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.8385\teval-rmse:2.54122                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.79577\teval-rmse:2.53367                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.7673\teval-rmse:2.52226                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.74195\teval-rmse:2.52622                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.7202\teval-rmse:2.52545                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.6973\teval-rmse:2.52755                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.67876\teval-rmse:2.53114                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.66672\teval-rmse:2.53137                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.64399\teval-rmse:2.53693                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.623\teval-rmse:2.56652                                                                                \n",
      "\n",
      "[17]\ttrain-rmse:2.60336\teval-rmse:2.57248                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.57914\teval-rmse:2.56175                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.55762\teval-rmse:2.55797                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.53595\teval-rmse:2.55767                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.51803\teval-rmse:2.56262                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.50856\teval-rmse:2.56238                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.47557\teval-rmse:2.57134                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.45758\teval-rmse:2.56863                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.43942\teval-rmse:2.56585                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.4193\teval-rmse:2.56527                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.41165\teval-rmse:2.56888                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.37818\teval-rmse:2.5627                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.35988\teval-rmse:2.56929                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.7673\teval-rmse:2.52226\n",
      "\n",
      "\n",
      "loss: 67193505.88525344                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 9.496797567439763e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.1756600231244708e-06, 'lambda': 0.3551532194338018, 'learning_rate': 0.375, 'max_depth': 3, 'min_child_weight': 1.3513200813749857, 'n_estimators': 285.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.54319\teval-rmse:5.26513                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.37444\teval-rmse:3.88042                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.78819\teval-rmse:3.16941                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.52093\teval-rmse:2.81892                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.4016\teval-rmse:2.64892                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.34485\teval-rmse:2.56999                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.31392\teval-rmse:2.53657                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.2876\teval-rmse:2.51971                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.27366\teval-rmse:2.50861                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.25467\teval-rmse:2.49802                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.24301\teval-rmse:2.4997                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.2315\teval-rmse:2.49588                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.2203\teval-rmse:2.48945                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.21323\teval-rmse:2.50598                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.20851\teval-rmse:2.50466                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.2018\teval-rmse:2.50534                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.19849\teval-rmse:2.50923                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.19396\teval-rmse:2.50624                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.18832\teval-rmse:2.50789                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.18322\teval-rmse:2.51543                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttrain-rmse:3.17693\teval-rmse:2.51089                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.17121\teval-rmse:2.51474                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.16683\teval-rmse:2.51497                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.16135\teval-rmse:2.52019                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.15896\teval-rmse:2.51649                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.15244\teval-rmse:2.50694                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.14749\teval-rmse:2.50821                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.14387\teval-rmse:2.50875                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.14067\teval-rmse:2.51437                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.13699\teval-rmse:2.51824                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.13456\teval-rmse:2.51518                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.1308\teval-rmse:2.51442                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:3.12643\teval-rmse:2.5132                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:3.2203\teval-rmse:2.48945\n",
      "\n",
      "\n",
      "loss: 81517971.06837483                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.5274786715392369e-06, 'colsample_bytree': 0.9, 'gamma': 3.726220928004246e-07, 'lambda': 3.1121035942744775, 'learning_rate': 0.47500000000000003, 'max_depth': 9, 'min_child_weight': 0.30779488192162713, 'n_estimators': 433.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.83026\teval-rmse:4.61471                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.52359\teval-rmse:3.25925                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.97622\teval-rmse:2.7619                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:2.73732\teval-rmse:2.61353                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.61079\teval-rmse:2.56623                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.53039\teval-rmse:2.56763                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.48122\teval-rmse:2.56761                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.42952\teval-rmse:2.57383                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.38995\teval-rmse:2.58593                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.34614\teval-rmse:2.59187                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.28721\teval-rmse:2.5819                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.24874\teval-rmse:2.59379                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.20158\teval-rmse:2.5935                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.16782\teval-rmse:2.58958                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.10602\teval-rmse:2.61011                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.08711\teval-rmse:2.61229                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.07264\teval-rmse:2.61291                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.04657\teval-rmse:2.62675                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.0331\teval-rmse:2.62669                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:1.98207\teval-rmse:2.62985                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.93008\teval-rmse:2.63644                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.883\teval-rmse:2.637                                                                                  \n",
      "\n",
      "[22]\ttrain-rmse:1.8592\teval-rmse:2.63728                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.84109\teval-rmse:2.63118                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.80505\teval-rmse:2.63126                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.61079\teval-rmse:2.56623\n",
      "\n",
      "\n",
      "loss: 69198022.53755422                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.100599358018405e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 6.335773716310978e-08, 'lambda': 0.03915058555153707, 'learning_rate': 0.30000000000000004, 'max_depth': 8, 'min_child_weight': 0.22010547926400464, 'n_estimators': 163.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.85913\teval-rmse:5.71879                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.63205\teval-rmse:4.39747                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.85238\teval-rmse:3.5699                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.38979\teval-rmse:3.0929                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.1073\teval-rmse:2.84049                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.94165\teval-rmse:2.70175                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.8354\teval-rmse:2.60812                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.74677\teval-rmse:2.59196                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.69983\teval-rmse:2.57207                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.65761\teval-rmse:2.58168                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.62729\teval-rmse:2.57649                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.60435\teval-rmse:2.56687                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.56994\teval-rmse:2.57138                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.55037\teval-rmse:2.56715                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\ttrain-rmse:2.53056\teval-rmse:2.57079                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.5068\teval-rmse:2.57985                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.47953\teval-rmse:2.5978                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.4634\teval-rmse:2.60086                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.44049\teval-rmse:2.60793                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.40209\teval-rmse:2.60675                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.37685\teval-rmse:2.62582                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.36022\teval-rmse:2.63428                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.34008\teval-rmse:2.62256                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.31939\teval-rmse:2.62565                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.3033\teval-rmse:2.62356                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.27692\teval-rmse:2.63328                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.25359\teval-rmse:2.62994                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.2353\teval-rmse:2.63241                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.20365\teval-rmse:2.6293                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.17596\teval-rmse:2.63555                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.16581\teval-rmse:2.63194                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.15234\teval-rmse:2.63211                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.60435\teval-rmse:2.56687\n",
      "\n",
      "\n",
      "loss: 67304114.69098693                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0002566151966842252, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.810979895910823e-07, 'lambda': 0.09171805395581226, 'learning_rate': 0.42500000000000004, 'max_depth': 8, 'min_child_weight': 1.0599767789546564, 'n_estimators': 202.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.12594\teval-rmse:4.92751                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.82632\teval-rmse:3.54775                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.23441\teval-rmse:2.93599                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.96956\teval-rmse:2.7194                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.814\teval-rmse:2.63122                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.74767\teval-rmse:2.60161                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.68226\teval-rmse:2.60826                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.63984\teval-rmse:2.60693                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.61156\teval-rmse:2.61186                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.55741\teval-rmse:2.62393                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.52065\teval-rmse:2.6585                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.48704\teval-rmse:2.66954                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.46285\teval-rmse:2.66993                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.45227\teval-rmse:2.67264                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.40864\teval-rmse:2.68728                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.38595\teval-rmse:2.69745                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.34836\teval-rmse:2.72095                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.33169\teval-rmse:2.71623                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.31779\teval-rmse:2.7274                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.28949\teval-rmse:2.72554                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.26237\teval-rmse:2.72486                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.24631\teval-rmse:2.72335                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.21054\teval-rmse:2.72329                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.18623\teval-rmse:2.72393                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.15303\teval-rmse:2.73924                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.13803\teval-rmse:2.74951                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.74767\teval-rmse:2.60161\n",
      "\n",
      "\n",
      "loss: 94391343.19791618                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.4302134479177823e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.00021824715928411216, 'lambda': 1.4039569959049756, 'learning_rate': 0.4, 'max_depth': 7, 'min_child_weight': 2.860973009305355, 'n_estimators': 144.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.31109\teval-rmse:5.07964                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.05086\teval-rmse:3.66453                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.44744\teval-rmse:2.98426                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.17243\teval-rmse:2.68277                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.0417\teval-rmse:2.56503                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.97011\teval-rmse:2.52875                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.93587\teval-rmse:2.51275                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.89922\teval-rmse:2.50965                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\ttrain-rmse:2.85685\teval-rmse:2.52183                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.82406\teval-rmse:2.52462                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.79453\teval-rmse:2.52436                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.75281\teval-rmse:2.56196                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.73707\teval-rmse:2.55396                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.7253\teval-rmse:2.55201                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.70934\teval-rmse:2.55338                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.68375\teval-rmse:2.55967                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.6692\teval-rmse:2.55752                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.63976\teval-rmse:2.56278                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.61505\teval-rmse:2.55959                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.58049\teval-rmse:2.55774                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.55058\teval-rmse:2.58636                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.54095\teval-rmse:2.58665                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.53043\teval-rmse:2.58183                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.51635\teval-rmse:2.5857                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.48863\teval-rmse:2.58525                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.46038\teval-rmse:2.6081                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.4509\teval-rmse:2.60724                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.43408\teval-rmse:2.60793                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.89922\teval-rmse:2.50965\n",
      "\n",
      "\n",
      "loss: 72608041.10154851                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.9491777233021987e-06, 'colsample_bytree': 0.9, 'gamma': 3.0862042843630723e-06, 'lambda': 0.5877971522194904, 'learning_rate': 0.35000000000000003, 'max_depth': 5, 'min_child_weight': 0.18449777678902501, 'n_estimators': 266.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.63516\teval-rmse:5.39817                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.4328\teval-rmse:4.0162                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:3.78865\teval-rmse:3.24405                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.46003\teval-rmse:2.84992                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.29829\teval-rmse:2.65043                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.2151\teval-rmse:2.56414                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.16644\teval-rmse:2.51668                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.12979\teval-rmse:2.49921                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.10891\teval-rmse:2.4918                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.08575\teval-rmse:2.4903                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.06801\teval-rmse:2.4849                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.0606\teval-rmse:2.49404                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.05024\teval-rmse:2.49256                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.03575\teval-rmse:2.49419                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.02474\teval-rmse:2.4892                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:3.01323\teval-rmse:2.49057                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.00186\teval-rmse:2.51204                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.9909\teval-rmse:2.51274                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.97804\teval-rmse:2.51245                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.96042\teval-rmse:2.51216                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.95119\teval-rmse:2.52051                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.94223\teval-rmse:2.51891                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.93495\teval-rmse:2.51904                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.92196\teval-rmse:2.51551                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.91593\teval-rmse:2.5295                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.91024\teval-rmse:2.53051                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.90051\teval-rmse:2.52816                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.89057\teval-rmse:2.53337                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.88494\teval-rmse:2.53288                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.87412\teval-rmse:2.54111                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.86468\teval-rmse:2.54214                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:3.06801\teval-rmse:2.4849\n",
      "\n",
      "\n",
      "loss: 79572934.815715                                                                                                  \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0010926737614412915, 'colsample_bytree': 0.9, 'gamma': 4.037429038050421e-06, 'lambda': 0.22607366339866863, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 6.627002642123265, 'n_estimators': 308.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.83995\teval-rmse:5.70795                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:4.5799\teval-rmse:4.38266                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.78925\teval-rmse:3.56064                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.29911\teval-rmse:3.06513                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.01082\teval-rmse:2.78492                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.84142\teval-rmse:2.62953                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.72126\teval-rmse:2.54114                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.63831\teval-rmse:2.5149                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.56794\teval-rmse:2.48619                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.51808\teval-rmse:2.48873                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.48166\teval-rmse:2.48745                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.45128\teval-rmse:2.49572                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.42816\teval-rmse:2.49796                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.40002\teval-rmse:2.50096                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.37817\teval-rmse:2.50779                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.36079\teval-rmse:2.5115                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.33855\teval-rmse:2.52596                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.33044\teval-rmse:2.52863                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.30443\teval-rmse:2.53017                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.28279\teval-rmse:2.52914                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.26275\teval-rmse:2.53481                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.2322\teval-rmse:2.54262                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.21888\teval-rmse:2.5474                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.19554\teval-rmse:2.55106                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.16282\teval-rmse:2.57063                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.15742\teval-rmse:2.57143                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.13038\teval-rmse:2.5823                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.12309\teval-rmse:2.58665                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.1024\teval-rmse:2.58445                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.56794\teval-rmse:2.48619\n",
      "\n",
      "\n",
      "loss: 65633428.72968446                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00015889882042143484, 'colsample_bytree': 0.9, 'gamma': 7.302090590070108e-06, 'lambda': 4.474498518068531, 'learning_rate': 0.45, 'max_depth': 6, 'min_child_weight': 0.27878197859641607, 'n_estimators': 225.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.06985\teval-rmse:4.77136                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.86915\teval-rmse:3.36694                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.39116\teval-rmse:2.78478                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.20226\teval-rmse:2.58036                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.11545\teval-rmse:2.54607                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.06409\teval-rmse:2.53411                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.02347\teval-rmse:2.53711                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.989\teval-rmse:2.54915                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:2.96367\teval-rmse:2.5721                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.94499\teval-rmse:2.5692                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.93135\teval-rmse:2.57438                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.90324\teval-rmse:2.59072                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.89337\teval-rmse:2.59007                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.88449\teval-rmse:2.58968                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.86461\teval-rmse:2.59727                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.83987\teval-rmse:2.59639                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.81362\teval-rmse:2.61468                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.80151\teval-rmse:2.61609                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.78627\teval-rmse:2.63251                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.7767\teval-rmse:2.6315                                                                                \n",
      "\n",
      "[20]\ttrain-rmse:2.76178\teval-rmse:2.63982                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.74612\teval-rmse:2.65628                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.72811\teval-rmse:2.65229                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.71232\teval-rmse:2.65466                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.70216\teval-rmse:2.65135                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.69258\teval-rmse:2.64687                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:3.06409\teval-rmse:2.53411\n",
      "\n",
      "\n",
      "loss: 76789008.07493985                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.1139730617813e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 5.344324182046781e-05, 'lambda': 2.32717616778275, 'learning_rate': 0.325, 'max_depth': 8, 'min_child_weight': 2.3595071622177666, 'n_estimators': 382.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.72395\teval-rmse:5.56459                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.47934\teval-rmse:4.20152                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.736\teval-rmse:3.38535                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:3.32094\teval-rmse:2.93336                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.07341\teval-rmse:2.70582                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.9267\teval-rmse:2.59389                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.82913\teval-rmse:2.54451                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.77984\teval-rmse:2.52324                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.72792\teval-rmse:2.5183                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.695\teval-rmse:2.50982                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.6667\teval-rmse:2.5128                                                                                \n",
      "\n",
      "[11]\ttrain-rmse:2.62409\teval-rmse:2.51462                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.58834\teval-rmse:2.52025                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.56605\teval-rmse:2.52014                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.53221\teval-rmse:2.53655                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.49864\teval-rmse:2.54366                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.48295\teval-rmse:2.55546                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.46835\teval-rmse:2.55811                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.44854\teval-rmse:2.55641                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.42523\teval-rmse:2.54389                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.41646\teval-rmse:2.53948                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.40114\teval-rmse:2.53725                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.37849\teval-rmse:2.53539                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.34371\teval-rmse:2.53194                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.33014\teval-rmse:2.52983                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.30745\teval-rmse:2.53788                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.28698\teval-rmse:2.53709                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.27847\teval-rmse:2.53838                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.25248\teval-rmse:2.54241                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.23937\teval-rmse:2.5503                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.695\teval-rmse:2.50982\n",
      "\n",
      "\n",
      "loss: 70483258.8662669                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.001970246193137691, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.590288330039456e-08, 'lambda': 6.336716338292468e-05, 'learning_rate': 0.42500000000000004, 'max_depth': 4, 'min_child_weight': 0.8565394742038643, 'n_estimators': 529.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.24547\teval-rmse:4.93715                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.06751\teval-rmse:3.52995                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.56631\teval-rmse:2.89836                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.36645\teval-rmse:2.65184                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.27555\teval-rmse:2.56579                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.23685\teval-rmse:2.52495                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.21526\teval-rmse:2.51328                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.19419\teval-rmse:2.497                                                                                 \n",
      "\n",
      "[8]\ttrain-rmse:3.18154\teval-rmse:2.50149                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.1712\teval-rmse:2.50659                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.15544\teval-rmse:2.5014                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.14758\teval-rmse:2.51112                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.13965\teval-rmse:2.50333                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.12422\teval-rmse:2.53138                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.11358\teval-rmse:2.52374                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.10501\teval-rmse:2.52689                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.09589\teval-rmse:2.52539                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.0866\teval-rmse:2.5307                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:3.07747\teval-rmse:2.52829                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.06997\teval-rmse:2.53246                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.05986\teval-rmse:2.52535                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.05546\teval-rmse:2.52648                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.05281\teval-rmse:2.52657                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.04526\teval-rmse:2.5318                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:3.03866\teval-rmse:2.52482                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.02688\teval-rmse:2.54386                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.01959\teval-rmse:2.54402                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27]\ttrain-rmse:3.01071\teval-rmse:2.55898                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:3.19419\teval-rmse:2.497\n",
      "\n",
      "\n",
      "loss: 89632411.32820095                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.0897048266274733e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.475099321833084e-06, 'lambda': 0.16527224670149473, 'learning_rate': 0.225, 'max_depth': 8, 'min_child_weight': 5.471314797593394, 'n_estimators': 400.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.32002\teval-rmse:6.20394                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.26135\teval-rmse:5.0666                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.49491\teval-rmse:4.23891                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.95\teval-rmse:3.65133                                                                                  \n",
      "\n",
      "[4]\ttrain-rmse:3.56861\teval-rmse:3.24588                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.29396\teval-rmse:2.97356                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.1134\teval-rmse:2.79529                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.9925\teval-rmse:2.68288                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.89714\teval-rmse:2.61048                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.84324\teval-rmse:2.56694                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.79562\teval-rmse:2.5357                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.75285\teval-rmse:2.52192                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.7153\teval-rmse:2.51772                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.69057\teval-rmse:2.51207                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.65893\teval-rmse:2.51169                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.64667\teval-rmse:2.51531                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.62807\teval-rmse:2.51715                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.61546\teval-rmse:2.51635                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.59865\teval-rmse:2.52223                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.57389\teval-rmse:2.53041                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.55713\teval-rmse:2.52949                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.54311\teval-rmse:2.52847                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.52197\teval-rmse:2.52179                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.51207\teval-rmse:2.52212                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.49738\teval-rmse:2.52915                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.49082\teval-rmse:2.52714                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.47746\teval-rmse:2.53118                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.46536\teval-rmse:2.54227                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.44021\teval-rmse:2.54115                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.42048\teval-rmse:2.55                                                                                 \n",
      "\n",
      "[30]\ttrain-rmse:2.41231\teval-rmse:2.55139                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.39825\teval-rmse:2.5445                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.38169\teval-rmse:2.54541                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.37196\teval-rmse:2.54874                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.34674\teval-rmse:2.55356                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[14]\ttrain-rmse:2.65893\teval-rmse:2.51169\n",
      "\n",
      "\n",
      "loss: 65478247.06649561                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.287832802855392e-05, 'colsample_bytree': 0.9, 'gamma': 3.23945786181482e-05, 'lambda': 1.6448566010499157, 'learning_rate': 0.5, 'max_depth': 9, 'min_child_weight': 2.575965966566408, 'n_estimators': 584.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.67687\teval-rmse:4.49077                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.38767\teval-rmse:3.17876                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.89509\teval-rmse:2.73356                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.69801\teval-rmse:2.62382                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.6181\teval-rmse:2.59819                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.56\teval-rmse:2.61116                                                                                  \n",
      "\n",
      "[6]\ttrain-rmse:2.51267\teval-rmse:2.62073                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.47563\teval-rmse:2.6192                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.42655\teval-rmse:2.6203                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.37224\teval-rmse:2.63223                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.31406\teval-rmse:2.62764                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.26067\teval-rmse:2.62073                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.23242\teval-rmse:2.63463                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.19875\teval-rmse:2.65192                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.16375\teval-rmse:2.65203                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.13218\teval-rmse:2.65016                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16]\ttrain-rmse:2.08148\teval-rmse:2.66885                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.02315\teval-rmse:2.69225                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.98787\teval-rmse:2.69231                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.97163\teval-rmse:2.69257                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.94714\teval-rmse:2.71164                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.93054\teval-rmse:2.7234                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.90108\teval-rmse:2.73238                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.86917\teval-rmse:2.72923                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.85055\teval-rmse:2.72427                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.6181\teval-rmse:2.59819\n",
      "\n",
      "\n",
      "loss: 67814229.34422086                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.69482748392155e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.0006516093287616603, 'lambda': 0.000842330943088724, 'learning_rate': 0.375, 'max_depth': 3, 'min_child_weight': 1.4714838046752141, 'n_estimators': 735.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:5.54583\teval-rmse:5.2602                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.37066\teval-rmse:3.84858                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.79184\teval-rmse:3.13898                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.52758\teval-rmse:2.80705                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.39526\teval-rmse:2.62813                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.33667\teval-rmse:2.5594                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.30774\teval-rmse:2.52164                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.2899\teval-rmse:2.50586                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.2752\teval-rmse:2.49776                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.26598\teval-rmse:2.49345                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.25006\teval-rmse:2.48748                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.24232\teval-rmse:2.48922                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.23031\teval-rmse:2.48049                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.22422\teval-rmse:2.48233                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.21751\teval-rmse:2.49084                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.20721\teval-rmse:2.48895                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.20628\teval-rmse:2.49063                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.19749\teval-rmse:2.50277                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.1885\teval-rmse:2.50337                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.18488\teval-rmse:2.50738                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.18254\teval-rmse:2.50711                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.17751\teval-rmse:2.52372                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.17307\teval-rmse:2.52755                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.17044\teval-rmse:2.5323                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:3.16404\teval-rmse:2.52934                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.15922\teval-rmse:2.52947                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.15361\teval-rmse:2.52975                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.14903\teval-rmse:2.54224                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.14182\teval-rmse:2.55265                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.13873\teval-rmse:2.54856                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.13297\teval-rmse:2.55104                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.12893\teval-rmse:2.55087                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.12326\teval-rmse:2.54865                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:3.23031\teval-rmse:2.48049\n",
      "\n",
      "\n",
      "loss: 96433362.61090797                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.3886736671543308e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 9.147442250180722e-07, 'lambda': 0.9888744177946733, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 0.5187906282479127, 'n_estimators': 469.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.56389\teval-rmse:5.3978                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.2774\teval-rmse:4.00639                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.56232\teval-rmse:3.2543                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.17632\teval-rmse:2.86587                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.96689\teval-rmse:2.67832                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.85718\teval-rmse:2.60143                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.78325\teval-rmse:2.54951                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.72657\teval-rmse:2.54768                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.6835\teval-rmse:2.53387                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.65762\teval-rmse:2.5289                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:2.61757\teval-rmse:2.55111                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.5834\teval-rmse:2.55189                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.53997\teval-rmse:2.54963                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.51666\teval-rmse:2.55014                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.49807\teval-rmse:2.55416                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.45804\teval-rmse:2.5561                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.40747\teval-rmse:2.57784                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.38305\teval-rmse:2.58015                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.33613\teval-rmse:2.60179                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.30887\teval-rmse:2.61025                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.28218\teval-rmse:2.61348                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.2691\teval-rmse:2.61171                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.25719\teval-rmse:2.60743                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.23883\teval-rmse:2.60496                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.21885\teval-rmse:2.6193                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.20407\teval-rmse:2.6334                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.1849\teval-rmse:2.63205                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.16612\teval-rmse:2.63571                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.1378\teval-rmse:2.63993                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.11461\teval-rmse:2.66116                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.65762\teval-rmse:2.5289\n",
      "\n",
      "\n",
      "loss: 67030477.532402806                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.006226854891826237, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.00011054523985858935, 'lambda': 0.032505089484058475, 'learning_rate': 0.4, 'max_depth': 7, 'min_child_weight': 2.027156515626703, 'n_estimators': 676.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.30758\teval-rmse:5.07404                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.04341\teval-rmse:3.66544                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.43631\teval-rmse:2.99221                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.16587\teval-rmse:2.69325                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.03469\teval-rmse:2.57816                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.9554\teval-rmse:2.55653                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.90523\teval-rmse:2.5628                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.8752\teval-rmse:2.56319                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.84433\teval-rmse:2.56579                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.83227\teval-rmse:2.56317                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.81909\teval-rmse:2.57509                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.80011\teval-rmse:2.56882                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.77467\teval-rmse:2.5762                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.74453\teval-rmse:2.57546                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.72575\teval-rmse:2.57881                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.71372\teval-rmse:2.58124                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.6883\teval-rmse:2.59653                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.6736\teval-rmse:2.60938                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.65098\teval-rmse:2.62285                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.63717\teval-rmse:2.62353                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.60516\teval-rmse:2.62132                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.58468\teval-rmse:2.62645                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.53846\teval-rmse:2.59533                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.52022\teval-rmse:2.60347                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.50763\teval-rmse:2.60404                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.47435\teval-rmse:2.62003                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.9554\teval-rmse:2.55653\n",
      "\n",
      "\n",
      "loss: 69527185.6933121                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0007446211113985947, 'colsample_bytree': 0.9, 'gamma': 2.3587582584784836e-06, 'lambda': 0.02121317905351035, 'learning_rate': 0.275, 'max_depth': 5, 'min_child_weight': 0.6263177412922359, 'n_estimators': 342.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:6.06579\teval-rmse:5.88244                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.94987\teval-rmse:4.61986                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.23275\teval-rmse:3.77922                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.79161\teval-rmse:3.24875                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.52126\teval-rmse:2.92955                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.36278\teval-rmse:2.72745                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\ttrain-rmse:3.27101\teval-rmse:2.62296                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.20838\teval-rmse:2.56782                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.17253\teval-rmse:2.52889                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.14773\teval-rmse:2.51153                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.12752\teval-rmse:2.51036                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.11165\teval-rmse:2.50434                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.09609\teval-rmse:2.49876                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.08025\teval-rmse:2.48441                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.06955\teval-rmse:2.48453                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.05857\teval-rmse:2.48068                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.04584\teval-rmse:2.48506                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.03839\teval-rmse:2.49807                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.0295\teval-rmse:2.49626                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.02297\teval-rmse:2.49518                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.01297\teval-rmse:2.5019                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:3.00592\teval-rmse:2.50944                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.99698\teval-rmse:2.50905                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.98472\teval-rmse:2.50374                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.97358\teval-rmse:2.50231                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.97118\teval-rmse:2.50061                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.96513\teval-rmse:2.50537                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.95682\teval-rmse:2.50821                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.94543\teval-rmse:2.50642                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.9363\teval-rmse:2.52154                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.92692\teval-rmse:2.52629                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.92384\teval-rmse:2.52301                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.91498\teval-rmse:2.51658                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.90881\teval-rmse:2.52497                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.90359\teval-rmse:2.52572                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.8988\teval-rmse:2.52328                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:3.05857\teval-rmse:2.48068\n",
      "\n",
      "\n",
      "loss: 78410295.01378858                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00392476623162973, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.1857688776863419e-07, 'lambda': 0.434457399652321, 'learning_rate': 0.47500000000000003, 'max_depth': 9, 'min_child_weight': 0.24728277161465226, 'n_estimators': 185.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.79947\teval-rmse:4.63657                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.47153\teval-rmse:3.2965                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:2.93476\teval-rmse:2.79307                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.70135\teval-rmse:2.63774                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.58802\teval-rmse:2.60902                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.51864\teval-rmse:2.60338                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.46222\teval-rmse:2.60266                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.42224\teval-rmse:2.62833                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.33531\teval-rmse:2.61736                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.31447\teval-rmse:2.61693                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.26597\teval-rmse:2.65308                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.22183\teval-rmse:2.65104                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.18982\teval-rmse:2.6455                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.12579\teval-rmse:2.64364                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.10567\teval-rmse:2.64352                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.0709\teval-rmse:2.66364                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.05565\teval-rmse:2.66146                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.02929\teval-rmse:2.67466                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.00513\teval-rmse:2.67534                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.96847\teval-rmse:2.67695                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.93674\teval-rmse:2.67861                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.9157\teval-rmse:2.69961                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.90623\teval-rmse:2.70402                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.85302\teval-rmse:2.70476                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.83815\teval-rmse:2.72957                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.80944\teval-rmse:2.73271                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.76478\teval-rmse:2.73553                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.46222\teval-rmse:2.60266\n",
      "\n",
      "\n",
      "loss: 66858999.61025234                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.849450005511757e-07, 'colsample_bytree': 0.9, 'gamma': 1.8243075165926886e-05, 'lambda': 0.008634857451874983, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 1.6956629930963836, 'n_estimators': 104.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:6.16726\teval-rmse:6.04151                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.04185\teval-rmse:4.82954                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.26647\teval-rmse:3.98403                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.74278\teval-rmse:3.42259                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.38945\teval-rmse:3.06194                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.15901\teval-rmse:2.84158                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.00557\teval-rmse:2.69046                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.90462\teval-rmse:2.61063                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.83352\teval-rmse:2.56188                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.78037\teval-rmse:2.53689                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.74295\teval-rmse:2.53154                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.7184\teval-rmse:2.52925                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.68966\teval-rmse:2.52663                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.66183\teval-rmse:2.5234                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.63492\teval-rmse:2.53314                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.5984\teval-rmse:2.5423                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:2.57306\teval-rmse:2.54378                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.5522\teval-rmse:2.54046                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.53509\teval-rmse:2.54374                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.49704\teval-rmse:2.5311                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.45337\teval-rmse:2.52885                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.43742\teval-rmse:2.53492                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.42727\teval-rmse:2.5383                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.40707\teval-rmse:2.53882                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.38775\teval-rmse:2.55021                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.38031\teval-rmse:2.55029                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.3604\teval-rmse:2.55076                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.34396\teval-rmse:2.55967                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.32878\teval-rmse:2.56377                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.31445\teval-rmse:2.56347                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.30131\teval-rmse:2.56382                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.27735\teval-rmse:2.55955                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.26696\teval-rmse:2.56048                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.25414\teval-rmse:2.57151                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[13]\ttrain-rmse:2.66183\teval-rmse:2.5234\n",
      "\n",
      "\n",
      "loss: 64341811.2814353                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0003747910642762533, 'colsample_bytree': 0.75, 'gamma': 1.1507743830185939e-05, 'lambda': 0.012626083629875029, 'learning_rate': 0.325, 'max_depth': 6, 'min_child_weight': 7.907398857350347, 'n_estimators': 241.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.76058\teval-rmse:5.56702                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.55628\teval-rmse:4.20503                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.86518\teval-rmse:3.40341                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.48638\teval-rmse:2.95901                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.27953\teval-rmse:2.74226                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.17624\teval-rmse:2.62091                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.11603\teval-rmse:2.56292                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.07469\teval-rmse:2.52742                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.04365\teval-rmse:2.52101                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.02304\teval-rmse:2.50258                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.00429\teval-rmse:2.50746                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.99408\teval-rmse:2.51095                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.96535\teval-rmse:2.51527                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.94986\teval-rmse:2.51375                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.94328\teval-rmse:2.51303                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.92435\teval-rmse:2.52514                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.90887\teval-rmse:2.52285                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.89641\teval-rmse:2.53271                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.87997\teval-rmse:2.53195                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.8756\teval-rmse:2.53468                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttrain-rmse:2.86427\teval-rmse:2.52457                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.84407\teval-rmse:2.5276                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.83211\teval-rmse:2.52515                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.82355\teval-rmse:2.52472                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.81522\teval-rmse:2.52428                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.80032\teval-rmse:2.52976                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.79081\teval-rmse:2.52988                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.78547\teval-rmse:2.53636                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.77853\teval-rmse:2.5372                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.767\teval-rmse:2.54064                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:3.02304\teval-rmse:2.50258\n",
      "\n",
      "\n",
      "loss: 77691349.69721845                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.578755756599713e-05, 'colsample_bytree': 0.8, 'gamma': 7.735314786437721e-05, 'lambda': 0.7147549797028006, 'learning_rate': 0.375, 'max_depth': 8, 'min_child_weight': 0.35072216352486235, 'n_estimators': 615.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.4155\teval-rmse:5.2484                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.11654\teval-rmse:3.85428                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.4404\teval-rmse:3.12831                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.10193\teval-rmse:2.79873                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.9093\teval-rmse:2.66295                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.80832\teval-rmse:2.62215                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.74276\teval-rmse:2.60799                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.69336\teval-rmse:2.60523                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.65795\teval-rmse:2.59898                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.60602\teval-rmse:2.61802                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.57839\teval-rmse:2.62976                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.56225\teval-rmse:2.63464                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.5213\teval-rmse:2.67775                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.51351\teval-rmse:2.67787                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.49913\teval-rmse:2.68665                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.47584\teval-rmse:2.69542                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.44277\teval-rmse:2.69878                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.41502\teval-rmse:2.69356                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.38267\teval-rmse:2.69706                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.36437\teval-rmse:2.69842                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.34356\teval-rmse:2.7019                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.32496\teval-rmse:2.70419                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.30514\teval-rmse:2.70658                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.28056\teval-rmse:2.70162                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.24441\teval-rmse:2.72146                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.19879\teval-rmse:2.72497                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.16805\teval-rmse:2.7153                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.14633\teval-rmse:2.71647                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.13627\teval-rmse:2.71504                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.65795\teval-rmse:2.59898\n",
      "\n",
      "\n",
      "loss: 73167767.63714297                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00010925147175243936, 'colsample_bytree': 0.8500000000000001, 'gamma': 4.788485492088082e-06, 'lambda': 7.031953351202265, 'learning_rate': 0.35000000000000003, 'max_depth': 4, 'min_child_weight': 0.4569581629286383, 'n_estimators': 294.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.65747\teval-rmse:5.40814                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.47313\teval-rmse:4.02719                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.84066\teval-rmse:3.25132                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.52463\teval-rmse:2.85773                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.37084\teval-rmse:2.65325                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.29665\teval-rmse:2.55786                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.25582\teval-rmse:2.50509                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.2286\teval-rmse:2.47851                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.20915\teval-rmse:2.4631                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.18965\teval-rmse:2.46746                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.17314\teval-rmse:2.48063                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.16481\teval-rmse:2.48099                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.15628\teval-rmse:2.48272                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\ttrain-rmse:3.14348\teval-rmse:2.4847                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.13859\teval-rmse:2.48467                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.12872\teval-rmse:2.48625                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.11636\teval-rmse:2.48639                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.10853\teval-rmse:2.48744                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.10046\teval-rmse:2.48957                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.09079\teval-rmse:2.48489                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.08255\teval-rmse:2.48117                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.08075\teval-rmse:2.48099                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.07716\teval-rmse:2.48259                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.06994\teval-rmse:2.47808                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.06626\teval-rmse:2.48155                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.06104\teval-rmse:2.48347                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.05559\teval-rmse:2.4863                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:3.0529\teval-rmse:2.48571                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:3.04503\teval-rmse:2.48109                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:3.20915\teval-rmse:2.4631\n",
      "\n",
      "\n",
      "loss: 91456427.1784756                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 9.111276142462185e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.0004433293023457583, 'lambda': 3.2033220324539937, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 0.3998267290130629, 'n_estimators': 510.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.85381\teval-rmse:5.72561                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.61762\teval-rmse:4.42222                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.82661\teval-rmse:3.60176                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.33548\teval-rmse:3.10693                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.02373\teval-rmse:2.83159                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.83587\teval-rmse:2.69594                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.72776\teval-rmse:2.61234                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.63105\teval-rmse:2.57717                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.56102\teval-rmse:2.53215                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.51764\teval-rmse:2.52141                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.46301\teval-rmse:2.52076                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.41974\teval-rmse:2.52001                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.39486\teval-rmse:2.5266                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.36935\teval-rmse:2.5263                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.34985\teval-rmse:2.52595                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.32647\teval-rmse:2.53961                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.30033\teval-rmse:2.54482                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.26089\teval-rmse:2.54311                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.2312\teval-rmse:2.5433                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:2.20426\teval-rmse:2.54585                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.18285\teval-rmse:2.54468                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.16918\teval-rmse:2.54863                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.14395\teval-rmse:2.55738                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.11682\teval-rmse:2.56356                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.09115\teval-rmse:2.56202                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.07297\teval-rmse:2.56089                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.05263\teval-rmse:2.56467                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.04396\teval-rmse:2.56407                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.01165\teval-rmse:2.57115                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.98903\teval-rmse:2.56686                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.97931\teval-rmse:2.57593                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.96789\teval-rmse:2.57541                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.41974\teval-rmse:2.52001\n",
      "\n",
      "\n",
      "loss: 63483938.5538556                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 9.476923600144087e-06, 'colsample_bytree': 0.7000000000000001, 'gamma': 0.2718231448254273, 'lambda': 0.0021909849333201733, 'learning_rate': 0.45, 'max_depth': 8, 'min_child_weight': 0.5469699684268936, 'n_estimators': 449.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.98873\teval-rmse:4.76291                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.70634\teval-rmse:3.37332                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.156\teval-rmse:2.82024                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:2.91456\teval-rmse:2.62299                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\ttrain-rmse:2.80585\teval-rmse:2.56669                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.72511\teval-rmse:2.55369                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.69016\teval-rmse:2.55158                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.64729\teval-rmse:2.55554                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.62209\teval-rmse:2.57248                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.57057\teval-rmse:2.58703                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.53066\teval-rmse:2.62746                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.49277\teval-rmse:2.63566                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.44226\teval-rmse:2.66021                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.41722\teval-rmse:2.66045                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.40253\teval-rmse:2.68025                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.35672\teval-rmse:2.72055                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.33994\teval-rmse:2.72002                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.31717\teval-rmse:2.72161                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.30049\teval-rmse:2.71995                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.2617\teval-rmse:2.71014                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.23114\teval-rmse:2.71069                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.21302\teval-rmse:2.71128                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.17017\teval-rmse:2.72893                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.14895\teval-rmse:2.74431                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.11402\teval-rmse:2.74633                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.09282\teval-rmse:2.76353                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.07419\teval-rmse:2.7682                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.69016\teval-rmse:2.55158\n",
      "\n",
      "\n",
      "loss: 274060904.8092916                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00018850804694536921, 'colsample_bytree': 0.6000000000000001, 'gamma': 0.002361315829223916, 'lambda': 0.05079353929353717, 'learning_rate': 0.42500000000000004, 'max_depth': 3, 'min_child_weight': 0.7129665854720295, 'n_estimators': 321.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.28468\teval-rmse:4.96353                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.1321\teval-rmse:3.55223                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.62734\teval-rmse:2.91586                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.43431\teval-rmse:2.6662                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.35243\teval-rmse:2.56261                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.318\teval-rmse:2.53033                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:3.29912\teval-rmse:2.52086                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.28435\teval-rmse:2.51017                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.26905\teval-rmse:2.49278                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.26121\teval-rmse:2.48818                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.25381\teval-rmse:2.48716                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.24527\teval-rmse:2.49128                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.23906\teval-rmse:2.48914                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.23425\teval-rmse:2.4896                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.2251\teval-rmse:2.48569                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:3.21607\teval-rmse:2.4806                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.20726\teval-rmse:2.47244                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.2035\teval-rmse:2.47806                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:3.20179\teval-rmse:2.47836                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.1963\teval-rmse:2.48731                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:3.19278\teval-rmse:2.48579                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.18661\teval-rmse:2.48204                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.18027\teval-rmse:2.47221                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.1715\teval-rmse:2.47294                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:3.16762\teval-rmse:2.47042                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.16304\teval-rmse:2.47412                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.15846\teval-rmse:2.48679                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.15394\teval-rmse:2.48264                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.14965\teval-rmse:2.49698                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.14358\teval-rmse:2.49423                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.13967\teval-rmse:2.49386                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.13816\teval-rmse:2.49912                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.13729\teval-rmse:2.49908                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.13389\teval-rmse:2.50157                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.13049\teval-rmse:2.50285                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.12364\teval-rmse:2.49874                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36]\ttrain-rmse:3.12064\teval-rmse:2.49846                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.11663\teval-rmse:2.49191                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.11365\teval-rmse:2.4918                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:3.11014\teval-rmse:2.49066                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.10771\teval-rmse:2.48868                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.10434\teval-rmse:2.49661                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.10035\teval-rmse:2.48464                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.09494\teval-rmse:2.48423                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.09125\teval-rmse:2.48336                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[24]\ttrain-rmse:3.16762\teval-rmse:2.47042\n",
      "\n",
      "\n",
      "loss: 78817169.74953154                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.446893612672639e-06, 'colsample_bytree': 0.9, 'gamma': 3.965440106492824e-08, 'lambda': 0.2570961975800076, 'learning_rate': 0.275, 'max_depth': 8, 'min_child_weight': 0.9733383883192743, 'n_estimators': 122.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:6.01718\teval-rmse:5.88528                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.84237\teval-rmse:4.61225                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.06617\teval-rmse:3.78209                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.56571\teval-rmse:3.25289                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.24826\teval-rmse:2.9407                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.0507\teval-rmse:2.7679                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:2.91981\teval-rmse:2.65423                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.83218\teval-rmse:2.60196                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.76131\teval-rmse:2.5668                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.70817\teval-rmse:2.55511                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.67779\teval-rmse:2.54493                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.6518\teval-rmse:2.54519                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.63252\teval-rmse:2.53683                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.60018\teval-rmse:2.57315                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.58187\teval-rmse:2.5747                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.55136\teval-rmse:2.5796                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.52444\teval-rmse:2.58621                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.50826\teval-rmse:2.58966                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.49178\teval-rmse:2.59669                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.4669\teval-rmse:2.59335                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.45552\teval-rmse:2.59496                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.42442\teval-rmse:2.60946                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.40517\teval-rmse:2.60328                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.3937\teval-rmse:2.60061                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.36882\teval-rmse:2.60161                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.35405\teval-rmse:2.6086                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.33857\teval-rmse:2.6153                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.30932\teval-rmse:2.60993                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.28698\teval-rmse:2.6129                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.27288\teval-rmse:2.61519                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.2613\teval-rmse:2.61398                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.23497\teval-rmse:2.61646                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.20716\teval-rmse:2.63368                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.63252\teval-rmse:2.53683\n",
      "\n",
      "\n",
      "loss: 68541105.86080766                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.87204352089542e-06, 'colsample_bytree': 0.9, 'gamma': 2.3790234256310478e-08, 'lambda': 0.12658245108906047, 'learning_rate': 0.4, 'max_depth': 7, 'min_child_weight': 1.1804117178828573, 'n_estimators': 419.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.30814\teval-rmse:5.06436                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.05331\teval-rmse:3.65612                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.44943\teval-rmse:2.98319                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.17264\teval-rmse:2.69435                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.04609\teval-rmse:2.57014                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.97107\teval-rmse:2.53401                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.92865\teval-rmse:2.52124                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.87814\teval-rmse:2.5259                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.85324\teval-rmse:2.50945                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.8385\teval-rmse:2.50921                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:2.80366\teval-rmse:2.53648                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.78272\teval-rmse:2.56114                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.74579\teval-rmse:2.57326                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.7172\teval-rmse:2.56804                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.69355\teval-rmse:2.56693                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.66522\teval-rmse:2.57145                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.6479\teval-rmse:2.57451                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.61656\teval-rmse:2.5928                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.58399\teval-rmse:2.60163                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.56233\teval-rmse:2.60139                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.54965\teval-rmse:2.60057                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.52831\teval-rmse:2.59904                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.50751\teval-rmse:2.59805                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.48292\teval-rmse:2.59546                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.46782\teval-rmse:2.6036                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.45178\teval-rmse:2.60465                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.43931\teval-rmse:2.60316                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.42887\teval-rmse:2.60345                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.40451\teval-rmse:2.61418                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.38382\teval-rmse:2.62472                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.8385\teval-rmse:2.50921\n",
      "\n",
      "\n",
      "loss: 69817547.83120358                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.18886508142926e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.0673345963783656e-08, 'lambda': 1.8550037071219743, 'learning_rate': 0.325, 'max_depth': 5, 'min_child_weight': 0.7783788720955551, 'n_estimators': 485.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.77827\teval-rmse:5.55913                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.59361\teval-rmse:4.20825                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.91737\teval-rmse:3.3994                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.55031\teval-rmse:2.94017                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.35863\teval-rmse:2.70424                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.25297\teval-rmse:2.58957                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.19885\teval-rmse:2.52847                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.16501\teval-rmse:2.50326                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.14193\teval-rmse:2.48183                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.11983\teval-rmse:2.48335                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.09934\teval-rmse:2.47364                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.08407\teval-rmse:2.47426                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.06973\teval-rmse:2.46993                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.05701\teval-rmse:2.47572                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.04644\teval-rmse:2.47639                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.03675\teval-rmse:2.47762                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.01826\teval-rmse:2.47841                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.00689\teval-rmse:2.47787                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.00066\teval-rmse:2.48097                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.99372\teval-rmse:2.48075                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.98112\teval-rmse:2.48855                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.97336\teval-rmse:2.48902                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.95989\teval-rmse:2.48557                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.94981\teval-rmse:2.48449                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.94544\teval-rmse:2.48166                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.93951\teval-rmse:2.48101                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.93431\teval-rmse:2.47873                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.9203\teval-rmse:2.47546                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.90912\teval-rmse:2.47307                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.89634\teval-rmse:2.47778                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.88769\teval-rmse:2.48467                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.8768\teval-rmse:2.48571                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.87236\teval-rmse:2.48729                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:3.06973\teval-rmse:2.46993\n",
      "\n",
      "\n",
      "loss: 67650718.24580562                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.729656076375834e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.00017707225607205344, 'lambda': 0.005289743348439097, 'learning_rate': 0.5, 'max_depth': 9, 'min_child_weight': 3.852455646870699, 'n_estimators': 259.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.66496\teval-rmse:4.49069                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.39415\teval-rmse:3.16981                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:2.90565\teval-rmse:2.76926                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.67993\teval-rmse:2.68387                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.59871\teval-rmse:2.63848                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.52041\teval-rmse:2.63689                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.44018\teval-rmse:2.66903                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.39338\teval-rmse:2.67701                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.37319\teval-rmse:2.67744                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.35224\teval-rmse:2.70612                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.3146\teval-rmse:2.73388                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.27604\teval-rmse:2.73964                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.21033\teval-rmse:2.75802                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.15869\teval-rmse:2.77861                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.0902\teval-rmse:2.79111                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.04925\teval-rmse:2.80089                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.01284\teval-rmse:2.82328                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:1.98697\teval-rmse:2.81461                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:1.95558\teval-rmse:2.79276                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:1.93783\teval-rmse:2.80118                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.89926\teval-rmse:2.81396                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.88489\teval-rmse:2.81133                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.87115\teval-rmse:2.81952                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.85283\teval-rmse:2.82413                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.81982\teval-rmse:2.82209                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.79704\teval-rmse:2.82599                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.52041\teval-rmse:2.63689\n",
      "\n",
      "\n",
      "loss: 236467942.9197584                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.49967654322536e-06, 'colsample_bytree': 0.8500000000000001, 'gamma': 2.1109535863371688e-07, 'lambda': 5.114523268942048, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 0.1934919884993711, 'n_estimators': 357.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.29456\teval-rmse:5.07725                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.99724\teval-rmse:3.65555                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.36171\teval-rmse:2.98649                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.05275\teval-rmse:2.69841                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.90607\teval-rmse:2.57936                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.80025\teval-rmse:2.5422                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.75201\teval-rmse:2.52856                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.71319\teval-rmse:2.51529                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.66495\teval-rmse:2.54368                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.62087\teval-rmse:2.56153                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.58933\teval-rmse:2.56142                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.56568\teval-rmse:2.56808                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.54372\teval-rmse:2.56708                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.52515\teval-rmse:2.56519                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.49591\teval-rmse:2.58065                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.48248\teval-rmse:2.57966                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.44667\teval-rmse:2.5686                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.4303\teval-rmse:2.57922                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.41491\teval-rmse:2.57381                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.39581\teval-rmse:2.5679                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.35828\teval-rmse:2.57479                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.32866\teval-rmse:2.58814                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.30193\teval-rmse:2.59122                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.29114\teval-rmse:2.5985                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.2569\teval-rmse:2.613                                                                                 \n",
      "\n",
      "[25]\ttrain-rmse:2.23599\teval-rmse:2.61264                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.20482\teval-rmse:2.62011                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.18389\teval-rmse:2.62656                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.71319\teval-rmse:2.51529\n",
      "\n",
      "\n",
      "loss: 69822564.67394729                                                                                                \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 3.482114170576613e-05, 'colsample_bytree': 0.9, 'gamma': 4.138658065358754e-05, 'lambda': 9.82662768300677, 'learning_rate': 0.30000000000000004, 'max_depth': 6, 'min_child_weight': 3.3391976367951965, 'n_estimators': 161.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.91568\teval-rmse:5.72302                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.74333\teval-rmse:4.40612                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.03138\teval-rmse:3.57489                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.61475\teval-rmse:3.08174                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.37547\teval-rmse:2.79626                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.2405\teval-rmse:2.64192                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.159\teval-rmse:2.57081                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:3.10815\teval-rmse:2.53454                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.074\teval-rmse:2.51273                                                                                 \n",
      "\n",
      "[9]\ttrain-rmse:3.04565\teval-rmse:2.49675                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.01972\teval-rmse:2.48645                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.00023\teval-rmse:2.4908                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.98565\teval-rmse:2.49921                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.96408\teval-rmse:2.506                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:2.95294\teval-rmse:2.51065                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.93794\teval-rmse:2.51594                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.92064\teval-rmse:2.51875                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.90964\teval-rmse:2.51838                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.89503\teval-rmse:2.51457                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.88409\teval-rmse:2.51586                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.87891\teval-rmse:2.51707                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.86622\teval-rmse:2.51731                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.85911\teval-rmse:2.51594                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.84543\teval-rmse:2.51122                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.83006\teval-rmse:2.51764                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.8203\teval-rmse:2.52037                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.80894\teval-rmse:2.52485                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.79243\teval-rmse:2.53172                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.7823\teval-rmse:2.54098                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.77308\teval-rmse:2.53455                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.7669\teval-rmse:2.53775                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:3.01972\teval-rmse:2.48645\n",
      "\n",
      "\n",
      "loss: 75918082.59765711                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.0135131922040166e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.0009901853708195177, 'lambda': 0.0001827957588414242, 'learning_rate': 0.375, 'max_depth': 8, 'min_child_weight': 0.12297393847704599, 'n_estimators': 220.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:5.43114\teval-rmse:5.24442                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.14494\teval-rmse:3.8573                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.47726\teval-rmse:3.13671                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.1332\teval-rmse:2.8156                                                                                 \n",
      "\n",
      "[4]\ttrain-rmse:2.9653\teval-rmse:2.67764                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.875\teval-rmse:2.61207                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:2.81731\teval-rmse:2.57132                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.77805\teval-rmse:2.5825                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.75337\teval-rmse:2.59866                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.73341\teval-rmse:2.63284                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.70978\teval-rmse:2.64697                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.68194\teval-rmse:2.6743                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.66693\teval-rmse:2.69378                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.64442\teval-rmse:2.69921                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.601\teval-rmse:2.70408                                                                                \n",
      "\n",
      "[15]\ttrain-rmse:2.57821\teval-rmse:2.72434                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.54731\teval-rmse:2.74267                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.50274\teval-rmse:2.76802                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.4763\teval-rmse:2.79071                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.44174\teval-rmse:2.7996                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.43385\teval-rmse:2.79679                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.41346\teval-rmse:2.81884                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.39198\teval-rmse:2.81467                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.35353\teval-rmse:2.8149                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24]\ttrain-rmse:2.33996\teval-rmse:2.81846                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.32057\teval-rmse:2.8302                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.30642\teval-rmse:2.84638                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.81731\teval-rmse:2.57132\n",
      "\n",
      "\n",
      "loss: 1054888839.8139703                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0004738882060972521, 'colsample_bytree': 0.8, 'gamma': 7.715142531383343e-06, 'lambda': 0.09197001242525212, 'learning_rate': 0.42500000000000004, 'max_depth': 4, 'min_child_weight': 0.16865873260299472, 'n_estimators': 374.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.25115\teval-rmse:4.95454                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.07881\teval-rmse:3.55587                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.58098\teval-rmse:2.90661                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.37633\teval-rmse:2.65721                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.2934\teval-rmse:2.55899                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.24645\teval-rmse:2.51784                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.22022\teval-rmse:2.49775                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.20563\teval-rmse:2.48601                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.19187\teval-rmse:2.48752                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.17481\teval-rmse:2.50882                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.16084\teval-rmse:2.51731                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.14954\teval-rmse:2.51979                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.13936\teval-rmse:2.5258                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.13508\teval-rmse:2.52294                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.12183\teval-rmse:2.51865                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.1163\teval-rmse:2.5212                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:3.11049\teval-rmse:2.51832                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.10856\teval-rmse:2.51784                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.10363\teval-rmse:2.51367                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.09146\teval-rmse:2.50538                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.08492\teval-rmse:2.50046                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.07749\teval-rmse:2.49224                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.06909\teval-rmse:2.50324                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.06169\teval-rmse:2.49605                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.05331\teval-rmse:2.49387                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.04533\teval-rmse:2.49875                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.03601\teval-rmse:2.49605                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.0281\teval-rmse:2.51362                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:3.20563\teval-rmse:2.48601\n",
      "\n",
      "\n",
      "loss: 83949883.30764042                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.896806400391888e-06, 'colsample_bytree': 0.9, 'gamma': 3.8214946955898234e-07, 'lambda': 0.4397400496874818, 'learning_rate': 0.35000000000000003, 'max_depth': 9, 'min_child_weight': 1.2974282094795522, 'n_estimators': 698.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.52809\teval-rmse:5.40428                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.19021\teval-rmse:4.03413                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.43018\teval-rmse:3.26894                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.00278\teval-rmse:2.87326                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.75612\teval-rmse:2.70821                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.60137\teval-rmse:2.62331                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.51282\teval-rmse:2.5803                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.46755\teval-rmse:2.5588                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.40228\teval-rmse:2.5562                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.3554\teval-rmse:2.56548                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.3274\teval-rmse:2.58365                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.29571\teval-rmse:2.58694                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.24848\teval-rmse:2.58716                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.22779\teval-rmse:2.59569                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.21109\teval-rmse:2.59223                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.16969\teval-rmse:2.59115                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.14142\teval-rmse:2.60129                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.11752\teval-rmse:2.60233                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.07775\teval-rmse:2.60534                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.06303\teval-rmse:2.61077                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.03699\teval-rmse:2.61099                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]\ttrain-rmse:1.99662\teval-rmse:2.61867                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.96266\teval-rmse:2.6122                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.94423\teval-rmse:2.61229                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.93182\teval-rmse:2.61035                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.92329\teval-rmse:2.61495                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.91666\teval-rmse:2.61834                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.88508\teval-rmse:2.63853                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.85195\teval-rmse:2.63232                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.40228\teval-rmse:2.5562\n",
      "\n",
      "\n",
      "loss: 66201828.830212764                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.3900458329753394e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 6.729339457819256e-07, 'lambda': 1.0469502122288414, 'learning_rate': 0.2, 'max_depth': 8, 'min_child_weight': 0.31897763020719194, 'n_estimators': 562.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:6.48318\teval-rmse:6.37407                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.51054\teval-rmse:5.33223                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.76835\teval-rmse:4.53925                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.21324\teval-rmse:3.93257                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.80396\teval-rmse:3.49845                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.50295\teval-rmse:3.18089                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.28564\teval-rmse:2.96115                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.12875\teval-rmse:2.82477                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.01692\teval-rmse:2.71361                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.93096\teval-rmse:2.65156                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.87389\teval-rmse:2.60961                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.8263\teval-rmse:2.58622                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.78801\teval-rmse:2.56534                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.76059\teval-rmse:2.5451                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.74045\teval-rmse:2.53388                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.71435\teval-rmse:2.52532                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.66945\teval-rmse:2.53146                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.64544\teval-rmse:2.53017                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.6155\teval-rmse:2.53478                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.59374\teval-rmse:2.5288                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.5704\teval-rmse:2.52373                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.55575\teval-rmse:2.52638                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.5414\teval-rmse:2.51782                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.51894\teval-rmse:2.53253                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.50539\teval-rmse:2.53743                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.49571\teval-rmse:2.53937                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.47364\teval-rmse:2.54505                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.45957\teval-rmse:2.55747                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.44017\teval-rmse:2.55749                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.42528\teval-rmse:2.55643                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.41018\teval-rmse:2.56337                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.39697\teval-rmse:2.56217                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.38497\teval-rmse:2.5745                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.37946\teval-rmse:2.57561                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.37371\teval-rmse:2.57335                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.36034\teval-rmse:2.57972                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.34686\teval-rmse:2.57883                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.33478\teval-rmse:2.5846                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:2.32418\teval-rmse:2.58424                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.31319\teval-rmse:2.58228                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.30647\teval-rmse:2.58366                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.29227\teval-rmse:2.58013                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.28258\teval-rmse:2.57162                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[22]\ttrain-rmse:2.5414\teval-rmse:2.51782\n",
      "\n",
      "\n",
      "loss: 67365035.32006636                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00025036812458948505, 'colsample_bytree': 0.9500000000000001, 'gamma': 7.050508846955885e-08, 'lambda': 0.0675802231832179, 'learning_rate': 0.45, 'max_depth': 8, 'min_child_weight': 1.830282629286183, 'n_estimators': 276.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.98545\teval-rmse:4.77488                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:3.69962\teval-rmse:3.41112                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.14953\teval-rmse:2.86279                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.9087\teval-rmse:2.68374                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.7868\teval-rmse:2.67131                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.72738\teval-rmse:2.64824                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.68189\teval-rmse:2.65939                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.62946\teval-rmse:2.67792                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.596\teval-rmse:2.6768                                                                                  \n",
      "\n",
      "[9]\ttrain-rmse:2.53856\teval-rmse:2.68308                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.50623\teval-rmse:2.70699                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.48209\teval-rmse:2.71192                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.43004\teval-rmse:2.71788                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.41727\teval-rmse:2.72011                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.40521\teval-rmse:2.71134                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.37167\teval-rmse:2.69908                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.34487\teval-rmse:2.69848                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.33228\teval-rmse:2.69882                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.28253\teval-rmse:2.71771                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.25793\teval-rmse:2.73007                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.20672\teval-rmse:2.73556                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.1799\teval-rmse:2.73559                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.14899\teval-rmse:2.74368                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.13198\teval-rmse:2.75467                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.1047\teval-rmse:2.77554                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.07527\teval-rmse:2.78609                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.72738\teval-rmse:2.64824\n",
      "\n",
      "\n",
      "loss: 80469644.60894017                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0009512267207529029, 'colsample_bytree': 0.9, 'gamma': 2.8434581730262756e-06, 'lambda': 2.694580946174961, 'learning_rate': 0.275, 'max_depth': 3, 'min_child_weight': 1.571092518004239, 'n_estimators': 203.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.10112\teval-rmse:5.90167                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.01716\teval-rmse:4.65662                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.31884\teval-rmse:3.83829                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.89451\teval-rmse:3.31173                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.64235\teval-rmse:2.98322                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.49424\teval-rmse:2.78298                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.40902\teval-rmse:2.66907                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.35493\teval-rmse:2.59446                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.32281\teval-rmse:2.56012                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.2997\teval-rmse:2.53463                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.28482\teval-rmse:2.5267                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.2736\teval-rmse:2.52071                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.26541\teval-rmse:2.51966                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.25771\teval-rmse:2.50914                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.24932\teval-rmse:2.50641                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.23772\teval-rmse:2.50224                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.22986\teval-rmse:2.50827                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.22701\teval-rmse:2.50778                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.21936\teval-rmse:2.51018                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.21301\teval-rmse:2.50966                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.20854\teval-rmse:2.50929                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.2038\teval-rmse:2.51437                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:3.19954\teval-rmse:2.51287                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.19507\teval-rmse:2.50752                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.19201\teval-rmse:2.50623                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.18915\teval-rmse:2.50223                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.18449\teval-rmse:2.50215                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.18016\teval-rmse:2.50192                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.17757\teval-rmse:2.50034                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.1746\teval-rmse:2.49971                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:3.17033\teval-rmse:2.49506                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.16521\teval-rmse:2.49049                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.16161\teval-rmse:2.49443                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.15718\teval-rmse:2.49654                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.15533\teval-rmse:2.49505                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35]\ttrain-rmse:3.15312\teval-rmse:2.49802                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.15053\teval-rmse:2.49803                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.14814\teval-rmse:2.49736                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.14487\teval-rmse:2.50462                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.14088\teval-rmse:2.50092                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.1383\teval-rmse:2.50497                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:3.13491\teval-rmse:2.50496                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.13185\teval-rmse:2.50545                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.13118\teval-rmse:2.50544                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.12865\teval-rmse:2.50509                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.12545\teval-rmse:2.51151                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.12057\teval-rmse:2.50496                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.11954\teval-rmse:2.50558                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.11862\teval-rmse:2.50396                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.11603\teval-rmse:2.50501                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.11282\teval-rmse:2.50569                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.11125\teval-rmse:2.50508                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[31]\ttrain-rmse:3.16521\teval-rmse:2.49049\n",
      "\n",
      "\n",
      "loss: 76835535.5543224                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.001532437902328704, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.00031535860501960875, 'lambda': 0.20601062540533163, 'learning_rate': 0.25, 'max_depth': 7, 'min_child_weight': 8.891645401303103, 'n_estimators': 131.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.18583\teval-rmse:6.04012                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.0894\teval-rmse:4.83324                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.33445\teval-rmse:3.98661                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.83169\teval-rmse:3.41791                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.50376\teval-rmse:3.04986                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.28949\teval-rmse:2.81199                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.15081\teval-rmse:2.67474                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.06039\teval-rmse:2.59404                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.99449\teval-rmse:2.54753                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.95395\teval-rmse:2.51786                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.91677\teval-rmse:2.50192                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.89824\teval-rmse:2.4959                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.87761\teval-rmse:2.48958                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.85881\teval-rmse:2.49133                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.83774\teval-rmse:2.49036                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.82527\teval-rmse:2.48841                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.80469\teval-rmse:2.49698                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.78594\teval-rmse:2.49522                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.76763\teval-rmse:2.4942                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.74963\teval-rmse:2.50173                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.73732\teval-rmse:2.51303                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.7237\teval-rmse:2.51367                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.70754\teval-rmse:2.51351                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.6986\teval-rmse:2.51797                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.68158\teval-rmse:2.53837                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.66674\teval-rmse:2.54473                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.64424\teval-rmse:2.54109                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.63741\teval-rmse:2.54082                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.62422\teval-rmse:2.54533                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.61512\teval-rmse:2.54996                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.60263\teval-rmse:2.55649                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.5953\teval-rmse:2.55659                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.59012\teval-rmse:2.55635                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.57854\teval-rmse:2.55584                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.56789\teval-rmse:2.55979                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.55346\teval-rmse:2.56078                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.82527\teval-rmse:2.48841\n",
      "\n",
      "\n",
      "loss: 66354752.85573542                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00012105665864661582, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.3747815356719307e-06, 'lambda': 9.940902175894967, 'learning_rate': 0.225, 'max_depth': 8, 'min_child_weight': 5.910424033449778, 'n_estimators': 331.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.33983\teval-rmse:6.20981                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.2963\teval-rmse:5.0801                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:4.53806\teval-rmse:4.24986                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.00117\teval-rmse:3.66034                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.62432\teval-rmse:3.26141                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.36222\teval-rmse:2.98438                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.18456\teval-rmse:2.7999                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.0583\teval-rmse:2.70215                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.96499\teval-rmse:2.6273                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.89984\teval-rmse:2.5789                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.8443\teval-rmse:2.54242                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.80709\teval-rmse:2.52323                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.76853\teval-rmse:2.51417                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.74376\teval-rmse:2.5081                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.7225\teval-rmse:2.50219                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.70739\teval-rmse:2.49797                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.67925\teval-rmse:2.48983                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.66646\teval-rmse:2.48536                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.64706\teval-rmse:2.4863                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.62498\teval-rmse:2.48696                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.60522\teval-rmse:2.49109                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.5912\teval-rmse:2.49099                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.57302\teval-rmse:2.49318                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.55913\teval-rmse:2.49685                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.54584\teval-rmse:2.50006                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.5337\teval-rmse:2.50445                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.521\teval-rmse:2.50526                                                                                \n",
      "\n",
      "[27]\ttrain-rmse:2.51504\teval-rmse:2.50528                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.50386\teval-rmse:2.50631                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.48678\teval-rmse:2.51408                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.47488\teval-rmse:2.51344                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.4612\teval-rmse:2.5127                                                                                \n",
      "\n",
      "[32]\ttrain-rmse:2.45017\teval-rmse:2.51595                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.43861\teval-rmse:2.52294                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.43367\teval-rmse:2.52287                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.42788\teval-rmse:2.52275                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.42088\teval-rmse:2.52335                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.40748\teval-rmse:2.51774                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:2.66646\teval-rmse:2.48536\n",
      "\n",
      "\n",
      "loss: 68898454.1071538                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0005735724492559413, 'colsample_bytree': 0.9500000000000001, 'gamma': 2.732494280702565e-05, 'lambda': 1.3591770356905934, 'learning_rate': 0.35000000000000003, 'max_depth': 5, 'min_child_weight': 0.5923061118006354, 'n_estimators': 181.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:5.63644\teval-rmse:5.39783                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.43376\teval-rmse:4.00618                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.79073\teval-rmse:3.22917                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.46795\teval-rmse:2.81867                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.30644\teval-rmse:2.62538                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.21923\teval-rmse:2.54631                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.17431\teval-rmse:2.49104                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.14168\teval-rmse:2.47389                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.12136\teval-rmse:2.47309                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.10533\teval-rmse:2.4664                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.08575\teval-rmse:2.48546                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.07439\teval-rmse:2.48355                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.0527\teval-rmse:2.46875                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:3.04018\teval-rmse:2.46606                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.03306\teval-rmse:2.47184                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.02226\teval-rmse:2.474                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:3.01402\teval-rmse:2.47437                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.00632\teval-rmse:2.48536                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.9988\teval-rmse:2.49203                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.98724\teval-rmse:2.49601                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttrain-rmse:2.97863\teval-rmse:2.48871                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.96795\teval-rmse:2.48496                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.9551\teval-rmse:2.47553                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.94544\teval-rmse:2.46434                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.93634\teval-rmse:2.46234                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.92693\teval-rmse:2.46452                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.92281\teval-rmse:2.46293                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.91553\teval-rmse:2.46944                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.90154\teval-rmse:2.4804                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.89131\teval-rmse:2.47781                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.88008\teval-rmse:2.4731                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.87017\teval-rmse:2.47145                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.86442\teval-rmse:2.47918                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.85654\teval-rmse:2.48748                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.84443\teval-rmse:2.49094                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.8352\teval-rmse:2.49363                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:2.8276\teval-rmse:2.49589                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.8157\teval-rmse:2.50034                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:2.80822\teval-rmse:2.49977                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.80085\teval-rmse:2.49284                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.7896\teval-rmse:2.49329                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.7813\teval-rmse:2.49434                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:2.77541\teval-rmse:2.49206                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.76979\teval-rmse:2.49894                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.76391\teval-rmse:2.50148                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[24]\ttrain-rmse:2.93634\teval-rmse:2.46234\n",
      "\n",
      "\n",
      "loss: 77504345.12027873                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.0642929581397955e-06, 'colsample_bytree': 0.8, 'gamma': 1.1191354760725413e-05, 'lambda': 0.6097638108959184, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.3816320590985982, 'n_estimators': 760.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:5.68639\teval-rmse:5.57111                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.39253\teval-rmse:4.22302                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.60208\teval-rmse:3.44012                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.15908\teval-rmse:3.01283                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.89411\teval-rmse:2.79506                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.73843\teval-rmse:2.71095                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.63975\teval-rmse:2.67289                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.55925\teval-rmse:2.65825                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.52326\teval-rmse:2.65413                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.48254\teval-rmse:2.64465                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.43283\teval-rmse:2.6409                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.40372\teval-rmse:2.65097                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.35183\teval-rmse:2.69828                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.32612\teval-rmse:2.69645                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.30664\teval-rmse:2.70982                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.26827\teval-rmse:2.69658                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.23045\teval-rmse:2.70885                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.21188\teval-rmse:2.71523                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.18853\teval-rmse:2.71263                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.16109\teval-rmse:2.72419                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.14305\teval-rmse:2.72829                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.11312\teval-rmse:2.73496                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.0843\teval-rmse:2.75517                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.05334\teval-rmse:2.75389                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.01872\teval-rmse:2.75287                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.00015\teval-rmse:2.75336                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.97542\teval-rmse:2.7507                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:1.94308\teval-rmse:2.7583                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:1.91742\teval-rmse:2.75967                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.90129\teval-rmse:2.75796                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.89406\teval-rmse:2.76499                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.43283\teval-rmse:2.6409\n",
      "\n",
      "\n",
      "loss: 80059038.47522022                                                                                                \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0729091456029578e-05, 'colsample_bytree': 0.9, 'gamma': 1.831866255633462e-06, 'lambda': 0.31309122491451846, 'learning_rate': 0.375, 'max_depth': 6, 'min_child_weight': 2.157046336420033, 'n_estimators': 396.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.47588\teval-rmse:5.23359                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.23896\teval-rmse:3.82194                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.61681\teval-rmse:3.10018                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.31615\teval-rmse:2.76246                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.1726\teval-rmse:2.61521                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.09406\teval-rmse:2.5409                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.05068\teval-rmse:2.51544                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.02326\teval-rmse:2.50114                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.00032\teval-rmse:2.48763                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.96939\teval-rmse:2.50219                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.94681\teval-rmse:2.49908                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.92918\teval-rmse:2.50129                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.90856\teval-rmse:2.51041                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.90015\teval-rmse:2.50261                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.88365\teval-rmse:2.50153                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.86112\teval-rmse:2.50593                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.84271\teval-rmse:2.52535                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.82061\teval-rmse:2.52265                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.79856\teval-rmse:2.5179                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.78275\teval-rmse:2.52163                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.76706\teval-rmse:2.51357                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.74803\teval-rmse:2.51013                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.73739\teval-rmse:2.51034                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.72138\teval-rmse:2.52422                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.70659\teval-rmse:2.52684                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.70426\teval-rmse:2.52773                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.69429\teval-rmse:2.53104                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.67818\teval-rmse:2.53872                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.66716\teval-rmse:2.54541                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:3.00032\teval-rmse:2.48763\n",
      "\n",
      "\n",
      "loss: 74820863.88157493                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.225390684935438e-07, 'colsample_bytree': 0.8500000000000001, 'gamma': 2.86689989205317e-07, 'lambda': 4.048961871396579, 'learning_rate': 0.47500000000000003, 'max_depth': 8, 'min_child_weight': 2.993167651059229, 'n_estimators': 600.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:4.88104\teval-rmse:4.61242                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.63452\teval-rmse:3.25465                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.13806\teval-rmse:2.76724                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.94792\teval-rmse:2.60529                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.84625\teval-rmse:2.57802                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.7792\teval-rmse:2.59319                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.72573\teval-rmse:2.61091                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.69488\teval-rmse:2.62335                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.65872\teval-rmse:2.61712                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.63107\teval-rmse:2.63609                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.5942\teval-rmse:2.64357                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.56393\teval-rmse:2.61936                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.5305\teval-rmse:2.63788                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.49535\teval-rmse:2.64808                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.48294\teval-rmse:2.65388                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.45698\teval-rmse:2.65146                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.4291\teval-rmse:2.67774                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.40232\teval-rmse:2.6831                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.36402\teval-rmse:2.69788                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.3311\teval-rmse:2.69263                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.29372\teval-rmse:2.69408                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.27403\teval-rmse:2.69227                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.2586\teval-rmse:2.69021                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.22016\teval-rmse:2.70029                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.19624\teval-rmse:2.72419                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.84625\teval-rmse:2.57802\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 66012299.04641678                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.958794832960042e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.0034451257751487146, 'lambda': 3.846197463472902e-06, 'learning_rate': 0.30000000000000004, 'max_depth': 4, 'min_child_weight': 0.4300436979307992, 'n_estimators': 664.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.93825\teval-rmse:5.7259                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.79766\teval-rmse:4.4078                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.10978\teval-rmse:3.58717                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.71159\teval-rmse:3.09142                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.48728\teval-rmse:2.80759                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.37053\teval-rmse:2.65959                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.30184\teval-rmse:2.57706                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.2584\teval-rmse:2.53827                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.23571\teval-rmse:2.51403                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.21473\teval-rmse:2.49867                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.20302\teval-rmse:2.49934                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.1898\teval-rmse:2.48851                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:3.17831\teval-rmse:2.48893                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.16898\teval-rmse:2.49024                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.15512\teval-rmse:2.48766                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.1415\teval-rmse:2.48665                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.13366\teval-rmse:2.49244                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.13058\teval-rmse:2.49017                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.12038\teval-rmse:2.48278                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.11429\teval-rmse:2.48002                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.10722\teval-rmse:2.48777                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.1\teval-rmse:2.48778                                                                                  \n",
      "\n",
      "[22]\ttrain-rmse:3.0951\teval-rmse:2.48663                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:3.09176\teval-rmse:2.48551                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.08358\teval-rmse:2.48326                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.07588\teval-rmse:2.48226                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.07053\teval-rmse:2.47972                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.06516\teval-rmse:2.4824                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:3.06114\teval-rmse:2.47883                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.05748\teval-rmse:2.48073                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.0527\teval-rmse:2.477                                                                                 \n",
      "\n",
      "[31]\ttrain-rmse:3.04418\teval-rmse:2.48962                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.03829\teval-rmse:2.48873                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.03461\teval-rmse:2.48654                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.03007\teval-rmse:2.48634                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.0244\teval-rmse:2.48893                                                                               \n",
      "\n",
      "[36]\ttrain-rmse:3.01958\teval-rmse:2.48875                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.01508\teval-rmse:2.4911                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:3.00724\teval-rmse:2.48935                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.00133\teval-rmse:2.48971                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.99648\teval-rmse:2.48576                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.98856\teval-rmse:2.48686                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.98114\teval-rmse:2.48734                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.97404\teval-rmse:2.49266                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.97023\teval-rmse:2.49212                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.96347\teval-rmse:2.4936                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:2.95906\teval-rmse:2.49322                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.95713\teval-rmse:2.49263                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.95263\teval-rmse:2.49314                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.94663\teval-rmse:2.49026                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.94499\teval-rmse:2.48735                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[30]\ttrain-rmse:3.0527\teval-rmse:2.477\n",
      "\n",
      "\n",
      "loss: 82320291.442778                                                                                                  \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.5845315710402807e-05, 'colsample_bytree': 0.9, 'gamma': 0.00010631000411647026, 'lambda': 2.08502698789887, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 4.830175614095208, 'n_estimators': 498.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.17125\teval-rmse:6.04624                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.04885\teval-rmse:4.84641                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\ttrain-rmse:4.27363\teval-rmse:4.00352                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.7497\teval-rmse:3.43778                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.4022\teval-rmse:3.07038                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.16959\teval-rmse:2.85003                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.0211\teval-rmse:2.71976                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.91655\teval-rmse:2.63854                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.84175\teval-rmse:2.59792                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.79151\teval-rmse:2.57372                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.75125\teval-rmse:2.55882                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.72071\teval-rmse:2.55125                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.69781\teval-rmse:2.54861                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.65577\teval-rmse:2.56463                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.62753\teval-rmse:2.57242                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.61257\teval-rmse:2.5711                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.58593\teval-rmse:2.57671                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.57734\teval-rmse:2.57727                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.54804\teval-rmse:2.5809                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.5337\teval-rmse:2.57893                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.51254\teval-rmse:2.58094                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.49736\teval-rmse:2.58303                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.4624\teval-rmse:2.58363                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.4519\teval-rmse:2.58304                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.44232\teval-rmse:2.58302                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.41453\teval-rmse:2.59342                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.39189\teval-rmse:2.59807                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.37361\teval-rmse:2.60009                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.35837\teval-rmse:2.59872                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.33732\teval-rmse:2.60214                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.3307\teval-rmse:2.60184                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.31593\teval-rmse:2.59793                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.30332\teval-rmse:2.59819                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.69781\teval-rmse:2.54861\n",
      "\n",
      "\n",
      "loss: 69265232.90782598                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.867371300057156e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 5.5578744863413166e-05, 'lambda': 7.195582101395785, 'learning_rate': 0.4, 'max_depth': 9, 'min_child_weight': 0.8236700431047353, 'n_estimators': 439.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.27411\teval-rmse:5.07538                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.93688\teval-rmse:3.67255                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.26784\teval-rmse:2.99946                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.9372\teval-rmse:2.7111                                                                                 \n",
      "\n",
      "[4]\ttrain-rmse:2.7636\teval-rmse:2.61141                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.66278\teval-rmse:2.58364                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.57023\teval-rmse:2.5837                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.51464\teval-rmse:2.58163                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.47743\teval-rmse:2.59035                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.43504\teval-rmse:2.58212                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.39426\teval-rmse:2.59887                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.35928\teval-rmse:2.60685                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.32406\teval-rmse:2.61499                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.27759\teval-rmse:2.62814                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.25605\teval-rmse:2.63687                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.24361\teval-rmse:2.63774                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.21928\teval-rmse:2.63664                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.19788\teval-rmse:2.64456                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.16107\teval-rmse:2.6367                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.15099\teval-rmse:2.63988                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.10967\teval-rmse:2.64243                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.06433\teval-rmse:2.64246                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.0216\teval-rmse:2.65634                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:1.98762\teval-rmse:2.66009                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.9575\teval-rmse:2.65849                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.94486\teval-rmse:2.65505                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.92778\teval-rmse:2.65861                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.90529\teval-rmse:2.66762                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.51464\teval-rmse:2.58163\n",
      "\n",
      "\n",
      "loss: 62823826.99249982                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.02893682740743162, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.022972426183394203, 'lambda': 0.15906653737295717, 'learning_rate': 0.375, 'max_depth': 3, 'min_child_weight': 0.9340415987319161, 'n_estimators': 878.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.54317\teval-rmse:5.26511                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.3744\teval-rmse:3.8804                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:3.78817\teval-rmse:3.1694                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.52091\teval-rmse:2.81891                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.40158\teval-rmse:2.64892                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.34483\teval-rmse:2.56999                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.31381\teval-rmse:2.53658                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.28744\teval-rmse:2.51972                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.2735\teval-rmse:2.50862                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.25436\teval-rmse:2.49803                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.24268\teval-rmse:2.4997                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.23133\teval-rmse:2.49589                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.22003\teval-rmse:2.48943                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.213\teval-rmse:2.50589                                                                                \n",
      "\n",
      "[14]\ttrain-rmse:3.20826\teval-rmse:2.50457                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.2025\teval-rmse:2.50712                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:3.19797\teval-rmse:2.50561                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.19426\teval-rmse:2.50253                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.19199\teval-rmse:2.50073                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.18639\teval-rmse:2.49446                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.17982\teval-rmse:2.49511                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.17347\teval-rmse:2.49219                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.17108\teval-rmse:2.49117                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.16612\teval-rmse:2.48185                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.16005\teval-rmse:2.49004                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.15793\teval-rmse:2.4901                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:3.14871\teval-rmse:2.48759                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.14315\teval-rmse:2.47925                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.13939\teval-rmse:2.47453                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.13463\teval-rmse:2.48836                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.13066\teval-rmse:2.48319                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.12608\teval-rmse:2.47996                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.12178\teval-rmse:2.47726                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.11691\teval-rmse:2.48467                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.11487\teval-rmse:2.48273                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.10956\teval-rmse:2.48981                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.10691\teval-rmse:2.49579                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.10313\teval-rmse:2.4878                                                                               \n",
      "\n",
      "[38]\ttrain-rmse:3.09995\teval-rmse:2.48604                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.09626\teval-rmse:2.4909                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:3.09225\teval-rmse:2.48439                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.08869\teval-rmse:2.48562                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.08572\teval-rmse:2.48446                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.08358\teval-rmse:2.48247                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.08118\teval-rmse:2.48098                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.07672\teval-rmse:2.48379                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.07344\teval-rmse:2.47967                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.07012\teval-rmse:2.48544                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.06684\teval-rmse:2.48891                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[28]\ttrain-rmse:3.13939\teval-rmse:2.47453\n",
      "\n",
      "\n",
      "loss: 81012638.85044834                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00032055579563203127, 'colsample_bytree': 0.9, 'gamma': 5.554769378548014e-06, 'lambda': 0.9271269204587794, 'learning_rate': 0.125, 'max_depth': 8, 'min_child_weight': 0.20743970204393153, 'n_estimators': 101.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:6.94869\teval-rmse:6.87818                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:6.26167\teval-rmse:6.14802                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.67683\teval-rmse:5.5214                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\ttrain-rmse:5.1772\teval-rmse:4.98299                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:4.75498\teval-rmse:4.52441                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:4.39937\teval-rmse:4.141                                                                                 \n",
      "\n",
      "[6]\ttrain-rmse:4.10281\teval-rmse:3.82303                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.85448\teval-rmse:3.55803                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.64752\teval-rmse:3.3377                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.47349\teval-rmse:3.15858                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.32983\teval-rmse:3.01793                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.21324\teval-rmse:2.90184                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.11577\teval-rmse:2.80904                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.0358\teval-rmse:2.74122                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.96618\teval-rmse:2.68457                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.91233\teval-rmse:2.64072                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.86306\teval-rmse:2.60716                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.82571\teval-rmse:2.57625                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.78748\teval-rmse:2.55696                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.76099\teval-rmse:2.54045                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.73399\teval-rmse:2.52884                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.70412\teval-rmse:2.51628                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.68306\teval-rmse:2.51195                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.66704\teval-rmse:2.50609                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.65089\teval-rmse:2.50808                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.63245\teval-rmse:2.50589                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.61811\teval-rmse:2.50464                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.60317\teval-rmse:2.50759                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.5889\teval-rmse:2.50916                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.56893\teval-rmse:2.51225                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.55834\teval-rmse:2.51646                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.54244\teval-rmse:2.51463                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.53006\teval-rmse:2.51572                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.52222\teval-rmse:2.51568                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.51353\teval-rmse:2.51722                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.49689\teval-rmse:2.51563                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.48636\teval-rmse:2.51261                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.47915\teval-rmse:2.51138                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.46941\teval-rmse:2.50994                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.45941\teval-rmse:2.51229                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.44503\teval-rmse:2.50678                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.43532\teval-rmse:2.50389                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.42383\teval-rmse:2.51                                                                                 \n",
      "\n",
      "[43]\ttrain-rmse:2.41399\teval-rmse:2.50964                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.40612\teval-rmse:2.50616                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.39526\teval-rmse:2.50841                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.37755\teval-rmse:2.50234                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.36871\teval-rmse:2.50606                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.3626\teval-rmse:2.50704                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:2.35145\teval-rmse:2.50459                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.346\teval-rmse:2.50686                                                                                \n",
      "\n",
      "[51]\ttrain-rmse:2.34025\teval-rmse:2.50597                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.33302\teval-rmse:2.504                                                                                \n",
      "\n",
      "[53]\ttrain-rmse:2.32307\teval-rmse:2.5069                                                                               \n",
      "\n",
      "[54]\ttrain-rmse:2.31187\teval-rmse:2.51209                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.30224\teval-rmse:2.5078                                                                               \n",
      "\n",
      "[56]\ttrain-rmse:2.29858\teval-rmse:2.50863                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.28576\teval-rmse:2.51226                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.27879\teval-rmse:2.51447                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.26848\teval-rmse:2.5135                                                                               \n",
      "\n",
      "[60]\ttrain-rmse:2.26175\teval-rmse:2.51876                                                                              \n",
      "\n",
      "[61]\ttrain-rmse:2.24896\teval-rmse:2.52082                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:2.23571\teval-rmse:2.52057                                                                              \n",
      "\n",
      "[63]\ttrain-rmse:2.22967\teval-rmse:2.52216                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:2.22341\teval-rmse:2.52272                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:2.21189\teval-rmse:2.52178                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:2.19627\teval-rmse:2.52362                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[46]\ttrain-rmse:2.37755\teval-rmse:2.50234\n",
      "\n",
      "\n",
      "loss: 66478133.01088488                                                                                                \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.433624496742942e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 9.26447820267434e-07, 'lambda': 0.026637343189082403, 'learning_rate': 0.42500000000000004, 'max_depth': 7, 'min_child_weight': 4.101587241628918, 'n_estimators': 150.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.16826\teval-rmse:4.91457                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.91599\teval-rmse:3.51076                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.34639\teval-rmse:2.88293                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.10627\teval-rmse:2.64799                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.98943\teval-rmse:2.56469                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.91968\teval-rmse:2.56943                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.87782\teval-rmse:2.57439                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.8473\teval-rmse:2.56105                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.80934\teval-rmse:2.56844                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.78314\teval-rmse:2.55031                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.76258\teval-rmse:2.56448                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.74309\teval-rmse:2.56958                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.72252\teval-rmse:2.57228                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.69226\teval-rmse:2.57595                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.67689\teval-rmse:2.57079                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.65461\teval-rmse:2.58161                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.62161\teval-rmse:2.57097                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.60662\teval-rmse:2.57173                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.58387\teval-rmse:2.57709                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.56445\teval-rmse:2.56574                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.53683\teval-rmse:2.5785                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.51875\teval-rmse:2.58853                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.50685\teval-rmse:2.591                                                                                \n",
      "\n",
      "[23]\ttrain-rmse:2.49647\teval-rmse:2.60715                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.48134\teval-rmse:2.61231                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.46656\teval-rmse:2.60928                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.43953\teval-rmse:2.59644                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.42731\teval-rmse:2.5924                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.40959\teval-rmse:2.60139                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.38876\teval-rmse:2.60057                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.78314\teval-rmse:2.55031\n",
      "\n",
      "\n",
      "loss: 74562252.87997213                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.5601367143128044e-05, 'colsample_bytree': 0.75, 'gamma': 4.821185279316292e-07, 'lambda': 0.0423247413117084, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 0.6495235699908424, 'n_estimators': 548.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:7.43493\teval-rmse:7.38957                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:7.13918\teval-rmse:7.06923                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:6.86091\teval-rmse:6.767                                                                                 \n",
      "\n",
      "[3]\ttrain-rmse:6.59937\teval-rmse:6.48102                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:6.35411\teval-rmse:6.21278                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:6.1247\teval-rmse:5.95897                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:5.9084\teval-rmse:5.71865                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:5.70599\teval-rmse:5.49234                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:5.51635\teval-rmse:5.27907                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:5.33938\teval-rmse:5.07877                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:5.17403\teval-rmse:4.89132                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:5.01936\teval-rmse:4.71549                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:4.87508\teval-rmse:4.54997                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:4.7413\teval-rmse:4.39729                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:4.61725\teval-rmse:4.25246                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:4.50135\teval-rmse:4.11747                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:4.39333\teval-rmse:3.99031                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:4.29409\teval-rmse:3.87152                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:4.20256\teval-rmse:3.76232                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:4.11714\teval-rmse:3.65959                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:4.03745\teval-rmse:3.56348                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.9646\teval-rmse:3.47568                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:3.89679\teval-rmse:3.39444                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.83457\teval-rmse:3.31828                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.77763\teval-rmse:3.24737                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25]\ttrain-rmse:3.7247\teval-rmse:3.17922                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:3.67565\teval-rmse:3.1197                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:3.63072\teval-rmse:3.06281                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.58869\teval-rmse:3.01239                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.55084\teval-rmse:2.96629                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.51503\teval-rmse:2.92368                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.48263\teval-rmse:2.88485                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.45354\teval-rmse:2.84841                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.42666\teval-rmse:2.81562                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.40151\teval-rmse:2.78506                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.37856\teval-rmse:2.75812                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.35642\teval-rmse:2.73229                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.33679\teval-rmse:2.70676                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.31799\teval-rmse:2.68379                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.30151\teval-rmse:2.66458                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.28544\teval-rmse:2.64671                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.27111\teval-rmse:2.6311                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:3.25736\teval-rmse:2.61474                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.24521\teval-rmse:2.60051                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.23334\teval-rmse:2.58602                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.22279\teval-rmse:2.57454                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.21265\teval-rmse:2.56501                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.20457\teval-rmse:2.55618                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.1962\teval-rmse:2.54869                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:3.18682\teval-rmse:2.54196                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.178\teval-rmse:2.53457                                                                                \n",
      "\n",
      "[51]\ttrain-rmse:3.17064\teval-rmse:2.52815                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.16386\teval-rmse:2.52193                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.15751\teval-rmse:2.51609                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.15145\teval-rmse:2.51146                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:3.1455\teval-rmse:2.50576                                                                               \n",
      "\n",
      "[56]\ttrain-rmse:3.14025\teval-rmse:2.50128                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:3.13509\teval-rmse:2.49666                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:3.13041\teval-rmse:2.49187                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.12634\teval-rmse:2.48887                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:3.12166\teval-rmse:2.4857                                                                               \n",
      "\n",
      "[61]\ttrain-rmse:3.11783\teval-rmse:2.48322                                                                              \n",
      "\n",
      "[62]\ttrain-rmse:3.1136\teval-rmse:2.47931                                                                               \n",
      "\n",
      "[63]\ttrain-rmse:3.10866\teval-rmse:2.47732                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:3.10436\teval-rmse:2.47453                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:3.10046\teval-rmse:2.47337                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:3.09705\teval-rmse:2.47081                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:3.09409\teval-rmse:2.46824                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:3.08959\teval-rmse:2.46706                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:3.08583\teval-rmse:2.46629                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:3.08299\teval-rmse:2.46503                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:3.08026\teval-rmse:2.46321                                                                              \n",
      "\n",
      "[72]\ttrain-rmse:3.07735\teval-rmse:2.46174                                                                              \n",
      "\n",
      "[73]\ttrain-rmse:3.07315\teval-rmse:2.46271                                                                              \n",
      "\n",
      "[74]\ttrain-rmse:3.07057\teval-rmse:2.46067                                                                              \n",
      "\n",
      "[75]\ttrain-rmse:3.06753\teval-rmse:2.46051                                                                              \n",
      "\n",
      "[76]\ttrain-rmse:3.06481\teval-rmse:2.46076                                                                              \n",
      "\n",
      "[77]\ttrain-rmse:3.06214\teval-rmse:2.45878                                                                              \n",
      "\n",
      "[78]\ttrain-rmse:3.05912\teval-rmse:2.46019                                                                              \n",
      "\n",
      "[79]\ttrain-rmse:3.05661\teval-rmse:2.46089                                                                              \n",
      "\n",
      "[80]\ttrain-rmse:3.05437\teval-rmse:2.46114                                                                              \n",
      "\n",
      "[81]\ttrain-rmse:3.05179\teval-rmse:2.46075                                                                              \n",
      "\n",
      "[82]\ttrain-rmse:3.04986\teval-rmse:2.46134                                                                              \n",
      "\n",
      "[83]\ttrain-rmse:3.04745\teval-rmse:2.46014                                                                              \n",
      "\n",
      "[84]\ttrain-rmse:3.045\teval-rmse:2.45964                                                                                \n",
      "\n",
      "[85]\ttrain-rmse:3.04298\teval-rmse:2.45868                                                                              \n",
      "\n",
      "[86]\ttrain-rmse:3.04056\teval-rmse:2.45877                                                                              \n",
      "\n",
      "[87]\ttrain-rmse:3.0378\teval-rmse:2.4579                                                                                \n",
      "\n",
      "[88]\ttrain-rmse:3.03516\teval-rmse:2.45736                                                                              \n",
      "\n",
      "[89]\ttrain-rmse:3.03309\teval-rmse:2.4582                                                                               \n",
      "\n",
      "[90]\ttrain-rmse:3.03058\teval-rmse:2.45827                                                                              \n",
      "\n",
      "[91]\ttrain-rmse:3.02878\teval-rmse:2.45831                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92]\ttrain-rmse:3.02626\teval-rmse:2.45853                                                                              \n",
      "\n",
      "[93]\ttrain-rmse:3.0246\teval-rmse:2.45888                                                                               \n",
      "\n",
      "[94]\ttrain-rmse:3.02262\teval-rmse:2.45897                                                                              \n",
      "\n",
      "[95]\ttrain-rmse:3.01934\teval-rmse:2.45958                                                                              \n",
      "\n",
      "[96]\ttrain-rmse:3.01787\teval-rmse:2.45912                                                                              \n",
      "\n",
      "[97]\ttrain-rmse:3.01627\teval-rmse:2.4579                                                                               \n",
      "\n",
      "[98]\ttrain-rmse:3.01416\teval-rmse:2.45864                                                                              \n",
      "\n",
      "[99]\ttrain-rmse:3.01226\teval-rmse:2.45855                                                                              \n",
      "\n",
      "loss: 89001500.84352271                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.009283173649344941, 'colsample_bytree': 0.65, 'gamma': 2.5077691442790608e-05, 'lambda': 0.39585750977180867, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 2.631949790889587, 'n_estimators': 234.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.57448\teval-rmse:5.38387                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.31215\teval-rmse:4.00196                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.60785\teval-rmse:3.24293                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.22586\teval-rmse:2.87298                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.03805\teval-rmse:2.6903                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.9009\teval-rmse:2.63198                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.8357\teval-rmse:2.61475                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.79002\teval-rmse:2.60147                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.76338\teval-rmse:2.60548                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.72611\teval-rmse:2.59436                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.69285\teval-rmse:2.6168                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.64652\teval-rmse:2.65086                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.61264\teval-rmse:2.66717                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.58686\teval-rmse:2.67156                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.57523\teval-rmse:2.66776                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.54106\teval-rmse:2.67467                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.51619\teval-rmse:2.6783                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.49918\teval-rmse:2.66034                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.47641\teval-rmse:2.68807                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.45873\teval-rmse:2.67379                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.44722\teval-rmse:2.68485                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.43297\teval-rmse:2.69808                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.42474\teval-rmse:2.69793                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.4036\teval-rmse:2.70288                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.38274\teval-rmse:2.70351                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.37108\teval-rmse:2.70718                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.33758\teval-rmse:2.70918                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.31313\teval-rmse:2.71494                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.2834\teval-rmse:2.71495                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.26821\teval-rmse:2.71208                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.72611\teval-rmse:2.59436\n",
      "\n",
      "\n",
      "loss: 73791737.47959961                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.003091632030613344, 'colsample_bytree': 0.9, 'gamma': 1.6937025303270473e-05, 'lambda': 0.014703111856939947, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.2960402294905431, 'n_estimators': 782.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.67367\teval-rmse:5.55331                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.36934\teval-rmse:4.21049                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.57709\teval-rmse:3.41929                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.09762\teval-rmse:2.9716                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:2.83095\teval-rmse:2.7551                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:2.66027\teval-rmse:2.66372                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.56794\teval-rmse:2.6095                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.47908\teval-rmse:2.60932                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.40998\teval-rmse:2.60028                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.37316\teval-rmse:2.59824                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.33045\teval-rmse:2.61882                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.29182\teval-rmse:2.61526                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.26614\teval-rmse:2.61642                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.22337\teval-rmse:2.62877                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.19513\teval-rmse:2.62376                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\ttrain-rmse:2.15797\teval-rmse:2.6351                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.13738\teval-rmse:2.65662                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.10533\teval-rmse:2.66222                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.07043\teval-rmse:2.66729                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.05391\teval-rmse:2.67091                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.0269\teval-rmse:2.67707                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.00553\teval-rmse:2.67647                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:1.98218\teval-rmse:2.68195                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.95608\teval-rmse:2.69087                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.9488\teval-rmse:2.69076                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:1.91714\teval-rmse:2.69044                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.89103\teval-rmse:2.69411                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.86654\teval-rmse:2.69272                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.83481\teval-rmse:2.69964                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.82037\teval-rmse:2.70175                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.37316\teval-rmse:2.59824\n",
      "\n",
      "\n",
      "loss: 67735790.38918377                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.410065382267498e-08, 'colsample_bytree': 0.7000000000000001, 'gamma': 4.056862096055453e-06, 'lambda': 0.003521467369393171, 'learning_rate': 0.45, 'max_depth': 6, 'min_child_weight': 0.13509739763845022, 'n_estimators': 304.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.06253\teval-rmse:4.78404                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.85891\teval-rmse:3.38757                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.37816\teval-rmse:2.8329                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.19025\teval-rmse:2.63508                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.1077\teval-rmse:2.57062                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.05595\teval-rmse:2.54658                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.02547\teval-rmse:2.53144                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.99897\teval-rmse:2.53864                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.98044\teval-rmse:2.53581                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.95316\teval-rmse:2.52926                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.92929\teval-rmse:2.5459                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.91808\teval-rmse:2.54764                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.90588\teval-rmse:2.54048                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.88779\teval-rmse:2.54354                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.87288\teval-rmse:2.53926                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.84449\teval-rmse:2.52677                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.81733\teval-rmse:2.52953                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.80437\teval-rmse:2.541                                                                                \n",
      "\n",
      "[18]\ttrain-rmse:2.78395\teval-rmse:2.55053                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.76822\teval-rmse:2.55856                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.75823\teval-rmse:2.57674                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.73744\teval-rmse:2.59205                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.7253\teval-rmse:2.61026                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.71475\teval-rmse:2.61109                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.69173\teval-rmse:2.62214                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.68445\teval-rmse:2.62804                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.67603\teval-rmse:2.66646                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.65919\teval-rmse:2.67196                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.6333\teval-rmse:2.67463                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.619\teval-rmse:2.67259                                                                                \n",
      "\n",
      "[30]\ttrain-rmse:2.607\teval-rmse:2.66966                                                                                \n",
      "\n",
      "[31]\ttrain-rmse:2.59414\teval-rmse:2.67434                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.57087\teval-rmse:2.69378                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.56284\teval-rmse:2.69211                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.54419\teval-rmse:2.69903                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.53785\teval-rmse:2.69667                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[15]\ttrain-rmse:2.84449\teval-rmse:2.52677\n",
      "\n",
      "\n",
      "loss: 76733895.29113509                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.08695659659072977, 'colsample_bytree': 0.9500000000000001, 'gamma': 4.898564778320763e-08, 'lambda': 0.09753043971703632, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 1.0452614518733665, 'n_estimators': 474.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.27349\teval-rmse:5.07948                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:3.97529\teval-rmse:3.68203                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.33142\teval-rmse:3.0276                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.02762\teval-rmse:2.75534                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.85516\teval-rmse:2.66018                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.7753\teval-rmse:2.62581                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.71279\teval-rmse:2.62253                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.6746\teval-rmse:2.62987                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.62937\teval-rmse:2.61307                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.59476\teval-rmse:2.61229                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.54786\teval-rmse:2.61556                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.51928\teval-rmse:2.62154                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.49604\teval-rmse:2.64345                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.45531\teval-rmse:2.65513                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.41673\teval-rmse:2.64298                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.37657\teval-rmse:2.64503                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.35524\teval-rmse:2.66853                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.34281\teval-rmse:2.66451                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.33109\teval-rmse:2.66529                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.29957\teval-rmse:2.67402                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.28534\teval-rmse:2.67128                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.25442\teval-rmse:2.66928                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.22546\teval-rmse:2.67063                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.18869\teval-rmse:2.66832                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.16548\teval-rmse:2.66323                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.13458\teval-rmse:2.6621                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.11083\teval-rmse:2.66149                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.07676\teval-rmse:2.6694                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.06245\teval-rmse:2.66785                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.04843\teval-rmse:2.67187                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.59476\teval-rmse:2.61229\n",
      "\n",
      "\n",
      "loss: 71161855.99001262                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00019224476372688574, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.4115439300601054e-07, 'lambda': 0.6068376770633108, 'learning_rate': 0.275, 'max_depth': 4, 'min_child_weight': 0.4771926162690295, 'n_estimators': 424.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.08246\teval-rmse:5.8896                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.97804\teval-rmse:4.6334                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.2712\teval-rmse:3.79612                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.8394\teval-rmse:3.26318                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.57994\teval-rmse:2.92884                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.42804\teval-rmse:2.73293                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.33834\teval-rmse:2.62567                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.28517\teval-rmse:2.56082                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.25052\teval-rmse:2.52286                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.22757\teval-rmse:2.50008                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.21275\teval-rmse:2.49126                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.19876\teval-rmse:2.48674                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.18384\teval-rmse:2.48753                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.1747\teval-rmse:2.48137                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.16516\teval-rmse:2.48193                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.15763\teval-rmse:2.48531                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.14975\teval-rmse:2.49257                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.14478\teval-rmse:2.49084                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.13146\teval-rmse:2.48662                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.1248\teval-rmse:2.48583                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:3.11471\teval-rmse:2.48477                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.1119\teval-rmse:2.48475                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:3.10388\teval-rmse:2.48748                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.10023\teval-rmse:2.49047                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.09374\teval-rmse:2.48606                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.09035\teval-rmse:2.4833                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:3.08133\teval-rmse:2.47457                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.07644\teval-rmse:2.47466                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.07037\teval-rmse:2.47011                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.0687\teval-rmse:2.47114                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttrain-rmse:3.0609\teval-rmse:2.47828                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:3.05357\teval-rmse:2.48407                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.04783\teval-rmse:2.48198                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.04216\teval-rmse:2.47819                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.03856\teval-rmse:2.47634                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.034\teval-rmse:2.47352                                                                                \n",
      "\n",
      "[36]\ttrain-rmse:3.02815\teval-rmse:2.47259                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.02623\teval-rmse:2.47323                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.01962\teval-rmse:2.46535                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.01803\teval-rmse:2.46534                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.01401\teval-rmse:2.46955                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.00969\teval-rmse:2.47666                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.00339\teval-rmse:2.49076                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.99854\teval-rmse:2.49516                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.99415\teval-rmse:2.49136                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.98976\teval-rmse:2.49295                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.98507\teval-rmse:2.48833                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.98132\teval-rmse:2.4947                                                                               \n",
      "\n",
      "[48]\ttrain-rmse:2.97594\teval-rmse:2.48876                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.97103\teval-rmse:2.48598                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.96714\teval-rmse:2.48724                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:2.96133\teval-rmse:2.48578                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:2.95717\teval-rmse:2.49517                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.95215\teval-rmse:2.49664                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.94902\teval-rmse:2.49645                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:2.9456\teval-rmse:2.49601                                                                               \n",
      "\n",
      "[56]\ttrain-rmse:2.94081\teval-rmse:2.49561                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:2.93757\teval-rmse:2.49822                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:2.93494\teval-rmse:2.49771                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:2.9325\teval-rmse:2.4979                                                                                \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[39]\ttrain-rmse:3.01803\teval-rmse:2.46534\n",
      "\n",
      "\n",
      "loss: 70961237.93362403                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.820185394064404e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 8.829697244928984e-08, 'lambda': 0.0069093606864008, 'learning_rate': 0.225, 'max_depth': 8, 'min_child_weight': 0.23676300683107618, 'n_estimators': 523.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.31707\teval-rmse:6.20879                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.25609\teval-rmse:5.07867                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.48448\teval-rmse:4.25463                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.93243\teval-rmse:3.67847                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.54082\teval-rmse:3.28099                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.27\teval-rmse:3.00875                                                                                  \n",
      "\n",
      "[6]\ttrain-rmse:3.07997\teval-rmse:2.83754                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.94597\teval-rmse:2.71508                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.84998\teval-rmse:2.64037                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.79212\teval-rmse:2.59715                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.73578\teval-rmse:2.58706                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.6968\teval-rmse:2.57267                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.66313\teval-rmse:2.56346                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.6187\teval-rmse:2.54799                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.60093\teval-rmse:2.54627                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.57516\teval-rmse:2.54799                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.55712\teval-rmse:2.56458                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.53038\teval-rmse:2.57162                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.51019\teval-rmse:2.57229                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.49572\teval-rmse:2.57605                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.4805\teval-rmse:2.56706                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.46399\teval-rmse:2.56093                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.44363\teval-rmse:2.55972                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.43252\teval-rmse:2.5554                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.41547\teval-rmse:2.56067                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.38526\teval-rmse:2.56752                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.36127\teval-rmse:2.57101                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.33357\teval-rmse:2.57893                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.32245\teval-rmse:2.57797                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.30605\teval-rmse:2.58061                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttrain-rmse:2.29131\teval-rmse:2.58131                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.28131\teval-rmse:2.59518                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.25344\teval-rmse:2.59679                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.2324\teval-rmse:2.59639                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:2.21663\teval-rmse:2.59839                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[14]\ttrain-rmse:2.60093\teval-rmse:2.54627\n",
      "\n",
      "\n",
      "loss: 65516295.31002196                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.40026785189791964, 'colsample_bytree': 0.9, 'gamma': 0.00021327121879312987, 'lambda': 5.1485109079069495, 'learning_rate': 0.47500000000000003, 'max_depth': 9, 'min_child_weight': 6.6633495464478845, 'n_estimators': 285.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:4.85391\teval-rmse:4.614                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.57397\teval-rmse:3.25116                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.05345\teval-rmse:2.75301                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.8278\teval-rmse:2.5969                                                                                 \n",
      "\n",
      "[4]\ttrain-rmse:2.73725\teval-rmse:2.56075                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.64697\teval-rmse:2.58351                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.59492\teval-rmse:2.61024                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.53162\teval-rmse:2.59813                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.45212\teval-rmse:2.63095                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.4331\teval-rmse:2.6268                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.38166\teval-rmse:2.62636                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.3613\teval-rmse:2.62712                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.33843\teval-rmse:2.62897                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.31537\teval-rmse:2.63771                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.24142\teval-rmse:2.65079                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.19737\teval-rmse:2.6501                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.18198\teval-rmse:2.64637                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.17072\teval-rmse:2.65291                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.16086\teval-rmse:2.65192                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.12033\teval-rmse:2.65346                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.08546\teval-rmse:2.66271                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.06709\teval-rmse:2.6595                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.04282\teval-rmse:2.66253                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.99991\teval-rmse:2.67516                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:1.99132\teval-rmse:2.6749                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.73725\teval-rmse:2.56075\n",
      "\n",
      "\n",
      "loss: 69597349.69536935                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 9.93624687184109e-07, 'colsample_bytree': 0.8, 'gamma': 0.001721228607768026, 'lambda': 1.4181647135166584, 'learning_rate': 0.30000000000000004, 'max_depth': 3, 'min_child_weight': 1.1154830235081603, 'n_estimators': 458.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.96476\teval-rmse:5.74783                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.84367\teval-rmse:4.47186                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.1632\teval-rmse:3.64276                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.77491\teval-rmse:3.15285                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.55887\teval-rmse:2.87547                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.44171\teval-rmse:2.72449                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.37173\teval-rmse:2.62881                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.33576\teval-rmse:2.57406                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.30956\teval-rmse:2.53951                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.29437\teval-rmse:2.52893                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.28146\teval-rmse:2.51216                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.26974\teval-rmse:2.50847                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.25883\teval-rmse:2.51634                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.24793\teval-rmse:2.51107                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.23913\teval-rmse:2.5092                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:3.23218\teval-rmse:2.51028                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.2268\teval-rmse:2.50744                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:3.22316\teval-rmse:2.50731                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.21442\teval-rmse:2.50172                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.20692\teval-rmse:2.51196                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.20089\teval-rmse:2.51536                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.19693\teval-rmse:2.51277                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-rmse:3.19095\teval-rmse:2.51175                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.18541\teval-rmse:2.50838                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.18382\teval-rmse:2.50824                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.179\teval-rmse:2.50606                                                                                \n",
      "\n",
      "[26]\ttrain-rmse:3.17491\teval-rmse:2.50706                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.16994\teval-rmse:2.50469                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.1648\teval-rmse:2.50639                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:3.16021\teval-rmse:2.50831                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.15579\teval-rmse:2.50604                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.15452\teval-rmse:2.50459                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.15109\teval-rmse:2.50979                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.14837\teval-rmse:2.50956                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.14691\teval-rmse:2.50937                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.14388\teval-rmse:2.504                                                                                \n",
      "\n",
      "[36]\ttrain-rmse:3.13928\teval-rmse:2.4958                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:3.13579\teval-rmse:2.49443                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.13257\teval-rmse:2.49402                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:3.13077\teval-rmse:2.4939                                                                               \n",
      "\n",
      "[40]\ttrain-rmse:3.12723\teval-rmse:2.4901                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:3.12576\teval-rmse:2.49481                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.12328\teval-rmse:2.49198                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.11951\teval-rmse:2.49448                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.11684\teval-rmse:2.49569                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.11386\teval-rmse:2.49975                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.11313\teval-rmse:2.50099                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.10974\teval-rmse:2.50381                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.10773\teval-rmse:2.50349                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.10461\teval-rmse:2.49474                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.10155\teval-rmse:2.49214                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.09864\teval-rmse:2.49507                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.09585\teval-rmse:2.49627                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:3.09372\teval-rmse:2.49463                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.09047\teval-rmse:2.49253                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:3.08703\teval-rmse:2.49514                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.08234\teval-rmse:2.49413                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:3.07941\teval-rmse:2.49365                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:3.07805\teval-rmse:2.49626                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.07445\teval-rmse:2.49691                                                                              \n",
      "\n",
      "[60]\ttrain-rmse:3.071\teval-rmse:2.501                                                                                  \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[40]\ttrain-rmse:3.12723\teval-rmse:2.4901\n",
      "\n",
      "\n",
      "loss: 80039725.73784125                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.002158240085136392, 'colsample_bytree': 0.9, 'gamma': 0.0005602734980120354, 'lambda': 3.0323548597000114, 'learning_rate': 0.375, 'max_depth': 8, 'min_child_weight': 0.34869012608422967, 'n_estimators': 724.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.4363\teval-rmse:5.24386                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.14425\teval-rmse:3.83022                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.46796\teval-rmse:3.09187                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.13227\teval-rmse:2.73928                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.95058\teval-rmse:2.58761                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.83783\teval-rmse:2.52897                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.76717\teval-rmse:2.50951                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.71475\teval-rmse:2.5188                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.67559\teval-rmse:2.52117                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.643\teval-rmse:2.52191                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.591\teval-rmse:2.5423                                                                                 \n",
      "\n",
      "[11]\ttrain-rmse:2.56108\teval-rmse:2.5467                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.53285\teval-rmse:2.54973                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.51372\teval-rmse:2.56082                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.49372\teval-rmse:2.56282                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.46407\teval-rmse:2.57319                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.43318\teval-rmse:2.57259                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.41527\teval-rmse:2.5729                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.3999\teval-rmse:2.57227                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.37806\teval-rmse:2.57147                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.34374\teval-rmse:2.56654                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21]\ttrain-rmse:2.3241\teval-rmse:2.56665                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.31349\teval-rmse:2.57445                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.28288\teval-rmse:2.5774                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.24764\teval-rmse:2.58309                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.23972\teval-rmse:2.58611                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.20858\teval-rmse:2.59727                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.76717\teval-rmse:2.50951\n",
      "\n",
      "\n",
      "loss: 70117794.02259496                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.82998947501041e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 7.556055249015059e-06, 'lambda': 0.017860346148223412, 'learning_rate': 0.35000000000000003, 'max_depth': 7, 'min_child_weight': 0.2752336714219772, 'n_estimators': 640.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.5931\teval-rmse:5.39583                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.34114\teval-rmse:4.01233                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.65093\teval-rmse:3.25783                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.28912\teval-rmse:2.86217                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.09797\teval-rmse:2.68977                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.99564\teval-rmse:2.61056                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.93233\teval-rmse:2.564                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:2.88341\teval-rmse:2.56202                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.85167\teval-rmse:2.55428                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.81959\teval-rmse:2.56196                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.78669\teval-rmse:2.56939                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.76729\teval-rmse:2.56638                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.73981\teval-rmse:2.58342                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.71388\teval-rmse:2.57597                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.69634\teval-rmse:2.57591                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.6774\teval-rmse:2.5937                                                                                \n",
      "\n",
      "[16]\ttrain-rmse:2.65111\teval-rmse:2.59574                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.63435\teval-rmse:2.60996                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.61793\teval-rmse:2.62088                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.60556\teval-rmse:2.62039                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.5891\teval-rmse:2.6163                                                                                \n",
      "\n",
      "[21]\ttrain-rmse:2.5681\teval-rmse:2.61786                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.54412\teval-rmse:2.62834                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.52366\teval-rmse:2.6245                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.48991\teval-rmse:2.63443                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.46578\teval-rmse:2.64562                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.4545\teval-rmse:2.65181                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.44367\teval-rmse:2.65155                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.42354\teval-rmse:2.65164                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.85167\teval-rmse:2.55428\n",
      "\n",
      "\n",
      "loss: 65297598.66324294                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.660042086155529e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 8.847701755798255e-05, 'lambda': 0.06609125727208029, 'learning_rate': 0.42500000000000004, 'max_depth': 8, 'min_child_weight': 5.345130802847323, 'n_estimators': 371.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.13247\teval-rmse:4.91651                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.83849\teval-rmse:3.52957                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.24491\teval-rmse:2.92407                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.98399\teval-rmse:2.70334                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.84888\teval-rmse:2.61605                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.77795\teval-rmse:2.60636                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.7281\teval-rmse:2.61551                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.69093\teval-rmse:2.61054                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.66944\teval-rmse:2.60996                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.64225\teval-rmse:2.6166                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.59887\teval-rmse:2.62822                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.58463\teval-rmse:2.62767                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.54853\teval-rmse:2.6597                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.51586\teval-rmse:2.67999                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.47531\teval-rmse:2.67716                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.43978\teval-rmse:2.65658                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.40708\teval-rmse:2.66549                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\ttrain-rmse:2.38333\teval-rmse:2.67515                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.34847\teval-rmse:2.69931                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.32692\teval-rmse:2.68683                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.30683\teval-rmse:2.71062                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.26904\teval-rmse:2.72549                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.23865\teval-rmse:2.72815                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.22424\teval-rmse:2.72729                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.21714\teval-rmse:2.72823                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.20226\teval-rmse:2.73109                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[5]\ttrain-rmse:2.77795\teval-rmse:2.60636\n",
      "\n",
      "\n",
      "loss: 62944566.51649812                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.442143585189516e-06, 'colsample_bytree': 0.9, 'gamma': 2.28624694501456e-06, 'lambda': 0.7798675909462338, 'learning_rate': 0.30000000000000004, 'max_depth': 9, 'min_child_weight': 0.7235994623578473, 'n_estimators': 578.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.83262\teval-rmse:5.72162                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.56569\teval-rmse:4.4081                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.75521\teval-rmse:3.59178                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.26007\teval-rmse:3.10603                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.95276\teval-rmse:2.84361                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.75361\teval-rmse:2.69946                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.63842\teval-rmse:2.62096                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.55025\teval-rmse:2.58719                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.50571\teval-rmse:2.57572                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.44217\teval-rmse:2.57484                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.39116\teval-rmse:2.55979                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.35515\teval-rmse:2.56044                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.34076\teval-rmse:2.55741                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.31044\teval-rmse:2.56325                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.27494\teval-rmse:2.57644                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.23908\teval-rmse:2.57324                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.21073\teval-rmse:2.57567                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.18581\teval-rmse:2.58286                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.15739\teval-rmse:2.58048                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.14531\teval-rmse:2.58459                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.11607\teval-rmse:2.59049                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.09468\teval-rmse:2.59407                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.08677\teval-rmse:2.59309                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.06665\teval-rmse:2.60266                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.01822\teval-rmse:2.60259                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.00624\teval-rmse:2.60889                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.97363\teval-rmse:2.60336                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.96515\teval-rmse:2.60709                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.93779\teval-rmse:2.60449                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.90007\teval-rmse:2.60141                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.87566\teval-rmse:2.60051                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:1.859\teval-rmse:2.59938                                                                                \n",
      "\n",
      "[32]\ttrain-rmse:1.83392\teval-rmse:2.60151                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.34076\teval-rmse:2.55741\n",
      "\n",
      "\n",
      "loss: 66260395.469019555                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 9.881243371139638e-06, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.11657006699460737, 'lambda': 0.2867700392226865, 'learning_rate': 0.325, 'max_depth': 5, 'min_child_weight': 0.15060610925445905, 'n_estimators': 348.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.77615\teval-rmse:5.55785                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.59304\teval-rmse:4.20445                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.91745\teval-rmse:3.38592                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.55685\teval-rmse:2.94523                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.36046\teval-rmse:2.70722                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.25597\teval-rmse:2.58446                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.1938\teval-rmse:2.51626                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.15765\teval-rmse:2.48793                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.13166\teval-rmse:2.47242                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.10876\teval-rmse:2.47544                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:3.0919\teval-rmse:2.46862                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.08013\teval-rmse:2.46433                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.06671\teval-rmse:2.46619                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.0584\teval-rmse:2.46618                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.04399\teval-rmse:2.47548                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.03405\teval-rmse:2.46992                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.02477\teval-rmse:2.47402                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.01667\teval-rmse:2.47269                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.00054\teval-rmse:2.47003                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.98802\teval-rmse:2.4682                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.98053\teval-rmse:2.47072                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.9704\teval-rmse:2.47589                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.95854\teval-rmse:2.48835                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.95428\teval-rmse:2.49092                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.95218\teval-rmse:2.48942                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.94802\teval-rmse:2.48828                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.93641\teval-rmse:2.4949                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.92758\teval-rmse:2.50832                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.92198\teval-rmse:2.50918                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.90853\teval-rmse:2.51105                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.89689\teval-rmse:2.51882                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.88842\teval-rmse:2.52112                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:3.08013\teval-rmse:2.46433\n",
      "\n",
      "\n",
      "loss: 75466610.454463                                                                                                  \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.7419268941768058e-08, 'colsample_bytree': 0.9, 'gamma': 6.30412248820459e-07, 'lambda': 3.916005888554399, 'learning_rate': 0.275, 'max_depth': 6, 'min_child_weight': 2.372468413574352, 'n_estimators': 248.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:6.05784\teval-rmse:5.87907                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.92662\teval-rmse:4.61609                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.19565\teval-rmse:3.76751                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.74225\teval-rmse:3.23292                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.46294\teval-rmse:2.91276                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.29737\teval-rmse:2.71921                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.19722\teval-rmse:2.60831                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.13242\teval-rmse:2.54223                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.08986\teval-rmse:2.50474                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.05785\teval-rmse:2.48262                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.03352\teval-rmse:2.47352                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.00857\teval-rmse:2.47528                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.98517\teval-rmse:2.46299                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.97472\teval-rmse:2.4614                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.96322\teval-rmse:2.46137                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.94918\teval-rmse:2.46787                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.92848\teval-rmse:2.4853                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.92066\teval-rmse:2.48144                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.91284\teval-rmse:2.48085                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.89662\teval-rmse:2.48214                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.88185\teval-rmse:2.48739                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.87232\teval-rmse:2.49147                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.85686\teval-rmse:2.48912                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.84412\teval-rmse:2.49365                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.83633\teval-rmse:2.49843                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.82106\teval-rmse:2.50867                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.81124\teval-rmse:2.50712                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.79834\teval-rmse:2.49956                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.78637\teval-rmse:2.49935                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.77692\teval-rmse:2.49984                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.76605\teval-rmse:2.49585                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.75614\teval-rmse:2.50362                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.74722\teval-rmse:2.5043                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.73479\teval-rmse:2.5122                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:2.72542\teval-rmse:2.51317                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[14]\ttrain-rmse:2.96322\teval-rmse:2.46137\n",
      "\n",
      "\n",
      "loss: 68190476.57367398                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.017462856860042564, 'colsample_bytree': 0.6000000000000001, 'gamma': 4.270167415777114e-05, 'lambda': 0.1286725837092415, 'learning_rate': 0.25, 'max_depth': 8, 'min_child_weight': 0.5301996163738816, 'n_estimators': 201.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:6.16773\teval-rmse:6.04247                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.0555\teval-rmse:4.84872                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.28344\teval-rmse:4.00793                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.75442\teval-rmse:3.43115                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.41135\teval-rmse:3.06402                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.18149\teval-rmse:2.83567                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.03128\teval-rmse:2.69261                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.93582\teval-rmse:2.61815                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.86489\teval-rmse:2.56542                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.81678\teval-rmse:2.54938                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.77017\teval-rmse:2.54273                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.73749\teval-rmse:2.54324                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.71154\teval-rmse:2.54754                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.67448\teval-rmse:2.57056                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.65688\teval-rmse:2.57109                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.63534\teval-rmse:2.56513                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.60534\teval-rmse:2.57139                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.59415\teval-rmse:2.56846                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.56543\teval-rmse:2.56815                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.54727\teval-rmse:2.57207                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.52538\teval-rmse:2.56304                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.50847\teval-rmse:2.5719                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.48589\teval-rmse:2.56957                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.4639\teval-rmse:2.57348                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.45474\teval-rmse:2.57655                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.43341\teval-rmse:2.57555                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.41044\teval-rmse:2.58768                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.39928\teval-rmse:2.5995                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.38252\teval-rmse:2.59738                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.3676\teval-rmse:2.60311                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:2.35458\teval-rmse:2.60505                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.77017\teval-rmse:2.54273\n",
      "\n",
      "\n",
      "loss: 76787110.91698693                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0001545268807282429, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.1524828765809286e-05, 'lambda': 1.895006214587897, 'learning_rate': 0.17500000000000002, 'max_depth': 8, 'min_child_weight': 1.4029429944753438, 'n_estimators': 316.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.63313\teval-rmse:6.54319                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.74333\teval-rmse:5.58891                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:5.03669\teval-rmse:4.82692                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.47949\teval-rmse:4.22531                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:4.05064\teval-rmse:3.75964                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.7197\teval-rmse:3.40448                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.46159\teval-rmse:3.14777                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.26927\teval-rmse:2.94714                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.12197\teval-rmse:2.80899                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.00621\teval-rmse:2.70386                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.91462\teval-rmse:2.63351                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.84824\teval-rmse:2.58668                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.79293\teval-rmse:2.55142                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.74963\teval-rmse:2.53509                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.71819\teval-rmse:2.51883                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.68793\teval-rmse:2.51173                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.65689\teval-rmse:2.50561                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.63129\teval-rmse:2.49726                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.60509\teval-rmse:2.49965                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.58294\teval-rmse:2.49835                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.56218\teval-rmse:2.5028                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.55092\teval-rmse:2.5021                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.5312\teval-rmse:2.50001                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\ttrain-rmse:2.51986\teval-rmse:2.50212                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.50869\teval-rmse:2.50114                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.48455\teval-rmse:2.51046                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.46094\teval-rmse:2.5145                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.44469\teval-rmse:2.51883                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.42869\teval-rmse:2.51927                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.41627\teval-rmse:2.52047                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.40312\teval-rmse:2.52079                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.39664\teval-rmse:2.52174                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.38079\teval-rmse:2.52135                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.36369\teval-rmse:2.52696                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.35467\teval-rmse:2.52631                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.34149\teval-rmse:2.52243                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.33724\teval-rmse:2.52261                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:2.32367\teval-rmse:2.5239                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:2.63129\teval-rmse:2.49726\n",
      "\n",
      "\n",
      "loss: 67267107.61265793                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.318517462739402e-05, 'colsample_bytree': 0.9, 'gamma': 2.1782314478035176e-07, 'lambda': 0.5081666270356605, 'learning_rate': 0.5, 'max_depth': 4, 'min_child_weight': 4.516567985033975, 'n_estimators': 405.0, 'nthread': 4, 'seed': 71, 'subsample': 0.65}\n",
      "[0]\ttrain-rmse:4.85889\teval-rmse:4.48276                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.77322\teval-rmse:3.16837                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.4139\teval-rmse:2.71175                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.29954\teval-rmse:2.55382                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.25416\teval-rmse:2.51569                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.22928\teval-rmse:2.50514                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.20606\teval-rmse:2.50554                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.19252\teval-rmse:2.49636                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.18094\teval-rmse:2.49692                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.15937\teval-rmse:2.50246                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.15429\teval-rmse:2.5099                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.13531\teval-rmse:2.50783                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.12683\teval-rmse:2.51938                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.1178\teval-rmse:2.51649                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:3.11253\teval-rmse:2.50599                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.10684\teval-rmse:2.50941                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.10016\teval-rmse:2.50872                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.0916\teval-rmse:2.50529                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:3.0825\teval-rmse:2.5061                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:3.07478\teval-rmse:2.50218                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.06689\teval-rmse:2.50213                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.05889\teval-rmse:2.50125                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.0511\teval-rmse:2.50312                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:3.04637\teval-rmse:2.49652                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.03952\teval-rmse:2.5137                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:3.0349\teval-rmse:2.51731                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:3.02889\teval-rmse:2.52016                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.02453\teval-rmse:2.5333                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:3.19252\teval-rmse:2.49636\n",
      "\n",
      "\n",
      "loss: 88874166.94156234                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.8880342990596058e-05, 'colsample_bytree': 0.8, 'gamma': 0.00014405186183575561, 'lambda': 0.00037453168421703773, 'learning_rate': 0.375, 'max_depth': 9, 'min_child_weight': 0.8571362883674891, 'n_estimators': 169.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.37744\teval-rmse:5.23787                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.03122\teval-rmse:3.86616                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.30616\teval-rmse:3.16086                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.91775\teval-rmse:2.82665                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.71054\teval-rmse:2.68048                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.56602\teval-rmse:2.66912                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.49337\teval-rmse:2.66093                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.44173\teval-rmse:2.66312                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.38865\teval-rmse:2.66246                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\ttrain-rmse:2.35066\teval-rmse:2.65893                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.30401\teval-rmse:2.67274                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.26595\teval-rmse:2.67644                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.24343\teval-rmse:2.67641                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.20855\teval-rmse:2.69377                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.18776\teval-rmse:2.69021                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.15709\teval-rmse:2.67684                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.12677\teval-rmse:2.67737                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.08856\teval-rmse:2.67133                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.06699\teval-rmse:2.67543                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.01093\teval-rmse:2.73421                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:1.98515\teval-rmse:2.74403                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:1.96146\teval-rmse:2.7455                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:1.94153\teval-rmse:2.74639                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:1.891\teval-rmse:2.74554                                                                                \n",
      "\n",
      "[24]\ttrain-rmse:1.86725\teval-rmse:2.74448                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:1.83684\teval-rmse:2.74863                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.82452\teval-rmse:2.75247                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.81591\teval-rmse:2.75466                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:1.77731\teval-rmse:2.74916                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.75036\teval-rmse:2.75178                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.35066\teval-rmse:2.65893\n",
      "\n",
      "\n",
      "loss: 72807250.8472688                                                                                                 \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.953440726360501e-06, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.007990102395701627, 'lambda': 0.0011269957439512608, 'learning_rate': 0.45, 'max_depth': 3, 'min_child_weight': 0.5641380258883283, 'n_estimators': 223.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.14628\teval-rmse:4.8047                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.01445\teval-rmse:3.44773                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.5656\teval-rmse:2.87283                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.40316\teval-rmse:2.65043                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.33702\teval-rmse:2.56916                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.30683\teval-rmse:2.5316                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.28766\teval-rmse:2.51992                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.27527\teval-rmse:2.52228                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.25326\teval-rmse:2.5162                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.24095\teval-rmse:2.53371                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.23457\teval-rmse:2.52875                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.22775\teval-rmse:2.53464                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.21796\teval-rmse:2.53643                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.21407\teval-rmse:2.53558                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.20903\teval-rmse:2.53232                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.20242\teval-rmse:2.52617                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.19611\teval-rmse:2.54114                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.18644\teval-rmse:2.54059                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.17957\teval-rmse:2.54127                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.17415\teval-rmse:2.55165                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.1683\teval-rmse:2.55119                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:3.16385\teval-rmse:2.53988                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.15631\teval-rmse:2.52491                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.15179\teval-rmse:2.52194                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.14588\teval-rmse:2.52604                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.14106\teval-rmse:2.52192                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.13543\teval-rmse:2.51751                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.13365\teval-rmse:2.51765                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.1278\teval-rmse:2.50539                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:3.12041\teval-rmse:2.50117                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.11717\teval-rmse:2.50114                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.11303\teval-rmse:2.50345                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.10899\teval-rmse:2.50755                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.10531\teval-rmse:2.50748                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.1005\teval-rmse:2.50377                                                                               \n",
      "\n",
      "[35]\ttrain-rmse:3.09627\teval-rmse:2.50846                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.09032\teval-rmse:2.52767                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.087\teval-rmse:2.52779                                                                                \n",
      "\n",
      "[38]\ttrain-rmse:3.08216\teval-rmse:2.53627                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39]\ttrain-rmse:3.07901\teval-rmse:2.53699                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.07488\teval-rmse:2.54298                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:3.07147\teval-rmse:2.54154                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.0679\teval-rmse:2.53356                                                                               \n",
      "\n",
      "[43]\ttrain-rmse:3.0631\teval-rmse:2.52993                                                                               \n",
      "\n",
      "[44]\ttrain-rmse:3.05988\teval-rmse:2.52278                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.05392\teval-rmse:2.52935                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.04959\teval-rmse:2.52815                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.04601\teval-rmse:2.53125                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.04248\teval-rmse:2.53125                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:3.03779\teval-rmse:2.52908                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.03527\teval-rmse:2.53675                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[30]\ttrain-rmse:3.11717\teval-rmse:2.50114\n",
      "\n",
      "\n",
      "loss: 83599679.47156137                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 4.8770735651034524e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 2.0665232876957914e-08, 'lambda': 6.494753691763544, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 1.2474401897314509, 'n_estimators': 263.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.29745\teval-rmse:5.08104                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.99759\teval-rmse:3.66895                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.36888\teval-rmse:2.97976                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.07392\teval-rmse:2.68208                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.93836\teval-rmse:2.56324                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.85967\teval-rmse:2.53345                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.80761\teval-rmse:2.5231                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.78225\teval-rmse:2.51217                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.75076\teval-rmse:2.50958                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.70949\teval-rmse:2.5274                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.6661\teval-rmse:2.53669                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.6397\teval-rmse:2.54212                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.62273\teval-rmse:2.55371                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.59244\teval-rmse:2.56029                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.57543\teval-rmse:2.58942                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.54759\teval-rmse:2.59078                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.51926\teval-rmse:2.59867                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.50375\teval-rmse:2.59885                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.47347\teval-rmse:2.5938                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.43323\teval-rmse:2.60189                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.40657\teval-rmse:2.6043                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.38044\teval-rmse:2.60876                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.35511\teval-rmse:2.60839                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.34238\teval-rmse:2.60863                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.31682\teval-rmse:2.63098                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.29403\teval-rmse:2.63273                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.25231\teval-rmse:2.64228                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.22828\teval-rmse:2.64871                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.21418\teval-rmse:2.65131                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.75076\teval-rmse:2.50958\n",
      "\n",
      "\n",
      "loss: 64335549.36785942                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0003704542592454804, 'colsample_bytree': 0.9500000000000001, 'gamma': 3.2204726360630565e-08, 'lambda': 0.20895881858470983, 'learning_rate': 0.325, 'max_depth': 7, 'min_child_weight': 0.4359393273852566, 'n_estimators': 622.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.73939\teval-rmse:5.55525                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.51518\teval-rmse:4.20361                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.80206\teval-rmse:3.39945                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.4023\teval-rmse:2.95704                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.17428\teval-rmse:2.73787                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.05434\teval-rmse:2.63372                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.9821\teval-rmse:2.57732                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.92744\teval-rmse:2.55304                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.88845\teval-rmse:2.55631                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.86101\teval-rmse:2.55503                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.82837\teval-rmse:2.56513                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\ttrain-rmse:2.78671\teval-rmse:2.57221                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.76264\teval-rmse:2.57419                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.73842\teval-rmse:2.58991                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.71952\teval-rmse:2.58656                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.69955\teval-rmse:2.58394                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.66938\teval-rmse:2.59492                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.65284\teval-rmse:2.60933                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.63158\teval-rmse:2.61443                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.61484\teval-rmse:2.61977                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.59053\teval-rmse:2.62426                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.57198\teval-rmse:2.6246                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.54606\teval-rmse:2.63458                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.53299\teval-rmse:2.64413                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.50989\teval-rmse:2.64667                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.49497\teval-rmse:2.64749                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.48444\teval-rmse:2.64828                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.4717\teval-rmse:2.64445                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.92744\teval-rmse:2.55304\n",
      "\n",
      "\n",
      "loss: 66401593.72405026                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0008333215273393585, 'colsample_bytree': 0.9, 'gamma': 0.041577249499904594, 'lambda': 0.0006445581407678707, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 7.823067917871584, 'n_estimators': 139.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.57159\teval-rmse:5.39071                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.29334\teval-rmse:4.00712                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.5844\teval-rmse:3.25084                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.21409\teval-rmse:2.86579                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.00043\teval-rmse:2.71085                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.89375\teval-rmse:2.64711                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.82443\teval-rmse:2.6088                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.77499\teval-rmse:2.59051                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.74353\teval-rmse:2.58259                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.71324\teval-rmse:2.582                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.69074\teval-rmse:2.58487                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.66828\teval-rmse:2.58336                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.64324\teval-rmse:2.59444                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.62127\teval-rmse:2.59875                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.60775\teval-rmse:2.59824                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.58135\teval-rmse:2.59954                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.56647\teval-rmse:2.60517                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.5545\teval-rmse:2.61268                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.53279\teval-rmse:2.61569                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.49349\teval-rmse:2.60904                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.45857\teval-rmse:2.61725                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.42677\teval-rmse:2.63343                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.41184\teval-rmse:2.63728                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.39226\teval-rmse:2.64444                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.38157\teval-rmse:2.6451                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.36362\teval-rmse:2.63824                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.33858\teval-rmse:2.63866                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.31956\teval-rmse:2.65211                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.30606\teval-rmse:2.66158                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.28587\teval-rmse:2.67822                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.71324\teval-rmse:2.582\n",
      "\n",
      "\n",
      "loss: 65536383.08977174                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 3.554999357929018e-08, 'colsample_bytree': 0.75, 'gamma': 1.1116245047792513e-06, 'lambda': 0.03128645974323282, 'learning_rate': 0.2, 'max_depth': 9, 'min_child_weight': 1.9766303584004086, 'n_estimators': 384.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.45764\teval-rmse:6.36915                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.45747\teval-rmse:5.317                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:4.68766\teval-rmse:4.50701                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.10434\teval-rmse:3.90501                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.66795\teval-rmse:3.46261                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttrain-rmse:3.34794\teval-rmse:3.14768                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.106\teval-rmse:2.92425                                                                                 \n",
      "\n",
      "[7]\ttrain-rmse:2.93439\teval-rmse:2.7772                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.79893\teval-rmse:2.67828                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.69431\teval-rmse:2.62289                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.61177\teval-rmse:2.58879                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.54007\teval-rmse:2.56768                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.47484\teval-rmse:2.55567                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.4399\teval-rmse:2.54689                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.40366\teval-rmse:2.5446                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.37241\teval-rmse:2.53974                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.34569\teval-rmse:2.54049                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.31296\teval-rmse:2.53621                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.2952\teval-rmse:2.53427                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.27877\teval-rmse:2.53356                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.25303\teval-rmse:2.53173                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.23719\teval-rmse:2.53114                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.21518\teval-rmse:2.53583                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.18861\teval-rmse:2.55464                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.17581\teval-rmse:2.55708                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.15666\teval-rmse:2.56361                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.12638\teval-rmse:2.57198                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.10971\teval-rmse:2.57052                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.09556\teval-rmse:2.5772                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.08413\teval-rmse:2.57725                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.07459\teval-rmse:2.57795                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.04886\teval-rmse:2.5758                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.04154\teval-rmse:2.576                                                                                \n",
      "\n",
      "[33]\ttrain-rmse:2.01496\teval-rmse:2.58506                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.00582\teval-rmse:2.58822                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:1.99859\teval-rmse:2.59068                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:1.9796\teval-rmse:2.59842                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:1.97332\teval-rmse:2.59832                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:1.95403\teval-rmse:2.59736                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:1.93973\teval-rmse:2.60225                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:1.925\teval-rmse:2.60184                                                                                \n",
      "\n",
      "[41]\ttrain-rmse:1.90468\teval-rmse:2.60143                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[21]\ttrain-rmse:2.23719\teval-rmse:2.53114\n",
      "\n",
      "\n",
      "loss: 64669381.347849295                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.925873349202225e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.8355053772381265e-05, 'lambda': 1.793701378322114e-06, 'learning_rate': 0.42500000000000004, 'max_depth': 5, 'min_child_weight': 1.6926417187705616, 'n_estimators': 980.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.21961\teval-rmse:4.92358                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.028\teval-rmse:3.51352                                                                                 \n",
      "\n",
      "[2]\ttrain-rmse:3.51256\teval-rmse:2.88883                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.3055\teval-rmse:2.63263                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.21544\teval-rmse:2.52995                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.16507\teval-rmse:2.50072                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.13483\teval-rmse:2.48105                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.1164\teval-rmse:2.48348                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.10111\teval-rmse:2.47853                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.07239\teval-rmse:2.46527                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.06253\teval-rmse:2.47488                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.05035\teval-rmse:2.46353                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.03917\teval-rmse:2.46299                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.02271\teval-rmse:2.46359                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.01497\teval-rmse:2.46142                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.00543\teval-rmse:2.45672                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.00113\teval-rmse:2.45668                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.98988\teval-rmse:2.48019                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.98003\teval-rmse:2.468                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:2.96774\teval-rmse:2.46582                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.95367\teval-rmse:2.47797                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.94277\teval-rmse:2.48299                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\ttrain-rmse:2.93407\teval-rmse:2.48654                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.92286\teval-rmse:2.48741                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.90519\teval-rmse:2.49372                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.88915\teval-rmse:2.49806                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.88079\teval-rmse:2.4982                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.8736\teval-rmse:2.50238                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.86632\teval-rmse:2.50801                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.85635\teval-rmse:2.51318                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.84497\teval-rmse:2.51786                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.83813\teval-rmse:2.51536                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.82753\teval-rmse:2.52024                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.82217\teval-rmse:2.53472                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.80943\teval-rmse:2.53014                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.80694\teval-rmse:2.53007                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.79228\teval-rmse:2.5626                                                                               \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[16]\ttrain-rmse:3.00113\teval-rmse:2.45668\n",
      "\n",
      "\n",
      "loss: 140136375.38423458                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.001319501679467797, 'colsample_bytree': 0.8500000000000001, 'gamma': 3.6519191014843282e-06, 'lambda': 0.0018837383956667895, 'learning_rate': 0.4, 'max_depth': 6, 'min_child_weight': 3.544575438869099, 'n_estimators': 511.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.3356\teval-rmse:5.07251                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.09944\teval-rmse:3.66086                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.5157\teval-rmse:2.99406                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.25522\teval-rmse:2.70486                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.14101\teval-rmse:2.59655                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.0751\teval-rmse:2.54381                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:3.03484\teval-rmse:2.52268                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.00622\teval-rmse:2.52279                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.97726\teval-rmse:2.52569                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.95085\teval-rmse:2.54483                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.93203\teval-rmse:2.55287                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.89974\teval-rmse:2.54931                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.87957\teval-rmse:2.55399                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.86607\teval-rmse:2.55622                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.8523\teval-rmse:2.55588                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.84461\teval-rmse:2.55817                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.83005\teval-rmse:2.55886                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.81599\teval-rmse:2.5683                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.79314\teval-rmse:2.57213                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.78311\teval-rmse:2.57976                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.77019\teval-rmse:2.58016                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.75995\teval-rmse:2.58577                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.74146\teval-rmse:2.60292                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.73181\teval-rmse:2.60077                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.7173\teval-rmse:2.59731                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.70903\teval-rmse:2.59585                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.69758\teval-rmse:2.59951                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:3.03484\teval-rmse:2.52268\n",
      "\n",
      "\n",
      "loss: 74836693.25826965                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00011534227895020955, 'colsample_bytree': 0.9, 'gamma': 1.5196102719189733e-06, 'lambda': 0.01121822208568739, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 0.379930791524018, 'n_estimators': 290.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.56119\teval-rmse:5.39614                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.26716\teval-rmse:4.01431                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.55587\teval-rmse:3.23097                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.16391\teval-rmse:2.85921                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.95537\teval-rmse:2.70272                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.81915\teval-rmse:2.63386                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.7435\teval-rmse:2.60112                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.68809\teval-rmse:2.59224                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.64951\teval-rmse:2.60347                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.6119\teval-rmse:2.59835                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\ttrain-rmse:2.55222\teval-rmse:2.61272                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.53206\teval-rmse:2.61698                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.50017\teval-rmse:2.62348                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.48557\teval-rmse:2.62039                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.4617\teval-rmse:2.62415                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.43366\teval-rmse:2.63206                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.41146\teval-rmse:2.64807                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.4004\teval-rmse:2.64963                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.35965\teval-rmse:2.65661                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.33629\teval-rmse:2.64243                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.32411\teval-rmse:2.64142                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.29119\teval-rmse:2.66254                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.27805\teval-rmse:2.66278                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.24991\teval-rmse:2.65575                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.23249\teval-rmse:2.65491                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.1955\teval-rmse:2.65617                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.18543\teval-rmse:2.66446                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.17725\teval-rmse:2.66299                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:2.68809\teval-rmse:2.59224\n",
      "\n",
      "\n",
      "loss: 74017872.66433914                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.00023886383490083645, 'colsample_bytree': 0.9500000000000001, 'gamma': 5.756631625358638e-06, 'lambda': 5.2024370932824877e-05, 'learning_rate': 0.375, 'max_depth': 4, 'min_child_weight': 0.33390703129848426, 'n_estimators': 821.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:5.51739\teval-rmse:5.23939                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.32386\teval-rmse:3.83616                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.7357\teval-rmse:3.11226                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.4583\teval-rmse:2.76267                                                                                \n",
      "\n",
      "[4]\ttrain-rmse:3.32901\teval-rmse:2.61337                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.26761\teval-rmse:2.53915                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.23236\teval-rmse:2.51209                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.21207\teval-rmse:2.49714                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.19442\teval-rmse:2.49108                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.18054\teval-rmse:2.49276                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.16499\teval-rmse:2.49004                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.15293\teval-rmse:2.48897                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.14134\teval-rmse:2.48085                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.13564\teval-rmse:2.48453                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.12575\teval-rmse:2.48476                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.11734\teval-rmse:2.49589                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.11363\teval-rmse:2.49073                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.10934\teval-rmse:2.49208                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.10626\teval-rmse:2.48772                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.1025\teval-rmse:2.48501                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:3.09542\teval-rmse:2.49076                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.09208\teval-rmse:2.49852                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.08355\teval-rmse:2.49934                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.07536\teval-rmse:2.50475                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.06949\teval-rmse:2.49974                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.06401\teval-rmse:2.50003                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.05807\teval-rmse:2.49906                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.04976\teval-rmse:2.50077                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.04041\teval-rmse:2.49795                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.03433\teval-rmse:2.49825                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.02495\teval-rmse:2.50246                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.02089\teval-rmse:2.50562                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.01342\teval-rmse:2.51081                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:3.14134\teval-rmse:2.48085\n",
      "\n",
      "\n",
      "loss: 80637466.26376525                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 6.854219266630096e-07, 'colsample_bytree': 0.9, 'gamma': 0.001075703405067922, 'lambda': 1.225386495915335e-05, 'learning_rate': 0.30000000000000004, 'max_depth': 8, 'min_child_weight': 9.821153251616686, 'n_estimators': 330.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.8662\teval-rmse:5.70811                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain-rmse:4.64188\teval-rmse:4.39399                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.87626\teval-rmse:3.56808                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.41818\teval-rmse:3.07393                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.14929\teval-rmse:2.80782                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.98531\teval-rmse:2.66306                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.88605\teval-rmse:2.5904                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.82532\teval-rmse:2.55191                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.77289\teval-rmse:2.5255                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.74005\teval-rmse:2.51877                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.70851\teval-rmse:2.50472                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.67538\teval-rmse:2.4962                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.64863\teval-rmse:2.50614                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.61668\teval-rmse:2.5107                                                                               \n",
      "\n",
      "[14]\ttrain-rmse:2.60264\teval-rmse:2.51026                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.58073\teval-rmse:2.51777                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.56943\teval-rmse:2.5244                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.55642\teval-rmse:2.53111                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.52852\teval-rmse:2.52262                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.52036\teval-rmse:2.52104                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.51225\teval-rmse:2.52012                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.49751\teval-rmse:2.52209                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.4802\teval-rmse:2.53152                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.46998\teval-rmse:2.53025                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.44028\teval-rmse:2.55578                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.42873\teval-rmse:2.55282                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.39079\teval-rmse:2.56241                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.38184\teval-rmse:2.56481                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.36066\teval-rmse:2.56756                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.34396\teval-rmse:2.56779                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.33139\teval-rmse:2.5672                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.31431\teval-rmse:2.56423                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.67538\teval-rmse:2.4962\n",
      "\n",
      "\n",
      "loss: 65903325.36860803                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.004202542586746109, 'colsample_bytree': 0.8500000000000001, 'gamma': 3.2982125540809794e-05, 'lambda': 0.00011182412453049005, 'learning_rate': 0.325, 'max_depth': 9, 'min_child_weight': 0.4972272764838974, 'n_estimators': 210.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.68468\teval-rmse:5.54876                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.37652\teval-rmse:4.1998                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.60171\teval-rmse:3.39337                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.15304\teval-rmse:2.95453                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.86162\teval-rmse:2.74155                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.69947\teval-rmse:2.64966                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.58423\teval-rmse:2.5957                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.50364\teval-rmse:2.56413                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.44998\teval-rmse:2.55862                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.40673\teval-rmse:2.55549                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.37004\teval-rmse:2.5493                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.34592\teval-rmse:2.55169                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.325\teval-rmse:2.56602                                                                                \n",
      "\n",
      "[13]\ttrain-rmse:2.30775\teval-rmse:2.60132                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.28954\teval-rmse:2.6027                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.26357\teval-rmse:2.6154                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.22248\teval-rmse:2.62886                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.20599\teval-rmse:2.63134                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.1866\teval-rmse:2.6313                                                                                \n",
      "\n",
      "[19]\ttrain-rmse:2.15656\teval-rmse:2.6354                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.14128\teval-rmse:2.64366                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.10202\teval-rmse:2.64182                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.08882\teval-rmse:2.64262                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.05437\teval-rmse:2.6494                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.02125\teval-rmse:2.6623                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.00297\teval-rmse:2.66098                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:1.98784\teval-rmse:2.67259                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:1.96454\teval-rmse:2.67122                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28]\ttrain-rmse:1.95105\teval-rmse:2.67586                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:1.93816\teval-rmse:2.67476                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:1.92278\teval-rmse:2.67686                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[10]\ttrain-rmse:2.37004\teval-rmse:2.5493\n",
      "\n",
      "\n",
      "loss: 118903274.51236457                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.2832452046812277e-05, 'colsample_bytree': 0.9500000000000001, 'gamma': 0.06301343034835079, 'lambda': 1.1203328283130505, 'learning_rate': 0.42500000000000004, 'max_depth': 3, 'min_child_weight': 0.645902340963902, 'n_estimators': 117.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.27584\teval-rmse:4.95746                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.1155\teval-rmse:3.54416                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:3.62078\teval-rmse:2.92302                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.42281\teval-rmse:2.65879                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.3449\teval-rmse:2.57184                                                                                \n",
      "\n",
      "[5]\ttrain-rmse:3.30352\teval-rmse:2.53587                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.28063\teval-rmse:2.53133                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.26694\teval-rmse:2.51935                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.2501\teval-rmse:2.51024                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.23578\teval-rmse:2.52392                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.22049\teval-rmse:2.51953                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.20964\teval-rmse:2.51247                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.20406\teval-rmse:2.50503                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.19676\teval-rmse:2.50701                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.19311\teval-rmse:2.51016                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.18526\teval-rmse:2.49078                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.17841\teval-rmse:2.48137                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.17164\teval-rmse:2.48137                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.16668\teval-rmse:2.48279                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.16184\teval-rmse:2.48272                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.15917\teval-rmse:2.48726                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.15395\teval-rmse:2.4871                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:3.14946\teval-rmse:2.48756                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.14444\teval-rmse:2.49368                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.14217\teval-rmse:2.49196                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.13774\teval-rmse:2.49199                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.13667\teval-rmse:2.48895                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.12871\teval-rmse:2.4926                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:3.12419\teval-rmse:2.49259                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.11823\teval-rmse:2.4992                                                                               \n",
      "\n",
      "[30]\ttrain-rmse:3.11443\teval-rmse:2.49617                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.10927\teval-rmse:2.493                                                                                \n",
      "\n",
      "[32]\ttrain-rmse:3.10518\teval-rmse:2.49029                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.10114\teval-rmse:2.49918                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:3.09593\teval-rmse:2.49393                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.09277\teval-rmse:2.50248                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.09107\teval-rmse:2.50022                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.08859\teval-rmse:2.50024                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[17]\ttrain-rmse:3.17164\teval-rmse:2.48137\n",
      "\n",
      "\n",
      "loss: 82680545.30793515                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.0965538974466935e-08, 'colsample_bytree': 0.65, 'gamma': 3.5399316477076446e-07, 'lambda': 9.73968867475307, 'learning_rate': 0.45, 'max_depth': 8, 'min_child_weight': 0.268297812890009, 'n_estimators': 442.0, 'nthread': 4, 'seed': 71, 'subsample': 0.7000000000000001}\n",
      "[0]\ttrain-rmse:5.04081\teval-rmse:4.76943                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.80124\teval-rmse:3.38181                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.26844\teval-rmse:2.81166                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.04077\teval-rmse:2.60826                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.93992\teval-rmse:2.55336                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.86483\teval-rmse:2.55149                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.82581\teval-rmse:2.54851                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.79088\teval-rmse:2.55763                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.76049\teval-rmse:2.56444                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.73601\teval-rmse:2.56762                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.70219\teval-rmse:2.57391                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11]\ttrain-rmse:2.65565\teval-rmse:2.56931                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.62446\teval-rmse:2.57202                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.58696\teval-rmse:2.56868                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.55623\teval-rmse:2.56812                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.52948\teval-rmse:2.5768                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.50506\teval-rmse:2.59332                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.49324\teval-rmse:2.59504                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.48197\teval-rmse:2.59929                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.45024\teval-rmse:2.58041                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.43598\teval-rmse:2.58258                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.41353\teval-rmse:2.57901                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.39856\teval-rmse:2.57385                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.36073\teval-rmse:2.58353                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.33892\teval-rmse:2.59145                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.31472\teval-rmse:2.58831                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.28066\teval-rmse:2.59107                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[6]\ttrain-rmse:2.82581\teval-rmse:2.54851\n",
      "\n",
      "\n",
      "loss: 71547579.27783021                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.094961151858657e-06, 'colsample_bytree': 0.9, 'gamma': 1.3532490408346271e-08, 'lambda': 0.3301443574021017, 'learning_rate': 0.275, 'max_depth': 7, 'min_child_weight': 0.7839955276618675, 'n_estimators': 533.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:6.03582\teval-rmse:5.88085                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.88271\teval-rmse:4.6216                                                                                \n",
      "\n",
      "[2]\ttrain-rmse:4.1255\teval-rmse:3.77666                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.64685\teval-rmse:3.24549                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.34739\teval-rmse:2.91901                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.16624\teval-rmse:2.73878                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.04686\teval-rmse:2.63887                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.96431\teval-rmse:2.58519                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.91501\teval-rmse:2.55985                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.87798\teval-rmse:2.53976                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.84075\teval-rmse:2.53639                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.82018\teval-rmse:2.53897                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.80021\teval-rmse:2.53206                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.78128\teval-rmse:2.53255                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.75964\teval-rmse:2.53213                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.73641\teval-rmse:2.53723                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.71447\teval-rmse:2.56333                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.70127\teval-rmse:2.56269                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.69406\teval-rmse:2.56049                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.66674\teval-rmse:2.56338                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.64675\teval-rmse:2.5766                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.62791\teval-rmse:2.58564                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.60863\teval-rmse:2.5858                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.59082\teval-rmse:2.59039                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.56869\teval-rmse:2.58233                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.55497\teval-rmse:2.58536                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.54587\teval-rmse:2.58411                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.5238\teval-rmse:2.58645                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.50626\teval-rmse:2.58482                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.50019\teval-rmse:2.58772                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.49493\teval-rmse:2.5872                                                                               \n",
      "\n",
      "[31]\ttrain-rmse:2.4797\teval-rmse:2.58924                                                                               \n",
      "\n",
      "[32]\ttrain-rmse:2.47166\teval-rmse:2.59168                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.80021\teval-rmse:2.53206\n",
      "\n",
      "\n",
      "loss: 67379831.28128065                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.2058329023413376e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 9.643222652023306e-08, 'lambda': 0.05061538531776244, 'learning_rate': 0.30000000000000004, 'max_depth': 8, 'min_child_weight': 1.5118943381311172, 'n_estimators': 365.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.85762\teval-rmse:5.71671                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.62968\teval-rmse:4.39409                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.8541\teval-rmse:3.56439                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\ttrain-rmse:3.39209\teval-rmse:3.07342                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.10326\teval-rmse:2.80286                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.94274\teval-rmse:2.66505                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.84465\teval-rmse:2.59664                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.76814\teval-rmse:2.56454                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.72001\teval-rmse:2.55456                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.68036\teval-rmse:2.56765                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.64798\teval-rmse:2.56262                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.5972\teval-rmse:2.56628                                                                               \n",
      "\n",
      "[12]\ttrain-rmse:2.57192\teval-rmse:2.57351                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.53267\teval-rmse:2.58491                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.50515\teval-rmse:2.58507                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.47258\teval-rmse:2.58174                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.45458\teval-rmse:2.588                                                                                \n",
      "\n",
      "[17]\ttrain-rmse:2.42777\teval-rmse:2.59553                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.40659\teval-rmse:2.59644                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.3996\teval-rmse:2.59536                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:2.37191\teval-rmse:2.59511                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.35101\teval-rmse:2.5925                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.32617\teval-rmse:2.59415                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.29987\teval-rmse:2.59434                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.26503\teval-rmse:2.59707                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.23578\teval-rmse:2.59381                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.21472\teval-rmse:2.59745                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.18534\teval-rmse:2.5945                                                                               \n",
      "\n",
      "[28]\ttrain-rmse:2.16434\teval-rmse:2.59461                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.72001\teval-rmse:2.55456\n",
      "\n",
      "\n",
      "loss: 96718373.64153892                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 7.052291490262294e-05, 'colsample_bytree': 0.8, 'gamma': 6.518265269105279e-05, 'lambda': 2.0940924849905453, 'learning_rate': 0.2, 'max_depth': 9, 'min_child_weight': 3.137281300696014, 'n_estimators': 494.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.465\teval-rmse:6.37672                                                                                 \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.47671\teval-rmse:5.33704                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.71555\teval-rmse:4.53544                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:4.14035\teval-rmse:3.93228                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.716\teval-rmse:3.50006                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:3.39916\teval-rmse:3.19487                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.1577\teval-rmse:2.97001                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.98751\teval-rmse:2.82062                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.86576\teval-rmse:2.72506                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.76808\teval-rmse:2.6599                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:2.68546\teval-rmse:2.61214                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.62133\teval-rmse:2.57273                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.56758\teval-rmse:2.56297                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.53167\teval-rmse:2.55288                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.50033\teval-rmse:2.54953                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.46815\teval-rmse:2.55135                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.44279\teval-rmse:2.5551                                                                               \n",
      "\n",
      "[17]\ttrain-rmse:2.42798\teval-rmse:2.55323                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.38832\teval-rmse:2.54898                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.37384\teval-rmse:2.55202                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.35557\teval-rmse:2.55066                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.32009\teval-rmse:2.54775                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.2961\teval-rmse:2.55473                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:2.27522\teval-rmse:2.54784                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.26682\teval-rmse:2.54828                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.25217\teval-rmse:2.5489                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.22646\teval-rmse:2.54808                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.20939\teval-rmse:2.55787                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.19182\teval-rmse:2.55496                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.18276\teval-rmse:2.55686                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.16731\teval-rmse:2.55794                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.16068\teval-rmse:2.55541                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.14163\teval-rmse:2.56124                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:2.13037\teval-rmse:2.55944                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34]\ttrain-rmse:2.11327\teval-rmse:2.55258                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:2.09835\teval-rmse:2.54711                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.08907\teval-rmse:2.5473                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.07429\teval-rmse:2.54685                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.05002\teval-rmse:2.54929                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.03611\teval-rmse:2.54919                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.03095\teval-rmse:2.5476                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:2.01663\teval-rmse:2.5484                                                                               \n",
      "\n",
      "[42]\ttrain-rmse:2.01057\teval-rmse:2.54956                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.00032\teval-rmse:2.55154                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:1.99337\teval-rmse:2.55174                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:1.9772\teval-rmse:2.55444                                                                               \n",
      "\n",
      "[46]\ttrain-rmse:1.95956\teval-rmse:2.55565                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:1.93864\teval-rmse:2.55387                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:1.93066\teval-rmse:2.55854                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:1.92245\teval-rmse:2.56055                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:1.90285\teval-rmse:2.55992                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:1.89319\teval-rmse:2.55992                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:1.88093\teval-rmse:2.55773                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:1.87017\teval-rmse:2.55756                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:1.8547\teval-rmse:2.55678                                                                               \n",
      "\n",
      "[55]\ttrain-rmse:1.83626\teval-rmse:2.55679                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:1.82537\teval-rmse:2.55657                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:1.80538\teval-rmse:2.55863                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[37]\ttrain-rmse:2.07429\teval-rmse:2.54685\n",
      "\n",
      "\n",
      "loss: 67248180.43439557                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.089015883181463e-06, 'colsample_bytree': 0.7000000000000001, 'gamma': 1.0087925533011793e-05, 'lambda': 2.6639744792730418, 'learning_rate': 0.25, 'max_depth': 5, 'min_child_weight': 0.10623839602614404, 'n_estimators': 190.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.21582\teval-rmse:6.06285                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.14822\teval-rmse:4.86189                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.42736\teval-rmse:4.02765                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.95569\teval-rmse:3.45198                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.65308\teval-rmse:3.08713                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.45925\teval-rmse:2.85936                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.34048\teval-rmse:2.71222                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.26688\teval-rmse:2.6137                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:3.21752\teval-rmse:2.55768                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.1822\teval-rmse:2.52577                                                                                \n",
      "\n",
      "[10]\ttrain-rmse:3.15965\teval-rmse:2.51091                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:3.14418\teval-rmse:2.49886                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.12354\teval-rmse:2.50323                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.10691\teval-rmse:2.49642                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.09791\teval-rmse:2.49501                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.08344\teval-rmse:2.48325                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.07086\teval-rmse:2.48003                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.06553\teval-rmse:2.47288                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.0584\teval-rmse:2.47347                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:3.0554\teval-rmse:2.47326                                                                               \n",
      "\n",
      "[20]\ttrain-rmse:3.0448\teval-rmse:2.48132                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:3.03407\teval-rmse:2.47618                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.02381\teval-rmse:2.4799                                                                               \n",
      "\n",
      "[23]\ttrain-rmse:3.01562\teval-rmse:2.48185                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.01174\teval-rmse:2.48012                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.99975\teval-rmse:2.47965                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.98935\teval-rmse:2.47799                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.98119\teval-rmse:2.47982                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.97463\teval-rmse:2.47979                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.97249\teval-rmse:2.48156                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.96277\teval-rmse:2.48251                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.95819\teval-rmse:2.48149                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.95582\teval-rmse:2.4815                                                                               \n",
      "\n",
      "[33]\ttrain-rmse:2.95186\teval-rmse:2.47993                                                                              \n",
      "\n",
      "[34]\ttrain-rmse:2.94117\teval-rmse:2.47321                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35]\ttrain-rmse:2.93233\teval-rmse:2.47351                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:2.9244\teval-rmse:2.47023                                                                               \n",
      "\n",
      "[37]\ttrain-rmse:2.91817\teval-rmse:2.46623                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:2.91483\teval-rmse:2.46973                                                                              \n",
      "\n",
      "[39]\ttrain-rmse:2.91152\teval-rmse:2.46935                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:2.90608\teval-rmse:2.47298                                                                              \n",
      "\n",
      "[41]\ttrain-rmse:2.90219\teval-rmse:2.47262                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:2.89541\teval-rmse:2.47622                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:2.88551\teval-rmse:2.48104                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:2.87877\teval-rmse:2.48421                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:2.87172\teval-rmse:2.49081                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:2.86405\teval-rmse:2.49134                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:2.86087\teval-rmse:2.49208                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:2.85628\teval-rmse:2.49066                                                                              \n",
      "\n",
      "[49]\ttrain-rmse:2.85071\teval-rmse:2.49313                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:2.8424\teval-rmse:2.49504                                                                               \n",
      "\n",
      "[51]\ttrain-rmse:2.84008\teval-rmse:2.4941                                                                               \n",
      "\n",
      "[52]\ttrain-rmse:2.83688\teval-rmse:2.49367                                                                              \n",
      "\n",
      "[53]\ttrain-rmse:2.82943\teval-rmse:2.48909                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:2.8263\teval-rmse:2.48909                                                                               \n",
      "\n",
      "[55]\ttrain-rmse:2.82292\teval-rmse:2.48458                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:2.81825\teval-rmse:2.484                                                                                \n",
      "\n",
      "[57]\ttrain-rmse:2.81043\teval-rmse:2.48266                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[37]\ttrain-rmse:2.91817\teval-rmse:2.46623\n",
      "\n",
      "\n",
      "loss: 75235434.48714559                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0005921690495994304, 'colsample_bytree': 0.9, 'gamma': 0.0003643213188345363, 'lambda': 0.7888396346132274, 'learning_rate': 0.5, 'max_depth': 8, 'min_child_weight': 0.2472310712492265, 'n_estimators': 688.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:4.71774\teval-rmse:4.46944                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.48074\teval-rmse:3.17521                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.04729\teval-rmse:2.77309                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:2.868\teval-rmse:2.66064                                                                                 \n",
      "\n",
      "[4]\ttrain-rmse:2.77132\teval-rmse:2.63959                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.69287\teval-rmse:2.67227                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.63499\teval-rmse:2.68147                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.61528\teval-rmse:2.67411                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.58392\teval-rmse:2.67152                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.53073\teval-rmse:2.66723                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.50061\teval-rmse:2.68895                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.43929\teval-rmse:2.70146                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.39894\teval-rmse:2.70113                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.36547\teval-rmse:2.71012                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.32236\teval-rmse:2.69866                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.29594\teval-rmse:2.71441                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.27449\teval-rmse:2.71462                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.2517\teval-rmse:2.70413                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.23121\teval-rmse:2.70373                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.20784\teval-rmse:2.68774                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.18359\teval-rmse:2.68967                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.1625\teval-rmse:2.68959                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.12005\teval-rmse:2.70268                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.0879\teval-rmse:2.70509                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.06237\teval-rmse:2.70824                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[4]\ttrain-rmse:2.77132\teval-rmse:2.63959\n",
      "\n",
      "\n",
      "loss: 70429528.75312015                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 2.3032641462711974e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 0.6392974402539192, 'lambda': 0.10739591221540533, 'learning_rate': 0.375, 'max_depth': 6, 'min_child_weight': 0.9457696245672709, 'n_estimators': 602.0, 'nthread': 4, 'seed': 71, 'subsample': 0.75}\n",
      "[0]\ttrain-rmse:5.4803\teval-rmse:5.22896                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.24273\teval-rmse:3.83513                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.61463\teval-rmse:3.10243                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.3236\teval-rmse:2.75268                                                                                \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\ttrain-rmse:3.18242\teval-rmse:2.59127                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.11473\teval-rmse:2.52921                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.06906\teval-rmse:2.47763                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.03494\teval-rmse:2.48165                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.01221\teval-rmse:2.4765                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.99858\teval-rmse:2.47633                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.96752\teval-rmse:2.48453                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.95417\teval-rmse:2.47354                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.93232\teval-rmse:2.47569                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.91837\teval-rmse:2.47731                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.89404\teval-rmse:2.47782                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.88121\teval-rmse:2.47759                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.86347\teval-rmse:2.50119                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.85125\teval-rmse:2.49627                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.84234\teval-rmse:2.50709                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.83408\teval-rmse:2.51408                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.81756\teval-rmse:2.51553                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.79531\teval-rmse:2.51623                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.78262\teval-rmse:2.51641                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.76987\teval-rmse:2.5223                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.75781\teval-rmse:2.52054                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.73304\teval-rmse:2.5277                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:2.72396\teval-rmse:2.51768                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.70588\teval-rmse:2.52606                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.69511\teval-rmse:2.52401                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.68628\teval-rmse:2.52021                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.667\teval-rmse:2.52669                                                                                \n",
      "\n",
      "[31]\ttrain-rmse:2.65914\teval-rmse:2.52005                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.95417\teval-rmse:2.47354\n",
      "\n",
      "\n",
      "loss: 66412430.574765794                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.1814248295625126e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 3.0595657671182034e-06, 'lambda': 0.002797837638771406, 'learning_rate': 0.47500000000000003, 'max_depth': 4, 'min_child_weight': 0.6904959974373012, 'n_estimators': 248.0, 'nthread': 4, 'seed': 71, 'subsample': 0.6000000000000001}\n",
      "[0]\ttrain-rmse:4.99302\teval-rmse:4.61194                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.86965\teval-rmse:3.25008                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.4629\teval-rmse:2.73338                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.32186\teval-rmse:2.55973                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.26279\teval-rmse:2.51394                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.23247\teval-rmse:2.48978                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.2116\teval-rmse:2.47478                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:3.19762\teval-rmse:2.47285                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.1853\teval-rmse:2.48592                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:3.17913\teval-rmse:2.48304                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.1692\teval-rmse:2.48851                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:3.16578\teval-rmse:2.48893                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.15498\teval-rmse:2.48667                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.14766\teval-rmse:2.49283                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.13964\teval-rmse:2.51286                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.13019\teval-rmse:2.49954                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.11684\teval-rmse:2.49444                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.10947\teval-rmse:2.48808                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.10194\teval-rmse:2.49598                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.09475\teval-rmse:2.49432                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.09029\teval-rmse:2.49596                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.08243\teval-rmse:2.50108                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:3.07794\teval-rmse:2.49688                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.06859\teval-rmse:2.50574                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.06634\teval-rmse:2.50606                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.06142\teval-rmse:2.5082                                                                               \n",
      "\n",
      "[26]\ttrain-rmse:3.05787\teval-rmse:2.5145                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:3.05047\teval-rmse:2.53472                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[7]\ttrain-rmse:3.19762\teval-rmse:2.47285\n",
      "\n",
      "\n",
      "loss: 93335772.96108346                                                                                                \n",
      "Training with params:                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 3.9135172257878836e-05, 'colsample_bytree': 0.9, 'gamma': 0.00027184416603586445, 'lambda': 0.17454606430476327, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 0.16630267758097134, 'n_estimators': 414.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.27803\teval-rmse:5.07674                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.97741\teval-rmse:3.66225                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.32911\teval-rmse:3.0042                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.01779\teval-rmse:2.74138                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.86875\teval-rmse:2.64486                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.77372\teval-rmse:2.64176                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.7188\teval-rmse:2.64683                                                                                \n",
      "\n",
      "[7]\ttrain-rmse:2.67816\teval-rmse:2.63629                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.62119\teval-rmse:2.63312                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.59258\teval-rmse:2.64446                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.55602\teval-rmse:2.66161                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.52732\teval-rmse:2.67012                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.49356\teval-rmse:2.68324                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.44666\teval-rmse:2.69377                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.41079\teval-rmse:2.6979                                                                               \n",
      "\n",
      "[15]\ttrain-rmse:2.38791\teval-rmse:2.68726                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.36722\teval-rmse:2.70232                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.33766\teval-rmse:2.7                                                                                  \n",
      "\n",
      "[18]\ttrain-rmse:2.32177\teval-rmse:2.69781                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.29084\teval-rmse:2.69977                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.27886\teval-rmse:2.70605                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.27251\teval-rmse:2.70661                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.25077\teval-rmse:2.71897                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.20774\teval-rmse:2.7253                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.18576\teval-rmse:2.73932                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.17008\teval-rmse:2.74103                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.14036\teval-rmse:2.7414                                                                               \n",
      "\n",
      "[27]\ttrain-rmse:2.11915\teval-rmse:2.75593                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.10637\teval-rmse:2.75428                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[8]\ttrain-rmse:2.62119\teval-rmse:2.63312\n",
      "\n",
      "\n",
      "loss: 73551767.75594936                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.8597166027137443e-07, 'colsample_bytree': 0.9500000000000001, 'gamma': 7.166841771573255e-07, 'lambda': 4.191656142260521, 'learning_rate': 0.225, 'max_depth': 9, 'min_child_weight': 0.3021129748220826, 'n_estimators': 271.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:6.31395\teval-rmse:6.20606                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:5.24523\teval-rmse:5.07538                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.46196\teval-rmse:4.2468                                                                                \n",
      "\n",
      "[3]\ttrain-rmse:3.90177\teval-rmse:3.65385                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.49684\teval-rmse:3.24405                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.20375\teval-rmse:2.97051                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.99837\teval-rmse:2.79816                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.8606\teval-rmse:2.68153                                                                                \n",
      "\n",
      "[8]\ttrain-rmse:2.7518\teval-rmse:2.60542                                                                                \n",
      "\n",
      "[9]\ttrain-rmse:2.67098\teval-rmse:2.56262                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.60127\teval-rmse:2.5301                                                                               \n",
      "\n",
      "[11]\ttrain-rmse:2.54423\teval-rmse:2.51653                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.49623\teval-rmse:2.50847                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.46352\teval-rmse:2.50903                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.43334\teval-rmse:2.50917                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.41175\teval-rmse:2.51362                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.37089\teval-rmse:2.51016                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.35479\teval-rmse:2.5096                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.33539\teval-rmse:2.51322                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.31679\teval-rmse:2.51778                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.30223\teval-rmse:2.51418                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.2718\teval-rmse:2.51573                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.263\teval-rmse:2.51677                                                                                \n",
      "\n",
      "[23]\ttrain-rmse:2.25425\teval-rmse:2.52273                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.2446\teval-rmse:2.52265                                                                               \n",
      "\n",
      "[25]\ttrain-rmse:2.2343\teval-rmse:2.52516                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26]\ttrain-rmse:2.21786\teval-rmse:2.53                                                                                 \n",
      "\n",
      "[27]\ttrain-rmse:2.19312\teval-rmse:2.53466                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.17774\teval-rmse:2.53903                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.15519\teval-rmse:2.53789                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.14037\teval-rmse:2.53967                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.12678\teval-rmse:2.53503                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:2.09803\teval-rmse:2.53474                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[12]\ttrain-rmse:2.49623\teval-rmse:2.50847\n",
      "\n",
      "\n",
      "loss: 64177084.074604556                                                                                               \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 8.853934022796055e-05, 'colsample_bytree': 0.8500000000000001, 'gamma': 1.5820499838476633e-07, 'lambda': 7.906039230462865, 'learning_rate': 0.325, 'max_depth': 3, 'min_child_weight': 7.239945287885617, 'n_estimators': 306.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9}\n",
      "[0]\ttrain-rmse:5.81995\teval-rmse:5.58254                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.67444\teval-rmse:4.24652                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:4.021\teval-rmse:3.4594                                                                                  \n",
      "\n",
      "[3]\ttrain-rmse:3.67035\teval-rmse:3.01505                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.48811\teval-rmse:2.78186                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:3.39342\teval-rmse:2.64865                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:3.34124\teval-rmse:2.57505                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:3.31129\teval-rmse:2.54452                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:3.29056\teval-rmse:2.52053                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:3.27763\teval-rmse:2.51822                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:3.267\teval-rmse:2.51093                                                                                \n",
      "\n",
      "[11]\ttrain-rmse:3.25411\teval-rmse:2.49609                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:3.24398\teval-rmse:2.51107                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:3.23709\teval-rmse:2.50539                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:3.23237\teval-rmse:2.50828                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:3.22425\teval-rmse:2.50252                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:3.21556\teval-rmse:2.49843                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:3.21177\teval-rmse:2.49905                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:3.20568\teval-rmse:2.49729                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:3.20094\teval-rmse:2.50118                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:3.19911\teval-rmse:2.50034                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:3.1934\teval-rmse:2.49664                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:3.18853\teval-rmse:2.50734                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:3.18226\teval-rmse:2.49748                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:3.17914\teval-rmse:2.49846                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:3.17582\teval-rmse:2.49577                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:3.17039\teval-rmse:2.49531                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:3.16666\teval-rmse:2.49581                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:3.16449\teval-rmse:2.49623                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:3.16167\teval-rmse:2.49611                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:3.15695\teval-rmse:2.49037                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:3.15495\teval-rmse:2.48751                                                                              \n",
      "\n",
      "[32]\ttrain-rmse:3.15162\teval-rmse:2.48429                                                                              \n",
      "\n",
      "[33]\ttrain-rmse:3.14902\teval-rmse:2.4841                                                                               \n",
      "\n",
      "[34]\ttrain-rmse:3.14621\teval-rmse:2.48022                                                                              \n",
      "\n",
      "[35]\ttrain-rmse:3.14454\teval-rmse:2.48149                                                                              \n",
      "\n",
      "[36]\ttrain-rmse:3.14053\teval-rmse:2.47895                                                                              \n",
      "\n",
      "[37]\ttrain-rmse:3.13738\teval-rmse:2.47269                                                                              \n",
      "\n",
      "[38]\ttrain-rmse:3.13406\teval-rmse:2.4756                                                                               \n",
      "\n",
      "[39]\ttrain-rmse:3.13107\teval-rmse:2.47999                                                                              \n",
      "\n",
      "[40]\ttrain-rmse:3.12948\teval-rmse:2.4783                                                                               \n",
      "\n",
      "[41]\ttrain-rmse:3.12443\teval-rmse:2.47132                                                                              \n",
      "\n",
      "[42]\ttrain-rmse:3.12161\teval-rmse:2.47375                                                                              \n",
      "\n",
      "[43]\ttrain-rmse:3.11879\teval-rmse:2.47851                                                                              \n",
      "\n",
      "[44]\ttrain-rmse:3.11675\teval-rmse:2.48015                                                                              \n",
      "\n",
      "[45]\ttrain-rmse:3.11305\teval-rmse:2.48309                                                                              \n",
      "\n",
      "[46]\ttrain-rmse:3.11219\teval-rmse:2.48316                                                                              \n",
      "\n",
      "[47]\ttrain-rmse:3.10844\teval-rmse:2.48168                                                                              \n",
      "\n",
      "[48]\ttrain-rmse:3.1048\teval-rmse:2.47792                                                                               \n",
      "\n",
      "[49]\ttrain-rmse:3.10014\teval-rmse:2.47153                                                                              \n",
      "\n",
      "[50]\ttrain-rmse:3.09628\teval-rmse:2.47211                                                                              \n",
      "\n",
      "[51]\ttrain-rmse:3.09264\teval-rmse:2.46768                                                                              \n",
      "\n",
      "[52]\ttrain-rmse:3.09023\teval-rmse:2.46823                                                                              \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53]\ttrain-rmse:3.08682\teval-rmse:2.47117                                                                              \n",
      "\n",
      "[54]\ttrain-rmse:3.08393\teval-rmse:2.47248                                                                              \n",
      "\n",
      "[55]\ttrain-rmse:3.08134\teval-rmse:2.47883                                                                              \n",
      "\n",
      "[56]\ttrain-rmse:3.08077\teval-rmse:2.47844                                                                              \n",
      "\n",
      "[57]\ttrain-rmse:3.07709\teval-rmse:2.47764                                                                              \n",
      "\n",
      "[58]\ttrain-rmse:3.07514\teval-rmse:2.47527                                                                              \n",
      "\n",
      "[59]\ttrain-rmse:3.0731\teval-rmse:2.47529                                                                               \n",
      "\n",
      "[60]\ttrain-rmse:3.06913\teval-rmse:2.4775                                                                               \n",
      "\n",
      "[61]\ttrain-rmse:3.066\teval-rmse:2.47729                                                                                \n",
      "\n",
      "[62]\ttrain-rmse:3.0637\teval-rmse:2.47746                                                                               \n",
      "\n",
      "[63]\ttrain-rmse:3.06171\teval-rmse:2.47975                                                                              \n",
      "\n",
      "[64]\ttrain-rmse:3.05925\teval-rmse:2.48025                                                                              \n",
      "\n",
      "[65]\ttrain-rmse:3.05685\teval-rmse:2.48228                                                                              \n",
      "\n",
      "[66]\ttrain-rmse:3.05447\teval-rmse:2.48108                                                                              \n",
      "\n",
      "[67]\ttrain-rmse:3.05277\teval-rmse:2.47931                                                                              \n",
      "\n",
      "[68]\ttrain-rmse:3.05046\teval-rmse:2.47975                                                                              \n",
      "\n",
      "[69]\ttrain-rmse:3.04943\teval-rmse:2.47914                                                                              \n",
      "\n",
      "[70]\ttrain-rmse:3.04687\teval-rmse:2.48252                                                                              \n",
      "\n",
      "[71]\ttrain-rmse:3.04326\teval-rmse:2.48234                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[51]\ttrain-rmse:3.09264\teval-rmse:2.46768\n",
      "\n",
      "\n",
      "loss: 73166524.74100195                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 0.0059460067598203475, 'colsample_bytree': 0.75, 'gamma': 2.2818200364785318e-05, 'lambda': 1.3642212642041156, 'learning_rate': 0.35000000000000003, 'max_depth': 8, 'min_child_weight': 0.2141733155698359, 'n_estimators': 153.0, 'nthread': 4, 'seed': 71, 'subsample': 0.9500000000000001}\n",
      "[0]\ttrain-rmse:5.57055\teval-rmse:5.39834                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.29191\teval-rmse:4.01049                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.57301\teval-rmse:3.24249                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.18587\teval-rmse:2.86824                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.97008\teval-rmse:2.68426                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.84451\teval-rmse:2.58941                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.76306\teval-rmse:2.56408                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.72188\teval-rmse:2.54563                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.67381\teval-rmse:2.53832                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.65016\teval-rmse:2.53698                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.60954\teval-rmse:2.55347                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.58718\teval-rmse:2.56223                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.5619\teval-rmse:2.56425                                                                               \n",
      "\n",
      "[13]\ttrain-rmse:2.54342\teval-rmse:2.56013                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.51159\teval-rmse:2.55764                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.47006\teval-rmse:2.56553                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.45295\teval-rmse:2.56684                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.42985\teval-rmse:2.57577                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.40463\teval-rmse:2.57914                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.37976\teval-rmse:2.57899                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.36623\teval-rmse:2.58008                                                                              \n",
      "\n",
      "[21]\ttrain-rmse:2.33727\teval-rmse:2.5774                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.31253\teval-rmse:2.59709                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.28052\teval-rmse:2.58953                                                                              \n",
      "\n",
      "[24]\ttrain-rmse:2.26354\teval-rmse:2.59374                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.23332\teval-rmse:2.59464                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.22035\teval-rmse:2.59541                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.20044\teval-rmse:2.59091                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.17453\teval-rmse:2.58776                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.15683\teval-rmse:2.58851                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.65016\teval-rmse:2.53698\n",
      "\n",
      "\n",
      "loss: 72422682.43120249                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 1.4341837450254542e-06, 'colsample_bytree': 0.9500000000000001, 'gamma': 1.4160742881689142e-05, 'lambda': 0.08070535726909775, 'learning_rate': 0.375, 'max_depth': 7, 'min_child_weight': 1.1868322990343976, 'n_estimators': 553.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8500000000000001}\n",
      "[0]\ttrain-rmse:5.44937\teval-rmse:5.22373                                                                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:4.19489\teval-rmse:3.81332                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.54704\teval-rmse:3.11649                                                                               \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\ttrain-rmse:3.23409\teval-rmse:2.78319                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:3.07991\teval-rmse:2.631                                                                                 \n",
      "\n",
      "[5]\ttrain-rmse:2.9961\teval-rmse:2.56213                                                                                \n",
      "\n",
      "[6]\ttrain-rmse:2.93573\teval-rmse:2.53549                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.89051\teval-rmse:2.52907                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.85815\teval-rmse:2.51931                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.83316\teval-rmse:2.524                                                                                 \n",
      "\n",
      "[10]\ttrain-rmse:2.79444\teval-rmse:2.51433                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.77904\teval-rmse:2.51291                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.74874\teval-rmse:2.52354                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.73384\teval-rmse:2.52536                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.71041\teval-rmse:2.53691                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.68895\teval-rmse:2.54515                                                                              \n",
      "\n",
      "[16]\ttrain-rmse:2.66061\teval-rmse:2.55748                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.64655\teval-rmse:2.56352                                                                              \n",
      "\n",
      "[18]\ttrain-rmse:2.6308\teval-rmse:2.55122                                                                               \n",
      "\n",
      "[19]\ttrain-rmse:2.61614\teval-rmse:2.55387                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.5926\teval-rmse:2.55218                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.57213\teval-rmse:2.55187                                                                              \n",
      "\n",
      "[22]\ttrain-rmse:2.55138\teval-rmse:2.55683                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.5178\teval-rmse:2.55192                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.49848\teval-rmse:2.58749                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.48396\teval-rmse:2.58852                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.46507\teval-rmse:2.58782                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.44001\teval-rmse:2.59693                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.4195\teval-rmse:2.59646                                                                               \n",
      "\n",
      "[29]\ttrain-rmse:2.40512\teval-rmse:2.59526                                                                              \n",
      "\n",
      "[30]\ttrain-rmse:2.39379\teval-rmse:2.59744                                                                              \n",
      "\n",
      "[31]\ttrain-rmse:2.38059\teval-rmse:2.59687                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[11]\ttrain-rmse:2.77904\teval-rmse:2.51291\n",
      "\n",
      "\n",
      "loss: 63456056.91632948                                                                                                \n",
      "Training with params:                                                                                                  \n",
      "{'alpha': 5.187148048303394e-07, 'colsample_bytree': 0.9, 'gamma': 2.0744856239517087e-06, 'lambda': 0.004909039207929328, 'learning_rate': 0.4, 'max_depth': 8, 'min_child_weight': 2.754493359017507, 'n_estimators': 336.0, 'nthread': 4, 'seed': 71, 'subsample': 0.8}\n",
      "[0]\ttrain-rmse:5.2788\teval-rmse:5.07106                                                                                \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.                                   \n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.                                                               \n",
      "\n",
      "[1]\ttrain-rmse:3.98419\teval-rmse:3.66416                                                                               \n",
      "\n",
      "[2]\ttrain-rmse:3.34872\teval-rmse:2.99316                                                                               \n",
      "\n",
      "[3]\ttrain-rmse:3.05419\teval-rmse:2.71101                                                                               \n",
      "\n",
      "[4]\ttrain-rmse:2.90191\teval-rmse:2.61046                                                                               \n",
      "\n",
      "[5]\ttrain-rmse:2.80372\teval-rmse:2.57961                                                                               \n",
      "\n",
      "[6]\ttrain-rmse:2.74583\teval-rmse:2.58034                                                                               \n",
      "\n",
      "[7]\ttrain-rmse:2.70322\teval-rmse:2.57444                                                                               \n",
      "\n",
      "[8]\ttrain-rmse:2.66882\teval-rmse:2.57959                                                                               \n",
      "\n",
      "[9]\ttrain-rmse:2.65614\teval-rmse:2.57432                                                                               \n",
      "\n",
      "[10]\ttrain-rmse:2.62333\teval-rmse:2.58931                                                                              \n",
      "\n",
      "[11]\ttrain-rmse:2.60235\teval-rmse:2.59882                                                                              \n",
      "\n",
      "[12]\ttrain-rmse:2.57939\teval-rmse:2.59358                                                                              \n",
      "\n",
      "[13]\ttrain-rmse:2.55044\teval-rmse:2.61711                                                                              \n",
      "\n",
      "[14]\ttrain-rmse:2.53557\teval-rmse:2.61334                                                                              \n",
      "\n",
      "[15]\ttrain-rmse:2.5004\teval-rmse:2.62484                                                                               \n",
      "\n",
      "[16]\ttrain-rmse:2.47057\teval-rmse:2.63703                                                                              \n",
      "\n",
      "[17]\ttrain-rmse:2.4553\teval-rmse:2.65374                                                                               \n",
      "\n",
      "[18]\ttrain-rmse:2.43951\teval-rmse:2.64708                                                                              \n",
      "\n",
      "[19]\ttrain-rmse:2.40127\teval-rmse:2.64638                                                                              \n",
      "\n",
      "[20]\ttrain-rmse:2.37332\teval-rmse:2.6479                                                                               \n",
      "\n",
      "[21]\ttrain-rmse:2.34378\teval-rmse:2.6576                                                                               \n",
      "\n",
      "[22]\ttrain-rmse:2.32474\teval-rmse:2.65938                                                                              \n",
      "\n",
      "[23]\ttrain-rmse:2.2991\teval-rmse:2.66384                                                                               \n",
      "\n",
      "[24]\ttrain-rmse:2.27494\teval-rmse:2.66588                                                                              \n",
      "\n",
      "[25]\ttrain-rmse:2.24507\teval-rmse:2.70049                                                                              \n",
      "\n",
      "[26]\ttrain-rmse:2.21265\teval-rmse:2.70953                                                                              \n",
      "\n",
      "[27]\ttrain-rmse:2.19526\teval-rmse:2.70194                                                                              \n",
      "\n",
      "[28]\ttrain-rmse:2.16695\teval-rmse:2.71652                                                                              \n",
      "\n",
      "[29]\ttrain-rmse:2.15252\teval-rmse:2.71505                                                                              \n",
      "\n",
      "Stopping. Best iteration:                                                                                              \n",
      "[9]\ttrain-rmse:2.65614\teval-rmse:2.57432\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loss: 77839243.17302002                                                                                                \n",
      "100%|████████████████████████████████████████████████| 250/250 [1:45:04<00:00, 24.40s/it, best loss: 57440721.44144043]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 2.8578608885510106e-05,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'eta': 0.375,\n",
       " 'gamma': 1.626902660420816e-05,\n",
       " 'lambda': 0.9604127545221981,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 2.029792498237964,\n",
       " 'n_estimators': 374.0,\n",
       " 'subsample': 0.9500000000000001}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "\n",
    "    evals = [(d_train_sales, 'train'), (d_val_sales, 'eval')]\n",
    "    evals_result = {}\n",
    "\n",
    "    model = xgb.train(params, \n",
    "              d_train_sales, \n",
    "              num_boost_round=1000, \n",
    "              evals=evals,\n",
    "              early_stopping_rounds=20,\n",
    "              evals_result=evals_result)\n",
    "    \n",
    "    d_pred = np.exp(model.predict(d_val))\n",
    "    loss = mean_squared_error(d_pred, df_val_Y['Cost'].values)\n",
    "    print(f'loss: {loss}')\n",
    "    return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "def optimize(random_state=71):\n",
    "    \n",
    "    space = {\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 1000, 1),\n",
    "        'learning_rate': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "        'max_depth':  hp.choice('max_depth', np.arange(3, 10, dtype=int)),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', np.log(0.1), np.log(10)),\n",
    "        'subsample': hp.quniform('subsample', 0.6, 0.95, 0.05),\n",
    "        'gamma': hp.loguniform('gamma', np.log(1e-8), np.log(1.0)),\n",
    "        'colsample_bytree': hp.quniform('colsample_bytree', 0.6, 0.95, 0.05),\n",
    "        'alpha': hp.loguniform('alpha', np.log(1e-8), np.log(1.0)),\n",
    "        'lambda': hp.loguniform('lambda', np.log(1e-6), np.log(10.0)),\n",
    "        'nthread': 4,\n",
    "        'seed': random_state\n",
    "    }\n",
    "    best = fmin(score, space, \n",
    "                algo=tpe.suggest, \n",
    "                max_evals=250)\n",
    "    return best\n",
    "optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.49476\teval-rmse:5.2374\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 20 rounds.\n",
      "[1]\ttrain-rmse:4.28208\teval-rmse:3.83962\n",
      "[2]\ttrain-rmse:3.67622\teval-rmse:3.10084\n",
      "[3]\ttrain-rmse:3.39705\teval-rmse:2.74351\n",
      "[4]\ttrain-rmse:3.25776\teval-rmse:2.58746\n",
      "[5]\ttrain-rmse:3.18402\teval-rmse:2.51802\n",
      "[6]\ttrain-rmse:3.14293\teval-rmse:2.49965\n",
      "[7]\ttrain-rmse:3.1193\teval-rmse:2.49439\n",
      "[8]\ttrain-rmse:3.0944\teval-rmse:2.48602\n",
      "[9]\ttrain-rmse:3.07496\teval-rmse:2.48181\n",
      "[10]\ttrain-rmse:3.05335\teval-rmse:2.49961\n",
      "[11]\ttrain-rmse:3.04342\teval-rmse:2.49619\n",
      "[12]\ttrain-rmse:3.0311\teval-rmse:2.51679\n",
      "[13]\ttrain-rmse:3.01386\teval-rmse:2.52773\n",
      "[14]\ttrain-rmse:3.00021\teval-rmse:2.52377\n",
      "[15]\ttrain-rmse:2.99226\teval-rmse:2.53072\n",
      "[16]\ttrain-rmse:2.98497\teval-rmse:2.52792\n",
      "[17]\ttrain-rmse:2.97035\teval-rmse:2.52227\n",
      "[18]\ttrain-rmse:2.95893\teval-rmse:2.52765\n",
      "[19]\ttrain-rmse:2.95288\teval-rmse:2.53353\n",
      "[20]\ttrain-rmse:2.94773\teval-rmse:2.53324\n",
      "[21]\ttrain-rmse:2.94137\teval-rmse:2.53261\n",
      "[22]\ttrain-rmse:2.93357\teval-rmse:2.52849\n",
      "[23]\ttrain-rmse:2.92103\teval-rmse:2.52848\n",
      "[24]\ttrain-rmse:2.90759\teval-rmse:2.52071\n",
      "[25]\ttrain-rmse:2.90092\teval-rmse:2.53339\n",
      "[26]\ttrain-rmse:2.89304\teval-rmse:2.53032\n",
      "[27]\ttrain-rmse:2.88315\teval-rmse:2.53575\n",
      "[28]\ttrain-rmse:2.87312\teval-rmse:2.53844\n",
      "[29]\ttrain-rmse:2.86191\teval-rmse:2.54902\n",
      "Stopping. Best iteration:\n",
      "[9]\ttrain-rmse:3.07496\teval-rmse:2.48181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1500,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_jobs': -1,\n",
    "    'reg_alpha': 10,\n",
    "    'reg_lambda':10,\n",
    "}\n",
    "\n",
    "params = {'alpha': 2.8578608885510106e-05,\n",
    " 'colsample_bytree': 0.9,\n",
    " 'eta': 0.375,\n",
    " 'gamma': 1.626902660420816e-05,\n",
    " 'lambda': 0.9604127545221981,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 2.029792498237964,\n",
    " 'n_estimators': 374.0,\n",
    " 'subsample': 0.9500000000000001}\n",
    "\n",
    "evals = [(d_train_sales, 'train'), (d_val_sales, 'eval')]\n",
    "evals_result = {}\n",
    "\n",
    "model = xgb.train(params, \n",
    "          d_train_sales, \n",
    "          num_boost_round=1000, \n",
    "          evals=evals,\n",
    "          early_stopping_rounds=20,\n",
    "          evals_result=evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_metric = evals_result['train']['rmse']\n",
    "plt.plot(train_metric, label='train rmse')\n",
    "eval_metric = evals_result['eval']['rmse']\n",
    "plt.plot(eval_metric, label='eval rmse')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel('rounds')\n",
    "plt.ylabel('rmse')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_pred_log = model.predict(d_val)\n",
    "d_pred = np.exp(d_pred_log)\n",
    "\n",
    "#plt.plot(d_pred)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(df_val_Y['Cost'].values, label='real')\n",
    "plt.plot(d_pred, label='pred')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x2160 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax = plt.subplots(figsize=(15,30))\n",
    "xgb.plot_importance(model, ax=ax, importance_type='gain')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cost_0',\n",
       " 'Clicks_0',\n",
       " 'Cost_1',\n",
       " 'Impressions_0',\n",
       " 'Clicks_1',\n",
       " 'Impressions_1',\n",
       " 'Cost_2',\n",
       " 'Audience_0',\n",
       " 'Audience_1',\n",
       " 'Impressions_2',\n",
       " 'Clicks_2',\n",
       " 'Clicks_6',\n",
       " 'Audience_2',\n",
       " 'Audience_6',\n",
       " 'Audience_3',\n",
       " 'Audience_5',\n",
       " 'Clicks_5',\n",
       " 'Clicks_3',\n",
       " 'Audience_4',\n",
       " 'CampaignId',\n",
       " 'OverallCompetitionWin_6',\n",
       " 'CpcBid_6',\n",
       " 'CpcBid_Y',\n",
       " 'AdvertiserId',\n",
       " 'UnitsRent_2',\n",
       " 'Reach_5',\n",
       " 'UnitsRent_3',\n",
       " 'MarketId',\n",
       " 'OverallCompetitionWin_5',\n",
       " 'CpcBid_5',\n",
       " 'Reach_6',\n",
       " 'UnitsRent_1',\n",
       " 'Impressions_5',\n",
       " 'UnitsRent_0',\n",
       " 'OverallCompetitionWin_4',\n",
       " 'Reach_4',\n",
       " 'Impressions_4',\n",
       " 'Clicks_4',\n",
       " 'UnitsRent_6',\n",
       " 'Impressions_6',\n",
       " 'CpcBid_2',\n",
       " 'CpcBid_0',\n",
       " 'Reach_0',\n",
       " 'UnitsRent_4',\n",
       " 'CpcBid_4',\n",
       " 'OverallCompetitionWin_0',\n",
       " 'Reach_1',\n",
       " 'OverallCompetitionWin_2',\n",
       " 'OverallCompetitionWin_1',\n",
       " 'Cost_3',\n",
       " 'OverallCompetitionWin_3',\n",
       " 'CpcBid_3',\n",
       " 'Reach_3',\n",
       " 'UnitsRyutsu_2',\n",
       " 'CpcBid_1',\n",
       " 'CategoryId',\n",
       " 'Cost_6',\n",
       " 'Impressions_3',\n",
       " 'Reach_2',\n",
       " 'UnitsRent_5',\n",
       " 'Cost_4',\n",
       " 'Cost_5',\n",
       " 'UnitsRyutsu_6',\n",
       " 'UnitsRyutsu_4',\n",
       " 'UnitsMansionKen_2',\n",
       " 'SalesRent_4',\n",
       " 'SalesRent_0',\n",
       " 'SalesKodateBkn_4',\n",
       " 'SalesKodateBkn_2',\n",
       " 'UnitsKodateBkn_2']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = model.get_score(importance_type='gain')\n",
    "sorted(m, key=lambda x: m[x], reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
